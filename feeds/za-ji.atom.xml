<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Aiki's Blog - 雑記</title><link href="/" rel="alternate"></link><link href="/feeds/za-ji.atom.xml" rel="self"></link><id>/</id><updated>2020-09-07T10:00:00+09:00</updated><entry><title>自由工作(3)</title><link href="/zi-you-gong-zuo-3.html" rel="alternate"></link><published>2020-09-07T10:00:00+09:00</published><updated>2020-09-07T10:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-09-07:/zi-you-gong-zuo-3.html</id><summary type="html">&lt;p&gt;しばらく夏休みしてた。作業再開。エンコード作成中。
ADPCMの音質改善にはノイズシェーピング（量子化ノイズ）をへらすのが有効らしい。特許に注意だけど切れてそう。&lt;/p&gt;
&lt;p&gt;休んでいる間に色々リンク見つけたからまとめてからねる。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/dbry/adpcm-xq"&gt;adpcm-xq&lt;/a&gt; WavPackの人のADPCM(IMA)の改良エンコーダ。いいアイデアが2つ。ノイズシェーピングと先読みエンコード。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://sericyb.com.au/audio.html"&gt;A comparison of Internet audio compression formats&lt;/a&gt; 音質比較&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://hydrogenaud.io/index.php?topic=109270.0"&gt;What quality measurement is best for (A)DPCM?&lt;/a&gt; ADPCMの評価指標について&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.kumikomi.net/archives/2010/07/ep22onse.php?page=5"&gt;G.726 ADPCMエンコーダの詳細&lt;/a&gt; 本と同じ内容だけど、こっちはいつでも見れる。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.jstage.jst.go.jp/article/isciesci/61/2/61_76/_pdf/-char/en"&gt;信号品質を保つディジタル化技術: ノイズシェーピング量子化—I&lt;/a&gt; ノイズシェーピングの基礎。Ⅵまである。丁寧。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://kamedo2.hatenablog.jp/entry/20100812/1281640220"&gt;ADPCM音質改善&lt;/a&gt; 重要。ノイズシェーピングの効果について書いてある …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;しばらく夏休みしてた。作業再開。エンコード作成中。
ADPCMの音質改善にはノイズシェーピング（量子化ノイズ）をへらすのが有効らしい。特許に注意だけど切れてそう。&lt;/p&gt;
&lt;p&gt;休んでいる間に色々リンク見つけたからまとめてからねる。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/dbry/adpcm-xq"&gt;adpcm-xq&lt;/a&gt; WavPackの人のADPCM(IMA)の改良エンコーダ。いいアイデアが2つ。ノイズシェーピングと先読みエンコード。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://sericyb.com.au/audio.html"&gt;A comparison of Internet audio compression formats&lt;/a&gt; 音質比較&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://hydrogenaud.io/index.php?topic=109270.0"&gt;What quality measurement is best for (A)DPCM?&lt;/a&gt; ADPCMの評価指標について&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.kumikomi.net/archives/2010/07/ep22onse.php?page=5"&gt;G.726 ADPCMエンコーダの詳細&lt;/a&gt; 本と同じ内容だけど、こっちはいつでも見れる。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.jstage.jst.go.jp/article/isciesci/61/2/61_76/_pdf/-char/en"&gt;信号品質を保つディジタル化技術: ノイズシェーピング量子化—I&lt;/a&gt; ノイズシェーピングの基礎。Ⅵまである。丁寧。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://kamedo2.hatenablog.jp/entry/20100812/1281640220"&gt;ADPCM音質改善&lt;/a&gt; 重要。ノイズシェーピングの効果について書いてある。ソースもある。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.a-r-tec.jp/DSADC2.pdf"&gt;ADCの動作原理&lt;/a&gt; ADCとノイズシェーピングの必要性がわかりやすく書いてある。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://kobaweb.ei.st.gunma-u.ac.jp/lecture/DSM_San_2008_pt02[1].pdf"&gt;AD変調器(2)&lt;/a&gt; こちらもADCとノイズシェーピングについて記述有り。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://graphics.stanford.edu/~seander/bithacks.html"&gt;Bit Twiddling Hacks&lt;/a&gt; Hacker's Delightに掲載されてないのもある。&lt;/li&gt;
&lt;/ul&gt;
</content><category term="雑記"></category><category term="ADPCM"></category></entry><entry><title>自由工作(2)</title><link href="/zi-you-gong-zuo-2.html" rel="alternate"></link><published>2020-08-31T10:00:00+09:00</published><updated>2020-08-31T10:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-08-31:/zi-you-gong-zuo-2.html</id><summary type="html">&lt;p&gt;ADPCMのデコードはほぼできた。次はエンコード。&lt;/p&gt;
&lt;p&gt;いろんなソース見とるが、予測時に分岐しまくるのやばくね？とおもってたらそのとおりで、ffmpeg実装は乗算を使ってる:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.ffmpeg.org/doxygen/trunk/adpcm_8c_source.html"&gt;ffmpegの実装（adpcm_ima_expand_nibble）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://ffmpeg.org/doxygen/trunk/adpcmenc_8c_source.html"&gt;ffmpegのエンコーダ実装(adpcm_ima_compress_sample)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="kr"&gt;inline&lt;/span&gt; &lt;span class="kt"&gt;int16_t&lt;/span&gt; &lt;span class="nf"&gt;adpcm_ima_expand_nibble&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ADPCMChannelStatus&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int8_t&lt;/span&gt; &lt;span class="n"&gt;nibble&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;shift&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;step_index&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;predictor&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;sign&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;delta&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;diff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ff_adpcm_step_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;step_index&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="n"&gt;step_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;step_index&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;ff_adpcm_index_table&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="kt"&gt;unsigned&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;nibble&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="n"&gt;step_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;av_clip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step_index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;88&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

    &lt;span class="n"&gt;sign&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nibble&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;delta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nibble&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="mi"&gt;7 …&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;ADPCMのデコードはほぼできた。次はエンコード。&lt;/p&gt;
&lt;p&gt;いろんなソース見とるが、予測時に分岐しまくるのやばくね？とおもってたらそのとおりで、ffmpeg実装は乗算を使ってる:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.ffmpeg.org/doxygen/trunk/adpcm_8c_source.html"&gt;ffmpegの実装（adpcm_ima_expand_nibble）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://ffmpeg.org/doxygen/trunk/adpcmenc_8c_source.html"&gt;ffmpegのエンコーダ実装(adpcm_ima_compress_sample)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="kr"&gt;inline&lt;/span&gt; &lt;span class="kt"&gt;int16_t&lt;/span&gt; &lt;span class="nf"&gt;adpcm_ima_expand_nibble&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ADPCMChannelStatus&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int8_t&lt;/span&gt; &lt;span class="n"&gt;nibble&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;shift&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;step_index&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;predictor&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;sign&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;delta&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;diff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ff_adpcm_step_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;step_index&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="n"&gt;step_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;step_index&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;ff_adpcm_index_table&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="kt"&gt;unsigned&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;nibble&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="n"&gt;step_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;av_clip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step_index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;88&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

    &lt;span class="n"&gt;sign&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nibble&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;delta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nibble&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="cm"&gt;/* perform direct multiplication instead of series of jumps proposed by&lt;/span&gt;
&lt;span class="cm"&gt;     * the reference ADPCM implementation since modern CPUs can do the mults&lt;/span&gt;
&lt;span class="cm"&gt;     * quickly enough */&lt;/span&gt;
    &lt;span class="n"&gt;diff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;delta&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;shift&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;predictor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;predictor&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sign&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;predictor&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;diff&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;predictor&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;diff&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;predictor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;av_clip_int16&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictor&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;step_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;step_index&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int16_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;predictor&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="kr"&gt;inline&lt;/span&gt; &lt;span class="kt"&gt;uint8_t&lt;/span&gt; &lt;span class="nf"&gt;adpcm_ima_compress_sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ADPCMChannelStatus&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                &lt;span class="kt"&gt;int16_t&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;delta&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;prev_sample&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;nibble&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;FFMIN&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;delta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;
                       &lt;span class="n"&gt;ff_adpcm_step_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;step_index&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;delta&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;prev_sample&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;ff_adpcm_step_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;step_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
                        &lt;span class="n"&gt;ff_adpcm_yamaha_difflookup&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;nibble&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;prev_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;av_clip_int16&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;prev_sample&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;step_index&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;av_clip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;step_index&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;ff_adpcm_index_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;nibble&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;88&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;nibble&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;nibbleってなんだよ・・・って思って調べたら1/2バイト(4bit)のことだった。&lt;/p&gt;
&lt;p&gt;デコーダ作って安定させてたら、AudacityとffmpegのADPCM(IMA)のデコード結果が違うことに気付く。
原因は、Audacityを始めとした多くのコーデックでは分岐が多い近似実装になっているからだった。 &lt;a class="reference external" href="http://web.mit.edu/ghudson/dev/nokrb/third/audiofile/libaudiofile/modules/adpcm.c"&gt;こいつ&lt;/a&gt; が原因か。
一方、ffmpegは近頃のCPUは十分乗算が早いからと言う理由で厳密計算している。ということで自分も厳密計算を選ぶ。&lt;/p&gt;
&lt;p&gt;もう一点、AudacityにADPCM(IMA)を突っ込むと末尾が伸びてしまう。これは末尾のブロックも同一サンプル数でデコードしているから…。
あきらかな不具合。PR送るか、送らざるべきか…。&lt;/p&gt;
&lt;p&gt;Audacityは内部でlibsndfileを使ってるから、 &lt;a class="reference external" href="https://github.com/erikd/libsndfile/blob/master/src/ima_adpcm.c"&gt;こっち&lt;/a&gt; にPRを送るべき。&lt;/p&gt;
</content><category term="雑記"></category><category term="ADPCM"></category></entry><entry><title>自由工作(1)</title><link href="/zi-you-gong-zuo-1.html" rel="alternate"></link><published>2020-08-29T10:00:00+09:00</published><updated>2020-08-29T10:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-08-29:/zi-you-gong-zuo-1.html</id><summary type="html">&lt;p&gt;まずはIMA-ADPCM互換のデコーダ/エンコーダを作ってみますかね。かなり情報あるし。
FFMPEGで出力する方法は:&lt;/p&gt;
&lt;p&gt;ffmpeg -i &amp;lt;input.wav&amp;gt; -f wav -acodec adpcm_ima_wav &amp;lt;output.wav&amp;gt;&lt;/p&gt;
&lt;p&gt;Macで再生もできた。ほぼ1/4になる。理論的には1/4だけどwavに余計なチャンクが入っているから減っている？&lt;/p&gt;
&lt;p&gt;ステレオ以上はどうなってるのか見ている。インターリーブしているようだ。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiki.multimedia.cx/index.php?title=Microsoft_IMA_ADPCM"&gt;Microsoft IMA ADPCM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上記のサイト含めてフォーマットをまとめると（ &lt;strong&gt;全て&lt;/strong&gt; リトルエンディアン）&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="25%" /&gt;
&lt;col width="12%" /&gt;
&lt;col width="63%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;名前&lt;/th&gt;
&lt;th class="head"&gt;サイズ[byte]&lt;/th&gt;
&lt;th class="head"&gt;内容&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;RIFFチャンクID&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;'R', 'I', 'F', 'F'&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;RIFFチャンクサイズ&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;ファイルサイズ - 8（これ以降の残りファイルサイズ）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;ファイルフォーマットタイプ&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;'W', 'A', 'V', 'E'&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;FMTチャンクID&lt;/td&gt;
&lt;td&gt;4 …&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;</summary><content type="html">&lt;p&gt;まずはIMA-ADPCM互換のデコーダ/エンコーダを作ってみますかね。かなり情報あるし。
FFMPEGで出力する方法は:&lt;/p&gt;
&lt;p&gt;ffmpeg -i &amp;lt;input.wav&amp;gt; -f wav -acodec adpcm_ima_wav &amp;lt;output.wav&amp;gt;&lt;/p&gt;
&lt;p&gt;Macで再生もできた。ほぼ1/4になる。理論的には1/4だけどwavに余計なチャンクが入っているから減っている？&lt;/p&gt;
&lt;p&gt;ステレオ以上はどうなってるのか見ている。インターリーブしているようだ。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiki.multimedia.cx/index.php?title=Microsoft_IMA_ADPCM"&gt;Microsoft IMA ADPCM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上記のサイト含めてフォーマットをまとめると（ &lt;strong&gt;全て&lt;/strong&gt; リトルエンディアン）&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="25%" /&gt;
&lt;col width="12%" /&gt;
&lt;col width="63%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;名前&lt;/th&gt;
&lt;th class="head"&gt;サイズ[byte]&lt;/th&gt;
&lt;th class="head"&gt;内容&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;RIFFチャンクID&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;'R', 'I', 'F', 'F'&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;RIFFチャンクサイズ&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;ファイルサイズ - 8（これ以降の残りファイルサイズ）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;ファイルフォーマットタイプ&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;'W', 'A', 'V', 'E'&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;FMTチャンクID&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;'f', 'm', 't', ' '&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;FMTチャンクサイズ&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;これ以降のFMTフィールドのサイズ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;WAVEフォーマットタイプ&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;IMA-ADPCMなら17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;チャンネル数&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;IMA-ADPCMの場合は1（モノラル）か2（ステレオ）しかないっぽい&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;サンプリングレート&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;データ速度（byte/sec）&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;= ブロックサイズ * サンプリングレート / ブロックあたりサンプル数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;ブロックサイズ&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;ブロックのヘッダと圧縮済みデータを含めたサイズ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;サンプルあたりビット数&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;IMA-ADPCMなら4のはず&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;エキストラサイズ&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;これ以降に続く追加データサイズ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;ブロックあたりサンプル数&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;FACTチャンクID&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;'f', 'a', 'c', 't'&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;FACTチャンクサイズ&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;これ以降のFACTチャンクサイズ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;サンプル数&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;= DATAチャンクサイズ * ブロックあたりサンプル数 / ブロックサイズ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;DATAチャンクID&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;'d', 'a', 't', 'a'&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;DATAチャンクサイズ&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;これ以降のDATAチャンクサイズ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;圧縮済みデータ&lt;/td&gt;
&lt;td&gt;※&lt;/td&gt;
&lt;td&gt;※ = DATAチャンクサイズ&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</content><category term="雑記"></category><category term="ADPCM"></category></entry><entry><title>自由工作</title><link href="/zi-you-gong-zuo.html" rel="alternate"></link><published>2020-08-28T10:00:00+09:00</published><updated>2020-08-28T10:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-08-28:/zi-you-gong-zuo.html</id><summary type="html">&lt;p&gt;発表会終わり。発表準備と並行して群論やってた。
夏休みは自由工作（息抜き）としてADPCMエンコーダデコーダ作ろうかと思ってる。
もちろん、群論（リー群まで）と情報幾何（統計的応用まで、行間のまとめ）は進める。&lt;/p&gt;
&lt;p&gt;ADPCMのフォーマットを見ている。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://forum.audacityteam.org/viewtopic.php?t=10950"&gt;IMA ADPCM vs MS ADPCM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiki.multimedia.cx/index.php/Microsoft_ADPCM"&gt;Microsoft ADPCM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiki.multimedia.cx/index.php/IMA_ADPCM"&gt;IMA ADPCM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiki.multimedia.cx/index.php/CRI_ADX_ADPCM"&gt;CRI ADX ADPCM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.cs.columbia.edu/~hgs/audio/dvi/IMA_ADPCM.pdf"&gt;Recommended Practices for Enhancing Digital Audio Compatibility in Multimedia Systems&lt;/a&gt; IMA公式の推奨規格。実装も掲載されてて有益。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MS-ADPCMかIMA-ADPCMやなあ。IMA-ADPCMの方が説明が充実している。
そして、なんとなくステップ幅をテーブル引きするところにTAKとの類似点を感じる。
G.726もありだがテーブル引きを使ってない。説明は「音声&amp;amp;画像処理の常識」に書いてある。&lt;/p&gt;
&lt;p&gt;研究としてはグラフィカルLASSOの導入忘れずに。もう一度張っとく。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://ide-research.net/papers/2016_Iwanami_Ide.pdf"&gt;依存関係にスハ …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;発表会終わり。発表準備と並行して群論やってた。
夏休みは自由工作（息抜き）としてADPCMエンコーダデコーダ作ろうかと思ってる。
もちろん、群論（リー群まで）と情報幾何（統計的応用まで、行間のまとめ）は進める。&lt;/p&gt;
&lt;p&gt;ADPCMのフォーマットを見ている。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://forum.audacityteam.org/viewtopic.php?t=10950"&gt;IMA ADPCM vs MS ADPCM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiki.multimedia.cx/index.php/Microsoft_ADPCM"&gt;Microsoft ADPCM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiki.multimedia.cx/index.php/IMA_ADPCM"&gt;IMA ADPCM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiki.multimedia.cx/index.php/CRI_ADX_ADPCM"&gt;CRI ADX ADPCM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.cs.columbia.edu/~hgs/audio/dvi/IMA_ADPCM.pdf"&gt;Recommended Practices for Enhancing Digital Audio Compatibility in Multimedia Systems&lt;/a&gt; IMA公式の推奨規格。実装も掲載されてて有益。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MS-ADPCMかIMA-ADPCMやなあ。IMA-ADPCMの方が説明が充実している。
そして、なんとなくステップ幅をテーブル引きするところにTAKとの類似点を感じる。
G.726もありだがテーブル引きを使ってない。説明は「音声&amp;amp;画像処理の常識」に書いてある。&lt;/p&gt;
&lt;p&gt;研究としてはグラフィカルLASSOの導入忘れずに。もう一度張っとく。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://ide-research.net/papers/2016_Iwanami_Ide.pdf"&gt;依存関係にスパース性を入れる — グラフィカル lasso の話&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content><category term="雑記"></category><category term="ADPCM"></category></entry><entry><title>研究会に向けて - 執筆(5)</title><link href="/yan-jiu-hui-nixiang-kete-zhi-bi-5.html" rel="alternate"></link><published>2020-08-03T10:00:00+09:00</published><updated>2020-08-03T10:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-08-03:/yan-jiu-hui-nixiang-kete-zhi-bi-5.html</id><content type="html">&lt;p&gt;自己相関行列の逆の推定、グラフィカルLASSOが有効ではというありがたい指摘あり。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://ide-research.net/papers/2016_Iwanami_Ide.pdf"&gt;依存関係にスパース性を入れる — グラフィカル lasso の話&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;他にも精度行列の推定を（スパース制約を入れて）高速にやるみたいな話がたくさん出てきている。参考にすべし。&lt;/p&gt;
</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>IGおべんきょ(4)</title><link href="/igobenkiyo4.html" rel="alternate"></link><published>2020-08-01T10:00:00+09:00</published><updated>2020-08-01T10:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-08-01:/igobenkiyo4.html</id><summary type="html">&lt;p&gt;しばらくIGをおべんきょしてた。行間メモは公開していきたい。
で、いまはChentsovの定理で絶賛ハマってる。(0,4)-テンソル場で定数倍にならない理由って何よ。&lt;/p&gt;
&lt;p&gt;証明の1ステップと言ったらラベルに対する付替えで、
4次元以上で起こる特殊なこと…を調べていて、群論が関わってくるのでは。と。
ラベルの付替えは対称群に相当するはず。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://orz107orz.hatenablog.com/entry/20140218/1392724434"&gt;交代群が非可換になること&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.tsuyama-ct.ac.jp/matsuda/eBooks/galios.pdf"&gt;ガロア理論を理解しよう&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;でももっと単純に考えるべきかも。 &lt;span class="math"&gt;\(F\)&lt;/span&gt; は当然計算できる上で、 &lt;span class="math"&gt;\(\~{F}\)&lt;/span&gt; も不変性の要求を満たす。
でも &lt;span class="math"&gt;\(\~{F}\)&lt;/span&gt; は &lt;span class="math"&gt;\(F\)&lt;/span&gt; の定数倍にならない、みたいな論法。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768 …&lt;/script&gt;</summary><content type="html">&lt;p&gt;しばらくIGをおべんきょしてた。行間メモは公開していきたい。
で、いまはChentsovの定理で絶賛ハマってる。(0,4)-テンソル場で定数倍にならない理由って何よ。&lt;/p&gt;
&lt;p&gt;証明の1ステップと言ったらラベルに対する付替えで、
4次元以上で起こる特殊なこと…を調べていて、群論が関わってくるのでは。と。
ラベルの付替えは対称群に相当するはず。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://orz107orz.hatenablog.com/entry/20140218/1392724434"&gt;交代群が非可換になること&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.tsuyama-ct.ac.jp/matsuda/eBooks/galios.pdf"&gt;ガロア理論を理解しよう&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;でももっと単純に考えるべきかも。 &lt;span class="math"&gt;\(F\)&lt;/span&gt; は当然計算できる上で、 &lt;span class="math"&gt;\(\~{F}\)&lt;/span&gt; も不変性の要求を満たす。
でも &lt;span class="math"&gt;\(\~{F}\)&lt;/span&gt; は &lt;span class="math"&gt;\(F\)&lt;/span&gt; の定数倍にならない、みたいな論法。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="IG"></category></entry><entry><title>IGおべんきょ(3)</title><link href="/igobenkiyo3.html" rel="alternate"></link><published>2020-07-30T10:00:00+09:00</published><updated>2020-07-30T10:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-30:/igobenkiyo3.html</id><content type="html">&lt;p&gt;IGがだいぶ止まってたので、レビューが帰るまでのあいだ進める。
今日の合言葉：写像の微分は接ベクトルの写像。&lt;/p&gt;
</content><category term="雑記"></category><category term="IG"></category></entry><entry><title>研究会に向けて - 執筆(4)</title><link href="/yan-jiu-hui-nixiang-kete-zhi-bi-4.html" rel="alternate"></link><published>2020-07-28T11:00:00+09:00</published><updated>2020-07-28T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-28:/yan-jiu-hui-nixiang-kete-zhi-bi-4.html</id><content type="html">&lt;p&gt;引き続き執筆。今日あたりであらすじ書いてレビュー予定。&lt;/p&gt;
&lt;p&gt;思ったのが、先にデータの自己相関行列の逆を計算して勾配計算用のデータを用意しちゃう発想はどうよ？という点。
もしくは、自己相関（の偏り）を打ち消すようなフィルタを先にかけてからフィルタ処理をおこなうのはどうか？演算誤差が気になるけど、ありえる発想。
これはもしかしたらプリエンファシスの一般化かもしれない。&lt;/p&gt;
</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて - 執筆(3)</title><link href="/yan-jiu-hui-nixiang-kete-zhi-bi-3.html" rel="alternate"></link><published>2020-07-26T11:00:00+09:00</published><updated>2020-07-26T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-26:/yan-jiu-hui-nixiang-kete-zhi-bi-3.html</id><content type="html">&lt;p&gt;土日は黙々と執筆してた。
1点気になったのが、自然勾配法を共役勾配法的にやれないかというところ。そうすれば逆行列を計算しなくて済む。
ここらへん誰かやってないのかな？誰でも思いつくと思うけど。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://edisciplinas.usp.br/pluginfile.php/227194/mod_resource/content/1/Nascimento_Silva_2014_Adaptive_Filters.pdf"&gt;Adaptive Filters&lt;/a&gt; 適応フィルタの新しい良さげなまとめ。&lt;/li&gt;
&lt;/ul&gt;
</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて - 執筆(2)</title><link href="/yan-jiu-hui-nixiang-kete-zhi-bi-2.html" rel="alternate"></link><published>2020-07-24T11:00:00+09:00</published><updated>2020-07-24T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-24:/yan-jiu-hui-nixiang-kete-zhi-bi-2.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\inprod[2]{\langle #1,\ #2 \rangle}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;うーん、SAの原典を探ってるときに&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://read.pudn.com/downloads125/ebook/529634/Adaptive_Filtering_-_Algorithms_and_Practical_Implementation.pdf"&gt;Adaptive Filtering: Algorithms and Practical Implementation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;が参照されてて、その中で&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www02.smt.ufrj.br/~diniz/conf/confi12.pdf"&gt;Performance of LMS-Newton Adaptation Algorithms With Variable Convergence Factor in Nonstationary Environments&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;が参照されてたけど、全く同じやん…&lt;/p&gt;
&lt;p&gt;どうも、Winner解を求める最適化問題のニュートン法を求めると、自己相関行列の逆が自然に出てくるみたい。そして、その適応ステップ版アルゴリズム（LMS Newton Algorithm, 初出はAdaptive Signal …&lt;/p&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\inprod[2]{\langle #1,\ #2 \rangle}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;うーん、SAの原典を探ってるときに&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://read.pudn.com/downloads125/ebook/529634/Adaptive_Filtering_-_Algorithms_and_Practical_Implementation.pdf"&gt;Adaptive Filtering: Algorithms and Practical Implementation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;が参照されてて、その中で&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www02.smt.ufrj.br/~diniz/conf/confi12.pdf"&gt;Performance of LMS-Newton Adaptation Algorithms With Variable Convergence Factor in Nonstationary Environments&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;が参照されてたけど、全く同じやん…&lt;/p&gt;
&lt;p&gt;どうも、Winner解を求める最適化問題のニュートン法を求めると、自己相関行列の逆が自然に出てくるみたい。そして、その適応ステップ版アルゴリズム（LMS Newton Algorithm, 初出はAdaptive Signal Processing(Widrow)）は上記論文と完全に同一。&lt;/p&gt;
&lt;p&gt;LMS Newton Algorithmは、Adaptive Signal Processingのp142あたり（Chapter8冒頭）が詳しいが、残差の二乗を目的関数（Adaptive Filter Theory p105 2.38, 2.50に注目）としたときのニュートン法を近似して得られる。導出にあたり勾配を近似（確率降下）することでNewton法が成立している。&lt;/p&gt;
&lt;p&gt;適応ステップサイズの設定法には他にもある。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.jstage.jst.go.jp/article/ieejeiss1987/119/8-9/119_8-9_1027/_pdf/-char/ja"&gt;準最適ステップゲインを用いたBlock LMS-Newtonアルゴリズム&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;これはLMS Newton Algorithmに関する話だけど、ここで提案されているやり方をSAに持っていけないか？→ブロック単位で更新しているから話が違う？いや、もうちょっと読み込もう。&lt;ul&gt;
&lt;li&gt;この論文で可変ステップサイズに関する議論が出てきている。最適係数から垂線を下ろしたところでステップサイズを決めるという方針。それにしたがってNGSAにおいても最適なステップサイズを求めたら今までのNNGSAと同一の結果が出た。&lt;/li&gt;
&lt;li&gt;勾配 &lt;span class="math"&gt;\(\ve{g}[n] = \mathrm{sgn}(\varepsilon[n])\ve{x}[n]\)&lt;/span&gt; に対して &lt;span class="math"&gt;\(\inprod{\ve{R}^{-1}\ve{g}[n]}{\ve{h}_{\rm opt} - (\ve{h}[n] + \mu[n] \ve{R}^{-1} \ve{g}[n])}_{\ve{R}} = 0\)&lt;/span&gt; を満たす &lt;span class="math"&gt;\(\mu[n]\)&lt;/span&gt; こそ、勾配のなす方向に対して &lt;span class="math"&gt;\(\ve{h}_{\rm opt}\)&lt;/span&gt; から垂線を降ろせているから最適になる。直交条件を展開すると、 &lt;span class="math"&gt;\(\ve{g}[n]^{\mathsf{T}} \ve{R}^{-1} \ve{R} (\ve{h}_{opt} - \ve{h}[n]) - \mu[n] \ve{g}[n]^{\mathsf{T}} \ve{R}^{-1} \ve{R} \ve{R}^{-1} \ve{g}[n] = 0\)&lt;/span&gt; で、 &lt;span class="math"&gt;\(\ve{g}[n] = \mathrm{sgn}(\varepsilon[n])\ve{x}[n]\)&lt;/span&gt; を突っ込むと &lt;span class="math"&gt;\(\mathrm{sgn}(\varepsilon[n]) \ve{x}[n]^{\mathsf{T}} (\ve{h}_{\rm opt} - \ve{h}[n]) - \mu[n] \ve{x}[n]^{\mathsf{T}} \ve{R}^{-1} \ve{x}[n] = \mathrm{sgn}(\varepsilon[n]) \varepsilon[n] + \mathrm{sgn}(\varepsilon[n]) v[n] - \mu[n] \ve{x}[n]^{\mathsf{T}} \ve{R}^{-1} \ve{x}[n] = 0\)&lt;/span&gt; より、&lt;span class="math"&gt;\(v[n]=0\)&lt;/span&gt; ならばいつものステップサイズが出てくる。論文間違ってると思う。。。&lt;/li&gt;
&lt;li&gt;つまり、NNGSAはその意味でも最適。追記すべきかも。しかし、勾配 &lt;span class="math"&gt;\(\ve{g}[n]\)&lt;/span&gt; がLMSのときとの差異が気になる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;有益そうなのは、ブロックあたり1回だけ逆行列補題を使うだけでもよいという主張（問題ないことを示している）。つまり自己相関行列の更新を間引く。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.academia.edu/14148013/Performance_of_LMS-Newton_adaptation_algorithms_with_variable_convergence_factor_in_nonstationary_environments"&gt;Analysis of LMS-Newton Adaptive Filtering Algorithms with Variable Convergence Factor&lt;/a&gt; Academaから落とした。&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Newton LMS AlgorithmはRLSと等価。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.academia.edu/17820650/Optimal_variable_step_size_for_the_LMS_Newton_algorithm_with_application_to_subband_adaptive_filtering?auto=download"&gt;Optimal variable step size for the LMS/Newton algorithm with application to subband adaptive filtering&lt;/a&gt; これもAcademiaから&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;でも、NNGSAまで至らないと上記の一致は指摘できない。また、こっちはFisher情報行列ベースで話を進めているから、射影の足がKLダイバージェンスに一致することを議論できる。&lt;/p&gt;
&lt;p&gt;あ、でもNGSAは残差のsgnとってるだけだから、LMS Newton Algorithmのステップサイズを荒く量子化したやつに対応するのか。いや、それでも、ラプラス分布仮定時に最急勾配になってるはずなんや。最適値近傍で頑張って0に近づけるし、しかも遠いときはゆっくり近づいてロングテールな分布を作っているんや。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://core.ac.uk/download/pdf/52288867.pdf"&gt;Adaptive filters: stable but divergent&lt;/a&gt; なんか適応フィルタのまとめ。時間があれば。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SAの収束性能解析論文がヒットし始めた&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Adaptive Filtering with Binary Reinforcement とても重要な論文。SAの限界について基本的な定理が述べられている。そして、SAはLMSより遅いという指摘あり。これが欲しかった。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://pdfs.semanticscholar.org/fe70/e6867138651ac95130ec53cebc2ba8b7ecab.pdf?_ga=2.105956032.2125347977.1595579214-2033161310.1595579214"&gt;CONVERGENCE ANALYSIS OF THE SIGN ALGORITHM FOR ADAPTIVE FILTERING&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて - 執筆(1)</title><link href="/yan-jiu-hui-nixiang-kete-zhi-bi-1.html" rel="alternate"></link><published>2020-07-22T11:00:00+09:00</published><updated>2020-07-22T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-22:/yan-jiu-hui-nixiang-kete-zhi-bi-1.html</id><summary type="html">&lt;p&gt;今日から執筆していく。目標、7/27に第一般。&lt;/p&gt;
&lt;p&gt;しかしまだ書き始めず、プロットを練る。プロットの構成はだいたい発表とおんなじだが、
イントロをしっかり書きたいから、既存のロスレス音声の論文の構成を参考にしていく。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.cs.tut.fi/~tabus/2013GhidoTabus.pdf"&gt;Sparse modeling for lossless audio compression&lt;/a&gt; OptimFROGのひと。&lt;ul&gt;
&lt;li&gt;オーディオ環境は高級化している。その中でロスレス圧縮は現実的である。プレーヤが使うから、デコーダは高速実装できるべきだ。今現在使われているいろんなコーデックがある。MP4-ALS, WMAL, ALAC, Monkey's Audio, FLAC, OptimFROG等。それぞれ異なる予測モデルと圧縮アルゴリズムを使用している。圧縮率、エンコード速度、デコード速度の3つの評価軸があるが、全てを最大にすることはできず、トレードオフの関係にある。例えば、予測次数を最大にすれば圧縮率は向上するが、エンコード/デコード速度が悪化する。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://decoy.iki.fi/dsound/ambisonic/motherlode/source/01215233.pdf"&gt;An Introduction to Super Audio CD and DVD-Audio&lt;/a&gt; Super Audio CD(SACD …&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;今日から執筆していく。目標、7/27に第一般。&lt;/p&gt;
&lt;p&gt;しかしまだ書き始めず、プロットを練る。プロットの構成はだいたい発表とおんなじだが、
イントロをしっかり書きたいから、既存のロスレス音声の論文の構成を参考にしていく。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.cs.tut.fi/~tabus/2013GhidoTabus.pdf"&gt;Sparse modeling for lossless audio compression&lt;/a&gt; OptimFROGのひと。&lt;ul&gt;
&lt;li&gt;オーディオ環境は高級化している。その中でロスレス圧縮は現実的である。プレーヤが使うから、デコーダは高速実装できるべきだ。今現在使われているいろんなコーデックがある。MP4-ALS, WMAL, ALAC, Monkey's Audio, FLAC, OptimFROG等。それぞれ異なる予測モデルと圧縮アルゴリズムを使用している。圧縮率、エンコード速度、デコード速度の3つの評価軸があるが、全てを最大にすることはできず、トレードオフの関係にある。例えば、予測次数を最大にすれば圧縮率は向上するが、エンコード/デコード速度が悪化する。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://decoy.iki.fi/dsound/ambisonic/motherlode/source/01215233.pdf"&gt;An Introduction to Super Audio CD and DVD-Audio&lt;/a&gt; Super Audio CD(SACD)なんてあったのか…すでに死んでるが…。OptimFROGでは高級なオーディオの規格として挙げていた。&lt;/li&gt;
&lt;li&gt;A hierarchical lossless/lossy coding system for high quality audio up to 192 kHz sampling 24 bit format: 公開されてない...&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.kecl.ntt.co.jp/people/harada.noboru/doc/thesis_noboru_harada_201630173_final.pdf"&gt;Lossless Compression of Speech and Audio Signals, and Its Application&lt;/a&gt; NTTの原田さんの博論。成果は符号化メイン。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://mi.eng.cam.ac.uk/reports/svr-ftp/auto-pdf/robinson_tr156.pdf"&gt;SHORTEN: Simple lossless and near-lossless waveform compression&lt;/a&gt; シンプルで宜しい。うざったるい背景描写ほとんどなし。&lt;ul&gt;
&lt;li&gt;デジタル化した音声ファイルをそのまま保存するとかなりの容量を食う。ZIP等の一般的な圧縮アルゴリズムは、音声の特徴を捉えていないからうまく圧縮できない。一般的な音声データは16bitで、サンプル間に相関がある。これらのファイルに対する圧縮ユーティリティは高速で、移植性があり、多くのデータを処理可能で素晴らしい圧縮率を達成する必要がある。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.jas-audio.or.jp/jas_cms/wp-content/uploads/2017/03/201703_027-033.pdf"&gt;国際標準 MPEG-4 ALS による ハイレゾ音源ロスレス伝送&lt;/a&gt; MPEG4-ALSの分かりやすい説明。飾り言葉がおおいので注意。（「コト」や「モノ」の下りは使えない）&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://elvera.nue.tu-berlin.de/files/1216Liebchen2009.pdf"&gt;MPEG­4 ALS – The Standard for Lossless Audio Coding&lt;/a&gt; MPEG4-ALSのもうちょっと分かりやすい説明。厚すぎず手軽で良い。&lt;ul&gt;
&lt;li&gt;ロッシー符号化は編集やアーカイビングに向かない。歪みを生む。MP3やAACを知覚符号化と言っていた。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://pdfs.semanticscholar.org/7991/abe1173b7ad06b23d5a51d7e5b5092b2f201.pdf"&gt;予測誤差の Golomb-Rice 符号量を最小化する線形予測分析&lt;/a&gt; これは遊びが無くて良いように見える。というかこれ引用するだろうし、しっかり参考にすべき。&lt;ul&gt;
&lt;li&gt;やはりバックグラウンドにロスレス音声は使える。うまく話を作ろう。&lt;/li&gt;
&lt;li&gt;「最小絶対値推定量がロバスト推定量で あることから線形予測分析に基づく音声分析の耐雑音 性能を向上する目的として応用されている」もよいアイデア。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.eie.polyu.edu.hk/~enyhchan/ce_ac_p1.pdf"&gt;Lossless compression of digital audio&lt;/a&gt; 今の発表につながる概観書。基礎は変わってない。&lt;ul&gt;
&lt;li&gt;デジタル配信で重要な役割を果たす、ミキシングを高い忠実性を保てる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://cs.joensuu.fi/sipu/pub/RLS-LMS_TIP2008.pdf"&gt;Cascaded RLS–LMS Prediction in MPEG-4 Lossless Audio Coding&lt;/a&gt; MPEG4にカスケード接続したLMS+RLSを突っ込むと3%程圧縮率がよくなるという話。MPEG4-ALSも適応フィルタを使っているので、引用する必要はある。そらそうよ。負荷大丈夫か。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;既存研究調査&lt;/h2&gt;
&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\end{equation*}
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;1回ざっと目を通した論文&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.452.7280&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;Natural Gradient Works Efficiently in Learning&lt;/a&gt; LMS界隈からの引用多数。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www2.ee.ic.ac.uk/publications/p3943.pdf"&gt;Adaptive algorithms for sparse echo cancellation&lt;/a&gt; 俯瞰した背景描写もある。&lt;ul&gt;
&lt;li&gt;PNLMSに偏っているか。古い。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://iiav.org/ijav/content/volumes/21_2016_590031458046128/vol_1/835_fullpaper_1207561458214850.pdf"&gt;Review and Comparison of Variable Step-Size LMS Algorithms&lt;/a&gt; 適応ステップサイズ手法の比較。2015年。&lt;ul&gt;
&lt;li&gt;比較について多くの手法を3つの応用例から見ている。結論はNLMSが最高ということだったけど、比較過程については要注目。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://pdfs.semanticscholar.org/bf3b/fe757d9156cc863ffdde15b1664c337819bd.pdf"&gt;Proportionate Normalized Least-Mean-Squares Adaptation in Echo Cancelers&lt;/a&gt; 頻繁に参照されるPNLMS。係数の絶対値をその最大値で正規化した値を対角要素に持つ対角行列をフィッシャー情報行列の逆行列とする。&lt;ul&gt;
&lt;li&gt;NLMSと比較。DSP実装して実ノイズで試してもいる。理論的解析（定常雑音に対する収束レート解析）もしている。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://scholarsmine.mst.edu/cgi/viewcontent.cgi?article=2780&amp;amp;context=ele_comeng_facwork"&gt;Normalized Natural Gradient Adaptive Filtering for Sparse and Nonsparse Systems&lt;/a&gt; フィッシャー情報行列を対角行列で与えている。&lt;ul&gt;
&lt;li&gt;まさに自然勾配をがっつり使う論文。絶対参照すべき。対角行列を計量にしたINLMSを導入し、スパース係数（1つだけ1.0で他全部0）ではPNLMSに負けたけど、非スパース係数（全部1）ではPNLMSよりも結果が良いとか言ってる。&lt;/li&gt;
&lt;li&gt;シミュレーション節が短すぎ。システム同定をやったらしいがよく分からん。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.eurasip.org/Proceedings/Eusipco/Eusipco2017/papers/1570346064.pdf"&gt;Full Proportionate Functional Link Adaptive Filters for Nonlinear Acoustic Echo Cancellation&lt;/a&gt; これも。謎のリーマン計量を作る。&lt;ul&gt;
&lt;li&gt;比較データの生成が恣意的すぎるので無し。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.907.849&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;New Sparse Adaptive Algorithms Based on the Natural Gradient and the l0-Norm&lt;/a&gt; これも謎のリーマン計量を使っている…。損失関数に計量が入っちゃってるけどいいのか？→大丈夫っぽい。損失関数の設計は自由。&lt;ul&gt;
&lt;li&gt;応用が特殊すぎる。オレオレデータセットに対して有効性を示されても困る。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arl.nus.edu.sg/twiki6/pub/ARL/BibEntries/Konstantinos_-_2011_-_Natural_Gradient-Based_Adaptive_Algorithms_For_Spa.pdf"&gt;NATURAL GRADIENT-BASED ADAPTIVE ALGORITHMS FOR SPARSE UNDERWATER ACOUSTIC CHANNEL IDENTIFICATION&lt;/a&gt; L0ノルム最小化に自然勾配法をあわせた。とある。やけに性能が良い。&lt;ul&gt;
&lt;li&gt;↑と著者が同じ。データセットも同じ。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1303.2261.pdf"&gt;l0 Norm Constraint LMS Algorithm for Sparse System Identification&lt;/a&gt; 係数l0ノルム最小化。l0ノルムをexpで近似して解析的最小化。&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;この論文で相関のあるガウス雑音の作り方が明確に示されている。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;ITU-Tのデータを使ってるのは参考になった、&lt;/li&gt;
&lt;li&gt;が、スパースなデータの作り方が恣意的すぎる。。。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1311.5242.pdf"&gt;AN IMPROVED VARIABLE STEP-SIZE AFFINE PROJECTION SIGN ALGORITHM FOR ECHO CANCELLATION&lt;/a&gt; &lt;strong&gt;これが一番近いかも。&lt;/strong&gt; なんでここまできて自然勾配に至らないのか？こいつの引用を漁ったけど同一の研究なし。&lt;ul&gt;
&lt;li&gt;謎の手順（ガウス雑音に1次のIIRフィルタを通して、しかもベルヌーイ試行で出力判定する）で入力を生成している。よくあるのか？？？&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://asl.epfl.ch/wp-content/uploads/publications/journal_articles/spl_feb_2004_b.pdf"&gt;Variable Step-Size NLMS and Affine Projection Algorithms&lt;/a&gt; これもそれなりに近い。affine projection algorithm で情報行列の逆を使っている。&lt;ul&gt;
&lt;li&gt;移動平均フィルタを理想フィルタにしている。ガウス雑音に謎の2次IIRフィルタを通したものをリファレンスとしている…。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1110.2907.pdf"&gt;System Identification Using Reweighted Zero Attracting Least Absolute Deviation Algorithms&lt;/a&gt; ZA-LADの原典。自分のやっている研究に近いかも。残差L1ノルム最小化はロバストだいう主張。&lt;ul&gt;
&lt;li&gt;スパースなときに有利であることを言いたいらしい。&lt;/li&gt;
&lt;li&gt;16タップの係数を使い、最初のXXXXイテレーションでは5番目のタップだけ1（他全部0）、次に奇数タップをすべて1にしてYYYYイテレーション、最後に偶数タップを-1にしてZZZZイテレーション。。。&lt;ul&gt;
&lt;li&gt;ノイズとして非ガウス的（α-stableと言っていた）なものを使用。SNRはGeneralized SNRという尺度を使用。&lt;/li&gt;
&lt;li&gt;他に、白色ガウス雑音に1次のフィルタを通して入力していた。出力に相関をもたせる意図か。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1311.6809.pdf"&gt;A Novel Family of Adaptive Filtering Algorithms Based on The Logarithmic Cost&lt;/a&gt; LLADの原典。&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;これのデータよい。採用。&lt;/strong&gt; 単純明快。(理論ばっかりで分かりにくいと思っていたが）&lt;ul&gt;
&lt;li&gt;リファレンス信号 &lt;span class="math"&gt;\(d_{t} = \ve{w}_{0}^{\mathsf{T}} \ve{x}_{t} + n_{t}\)&lt;/span&gt; で、 &lt;span class="math"&gt;\(\ve{w}_{0}\)&lt;/span&gt; はリファレンス係数（論文ではランダム選択にしていた。スパースじゃないならいいかも。）、 &lt;span class="math"&gt;\(\ve{x}_{t}\)&lt;/span&gt; は分散 &lt;span class="math"&gt;\(\sigma_{x}^{2} = 1\)&lt;/span&gt; の i.i.d な平均0ガウス信号系列、 &lt;span class="math"&gt;\(n_{t}\)&lt;/span&gt; はノイズ信号（分散0.01のガウス雑音と分散10000(偏差100)で一定確率(1,2,5%)で発生するインパルス雑音）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;一定確率でインパルス雑音が発生するケースはロバスト性を示すために使われていた。LMSは全く等化できずにいた。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://gr.xjtu.edu.cn/c/document_library/get_file?folderId=1540809&amp;amp;name=DLFE-38423.pdf"&gt;Sparse Least Logarithmic Absolute Difference Algorithm with Correntropy-Induced Metric Penalty&lt;/a&gt; 重みによくわからないペナルティを付加したSigned LMS。&lt;ul&gt;
&lt;li&gt;これもしかしたら重要かもしれない。ちゃんと書けてる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Convergence Analysis of Zero Attracting Natural Gradient Non-Parametric Maximum Likelihood Algorithm これ読めないんだけどAbstract読み限り相当やってそう。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下、日本語論文&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.jstage.jst.go.jp/article/jasj/50/1/50_KJ00001456848/_pdf/-char/ja"&gt;音響エコー経路の変動特性を反映させたRLS適応アルゴリズム&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.tara.tsukuba.ac.jp/~maki/reprint/Makino/sm92ieice9-20.pdf"&gt;室内インパルス応答の統計的性質に基づく指数重み付けLMSフィルタ&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;実験としては微妙で、理論と一致しているかどうかの議論で終わっている。比較実験なし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.cepstrum.co.jp/rd/nlms/nlms_txt.pdf"&gt;エコーキャンセラ向けのNormalizedLMSアルゴリズムの改良&lt;/a&gt; 社内発表資料？&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://leo.ec.t.kanazawa-u.ac.jp/staffs/nakayama/pub/file/dsp_symp03_dougahara.pdf"&gt;適応フィルタにおけるブロック形重み付けステップサイズの制御法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://ir.lib.u-ryukyu.ac.jp/bitstream/20.500.12000/1487/1/No59p107.pdf"&gt;直交ECLMSアルゴリズムを用いたエコーキャンセラーの設計&lt;/a&gt; ダブルトーク問題も入ってきちゃってる。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.topic.ad.jp/sice/htdocs/papers/242/242-3.pdf"&gt;エコーキャンセラにおける適応アルゴリズムとダブルトーク検出の関係&lt;/a&gt; これもダブルトーク問題。しっかしNLMSとの比較のみ。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;比較対象にすべき手法&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;NLMS, Signed-LMS, RLS&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://pdfs.semanticscholar.org/bf3b/fe757d9156cc863ffdde15b1664c337819bd.pdf"&gt;PNLMS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;IPNLMS(Improved PNLMS)&lt;/li&gt;
&lt;li&gt;APA(Affine Projection Algorithm)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;比較対象にすべきデータ&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;発話音声（ソースがない...）&lt;/li&gt;
&lt;li&gt;理想係数に入力として単位インパルス（雑音源よりもレベルの小さいノイズもあり）をXXXX回繰り返し入れ続け（途中で理想係数を急に変える）、同時にレベルを決めた雑音源を入力。&lt;ul&gt;
&lt;li&gt;シードのみを変えて、XXX回独立した試行を行ってその平均を（残差トレンドの平均も）とる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ITU G.168のエコーパスモデル&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.itu.int/ITU-T/recommendations/rec.aspx?rec=12451&amp;amp;lang=en"&gt;公式&lt;/a&gt; から資料入手可能。&lt;/li&gt;
&lt;li&gt;Annex Dに8つのエコーインパルスのデータが乗っかっている。5番目のインパルスがスパースだから良いらしい。&lt;/li&gt;
&lt;li&gt;また、リファレンスの波形にフィルタを通して使うらしい。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ほぼ0で、ランダムに選んだいくつかの係数だけが1になっているリファレンスフィルタの出力
* 入力例1: ガウス雑音に1次（極が1つの）のIIRを通し、さらにベルヌーイ過程として、一定確率pでノイズ、1-pで0となる信号
* 入力例2: ガウス雑音に2次のIIRを通す&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h3&gt;比較基準&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;2乗誤差(misalignmentとか行ったりする)[dB]&lt;/li&gt;
&lt;li&gt;計算量（畳み込み、係数更新における乗算+加算回数）&lt;/li&gt;
&lt;li&gt;定常状態での係数の分散&lt;/li&gt;
&lt;li&gt;理想係数との誤差MSE（MSD(Mean Square Deviationとも言う。Simonの本から来てると思われる)。もし計算できるなら。正規化してdB表示する: &lt;span class="math"&gt;\(10 \log_{10} ( ||h - \hat{h}|| / ||h|| )\)&lt;/span&gt; ）&lt;/li&gt;
&lt;li&gt;定常状態でのMSE&lt;/li&gt;
&lt;li&gt;MSEの和（全実験での）&lt;/li&gt;
&lt;li&gt;可変ステップサイズアルゴリズムの場合は、ステップサイズの変化&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h3&gt;思ったこと&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;ブロック線図を書くと良さそう？多くの論文が書いてる。エコーキャンセラーのアーキテクチャは示すべきか。&lt;/li&gt;
&lt;li&gt;提案手法はウィーナー解に収束するか？&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://onsen-mula.org/wp-content/uploads/2017/04/inoue.pdf"&gt;ロバスト適応同定手法によるエコーキャンセラの設計&lt;/a&gt; ここにウィーナー解との関連がある&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.bode.amp.i.kyoto-u.ac.jp/~kashima/lecture/ss/slide17_8.pdf"&gt;信号とシステム&lt;/a&gt; ここにもそれなりにある。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;音響データベースがある...&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.nii.ac.jp/dsc/idr/speech/submit/RWCP-SSD.html"&gt;6. RWCP 実環境音声・音響データベース (RWCP-SSD)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sign アルゴリズムの概観については、以下もどっかで見ておきたい。&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.jstage.jst.go.jp/article/essfr/8/4/8_292/_pdf/-char/ja"&gt;再考・適応アルゴリズム&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;実は自然勾配法による適応アルゴリズムは非線形適応アルゴリズムになってる？&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.ykw.elec.keio.ac.jp/yukawa/yukawa_tutorial2014.pdf"&gt;非線形適応信号処理技術の新潮流 ──再生核の応用──&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(17) - 中間発表</title><link href="/yan-jiu-hui-nixiang-kete17-zhong-jian-fa-biao.html" rel="alternate"></link><published>2020-07-20T11:00:00+09:00</published><updated>2020-07-20T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-20:/yan-jiu-hui-nixiang-kete17-zhong-jian-fa-biao.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;資料に追い込みを掛けていたので、あまり進捗なし。発表してもらったコメントで大きそうなのをメモる。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;SA、実はヘブ則そのものでは？&lt;ul&gt;
&lt;li&gt;全くその通り。識別タスクにしたらまんまそれ。NN的に見ると〜はヘブ則と言ってもいいくらい。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;グラフは正方形にすべし。&lt;ul&gt;
&lt;li&gt;全くその通り。すぐに修正するべし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;尤度は独立な観測では不完全。独立同分布な(i.i.d.)な観測や&lt;/li&gt;
&lt;li&gt;NNGSAの最適化問題による定式化ってリッジ回帰に似てる。対角行列を計量にしてる。&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathrm{E}\left[ \left\{ \frac{\mathrm{sgn}(\varepsilon[n])}{\sigma} \right\}^{2} \ve{x}[n] \ve{x}[n]^{\mathsf{T}} \right …&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;資料に追い込みを掛けていたので、あまり進捗なし。発表してもらったコメントで大きそうなのをメモる。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;SA、実はヘブ則そのものでは？&lt;ul&gt;
&lt;li&gt;全くその通り。識別タスクにしたらまんまそれ。NN的に見ると〜はヘブ則と言ってもいいくらい。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;グラフは正方形にすべし。&lt;ul&gt;
&lt;li&gt;全くその通り。すぐに修正するべし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;尤度は独立な観測では不完全。独立同分布な(i.i.d.)な観測や&lt;/li&gt;
&lt;li&gt;NNGSAの最適化問題による定式化ってリッジ回帰に似てる。対角行列を計量にしてる。&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathrm{E}\left[ \left\{ \frac{\mathrm{sgn}(\varepsilon[n])}{\sigma} \right\}^{2} \ve{x}[n] \ve{x}[n]^{\mathsf{T}} \right] = \frac{1}{\sigma^{2}} \mathrm{E} \left[ \ve{x}[n] \ve{x}[n]^{\mathsf{T}} \right]\)&lt;/span&gt; はほんまか？a.e.では？近似では？ &lt;span class="math"&gt;\(\mathrm{E}\)&lt;/span&gt; だから厳密？&lt;ul&gt;
&lt;li&gt;やっぱり要審査。自分は期待値操作でルベーグ積分するから、測度0の点は抜いても大丈夫だと思っている。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;厳密にいけそう。&lt;/strong&gt; &lt;span class="math"&gt;\(\mathrm{sgn}(x) := \frac{x}{|x|}\)&lt;/span&gt; と定義すると、 &lt;span class="math"&gt;\((\mathrm{sgn}(x))^{2} = \frac{x^{2}}{|x|^{2}} = 1\)&lt;/span&gt; 。 &lt;span class="math"&gt;\(x=0\)&lt;/span&gt; のときが怪しくなるが、これは、 &lt;span class="math"&gt;\(\mathrm{sgn}(x) \approx \frac{x}{\sqrt{x^{2} + \varepsilon}}\)&lt;/span&gt; としてやって（ &lt;span class="math"&gt;\(\varepsilon \to 0\)&lt;/span&gt; とすれば符号関数に一致）、 &lt;span class="math"&gt;\((\mathrm{sgn}(x))^{2} \approx \frac{x^{2}}{x^{2} + \varepsilon}\)&lt;/span&gt; で、 &lt;span class="math"&gt;\(\varepsilon \to 0\)&lt;/span&gt; としてやれば恒等的に1になる。多分、近似を使ったやり方のほうが &lt;span class="math"&gt;\(x=0\)&lt;/span&gt; でややこしくならないから筋がいい。&lt;/li&gt;
&lt;li&gt;答えとしては、 &lt;span class="math"&gt;\(\mathrm{sgn}(x) := \lim_{\varepsilon \to 0} \frac{x}{\sqrt{x^{2} + \varepsilon}}\)&lt;/span&gt; がいいかも。&lt;/li&gt;
&lt;li&gt;いや、まだ怪しい… &lt;span class="math"&gt;\(\mathrm{sgn}(0) = 0\)&lt;/span&gt; という定義だから、絶対 &lt;span class="math"&gt;\((\mathrm{sgn}(0))^{2} = 0\)&lt;/span&gt; になる。積分を絡めて考えないとだめか。至るところ1なんだけど、1点 &lt;span class="math"&gt;\(x=0\)&lt;/span&gt; において &lt;span class="math"&gt;\(0\)&lt;/span&gt; を取る関数の平均。。。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;グラフのitaration → iteration&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\ve{R}^{-1}\)&lt;/span&gt; の計算について。&lt;ul&gt;
&lt;li&gt;低ランク近似、とくに、 &lt;span class="math"&gt;\(n\)&lt;/span&gt; 重対角行列で近似できん？→確かに。相関行列は端っこに近づくほど0になっていくから、有効かも。&lt;/li&gt;
&lt;li&gt;DFTしてなだらかに変化する要素（つまり低域信号）のパワーは切り捨てる近似がオッケーだったりしないか。→まったくそのとおり、&lt;span class="math"&gt;\(\ve{R}\)&lt;/span&gt; をDFTすると、ウィーナ・ヒンチンが顔を出しそう。&lt;/li&gt;
&lt;li&gt;スレ―ビングというらしい。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;（所感）残差がガウス分布に従うとしたLMS ←ちょっと突然すぎる。&lt;ul&gt;
&lt;li&gt;LMS（残差がガウス分布に従う）は… ←こっちのほうがいい。むしろ、ガウス分布の話はいらない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;損失関数はReLuにしても良いのでは→あり。でもどうなるんだろう。&lt;/li&gt;
&lt;/ul&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(16)</title><link href="/yan-jiu-hui-nixiang-kete16.html" rel="alternate"></link><published>2020-07-14T11:00:00+09:00</published><updated>2020-07-14T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-14:/yan-jiu-hui-nixiang-kete16.html</id><content type="html">&lt;p&gt;引き続き資料を作っている。&lt;/p&gt;
&lt;p&gt;昨日気になっていた&lt;/p&gt;
&lt;blockquote&gt;
NNGSAの収束する最適係数はWienner解で間違いないのか検証する必要あり。&lt;/blockquote&gt;
&lt;p&gt;は並行して確認中。直交原理（勾配が0になる解）を満たす解はWienner解に一致するのか？というところ。
怪しいかもしれない。適応ステップサイズがミソで、最適係数時、そいつを含めて平均をとったときにゼロになるとは思えない。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://towardsdatascience.com/natural-gradient-ce454b3dcdfa"&gt;Natural Gradient A better gradient for gradient descent?&lt;/a&gt; 面白そうだけどちとタイミングが悪い。&lt;/li&gt;
&lt;/ul&gt;
</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(15)</title><link href="/yan-jiu-hui-nixiang-kete15.html" rel="alternate"></link><published>2020-07-13T11:00:00+09:00</published><updated>2020-07-13T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-13:/yan-jiu-hui-nixiang-kete15.html</id><content type="html">&lt;p&gt;淡々と資料を作っている。
NNGSAの収束する最適係数はWienner解で間違いないのか検証する必要あり。&lt;/p&gt;
</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(14)</title><link href="/yan-jiu-hui-nixiang-kete14.html" rel="alternate"></link><published>2020-07-12T11:00:00+09:00</published><updated>2020-07-12T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-12:/yan-jiu-hui-nixiang-kete14.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand{\parfrac}[2]{{\frac{\partial #1}{\partial #2}}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;今日から発表資料作る。久々にBeamerでやろうかね。&lt;/p&gt;
&lt;p&gt;資料作ってたら、ラグランジュ未定乗数法による定式化で &lt;span class="math"&gt;\((\ve{h} - \ve{h}^{\prime})^{\mathsf{T}}\ve{R}(\ve{h} - \ve{h}^{\prime})\)&lt;/span&gt; の最小化を考えたけど、これってレイリー商の下限すなわち最小固有値が答えでは。もうちょっと考えたくなってきた。 &lt;span class="math"&gt;\(\mu(n)\)&lt;/span&gt; は垂線の長さに対応するんだっけ？&lt;/p&gt;
&lt;p&gt;アフィン写像アルゴリズムへの拡張は、NLMSの制約を増やしたものに過ぎない。ラグランジュの未定乗数法を使って、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\mathcal{L} &amp;amp;= (\ve{h …&lt;/div&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand{\parfrac}[2]{{\frac{\partial #1}{\partial #2}}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;今日から発表資料作る。久々にBeamerでやろうかね。&lt;/p&gt;
&lt;p&gt;資料作ってたら、ラグランジュ未定乗数法による定式化で &lt;span class="math"&gt;\((\ve{h} - \ve{h}^{\prime})^{\mathsf{T}}\ve{R}(\ve{h} - \ve{h}^{\prime})\)&lt;/span&gt; の最小化を考えたけど、これってレイリー商の下限すなわち最小固有値が答えでは。もうちょっと考えたくなってきた。 &lt;span class="math"&gt;\(\mu(n)\)&lt;/span&gt; は垂線の長さに対応するんだっけ？&lt;/p&gt;
&lt;p&gt;アフィン写像アルゴリズムへの拡張は、NLMSの制約を増やしたものに過ぎない。ラグランジュの未定乗数法を使って、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\mathcal{L} &amp;amp;= (\ve{h} - \ve{h}^{\prime})^{\mathsf{T}}\ve{R}(\ve{h} - \ve{h}^{\prime}) + (\ve{d} - \ve{A}\ve{h}^{\prime})^{\mathsf{T}} \ve{\lambda} \\
\parfrac{\mathcal{L}}{\ve{h}^{\prime}} &amp;amp;= 2\ve{R}(\ve{h} - \ve{h}^{\prime}) - \parfrac{}{\ve{h}^{\prime}} \ve{h}^{\prime\mathsf{T}} \ve{A}^{\mathsf{T}} \ve{\lambda} \\
&amp;amp;= 2\ve{R}(\ve{h} - \ve{h}^{\prime}) - \ve{A}^{\mathsf{T}} \ve{\lambda} \\
\implies \ve{h}^{\prime} &amp;amp;= \ve{h} + \frac{1}{2} \ve{R}^{-1} \ve{A}^{\mathsf{T}} \ve{\lambda} \\
\implies \ve{\lambda} &amp;amp;= 2 (\ve{A} \ve{R}^{-1} \ve{A}^{\mathsf{T}})\ve{e}
\end{align*}
&lt;/div&gt;
&lt;p&gt;から、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ve{h}^{\prime} &amp;amp;= \ve{h} + \ve{R}^{-1}\ve{A}^{\mathsf{T}}(\ve{A} \ve{R}^{-1} \ve{A}^{\mathsf{T}})^{-1} \ve{e} \\
&amp;amp;= \ve{h} + \ve{R}^{-1}\ve{A}^{\mathsf{T}}(\ve{A} \ve{R}^{-1} \ve{A}^{\mathsf{T}})^{-1}(\ve{d} - \ve{A} \ve{h}) \\
&amp;amp;= \left\{ \ve{I} - \ve{R}^{-1}\ve{A}^{\mathsf{T}}(\ve{A} \ve{R}^{-1} \ve{A}^{\mathsf{T}})^{-1}\ve{A} \right\} \ve{h} + \ve{R}^{-1}\ve{A}^{\mathsf{T}}(\ve{A} \ve{R}^{-1} \ve{A}^{\mathsf{T}})\ve{d}
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\ve{P} = \ve{R}^{-1}\ve{A}^{\mathsf{T}}(\ve{A} \ve{R}^{-1} \ve{A}^{\mathsf{T}})^{-1}\ve{A}\)&lt;/span&gt; とすれば &lt;span class="math"&gt;\(\ve{P}^{2} = \ve{P}\)&lt;/span&gt; だから射影行列になっている。&lt;/p&gt;
&lt;p&gt;アルゴリズムを導いたけどあんまりいい考察は出てこない、というか、煩雑。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(13)</title><link href="/yan-jiu-hui-nixiang-kete13.html" rel="alternate"></link><published>2020-07-11T11:00:00+09:00</published><updated>2020-07-11T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-11:/yan-jiu-hui-nixiang-kete13.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;発表向けの脚本を書いてた。&lt;/p&gt;
&lt;p&gt;正規化アルゴリズムに関して、まだしたりない考察がある。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;射影先の超平面の曲率はもしかして &lt;span class="math"&gt;\(\ve{R}\)&lt;/span&gt; だったりしない？漠然とした超平面ではなく、何らかの性質がないか？&lt;ul&gt;
&lt;li&gt;これは、制約が一次式だから絶対に超平面になる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;アフィン写像アルゴリズムへ拡張するべきでは？&lt;ul&gt;
&lt;li&gt;やってみた。次の日へどうぞ。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen …&lt;/script&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;発表向けの脚本を書いてた。&lt;/p&gt;
&lt;p&gt;正規化アルゴリズムに関して、まだしたりない考察がある。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;射影先の超平面の曲率はもしかして &lt;span class="math"&gt;\(\ve{R}\)&lt;/span&gt; だったりしない？漠然とした超平面ではなく、何らかの性質がないか？&lt;ul&gt;
&lt;li&gt;これは、制約が一次式だから絶対に超平面になる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;アフィン写像アルゴリズムへ拡張するべきでは？&lt;ul&gt;
&lt;li&gt;やってみた。次の日へどうぞ。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(12)</title><link href="/yan-jiu-hui-nixiang-kete12.html" rel="alternate"></link><published>2020-07-10T11:00:00+09:00</published><updated>2020-07-10T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-10:/yan-jiu-hui-nixiang-kete12.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;発表に向けてのプロットに集中したい。また、正規化自然勾配SAが事後残差最小化ではなくラグランジュから導いて同じ結論が得られるか見たい。（もしかしたら、別の更新式が出る可能性がある）&lt;/p&gt;
&lt;p&gt;ラグランジュの結果、かなり良い解釈が得られた。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document …&lt;/script&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;発表に向けてのプロットに集中したい。また、正規化自然勾配SAが事後残差最小化ではなくラグランジュから導いて同じ結論が得られるか見たい。（もしかしたら、別の更新式が出る可能性がある）&lt;/p&gt;
&lt;p&gt;ラグランジュの結果、かなり良い解釈が得られた。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(11)</title><link href="/yan-jiu-hui-nixiang-kete11.html" rel="alternate"></link><published>2020-07-09T11:00:00+09:00</published><updated>2020-07-09T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-09:/yan-jiu-hui-nixiang-kete11.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;乗せるデータをまとめる。&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;自然勾配SA法の有効性を示す。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;人口データに対する実験: SA(ステップサイズ=0.005,0.01,0.02)と比較して収束が速いことを示す。しかし係数適応は遅いことは同時に指摘。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;正規化自然勾配SA法の有効性を示す。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;人口データに対する実験: RLS(忘却係数=1,0.9,0.99)と比較。収束は遅い場合があるが、定常誤差は小さく、また係数変更時の適応が早い。忘却係数に依存せず安定した収束性能を示す。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;自然勾配法の有効性を示す。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;実データに対する実験: 音楽の一部データに対する比較。SA, RLS(忘却係数=0.99), 正規化自然勾配SA, 自然勾配SAで比較。&lt;/li&gt;
&lt;li&gt;RMSを比較。RLSとほぼ同等の性能を達成している。&lt;/li&gt;
&lt;/ul&gt;
&lt;script type='text/javascript'&gt;if (!document …&lt;/script&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;乗せるデータをまとめる。&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;自然勾配SA法の有効性を示す。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;人口データに対する実験: SA(ステップサイズ=0.005,0.01,0.02)と比較して収束が速いことを示す。しかし係数適応は遅いことは同時に指摘。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;正規化自然勾配SA法の有効性を示す。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;人口データに対する実験: RLS(忘却係数=1,0.9,0.99)と比較。収束は遅い場合があるが、定常誤差は小さく、また係数変更時の適応が早い。忘却係数に依存せず安定した収束性能を示す。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;自然勾配法の有効性を示す。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;実データに対する実験: 音楽の一部データに対する比較。SA, RLS(忘却係数=0.99), 正規化自然勾配SA, 自然勾配SAで比較。&lt;/li&gt;
&lt;li&gt;RMSを比較。RLSとほぼ同等の性能を達成している。&lt;/li&gt;
&lt;/ul&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(10)</title><link href="/yan-jiu-hui-nixiang-kete10.html" rel="alternate"></link><published>2020-07-08T11:00:00+09:00</published><updated>2020-07-08T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-08:/yan-jiu-hui-nixiang-kete10.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;今日あたりで目処を…というか、デフォルトの自然勾配法に対する言い訳を考えておきたい。
ガチャガチャいじっていると、LMSに &lt;span class="math"&gt;\(\ve{R}^{-1}\)&lt;/span&gt; を掛けたのも強いということが分かってくる…。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{h}^{\prime} \leftarrow \ve{h} + \mu \ve{R}^{-1} \varepsilon(n) \ve{x}(n)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;何度も見てきた通りだが、上式のステップサイズを（事後誤差最小化基準により）適応化すると正規化版の式に一致する。ちなみに、LMSに対してはフィッシャー情報行列が意味のある統計量に結びつかない。Signアルゴリズムの改良から話を初めて、ステップサイズ適応化してまでたどり着くと、初めてLMS版に対応する式が導かれる。&lt;/p&gt;
&lt;p&gt;確かに上は性能が良いが、裏付けが薄く眉唾の感を逃れられない。疑似自然勾配LMSと名付けて実装しておく。名目としては …&lt;/p&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;今日あたりで目処を…というか、デフォルトの自然勾配法に対する言い訳を考えておきたい。
ガチャガチャいじっていると、LMSに &lt;span class="math"&gt;\(\ve{R}^{-1}\)&lt;/span&gt; を掛けたのも強いということが分かってくる…。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{h}^{\prime} \leftarrow \ve{h} + \mu \ve{R}^{-1} \varepsilon(n) \ve{x}(n)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;何度も見てきた通りだが、上式のステップサイズを（事後誤差最小化基準により）適応化すると正規化版の式に一致する。ちなみに、LMSに対してはフィッシャー情報行列が意味のある統計量に結びつかない。Signアルゴリズムの改良から話を初めて、ステップサイズ適応化してまでたどり着くと、初めてLMS版に対応する式が導かれる。&lt;/p&gt;
&lt;p&gt;確かに上は性能が良いが、裏付けが薄く眉唾の感を逃れられない。疑似自然勾配LMSと名付けて実装しておく。名目としては、正規化の簡略版と見れるはず。収束議論もしておきたい。&lt;/p&gt;
&lt;p&gt;と思ったら、疑似自然勾配LMSは実データですっ飛ぶ傾向あり。誤差が急上昇するところで係数が吹っ飛んでしまう。。トレードオフのようで、誤差の符号をとる（自然勾配SA）は適応が遅すぎて、残差をそのまま使う（疑似自然勾配LMS）は適応が敏感すぎてすっ飛ぶ傾向がある。正規化は本質的な働きをしているように見える。&lt;/p&gt;
&lt;p&gt;まとめようか。
勾配を観察すれば分かることだけど、やっぱり自然勾配SAは勾配が平坦になりすぎるきらいがある。どんなに最適値との差があっても同一の勾配になりやすい。
実データでは十分なサンプルが取れて、しかも特性はのんびり変化するから性能が良くなる。
忘却係数は高く取れば定常誤差を小さくできるが、1.0にすると特性追従が遅くなるので、1にほど近い0.997等に設定する。ステップサイズは実験では1.0等大きめに、実データは0.1等にとる。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(9)</title><link href="/yan-jiu-hui-nixiang-kete9.html" rel="alternate"></link><published>2020-07-07T11:00:00+09:00</published><updated>2020-07-07T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-07:/yan-jiu-hui-nixiang-kete9.html</id><summary type="html">&lt;p&gt;トイデータに対する実験をやっているが、色々と悲しい。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;自然勾配SignAlgorithmの性能が悪い。下手するとSignAlgorithmとどっこい&lt;ul&gt;
&lt;li&gt;実データに対しては良い結果を出していた。&lt;/li&gt;
&lt;li&gt;原因を調べていたら、係数の初期値が最適値の近くにあると収束が早いということが分かった。&lt;/li&gt;
&lt;li&gt;トイデータ実験は[-1,1]から一様乱数選択していたので、それだと広すぎるらしく、収束が遅い。勾配が平坦に広がりすぎている可能性がある。&lt;/li&gt;
&lt;li&gt;忘却係数を低く（ステップサイズを大きく）すると応答は良くなるけどオフセットが残る。&lt;/li&gt;
&lt;li&gt;実データはサンプル数が多いのと、係数が大きな値を取りにくいことから性能が良かったものと想像。&lt;ul&gt;
&lt;li&gt;正規化版は自己相関行列の逆行列の二次形式で割ってるから、自己相関の逆数で割ってる、即ち、自己相関を掛けてると見れる。じゃあ、簡易的に入力データのノルムの平均値を掛けてやればいいんじゃねと思ってやってみたらそれなりに安定してきた。&lt;/li&gt;
&lt;li&gt;眉唾だから再度要検証。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RLSが強すぎる。忘却係数付きRLSが一番強い。&lt;ul&gt;
&lt;li&gt;忘却係数はトレードオフという感じ。0.9まで下げると収束は早いけどオフセットが残る。0.99だと係数が変わったときに収束が遅くなる。1.0（普通のRLS）だと係数が変わったときにまったく収束していかない。&lt;/li&gt;
&lt;li&gt;正規化自然勾配SignAlgorithmは忘却係数の値によらずほぼ同じ学習曲線になる。依存するのはステップサイズくらいか。そこは主張できるかも。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NLMSもMSD（係数誤差）の意味ではRLSと同程度まで下げられているが、正規化自然勾配SignAlgorithmは収束ははやいがそこまで誤差が下がらない。&lt;/li&gt;
&lt;li&gt;実装ミスあり。係数更新がFinvの更新前に行われていた。&lt;ul&gt;
&lt;li&gt;普通の自然勾配法は大きな影響あり。あれ？でも正規化自然勾配の方はあまり影響がない。&lt;/li&gt;
&lt;li&gt;実装ミスなのか微妙 …&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;トイデータに対する実験をやっているが、色々と悲しい。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;自然勾配SignAlgorithmの性能が悪い。下手するとSignAlgorithmとどっこい&lt;ul&gt;
&lt;li&gt;実データに対しては良い結果を出していた。&lt;/li&gt;
&lt;li&gt;原因を調べていたら、係数の初期値が最適値の近くにあると収束が早いということが分かった。&lt;/li&gt;
&lt;li&gt;トイデータ実験は[-1,1]から一様乱数選択していたので、それだと広すぎるらしく、収束が遅い。勾配が平坦に広がりすぎている可能性がある。&lt;/li&gt;
&lt;li&gt;忘却係数を低く（ステップサイズを大きく）すると応答は良くなるけどオフセットが残る。&lt;/li&gt;
&lt;li&gt;実データはサンプル数が多いのと、係数が大きな値を取りにくいことから性能が良かったものと想像。&lt;ul&gt;
&lt;li&gt;正規化版は自己相関行列の逆行列の二次形式で割ってるから、自己相関の逆数で割ってる、即ち、自己相関を掛けてると見れる。じゃあ、簡易的に入力データのノルムの平均値を掛けてやればいいんじゃねと思ってやってみたらそれなりに安定してきた。&lt;/li&gt;
&lt;li&gt;眉唾だから再度要検証。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RLSが強すぎる。忘却係数付きRLSが一番強い。&lt;ul&gt;
&lt;li&gt;忘却係数はトレードオフという感じ。0.9まで下げると収束は早いけどオフセットが残る。0.99だと係数が変わったときに収束が遅くなる。1.0（普通のRLS）だと係数が変わったときにまったく収束していかない。&lt;/li&gt;
&lt;li&gt;正規化自然勾配SignAlgorithmは忘却係数の値によらずほぼ同じ学習曲線になる。依存するのはステップサイズくらいか。そこは主張できるかも。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NLMSもMSD（係数誤差）の意味ではRLSと同程度まで下げられているが、正規化自然勾配SignAlgorithmは収束ははやいがそこまで誤差が下がらない。&lt;/li&gt;
&lt;li&gt;実装ミスあり。係数更新がFinvの更新前に行われていた。&lt;ul&gt;
&lt;li&gt;普通の自然勾配法は大きな影響あり。あれ？でも正規化自然勾配の方はあまり影響がない。&lt;/li&gt;
&lt;li&gt;実装ミスなのか微妙。。負荷減らしのための方策だった（フィッシャー情報行列の逆との積を使い回せるから）&lt;/li&gt;
&lt;li&gt;性能差が顕著なのでこれはよく考えたほうが良い。アルゴリズムの整合性的にもあやしい。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(8)</title><link href="/yan-jiu-hui-nixiang-kete8.html" rel="alternate"></link><published>2020-07-06T11:00:00+09:00</published><updated>2020-07-06T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-06:/yan-jiu-hui-nixiang-kete8.html</id><summary type="html">&lt;p&gt;昨日の結果を受けて、相関があるガウス雑音信号を実験の対象にしたいと思っている。（なぜなら、現実のデータは相関があるから。そして、NLMSは相関のあるデータに弱いから。）いろんな論文で構成法が乗っていたので再調査。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1303.2261.pdf"&gt;l0 Norm Constraint LMS Algorithm for Sparse System Identification&lt;/a&gt; に明確に記述あり。v[t]をi.i.dなガウス雑音として、1次の自己回帰(Auto Regressive)フィルタ x[t] = x[t-1] * 0.8 + v[t] で信号に相関をもたせたあとに、正規化（標準偏差で割る）して分散を1にしている。有色雑音と言っていた。&lt;/p&gt;
&lt;p&gt;また、昨日の夜にモデルに係数を状態として持たせるか考えた。係数が途中で変わるケースの結果が取りにくいので。
でも、扱う側でうまく計算すればできそうなのでやめた。モデル側の実装が複雑になるのは避けたい。&lt;/p&gt;
&lt;p&gt;実験ケースを分類しよう。&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;人口データ: 観測雑音: -40dBの白色ガウス雑音、MSD …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;昨日の結果を受けて、相関があるガウス雑音信号を実験の対象にしたいと思っている。（なぜなら、現実のデータは相関があるから。そして、NLMSは相関のあるデータに弱いから。）いろんな論文で構成法が乗っていたので再調査。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1303.2261.pdf"&gt;l0 Norm Constraint LMS Algorithm for Sparse System Identification&lt;/a&gt; に明確に記述あり。v[t]をi.i.dなガウス雑音として、1次の自己回帰(Auto Regressive)フィルタ x[t] = x[t-1] * 0.8 + v[t] で信号に相関をもたせたあとに、正規化（標準偏差で割る）して分散を1にしている。有色雑音と言っていた。&lt;/p&gt;
&lt;p&gt;また、昨日の夜にモデルに係数を状態として持たせるか考えた。係数が途中で変わるケースの結果が取りにくいので。
でも、扱う側でうまく計算すればできそうなのでやめた。モデル側の実装が複雑になるのは避けたい。&lt;/p&gt;
&lt;p&gt;実験ケースを分類しよう。&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;人口データ: 観測雑音: -40dBの白色ガウス雑音、MSD（Mean Square Deviations, 係数2乗誤差）とMSE（Mean Square Error, 二乗誤差）を比較&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;入力: i.i.d.ガウス雑音、係数: 一様乱数で選択&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;主張: NLMSと同程度、RLSは収束が早い&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;入力: 相関のあるi.i.d.ガウス雑音、係数: 一様乱数で選択&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;主張: NLMSよりは早い&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;入力: 相関のあるi.i.d.ガウス雑音、係数: 一様乱数で選択、XXXXサンプル後に係数を一様乱数で変更&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;主張: 係数変更後の適応でRLSより収束が早い&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;実データに対する等価実験: MSEを比較。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;音源は著作権切れデータベースから10秒程度を切り出して使用。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;この通りにコードをまとめていく。水曜日あたりで結果が出ると◎。
人口データについてはまとまったかな。火曜日で実データ選定と実験をやっていく。&lt;/p&gt;
&lt;p&gt;「信号とシステム」にシステムを等価する際の図が描かれている。ロスレス音声ではどうなっているか、資料作りまでに要観察。&lt;/p&gt;
</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(7)</title><link href="/yan-jiu-hui-nixiang-kete7.html" rel="alternate"></link><published>2020-07-05T11:00:00+09:00</published><updated>2020-07-05T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-05:/yan-jiu-hui-nixiang-kete7.html</id><content type="html">&lt;p&gt;トイデータ対象の実験スクリプトを作ってた。で、RLSが強いことが分かった。
定常的なガウス雑音（ラプラス雑音でも！）環境下では、指数レートよりも早く最適解に入っていく。
途中で最適係数を変えると収束は他よりも鈍くなる。そこを突くべきか。
（RLSの忘却係数を0.8くらいにしないと同等にならない。）&lt;/p&gt;
&lt;p&gt;また、正規化込みの自然勾配法はNLMSと同程度の収束レートだった。ていうか性能ほぼ同じ。
→入力に強い相関をもたせる（x[t] += x[t-1] * 0.97）とNLMSの性能が大幅悪化することを確認した。
入力に相関がない場合は（自己相関行列が等方的になるので）NLMSと同等になるようだ。&lt;/p&gt;
</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(6)</title><link href="/yan-jiu-hui-nixiang-kete6.html" rel="alternate"></link><published>2020-07-04T11:00:00+09:00</published><updated>2020-07-04T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-04:/yan-jiu-hui-nixiang-kete6.html</id><content type="html">&lt;p&gt;&lt;a class="reference external" href="https://www.cs.tut.fi/~tabus/course/ASP/SGN2206LectureNew5.pdf"&gt;Lecture 5: Variants of the LMS algorithm&lt;/a&gt; を見ていたらNLMSをラグランジュ未定乗数法で求める方法があった。今までは事後残差最小化で見ていたけど、これは本質かもしれない。持ち帰って再度計算してみるべきかも。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.cs.tut.fi/~tabus/course/ASP/SGN2206LectureNew4.pdf"&gt;Lecture 4: Stochastic gradient based adaptation: Least Mean Square (LMS) Algorithm&lt;/a&gt; にHeykinの簡易まとめあり。有益。&lt;/p&gt;
&lt;p&gt;t-wadaさんのプレゼンテーションで情熱を持って話しているか？をチェックポイントにしている。 &lt;a class="reference external" href="https://www.slideshare.net/t_wada/the-only-one-big-thing-every-programmer-should-know/51"&gt;ここ&lt;/a&gt; 。 全くそのとおりだと思うので思い出しておく。&lt;/p&gt;
</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(5)</title><link href="/yan-jiu-hui-nixiang-kete5.html" rel="alternate"></link><published>2020-07-03T11:00:00+09:00</published><updated>2020-07-03T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-03:/yan-jiu-hui-nixiang-kete5.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;引き続き周辺を見るが、そろそろRLSとPNLMSの実装に入ろうかな。
トイデータの実験条件も整理したい。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1311.6809.pdf"&gt;A Novel Family of Adaptive Filtering Algorithms Based on The Logarithmic Cost&lt;/a&gt; のデータの作り方を参考にしようと思う。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;リファレンス信号 &lt;span class="math"&gt;\(d_{t} = \ve{w}_{0}^{\mathsf{T}} \ve{x}_{t} + n_{t}\)&lt;/span&gt; で、 &lt;span class="math"&gt;\(\ve{w}_{0}\)&lt;/span&gt; はリファレンス係数（論文ではランダム選択にしていた。スパースじゃないならいいかも。）、 &lt;span class="math"&gt;\(\ve{x …&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\ve[1]{\boldsymbol{#1}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;引き続き周辺を見るが、そろそろRLSとPNLMSの実装に入ろうかな。
トイデータの実験条件も整理したい。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1311.6809.pdf"&gt;A Novel Family of Adaptive Filtering Algorithms Based on The Logarithmic Cost&lt;/a&gt; のデータの作り方を参考にしようと思う。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;リファレンス信号 &lt;span class="math"&gt;\(d_{t} = \ve{w}_{0}^{\mathsf{T}} \ve{x}_{t} + n_{t}\)&lt;/span&gt; で、 &lt;span class="math"&gt;\(\ve{w}_{0}\)&lt;/span&gt; はリファレンス係数（論文ではランダム選択にしていた。スパースじゃないならいいかも。）、 &lt;span class="math"&gt;\(\ve{x}_{t}\)&lt;/span&gt; は分散 &lt;span class="math"&gt;\(\sigma_{x}^{2} = 1\)&lt;/span&gt; の i.i.d な平均0ガウス信号系列、 &lt;span class="math"&gt;\(n_{t}\)&lt;/span&gt; はノイズ信号（分散0.01のガウス雑音と分散10000(偏差100)で一定確率(1,2,5%)で発生するインパルス雑音）&lt;ul&gt;
&lt;li&gt;一定確率でインパルス雑音が発生するケースはロバスト性を示すために使われていた。LMSは全く等化できずにいた。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;念の為Simon, Heykinを見てから方針を固める。
5.7節(p285)あたりから実験の記述あり。図5.19(p287)は必要になるはず。しかし、入力はベルヌーイ列、フィルタ係数は偶対称。。。
p297あたりに誤差曲面が書いてあった。遅いケースが有るということを、たしかに自分も確認している。&lt;/p&gt;
&lt;p&gt;RLSを実装し、トイデータ向けの実験フレームワークを作ってしまうべきか。
その後にPNLMSを追加できれば良い。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(4)</title><link href="/yan-jiu-hui-nixiang-kete4.html" rel="alternate"></link><published>2020-07-02T11:00:00+09:00</published><updated>2020-07-02T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-02:/yan-jiu-hui-nixiang-kete4.html</id><content type="html">&lt;p&gt;外出したのであんまり進捗なし。周辺調査してるけど、よい（コンセンサスのとれた）比較方法ないなあ…
実音声でやるのは確定として、トイデータはどうしようか。再考・適応アルゴリズムにあるように、完全に人工のインパルス応答（指数敵減衰信号）でもいいかも。係数をスパースにするのが目的ではないし。&lt;/p&gt;
</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(3)</title><link href="/yan-jiu-hui-nixiang-kete3.html" rel="alternate"></link><published>2020-07-01T11:00:00+09:00</published><updated>2020-07-01T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-07-01:/yan-jiu-hui-nixiang-kete3.html</id><content type="html">&lt;p&gt;今日は予定を立てよう。ちょうど良いタイミングでゼミ発表も入った。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.math.titech.ac.jp/~kawahira/courses.html"&gt;Tomoki Kawahira Courses&lt;/a&gt; 東工大の教授の数学の資料集&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.math.titech.ac.jp/~kawahira/courses/kiso.html"&gt;多様体の基礎のキソ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.math.titech.ac.jp/~kawahira/courses/lebesgue.pdf"&gt;ルベーグ積分の基礎のキソ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;係数をスパースにするLMSって、そういえば更新をたまにしか行わない手法もあったな。&lt;/p&gt;
</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>IGおべんきょ(2)</title><link href="/igobenkiyo2.html" rel="alternate"></link><published>2020-06-30T11:00:00+09:00</published><updated>2020-06-30T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-06-30:/igobenkiyo2.html</id><content type="html">&lt;p&gt;学会までには3-4章が手一杯に見える。しっかし先に進みたい。Fisher情報行列の意味付けをしないといかん。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiki.helsinki.fi/pages/viewpage.action?pageId=59051195"&gt;ヘルシンキ大の幾何学講義ノート？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiki.helsinki.fi/pages/viewpage.action?pageId=59051195&amp;amp;preview=/59051195/67371372/luku3.pdf"&gt;アフィン接続について&lt;/a&gt;
- p79の座標変換則を満たすことを証明するときの切り口として参考になった&lt;/li&gt;
&lt;/ul&gt;
</content><category term="雑記"></category><category term="Information Geometry"></category></entry><entry><title>FCMの係数更新式の導出</title><link href="/fcmnoxi-shu-geng-xin-shi-nodao-chu.html" rel="alternate"></link><published>2020-06-29T17:00:00+09:00</published><updated>2020-06-29T17:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-06-29:/fcmnoxi-shu-geng-xin-shi-nodao-chu.html</id><summary type="html">&lt;p class="first last"&gt;FCMの係数更新式がすぐ出てこなくてムラムラした。&lt;/p&gt;
</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\mean[2]{\mathrm{E}_{#1} \left[ #2 \right]}
\newcommand\KL[2]{\mathrm{KL} \left[ #1 \ \middle| \middle| \ #2 \right]}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;FCMの目的関数:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
J = \sum_{i = 1}^{N} \sum_{j = 1}^{c} \mu_{ij}^{m} D_{ij}^{2}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで、 &lt;span class="math"&gt;\(N,c\)&lt;/span&gt; はそれぞれデータ数とクラスタ数、 &lt;span class="math"&gt;\(\mu_{ij}\)&lt;/span&gt; はファジイ係数で &lt;span class="math"&gt;\(i\)&lt;/span&gt; 番目のデータがクラスタ &lt;span class="math"&gt;\(j\)&lt;/span&gt; に持つ重みを示す。 &lt;span class="math"&gt;\(m \in [1, \infty)\)&lt;/span&gt; はファジイ度合いを決める係数で大きく取ればよりファジイ（曖昧さを許す）になる。 &lt;span class="math"&gt;\(m = 1\)&lt;/span&gt; のときはハードなクラスタリングになる（らしい）
。 &lt;span class="math"&gt;\(D_{ij}\)&lt;/span&gt; は &lt;span class="math"&gt;\(i\)&lt;/span&gt; 番目のデータと &lt;span class="math"&gt;\(j\)&lt;/span&gt; 番目のクラスタの中心との距離。&lt;/p&gt;
&lt;p&gt;各データの重みの総和は1になるように制約を課す。式で書くと&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\sum_{j = 1}^{c} \mu_{ij} = 1 \quad i = 1, ..., N
\end{equation*}
&lt;/div&gt;
&lt;p&gt;この制約条件下でのラグランジュ関数（ラグランジアン） &lt;span class="math"&gt;\(L\)&lt;/span&gt; は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
L = \sum_{i = 1}^{N} \sum_{j = 1}^{c} \mu_{ij}^{m} D_{ij}^{2} + \sum_{i = 1}^{N} \lambda_{i} \left[ 1 - \sum_{j = 1}^{c} \mu_{ij} \right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となる。偏微分して0とおき、最適条件を求めることを考える。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\parfrac{L}{\mu_{ij}} &amp;amp;= m \mu_{ij}^{m-1} D_{ij}^{2} - \lambda_{j} = 0 \tag{1} \\
\parfrac{L}{\lambda_{i}} &amp;amp;= 1 - \sum_{j = 1}^{c} \mu_{ij} = 0 \tag{2}
\end{align*}
&lt;/div&gt;
&lt;p&gt;より、まず(1)式から &lt;span class="math"&gt;\(\mu_{ij}\)&lt;/span&gt; について解くと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\mu_{ij} = \left( \frac{\lambda_{i}}{mD_{ij}^{2}} \right)^{\frac{1}{m-1}} = \lambda_{i}^{\frac{1}{m-1}} \left( \frac{1}{mD_{ij}^{2}} \right)^{\frac{1}{m-1}} \tag{3}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;これを(2)式に代入すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
1 &amp;amp;= \sum_{j=1}^{c} \mu_{ij} = \sum_{j=1}^{c} \left( \frac{\lambda_{i}}{mD_{ij}^{2}} \right)^{\frac{1}{m-1}} \\
&amp;amp;= \lambda_{i}^{\frac{1}{m-1}} \sum_{j=1}^{c} \left( \frac{1}{mD_{ij}^{2}} \right)^{\frac{1}{m-1}} \\
\implies \lambda_{i}^{\frac{1}{m-1}} &amp;amp;= \frac{1}{\sum_{j=1}^{c} \left( \frac{1}{mD_{ij}^{2}} \right)^{\frac{1}{m-1}}}
\end{align*}
&lt;/div&gt;
&lt;p&gt;これを(3)式に代入すれば、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\mu_{ij} &amp;amp;= \lambda_{i}^{\frac{1}{m-1}} \left( \frac{1}{mD_{ij}^{2}} \right)^{\frac{1}{m-1}} = \frac{1}{\sum_{k=1}^{c} \left( \frac{1}{mD_{ik}^{2}} \right)^{\frac{1}{m-1}}} \left( \frac{1}{mD_{ij}^{2}} \right)^{\frac{1}{m-1}} \\
&amp;amp;= \frac{1}{\sum_{k=1}^{c} \left( \frac{1}{mD_{ik}^{2}} \right)^{\frac{1}{m-1}} \left( \frac{1}{mD_{ij}^{2}} \right)^{-\frac{1}{m-1}}} = \frac{1}{\sum_{k=1}^{c} \left( \frac{mD_{ij}^{2}}{mD_{ik}^{2}} \right)^{\frac{1}{m-1}}} \\
&amp;amp;= \frac{1}{\sum_{k=1}^{c} \left( \frac{D_{ij}}{D_{ik}} \right)^{\frac{2}{m-1}}}
\end{align*}
&lt;/div&gt;
&lt;p&gt;最後が気持ちよかった（小並感）&lt;/p&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;参考文献&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://fuzzy.cs.ovgu.de/ci/fs/fs_ch09_clustering.pdf"&gt;Fuzzy Systems Fuzzy Clustering 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://homes.di.unimi.it/~valentini/SlideCorsi/Bioinformatica05/Fuzzy-Clustering-lecture-Babuska.pdf"&gt;4 FUZZY CLUSTERING&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="Fuzzy Clustering"></category></entry><entry><title>IGおべんきょ(1)</title><link href="/igobenkiyo1.html" rel="alternate"></link><published>2020-06-24T11:00:00+09:00</published><updated>2020-06-24T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-06-24:/igobenkiyo1.html</id><content type="html">&lt;p&gt;月内は情報幾何重視で行こう。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.grammarly.com/"&gt;英文校正サービス&lt;/a&gt; よさそう。研究会向け原稿もOverleaf上でやるべく整理するか。&lt;/p&gt;
</content><category term="雑記"></category><category term="Information Geometry"></category></entry><entry><title>研究会に向けて(2)</title><link href="/yan-jiu-hui-nixiang-kete2.html" rel="alternate"></link><published>2020-06-22T11:00:00+09:00</published><updated>2020-06-22T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-06-22:/yan-jiu-hui-nixiang-kete2.html</id><content type="html">&lt;p&gt;AdaBoostのリスクがexpなのはリスクの上界を与えているから。また、更新式は学習理論p64など以下で。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.iip.ist.i.kyoto-u.ac.jp/member/keisuke/resources/11adaboost.pdf"&gt;AdaBoost&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://cmp.felk.cvut.cz/~sochmj1/adaboost_talk.pdf"&gt;AdaBoost&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://ysk24ok.github.io/2016/09/27/hajipata-boosting.html"&gt;はじめてのパターン認識 第11章 boosting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=46B996D5722EB4734D3A7381AFBA95CE?doi=10.1.1.56.9855&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;A decision-theoretic generalication of on-line learning and application to boosting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;情報幾何本読み進め中。
美しい結果（曲線上に平行移動はすごいと思った）が次々出てくるが、リーマン曲率テンソルのテンソル性を示すのに手間取ってる。&lt;/p&gt;
&lt;p&gt;研究会に向けては、実験計画を立てておきたい。
既存研究調査を引き続きやっていき、比較対象の手法をまとめる。また、比較対象手法と、対象のデータを纏めていく。&lt;/p&gt;
</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>研究会に向けて(1)</title><link href="/yan-jiu-hui-nixiang-kete1.html" rel="alternate"></link><published>2020-06-19T11:00:00+09:00</published><updated>2020-06-19T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-06-19:/yan-jiu-hui-nixiang-kete1.html</id><content type="html">&lt;p&gt;今週前半は休んでいた。流石にイベント中止が連打されて精神的に余裕がなくなった。
イベントレポートをこっちに移動しようか考えている。&lt;/p&gt;
&lt;p&gt;研究の方は、研究会への申込みに着手した。
正則化はタイムアップ。将来の課題に回す。研究会の準備をしていく。
他にも、事故相関行列の計算高速化が色々試せそう。例えば、クロネッカ積に分解したり。&lt;/p&gt;
</content><category term="雑記"></category><category term="Signed LMS"></category><category term="LMS"></category><category term="Natural Gradient"></category></entry><entry><title>逆写像定理までの整理(3)</title><link href="/ni-xie-xiang-ding-li-madenozheng-li-3.html" rel="alternate"></link><published>2020-06-13T11:00:00+09:00</published><updated>2020-06-13T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-06-13:/ni-xie-xiang-ding-li-madenozheng-li-3.html</id><content type="html">&lt;p&gt;記事に起こしてたら誤りなども見つかって1週間かかってしまった。。
これでようやく情報幾何学に入門できそう。&lt;/p&gt;
</content><category term="雑記"></category><category term="Manifold"></category></entry><entry><title>逆写像定理までの整理(2)</title><link href="/ni-xie-xiang-ding-li-madenozheng-li-2.html" rel="alternate"></link><published>2020-06-07T11:00:00+09:00</published><updated>2020-06-07T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-06-07:/ni-xie-xiang-ding-li-madenozheng-li-2.html</id><content type="html">&lt;p&gt;ついでにラグランジュ未定乗数法とKKT条件まで行ってしまった。欲張った。
予定より断然時間かかってしまったけど、だいたい落ち着いたかも。記事に起こす。&lt;/p&gt;
</content><category term="雑記"></category><category term="Manifold"></category></entry><entry><title>逆写像定理までの整理</title><link href="/ni-xie-xiang-ding-li-madenozheng-li.html" rel="alternate"></link><published>2020-06-05T11:00:00+09:00</published><updated>2020-06-05T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-06-05:/ni-xie-xiang-ding-li-madenozheng-li.html</id><content type="html">&lt;p&gt;評価を待つ間逆写像定理までを写経中。だいたい飲み込めてるが、やっぱ基礎の抜けがある…。
陰関数定理はだいたいOK。ついでにラグランジュ未定乗数法の厳密な証明を与えたい。（いままでなんとなくで済ませていたので止めを刺す。）&lt;/p&gt;
</content><category term="雑記"></category><category term="Manifold"></category></entry><entry><title>正則化(8)</title><link href="/zheng-ze-hua-8.html" rel="alternate"></link><published>2020-06-04T11:00:00+09:00</published><updated>2020-06-04T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-06-04:/zheng-ze-hua-8.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\mean[2]{\mathrm{E}_{#1} \left[ #2 \right]}
\newcommand\KL[2]{\mathrm{KL} \left[ #1 \ \middle| \middle| \ #2 \right]}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;前日思い立った内容って既に試していて、だめなところまで見えてた。すなわち直接 &lt;span class="math"&gt;\(\mathrm{E …&lt;/span&gt;&lt;/p&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\mean[2]{\mathrm{E}_{#1} \left[ #2 \right]}
\newcommand\KL[2]{\mathrm{KL} \left[ #1 \ \middle| \middle| \ #2 \right]}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;前日思い立った内容って既に試していて、だめなところまで見えてた。すなわち直接 &lt;span class="math"&gt;\(\mathrm{E}[(\ve{x} + \ve{a})(\ve{x} + \ve{a})^{\mathsf{T}}]\)&lt;/span&gt; を計算する方針は試行済み。&lt;/p&gt;
&lt;p&gt;色々探しているうちに、K-FACという自然勾配学習法の近似手法を見つける。クロネッカ積を使ってフィッシャー情報行列を分解しようというアイデアだ。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://medium.com/&amp;#64;osawa1021/k-fac%E3%81%A8%E3%81%AF-de30537f7096"&gt;K-FACとは？ 大規模深層学習のための二次最適化の実現&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;これはすごい。少し前にクロネッカ積で計算できるんじゃないの？とは指摘もらってたけど、普通にメジャーな手法だ。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.jstage.jst.go.jp/article/pjsai/JSAI2017/0/JSAI2017_1A2OS05b4/_pdf/-char/ja"&gt;自然勾配近似法を起点としたバッチ正規化の数理的理解&lt;/a&gt; に近似手法が挙げられている。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1810.12281.pdf"&gt;THREE MECHANISMS OF WEIGHT DECAY REGULARIZATION&lt;/a&gt; でWeight Decayの文脈でL2正則化学習則が示されている。&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1512.04202.pdf"&gt;Preconditioned Stochastic Gradient Descent&lt;/a&gt; Precondition行列で勾配を更新する方法。ちょっと待て、自然勾配とちょっと違う。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.mdpi.com/2076-3417/9/21/4568/pdf"&gt;Adaptive Natural Gradient Method for Learning of Stochastic Neural Networks in Mini-Batch Mode&lt;/a&gt; ではMatrix cookbookの(191)を使って行列に対する正則化を行っている。&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\((\ve{Q} + \sigma^{2}\ve{M})^{-1} \approx \ve{Q}^{-1} - \sigma^{2}\ve{Q}^{-1}\ve{M}\ve{Q}^{-1}\ (\sigma\text{ is small})\)&lt;/span&gt; という近似。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;逆写像定理までをおべんきょ中。まだ陰関数定理の途中。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category><category term="Regularization"></category></entry><entry><title>正則化(7)</title><link href="/zheng-ze-hua-7.html" rel="alternate"></link><published>2020-06-03T11:00:00+09:00</published><updated>2020-06-03T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-06-03:/zheng-ze-hua-7.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\mean[2]{\mathrm{E}_{#1} \left[ #2 \right]}
\newcommand\KL[2]{\mathrm{KL} \left[ #1 \ \middle| \middle| \ #2 \right]}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf"&gt;Matrix cookbook&lt;/a&gt; を眺めていたら有益そうな等式を見つける。 &lt;span class="math"&gt;\(E[\ve …&lt;/span&gt;&lt;/p&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\mean[2]{\mathrm{E}_{#1} \left[ #2 \right]}
\newcommand\KL[2]{\mathrm{KL} \left[ #1 \ \middle| \middle| \ #2 \right]}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf"&gt;Matrix cookbook&lt;/a&gt; を眺めていたら有益そうな等式を見つける。 &lt;span class="math"&gt;\(E[\ve{x}] = \ve{m}\)&lt;/span&gt; として、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\mathrm{E}[(\ve{x} + \ve{a})(\ve{x} + \ve{a})^{\mathsf{T}}] &amp;amp;= \mathrm{E}[\ve{x}\ve{x}^{\mathsf{T}} + \ve{x}\ve{a}^{\mathsf{T}} + \ve{a}\ve{x}^{\mathsf{T}} + \ve{a}\ve{a}^{\mathsf{T}}] \\
&amp;amp;= \mathrm{E}[\ve{x}\ve{x}^{\mathsf{T}} - \ve{x}\ve{m}^{\mathsf{T}} - \ve{m}\ve{x}^{\mathsf{T}} + \ve{m}\ve{m}^{\mathsf{T}} + \ve{x}\ve{m}^{\mathsf{T}} + \ve{m}\ve{x}^{\mathsf{T}} - \ve{m}\ve{m}^{\mathsf{T}} + \ve{x}\ve{a}^{\mathsf{T}} + \ve{a}\ve{x}^{\mathsf{T}} + \ve{a}\ve{a}^{\mathsf{T}}] \\
&amp;amp;= \mathrm{E}[\ve{x}\ve{x}^{\mathsf{T}} - \ve{x}\ve{m}^{\mathsf{T}} - \ve{m}\ve{x}^{\mathsf{T}} + \ve{m}\ve{m}^{\mathsf{T}}] + \ve{m}\ve{m}^{\mathsf{T}} + \ve{m}\ve{m}^{\mathsf{T}} - \ve{m}\ve{m}^{\mathsf{T}} + \ve{m}\ve{a}^{\mathsf{T}} + \ve{a}\ve{m}^{\mathsf{T}} + \ve{a}\ve{a}^{\mathsf{T}} \\
&amp;amp;= \mathrm{E}[(\ve{x} - \ve{m})(\ve{x} - \ve{m})^{\mathsf{T}}] + \ve{m}\ve{m}^{\mathsf{T}} + \ve{m}\ve{a}^{\mathsf{T}} + \ve{a}\ve{m}^{\mathsf{T}} + \ve{a}\ve{a}^{\mathsf{T}} \\
&amp;amp;= \mathrm{E}[(\ve{x} - \ve{m})(\ve{x} - \ve{m})^{\mathsf{T}}] + (\ve{m} + \ve{a})(\ve{m} + \ve{a})^{\mathsf{T}} \\
&amp;amp;= \mathrm{E}[\ve{x}\ve{x}^{\mathsf{T}}] - \ve{m}\ve{m}^{\mathsf{T}} + (\ve{m} + \ve{a})(\ve{m} + \ve{a})^{\mathsf{T}}
\end{align*}
&lt;/div&gt;
&lt;p&gt;が成立する。 &lt;span class="math"&gt;\(\ve{a}\)&lt;/span&gt; を正則化で出てくるベクトルとすると、割と有益に見える。しかも &lt;span class="math"&gt;\(\ve{m} = \ve{0}\)&lt;/span&gt; とできるならばもっとさっぱりする。&lt;/p&gt;
&lt;p&gt;早速手元のデータで &lt;span class="math"&gt;\(\ve{m} = \ve{0}\)&lt;/span&gt; とならないか、つまり、勾配 &lt;span class="math"&gt;\(\mathrm{sign}[\varepsilon(n)]\ve{x}(n)\)&lt;/span&gt; の平均が &lt;span class="math"&gt;\(\ve{0}\)&lt;/span&gt; にならないか観察したけど、成り立っていなそう。。。長時間平均をとっても収束している感じはしない。（自然勾配は、当然 &lt;span class="math"&gt;\(\ve{0}\)&lt;/span&gt; に漸近する傾向あり。学習が進んでいるから当然。）&lt;/p&gt;
&lt;p&gt;平均 &lt;span class="math"&gt;\(\ve{m}\)&lt;/span&gt; を逐次推定すれば良さそうで、試してみたい。しかし今は情報幾何もやるのだ。明日やる。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category><category term="Regularization"></category></entry><entry><title>正則化(6)</title><link href="/zheng-ze-hua-6.html" rel="alternate"></link><published>2020-05-31T11:00:00+09:00</published><updated>2020-05-31T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-31:/zheng-ze-hua-6.html</id><content type="html">&lt;p&gt;残った課題をやってたら土日が飛ぶ。ついでにカサゴ本を読み切る。
6月からは英語のおべんきょうをしようかと思っている。同時に情報幾何も進める。
早いところ進捗を見てもらいたいが、まだ無理っぽい。。。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://solid4.mech.okayama-u.ac.jp/%E3%83%86%E3%83%B3%E3%82%BD%E3%83%AB.pdf"&gt;テンソル&lt;/a&gt; テンソルの定義。分かりやすい説明。&lt;/li&gt;
&lt;/ul&gt;
</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category><category term="Regularization"></category></entry><entry><title>正則化(5)</title><link href="/zheng-ze-hua-5.html" rel="alternate"></link><published>2020-05-30T11:00:00+09:00</published><updated>2020-05-30T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-30:/zheng-ze-hua-5.html</id><content type="html">&lt;p&gt;課題やってたら木金が飛んだ。。。&lt;/p&gt;
&lt;p&gt;古い資料を漁ってたら、SPSA（Simultaneous perturbation stochastic approximation）が掘り返された。たしかシステム同定で使ったよな。なんか面白いかも知んない。&lt;/p&gt;
</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category><category term="Regularization"></category></entry><entry><title>正則化(4)</title><link href="/zheng-ze-hua-4.html" rel="alternate"></link><published>2020-05-27T11:00:00+09:00</published><updated>2020-05-27T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-27:/zheng-ze-hua-4.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\mean[2]{\mathrm{E}_{#1} \left[ #2 \right]}
\newcommand\KL[2]{\mathrm{KL} \left[ #1 \ \middle| \middle| \ #2 \right]}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;引き続きMAP推定における自然勾配を調査する。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1712.02390.pdf"&gt;Noisy Natural Gradient as …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\mean[2]{\mathrm{E}_{#1} \left[ #2 \right]}
\newcommand\KL[2]{\mathrm{KL} \left[ #1 \ \middle| \middle| \ #2 \right]}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;引き続きMAP推定における自然勾配を調査する。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1712.02390.pdf"&gt;Noisy Natural Gradient as Variational Inference&lt;/a&gt; の式(5)からスタートするも…はっきりしたことを言ってないように見える。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://bsi-ni.brain.riken.jp/database/file/215/221.pdf"&gt;Adaptive natural gradient learning algorithms for various stochastic models&lt;/a&gt; これの式(5)も参考になりそう。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1803.09151.pdf"&gt;Natural Gradients in Practice: Non-Conjugate Variational Inference in Gaussian Process Models&lt;/a&gt; 指数族の事後確率最大化を考える。フィッシャー情報行列を計算するための平均のとり方が妙。もうちょっと読みたい。&lt;/li&gt;
&lt;/ul&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category><category term="Regularization"></category></entry><entry><title>正則化(3)</title><link href="/zheng-ze-hua-3.html" rel="alternate"></link><published>2020-05-26T11:00:00+09:00</published><updated>2020-05-26T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-26:/zheng-ze-hua-3.html</id><summary type="html">&lt;p&gt;実装の整理できて、正則化込で動かしているけど芳しくない。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;正則化入れたらRMSが悪化。しかも、正則化係数を十分小さく取らないと誤差が大きくなる。&lt;/li&gt;
&lt;li&gt;タップ数が多い場合は多少の効果あり。&lt;ul&gt;
&lt;li&gt;タップ数が少ない（〜16個）のときは旨味が無いように思える。係数がスパースじゃないのでは。&lt;/li&gt;
&lt;li&gt;試しに128個とかにしたら少しの改善が見られた。けど適応が遅くて正則化なしでもRMSが悪い。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;フィッシャー情報行列固定で、勾配だけ正則化かける方は発散していく。&lt;/li&gt;
&lt;li&gt;ついでにLMSでも自然勾配法試してみたけど、SignedLMSの自然勾配よりもRMSが悪い。&lt;/li&gt;
&lt;li&gt;もう一度適応的自然勾配学習法を試したけど、十分に係数を小さく取らないと発散するし、小さくとっても性能が悪い。フィッシャー情報行列はちゃんと更新するべし。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;なんで正則化したら性能落ちるのか？をもっと考えていたら、パラメータの事前分布を入れた瞬間に計量がさらに歪んでいそう（単純な残差の分散ではダメそう）。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1712.02390.pdf"&gt;Noisy Natural Gradient as Variational Inference&lt;/a&gt; の式(5)。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.luigimalago.it/papers/2013GSI.pdf"&gt;Robust Estimation of Natural Gradient in Optimization by Regularized Linear Regression&lt;/a&gt; 線形回帰における正則化に触れている。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://ipvs.informatik.uni-stuttgart.de/mlr/papers/05-igel-Rprop.pdf"&gt;Rprop Using the Natural Gradient&lt;/a&gt; パラメータの正則化ではない …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;実装の整理できて、正則化込で動かしているけど芳しくない。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;正則化入れたらRMSが悪化。しかも、正則化係数を十分小さく取らないと誤差が大きくなる。&lt;/li&gt;
&lt;li&gt;タップ数が多い場合は多少の効果あり。&lt;ul&gt;
&lt;li&gt;タップ数が少ない（〜16個）のときは旨味が無いように思える。係数がスパースじゃないのでは。&lt;/li&gt;
&lt;li&gt;試しに128個とかにしたら少しの改善が見られた。けど適応が遅くて正則化なしでもRMSが悪い。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;フィッシャー情報行列固定で、勾配だけ正則化かける方は発散していく。&lt;/li&gt;
&lt;li&gt;ついでにLMSでも自然勾配法試してみたけど、SignedLMSの自然勾配よりもRMSが悪い。&lt;/li&gt;
&lt;li&gt;もう一度適応的自然勾配学習法を試したけど、十分に係数を小さく取らないと発散するし、小さくとっても性能が悪い。フィッシャー情報行列はちゃんと更新するべし。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;なんで正則化したら性能落ちるのか？をもっと考えていたら、パラメータの事前分布を入れた瞬間に計量がさらに歪んでいそう（単純な残差の分散ではダメそう）。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1712.02390.pdf"&gt;Noisy Natural Gradient as Variational Inference&lt;/a&gt; の式(5)。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.luigimalago.it/papers/2013GSI.pdf"&gt;Robust Estimation of Natural Gradient in Optimization by Regularized Linear Regression&lt;/a&gt; 線形回帰における正則化に触れている。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://ipvs.informatik.uni-stuttgart.de/mlr/papers/05-igel-Rprop.pdf"&gt;Rprop Using the Natural Gradient&lt;/a&gt; パラメータの正則化ではない。フィッシャー情報行列に正則化パラメータを乗じた単位行列を足して逆行列を求めている。なんでも、正則化パラメータが大きければ普通の勾配法に近づくとのこと。そのとおりだが、一体どういう発想なんだろう。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1703.00209.pdf"&gt;Online Natural Gradient as a Kalman Filter&lt;/a&gt; ドンピシャであった（Proposition 4）けどだいぶ複雑。しかも、自然勾配法とカルマンフィルタの関係性を示している。カルマンフィルタのノイズの事前分布を取り入れている。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;あがいてたら適応的自然勾配の近似計算があった。計算負荷削減に有益そう。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://papers.nips.cc/paper/3234-topmoumoute-online-natural-gradient-algorithm.pdf"&gt;Topmoumoute online natural gradient algorithm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category><category term="Regularization"></category></entry><entry><title>正則化(2)</title><link href="/zheng-ze-hua-2.html" rel="alternate"></link><published>2020-05-25T11:00:00+09:00</published><updated>2020-05-25T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-25:/zheng-ze-hua-2.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\mean[2]{\mathrm{E}_{#1} \left[ #2 \right]}
\newcommand\KL[2]{\mathrm{KL} \left[ #1 \ \middle| \middle| \ #2 \right]}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;まだ悩んでいる。今は &lt;span class="math"&gt;\(\ve{R}^{-1 …&lt;/span&gt;&lt;/p&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\mean[2]{\mathrm{E}_{#1} \left[ #2 \right]}
\newcommand\KL[2]{\mathrm{KL} \left[ #1 \ \middle| \middle| \ #2 \right]}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;まだ悩んでいる。今は &lt;span class="math"&gt;\(\ve{R}^{-1}\)&lt;/span&gt; を直接計算してるので、正則化込みの結果（ &lt;span class="math"&gt;\((\ve{R} + \lambda\ve{I})^{-1}\)&lt;/span&gt; ）になっていない。この式を近似でもいいから計算できないか？&lt;/p&gt;
&lt;p&gt;なんかうまくいきそうなんだけど、定式化にあたって一つ疑問が： &lt;strong&gt;自然勾配って一般の損失関数にも使えるのか？&lt;/strong&gt;
対数尤度を損失関数に使った場合は、無論自然勾配になるけど、一般の損失関数の場合、フィッシャー情報行列と損失関数の勾配が噛み合わない気がする。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1808.07172.pdf"&gt;Fisher Information and Natural Gradient Learning of Random Deep Networks&lt;/a&gt; 甘利先生の論文だけど一般の損失に適用しているように見える&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.7538&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;Why Natural Gradient?&lt;/a&gt; &lt;strong&gt;→大丈夫っぽい。ちゃんと読もう。&lt;/strong&gt; 簡単な例（極座標系）で示している。普通の勾配はユークリッド空間上になるけど、極座標の逆行列を乗じて自然勾配を得ている。&lt;ul&gt;
&lt;li&gt;とは言っても目的関数の構造を適切に表していないと、性能が悪そうに見える。対数尤度以外でどういうときに有効なんだ？&lt;/li&gt;
&lt;li&gt;試してみるしかない？つまり、勾配分散を毎回求める必要があるのか、それとも、一つの計量を複数の損失関数で使い回せるかやってみる。&lt;/li&gt;
&lt;li&gt;もう少し考えた。やっぱり正則化項を入れると損失関数の勾配は歪んでくると思う。だから、正則化項も含めてフィッシャー情報行列を計算しなければいかんと思う。ていうか、もはやフィッシャー情報行列は勾配の分散でしか無いように見えてきた。やり方としては、パラメータの事前分布にガウスorラプラス分布を入れて、そいつの対数尤度をとって最適化問題を考える。フィッシャー情報行列の式変形が難しくなるけど、そんなことは無視して（考察の余地はあるけど）逆行列補題でストレートにフィッシャー情報行列の逆行列を計算できる。&lt;ul&gt;
&lt;li&gt;ようはMAP推定。 &lt;span class="math"&gt;\(\max p(\ve{x} | \ve{\theta}) p(\ve{\theta})\)&lt;/span&gt; で、 &lt;span class="math"&gt;\(p(\ve{x} | \ve{\theta})\)&lt;/span&gt; は誤差分布、 &lt;span class="math"&gt;\(p(\ve{\theta})\)&lt;/span&gt; はパラメータ事前分布。&lt;span class="math"&gt;\(p(\ve{\theta}) = \exp(-\beta ||\ve{\theta}||_{2}), \exp(-\beta ||\ve{\theta}||_{1})\)&lt;/span&gt; なり何でもあり。対数とって勾配の分散をとればフィッシャー情報行列が求まる。&lt;/li&gt;
&lt;li&gt;試すこともできると思うのでやってみたい。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category><category term="Regularization"></category></entry><entry><title>正則化(1)</title><link href="/zheng-ze-hua-1.html" rel="alternate"></link><published>2020-05-24T11:00:00+09:00</published><updated>2020-05-24T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-24:/zheng-ze-hua-1.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\mean[2]{\mathrm{E}_{#1} \left[ #2 \right]}
\newcommand\KL[2]{\mathrm{KL} \left[ #1 \ \middle| \middle| \ #2 \right]}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;逆行列補題を使えば、どんな自然勾配法でも上手く動きそうな気がしてきた…。
勾配の分散行列を逐次的に求められるから相当強い。
自己相関行列であることはそんなに重要でもないかも。。。。でも評価待ちましょう …&lt;/p&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\mean[2]{\mathrm{E}_{#1} \left[ #2 \right]}
\newcommand\KL[2]{\mathrm{KL} \left[ #1 \ \middle| \middle| \ #2 \right]}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;逆行列補題を使えば、どんな自然勾配法でも上手く動きそうな気がしてきた…。
勾配の分散行列を逐次的に求められるから相当強い。
自己相関行列であることはそんなに重要でもないかも。。。。でも評価待ちましょう。。。&lt;/p&gt;
&lt;p&gt;一方で今日から正則化をどうすればいいか考えている。答えはフィッシャー情報行列に &lt;span class="math"&gt;\(\lambda \ve{I}\)&lt;/span&gt; を足すだけなんだが、意味づけというか解釈が上手くできない。どういう損失関数ならばフィッシャー情報行列に単位行列を足す形になるのか。。。&lt;/p&gt;
&lt;p&gt;SignedLMSで試したけど難航中。どうしても &lt;span class="math"&gt;\(\mathrm{sign}[\varepsilon(n)]\ve{x}(n)\)&lt;/span&gt; との積をとる項が出てきて、その平均がどうなるかわからない。。。&lt;/p&gt;
&lt;p&gt;実験的に勾配に係数ベクトルを足すなり係数の符号ベクトルを足すなりしてるけど、
正則化パラメータをめちゃくちゃ小さく取らないと結果が発散する…。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category><category term="Regularization"></category></entry><entry><title>成果まとめ中(5) / 自然勾配法の概観</title><link href="/cheng-guo-matomezhong-5-zi-ran-gou-pei-fa-nogai-guan.html" rel="alternate"></link><published>2020-05-23T11:00:00+09:00</published><updated>2020-05-23T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-23:/cheng-guo-matomezhong-5-zi-ran-gou-pei-fa-nogai-guan.html</id><content type="html">&lt;p&gt;昨日まで苦悩しつつ収束条件をまとめた（運良く見つけることができた。同時にNLMSの収束条件も掴んだ。）
でも、同時に新規性が無い気がしてきた。発見となるのは、SignedLMSのフィッシャー情報行列が自己相関行列になっているくらいか？
適応ステップサイズ導出後は、普通のフィッシャー情報行列込みのNLMSと全く同じだし。&lt;/p&gt;
</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="RLS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category></entry><entry><title>成果まとめ中(4)</title><link href="/cheng-guo-matomezhong-4.html" rel="alternate"></link><published>2020-05-21T23:00:00+09:00</published><updated>2020-05-21T23:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-21:/cheng-guo-matomezhong-4.html</id><content type="html">&lt;p&gt;AdaptiveFilterの本見てNLMSの議論を色々見てる。が、いい結果が出てこない。
本の内容も掴みかねてる。NLMSは係数誤差ベクトルのL2ノルムが指数的に減少するようだが本当か…？&lt;/p&gt;
&lt;p&gt;LMSの収束条件が分かっていないことに気づく。
「Adaptive Filter Theory」では式4.22に、「Adaptive Signal Processing」では式4.45で示されているので確認中。&lt;/p&gt;
</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="RLS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category></entry><entry><title>成果まとめ中(3)</title><link href="/cheng-guo-matomezhong-3.html" rel="alternate"></link><published>2020-05-20T23:00:00+09:00</published><updated>2020-05-20T23:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-20:/cheng-guo-matomezhong-3.html</id><summary type="html">&lt;p&gt;SGD（確率的最急勾配法）の収束レートが少し気になったのちょっと観察。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.jstage.jst.go.jp/article/bjsiam/28/3/28_27/_pdf"&gt;機械学習における確率的最適化&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;もっと初等的な説明があると良いなあ。確率1で極値に収束したような気がしている…。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;適応ステップサイズの分母の &lt;span class="math"&gt;\(\ve{x}(n)^{\mathsf{T}}\ve{R}^{-1}\ve{x}(n)\)&lt;/span&gt; がめちゃくちゃ気になって止まる。学習理論に「例えばパラメタ空間上のベクトル &lt;span class="math"&gt;\(x(\theta)\)&lt;/span&gt; の内積 &lt;span class="math"&gt;\(\innerp{x …&lt;/span&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;SGD（確率的最急勾配法）の収束レートが少し気になったのちょっと観察。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.jstage.jst.go.jp/article/bjsiam/28/3/28_27/_pdf"&gt;機械学習における確率的最適化&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;もっと初等的な説明があると良いなあ。確率1で極値に収束したような気がしている…。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;適応ステップサイズの分母の &lt;span class="math"&gt;\(\ve{x}(n)^{\mathsf{T}}\ve{R}^{-1}\ve{x}(n)\)&lt;/span&gt; がめちゃくちゃ気になって止まる。学習理論に「例えばパラメタ空間上のベクトル &lt;span class="math"&gt;\(x(\theta)\)&lt;/span&gt; の内積 &lt;span class="math"&gt;\(\innerp{x}{x}\)&lt;/span&gt; は、座標変換により不変な量として定義するならば &lt;span class="math"&gt;\(x^{\prime}(g_{ij}(\theta))^{-1}x\)&lt;/span&gt; となる。」（なるべく原文ママ）と言ってて、まさにこの不変な量を指していると思っている。&lt;/p&gt;
&lt;p&gt;これどういうこと？と思って探し始めたら沼。相対性理論にぶつかる。わかりやすかったのは下くらいか？&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://yuru2physics.blog.fc2.com/blog-entry-99.html"&gt;内積が不変という意味&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://fnorio.com/0180covariant_contravariant/covariant_contravariant.html#3-6"&gt;(6)ベクトル内積の座標変換不変性の確認&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;情報幾何の観点からすると、幾何的に微小線素は座標変換によって値を全く変えないことが重要らしい。&lt;span class="math"&gt;\(\ve{x}(n)\)&lt;/span&gt; をパラメタ空間上のベクトルと捉えると、&lt;span class="math"&gt;\(\ve{R}^{-1}\)&lt;/span&gt; はパラメタ空間上の計量（元の空間の計量は:math:&lt;cite&gt;ve{R}&lt;/cite&gt; ）を定め、&lt;span class="math"&gt;\(\ve{x}(n)^{\mathsf{T}}\ve{R}^{-1}\ve{x}(n)\)&lt;/span&gt; はパラメタ空間上のノルムを計算していて、ノルムだから不変でしょっていう議論になる？まだピンとこない。&lt;/p&gt;
&lt;p&gt;あと、AdaptiveFilterの本見てNLMSの議論を色々見てる。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="RLS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category></entry><entry><title>成果まとめ中(2)</title><link href="/cheng-guo-matomezhong-2.html" rel="alternate"></link><published>2020-05-19T11:00:00+09:00</published><updated>2020-05-19T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-19:/cheng-guo-matomezhong-2.html</id><content type="html">&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://dsl4.eee.u-ryukyu.ac.jp/DOCS/DSP/p10.pdf"&gt;ディジタル信号処理 第 10 回 適応信号処理&lt;/a&gt; 少し詳しく書いてある。やはり適応フィルタの原典を当たりたい。&lt;/li&gt;
&lt;/ul&gt;
</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="RLS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category></entry><entry><title>書類整理終わり、復帰 / 成果まとめ中(1)</title><link href="/shu-lei-zheng-li-zhong-wari-fu-gui-cheng-guo-matomezhong-1.html" rel="alternate"></link><published>2020-05-18T11:00:00+09:00</published><updated>2020-05-18T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-18:/shu-lei-zheng-li-zhong-wari-fu-gui-cheng-guo-matomezhong-1.html</id><content type="html">&lt;p&gt;諸々の提出書類で実験できず。1週間空けて復帰。&lt;/p&gt;
&lt;p&gt;報告書類を書いていたら、やっぱりフィッシャー情報行列とヘッセ行列の違いがよくわからなくなってきた。
対数尤度のヘッセ行列とフィッシャー情報行列に何かしらの共通点があるはず。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.inference.vc/on-empirical-fisher-information/"&gt;Notes on the Limitations of the Empirical Fisher Approximation&lt;/a&gt; 経験フィッシャー行列の性能限界について。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ヘッセ行列のくだりから自然勾配の導出まで、紙に証明をまとめた。明日辺りに記事に起こす。&lt;/p&gt;
</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="RLS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category></entry><entry><title>LMS Filterの挙動観察中(10)</title><link href="/lms-filternoju-dong-guan-cha-zhong-10.html" rel="alternate"></link><published>2020-05-06T11:00:00+09:00</published><updated>2020-05-06T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-06:/lms-filternoju-dong-guan-cha-zhong-10.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;Normalizeするやつの意味付けを追っている。非常にRLS(Recursive Least Square)に近い、下手するとRLSそのものかも知れない。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align …&lt;/script&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;Normalizeするやつの意味付けを追っている。非常にRLS(Recursive Least Square)に近い、下手するとRLSそのものかも知れない。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="RLS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category></entry><entry><title>書類整理中</title><link href="/shu-lei-zheng-li-zhong.html" rel="alternate"></link><published>2020-05-06T11:00:00+09:00</published><updated>2020-05-06T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-06:/shu-lei-zheng-li-zhong.html</id><content type="html">&lt;p&gt;色々と書類整理しているためあんまり実験が進んでいない。でも、既存研究がありそうでヒヤヒヤする毎日。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://scholarsmine.mst.edu/cgi/viewcontent.cgi?article=2780&amp;amp;context=ele_comeng_facwork"&gt;Normalized Natural Gradient Adaptive Filtering for Sparse and Nonsparse Systems&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;かなり近い。が、LMSベースの計量を自ら設計している。コスト関数に、2乗誤差項に何か変換のL2ノルムを加算しており、それに対しての自然勾配を求めている。そうか、コスト関数の自然勾配を考えればいいのか。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://pdfs.semanticscholar.org/bf3b/fe757d9156cc863ffdde15b1664c337819bd.pdf"&gt;Proportionate Normalized Least-Mean-Squares Adaptation in Echo Cancelers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自然勾配の発想に近づいていたPNLMSの実装&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiki.eecs.umich.edu/global/data/hero/images/7/7b/Yilun-icassp2-09.pdf"&gt;SPARSE LMS FOR SYSTEM IDENTIFICATION&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;スパースLMS(ZA-LMS)の最初の論文。定式化が明確。&lt;/p&gt;
</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="RLS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category></entry><entry><title>LMS Filterの挙動観察中(9)</title><link href="/lms-filternoju-dong-guan-cha-zhong-9.html" rel="alternate"></link><published>2020-05-05T11:00:00+09:00</published><updated>2020-05-05T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-05:/lms-filternoju-dong-guan-cha-zhong-9.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;実装誤りを見直しながらもう一度。&lt;/p&gt;
&lt;p&gt;やはり、自然勾配法が何故うまくいくのか、更新式の導出までやったほうが宜しい。実装間違いするから。適応的自然勾配の更新式は微小量の近似を使っている。微小量の近似は今まで何度も避けてきたが、この際おさらいする。ようはテイラー展開して2次以降の項を打ち切れば良し。高校数学レベルの話。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://physnotes.jp/foundations/approximation/"&gt;近似式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://w3e.kanazawa-it.ac.jp/math/category/suuretu/maclaurin/henkan-tex.cgi?target=/math/category/suuretu/maclaurin/maclaurin_1-x.html"&gt;1/(1-x)のマクローリン展開&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;実験が落ち着いたら書いていきたい。&lt;/p&gt;
&lt;p&gt;→実験OK。ステップサイズの設定が難しかったけど、ナイーブなものよりは性能がよいはず。&lt;/p&gt;
&lt;p&gt;また、軽く見た感じでも自然勾配学習法は発散しやすい。以下の記事にあるように、正則化を掛けたほうが良さそう。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://tfjgeorge.github.io/articles/note/2018/11/09/empirical-fisher.html"&gt;What is the empirical …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;実装誤りを見直しながらもう一度。&lt;/p&gt;
&lt;p&gt;やはり、自然勾配法が何故うまくいくのか、更新式の導出までやったほうが宜しい。実装間違いするから。適応的自然勾配の更新式は微小量の近似を使っている。微小量の近似は今まで何度も避けてきたが、この際おさらいする。ようはテイラー展開して2次以降の項を打ち切れば良し。高校数学レベルの話。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://physnotes.jp/foundations/approximation/"&gt;近似式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://w3e.kanazawa-it.ac.jp/math/category/suuretu/maclaurin/henkan-tex.cgi?target=/math/category/suuretu/maclaurin/maclaurin_1-x.html"&gt;1/(1-x)のマクローリン展開&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;実験が落ち着いたら書いていきたい。&lt;/p&gt;
&lt;p&gt;→実験OK。ステップサイズの設定が難しかったけど、ナイーブなものよりは性能がよいはず。&lt;/p&gt;
&lt;p&gt;また、軽く見た感じでも自然勾配学習法は発散しやすい。以下の記事にあるように、正則化を掛けたほうが良さそう。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://tfjgeorge.github.io/articles/note/2018/11/09/empirical-fisher.html"&gt;What is the empirical Fisher ?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ヘッセ行列の計算は少し回り道になったが、理論的最適値との比較において議論できそう。&lt;/p&gt;
&lt;p&gt;逆行列補題を使っていて、最早カルマンフィルタやRLSに近いんでないかと思えてきた。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.bode.amp.i.kyoto-u.ac.jp/~kashima/lecture/ss/slide17_8.pdf"&gt;信号とシステム 第6章 適応フィルタ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.cs.tut.fi/~tabus/course/ASP/LectureNew10.pdf"&gt;Recursive Least Squares Estimation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;にLMSからRLSまで記述あり。&lt;/p&gt;
&lt;p&gt;上の「信号とシステム」を眺めていたら、NLMSにおける適応的ステップサイズ決定則が使えそうな印象。NLMSは事後誤差 &lt;span class="math"&gt;\(e^{+}(k)\)&lt;/span&gt; を0にするように適応的なステップサイズ &lt;span class="math"&gt;\(\alpha(k)\)&lt;/span&gt; を定める。普通のSigned-LMSでは、リファレンス信号 &lt;span class="math"&gt;\(d(k)\)&lt;/span&gt;, フィルタ係数 &lt;span class="math"&gt;\(\ve{h}(k)\)&lt;/span&gt;, 入力データ &lt;span class="math"&gt;\(\ve{x}(k)\)&lt;/span&gt; に対し、事後誤差は次のように展開できる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
e^{+}(k) &amp;amp;= d(k) - \innerp{\ve{h}(k+1)}{\ve{x}(k)} \\
&amp;amp;= d(k) - \innerp{\ve{h}(k) + \alpha(k) \mathrm{sign}[e(k)] \ve{x}(k)}{\ve{x}(k)} \\
&amp;amp;= d(k) - \innerp{\ve{h}(k)}{\ve{x}(k)} - \alpha(k) \mathrm{sign}[e(k)] \innerp{\ve{x}(k)}{\ve{x}(k)} \\
&amp;amp;= e(k) - \alpha(k) \mathrm{sign}[e(k)] ||\ve{x}(k)||_{2}^{2}
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(e^{+}(k) = 0\)&lt;/span&gt; となるように &lt;span class="math"&gt;\(\alpha(k)\)&lt;/span&gt; を選ぶと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\alpha(k) = \frac{e(k)}{\mathrm{sign}[e(k)] ||\ve{x}(k)||_{2}^{2}} = \frac{|e(k)|}{||\ve{x}(k)||_{2}^{2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;として、事後誤差を最小にするステップサイズが求まった。（Signed-LMSでこういう議論があんまり見られないのはなぜだ？&lt;strong&gt;この&lt;/strong&gt; &lt;span class="math"&gt;\(\alpha(k)\)&lt;/span&gt; &lt;strong&gt;をSigned-LMSの更新則に突っ込むとNLMSになる&lt;/strong&gt; ）&lt;/p&gt;
&lt;p&gt;自然勾配を使った場合が有益（ステップサイズ設定つらい）なので、求めてみると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
e^{+}(k) &amp;amp;= d(k) - \innerp{\ve{h}(k+1)}{\ve{x}(k)} \\
&amp;amp;= d(k) - \innerp{\ve{h}(k) + \alpha(k) \mathrm{sign}[e(k)] \ve{F}(k)^{-1} \ve{x}(k)}{\ve{x}(k)} \\
&amp;amp;= d(k) - \innerp{\ve{h}(k)}{\ve{x}(k)} - \alpha(k) \mathrm{sign}[e(k)] \innerp{\ve{F}(k)^{-1}\ve{x}(k)}{\ve{x}(k)} \\
&amp;amp;= e(k) - \alpha(k) \mathrm{sign}[e(k)] \innerp{\ve{x}(k)}{\ve{F}(k)^{-1}\ve{x}(k)}
\end{align*}
&lt;/div&gt;
&lt;p&gt;よって、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\alpha(k) = \frac{e(k)}{\mathrm{sign}[e(k)] \innerp{\ve{x}}{\ve{F}(k)^{-1}\ve{x}(k)}} = \frac{|e(k)|}{\innerp{\ve{x}(k)}{\ve{F}(k)^{-1}\ve{x}(k)}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が得られる。これは計量としてフィッシャー情報行列の逆行列を使った時の &lt;span class="math"&gt;\(\ve{x}(k)\)&lt;/span&gt; のノルムによる正規化に対応する。すると残差の絶対値が外れる。NLMSとかなり近いけど計量が入っているところが違う。&lt;/p&gt;
&lt;p&gt;実装してみたら実験でも音源に依存せず安定している印象（注意！ノイズのない正弦波で発散した！おそらく、情報行列の要素が全て同一で特異になっている。）。&lt;/p&gt;
&lt;p&gt;結果の意味付けが非常に大事な気がする。資料35pあたりの議論を当てはまると、何か幾何的な解釈が出てくるはずだ。改めて、ここらへんの議論って誰かやっていないか、気になる。明日はそこを考えてみる。改めて既存研究が無いか見て、報告に移そうか。&lt;/p&gt;
&lt;p&gt;TODO:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Normalizeするやつの結果の意味付け&lt;/li&gt;
&lt;li&gt;忘却係数として捉えれば式が簡単にならんか？ &lt;span class="math"&gt;\((\lambda \ve{F} + \ve{x}\ve{x}^{\mathsf{T}})^{-1}\)&lt;/span&gt; で &lt;span class="math"&gt;\(0 &amp;lt; \lambda &amp;lt; 1\)&lt;/span&gt; は1に近い係数。&lt;/li&gt;
&lt;li&gt;自然勾配法がなんでうまくいくのか &lt;a class="reference external" href="https://wiseodd.github.io/techblog/2018/03/14/natural-gradient/"&gt;Natural Gradient Descent&lt;/a&gt; を訳しながら理解していく。 &lt;a class="reference external" href="https://arxiv.org/pdf/1412.1193.pdf"&gt;New insights and perspectives on the natural gradient method&lt;/a&gt; も参考になりそう。&lt;/li&gt;
&lt;li&gt;RLS(Recursive Least Square)の更新式の誤差に符号関数を被せたものが、自分が導いているものかも知れないと思い立つ。確認。&lt;/li&gt;
&lt;/ul&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="RLS"></category><category term="Natural Gradient"></category><category term="Empirical Fisher"></category></entry><entry><title>LMS Filterの挙動観察中(8)</title><link href="/lms-filternoju-dong-guan-cha-zhong-8.html" rel="alternate"></link><published>2020-05-04T11:00:00+09:00</published><updated>2020-05-04T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-04:/lms-filternoju-dong-guan-cha-zhong-8.html</id><summary type="html">&lt;p&gt;まだ粘る。GW終わるまでには何らかのアウトプットがほしい。&lt;/p&gt;
&lt;p&gt;指数移動平均のαを増やすと性能（誤差、エントロピー）が悪化する傾向あり。特に0.5以上（瞬間値の重みを大きく）すると、悪化が顕著。&lt;/p&gt;
&lt;p&gt;分散行列の逆行列を見てみると、非常に大きい値を取っていることが分かる。これは特異にかなり近いのではないかと予測している。&lt;/p&gt;
&lt;p&gt;また、指数移動平均で求めた分散行列の対角要素は経験分散に漸近するはずで、対角要素は時間遅延が加わった自分自身との2乗和で、全てが同じ値になることを期待していたが、なっていなかった。これは、指数移動平均は入力の順序により最終結果が異なるという状態が現れていると思う。（例：1,1,1,0 という系列と 0,1,1,1 という系列では指数移動平均の結果が異なる。）&lt;/p&gt;
&lt;p&gt;学習率の設定も音源依存でだいぶ変わってしまう印象。ボイスでは 0.0001 が、ピアノでは 0.00001、50Hzサイン波では発散した（恐らくこれはほぼ定常な信号になっているからと思われる。定常な信号では全ての分散と共分散が同じ値になって、行列が特異になる。正則化（分散行列に定数を掛けた単位行列を加算）を行ったら安定した...）&lt;/p&gt;
&lt;p&gt;行き詰まりを感じ、適応的自然勾配の更新式を逆行列補題（Woodburyの恒等式 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;まだ粘る。GW終わるまでには何らかのアウトプットがほしい。&lt;/p&gt;
&lt;p&gt;指数移動平均のαを増やすと性能（誤差、エントロピー）が悪化する傾向あり。特に0.5以上（瞬間値の重みを大きく）すると、悪化が顕著。&lt;/p&gt;
&lt;p&gt;分散行列の逆行列を見てみると、非常に大きい値を取っていることが分かる。これは特異にかなり近いのではないかと予測している。&lt;/p&gt;
&lt;p&gt;また、指数移動平均で求めた分散行列の対角要素は経験分散に漸近するはずで、対角要素は時間遅延が加わった自分自身との2乗和で、全てが同じ値になることを期待していたが、なっていなかった。これは、指数移動平均は入力の順序により最終結果が異なるという状態が現れていると思う。（例：1,1,1,0 という系列と 0,1,1,1 という系列では指数移動平均の結果が異なる。）&lt;/p&gt;
&lt;p&gt;学習率の設定も音源依存でだいぶ変わってしまう印象。ボイスでは 0.0001 が、ピアノでは 0.00001、50Hzサイン波では発散した（恐らくこれはほぼ定常な信号になっているからと思われる。定常な信号では全ての分散と共分散が同じ値になって、行列が特異になる。正則化（分散行列に定数を掛けた単位行列を加算）を行ったら安定した...）&lt;/p&gt;
&lt;p&gt;行き詰まりを感じ、適応的自然勾配の更新式を逆行列補題（Woodburyの恒等式）から導いていた。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://mathtrain.jp/woodbury"&gt;逆行列の補助定理（Woodburyの恒等式）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://sigmagic.net/math/inverse-mat/"&gt;逆行列の公式&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;そのときに、論文では勾配ベクトルの分散行列を求めていることに気づく。そして自分が間違っている事がわかった。
情報行列は勾配ベクトルの分散行列だった。（データベクトルの分散行列ではない...）
いままで入力データの分散行列を計算していたので、これは明確な誤り。&lt;/p&gt;
&lt;p&gt;フィッシャー情報行列はスコア関数（対数尤度関数の勾配）の分散行列で定義される。よって、情報行列とデータの分散行列は一般に一致しない。&lt;/p&gt;
&lt;p&gt;もう一つ自然勾配とフィッシャー情報行列に関する有益な情報源あり:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://tfjgeorge.github.io/articles/note/2018/11/09/empirical-fisher.html"&gt;What is the empirical Fisher ?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;今一度Jupyterから出戻りしてみる。
思ったけど、今考えているのは絶対値誤差最小化のためにSigned-LMSだけど、データ側を符号とするLMSや、Sign-SignLMSの解析もありじゃないかと思ってきた。データ側を符号とするLMSは何を最小化しているのか？などが気になる。&lt;/p&gt;
</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category></entry><entry><title>LMS Filterの挙動観察中(7)</title><link href="/lms-filternoju-dong-guan-cha-zhong-7.html" rel="alternate"></link><published>2020-05-03T11:00:00+09:00</published><updated>2020-05-03T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-03:/lms-filternoju-dong-guan-cha-zhong-7.html</id><content type="html">&lt;p&gt;実データ適用で、どうも上手く行かない。やっぱり分散行列の逆行列が発散している。&lt;/p&gt;
&lt;p&gt;適応的自然勾配をやめて、真面目に（毎サンプル平均を求めて）計算するようにしているけども結果がよろしくない。分散行列を標本平均ではなくて指数移動平均（α=0.1）に置き換えたらそれなりの性能が出ることを確認。しかし、ラプラス分布の計量を取り入れていない...。&lt;/p&gt;
</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category></entry><entry><title>LMS Filterの挙動観察中(6)</title><link href="/lms-filternoju-dong-guan-cha-zhong-6.html" rel="alternate"></link><published>2020-05-02T11:00:00+09:00</published><updated>2020-05-02T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-02:/lms-filternoju-dong-guan-cha-zhong-6.html</id><content type="html">&lt;p&gt;今日は実装整理して実データへ適用してみる。気になってるのが適応的自然勾配の更新式。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;確率の重み付けは正規化しないと使えそうにないということ。&lt;/li&gt;
&lt;li&gt;確率の重み付けをしても問題ないか？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;実データ適用、うーん性能が良くない！発散する！実装を確認しながら進行中。情報行列の逆行列を正規化すると発散はしないけど、逆行列がほぼ単位行列とほぼ同一で、元のSignedLMSと性能が同等。。。
まずは、適応的自然勾配じゃなくて負荷でかいけど真面目に計算する方針で行ってみる。&lt;/p&gt;
&lt;p&gt;また、フィルタ処理をfor文でやるよりnumpyの演算にした方が格段に早かった。numpy大事。&lt;/p&gt;
</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category></entry><entry><title>LMS Filterの挙動観察中(5)</title><link href="/lms-filternoju-dong-guan-cha-zhong-5.html" rel="alternate"></link><published>2020-05-01T11:00:00+09:00</published><updated>2020-05-01T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-01:/lms-filternoju-dong-guan-cha-zhong-5.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;別のことをしているときに、ふと適応的自然勾配学習法を弄ってて、なんとなくIRLSに応用できそうな印象が。
以下のような式でヘッセ行列（というか、重み付きの分散行列）を更新する。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{H} \leftarrow \ve{H} + \frac{1}{|y_{i} - \ve{\beta}^{\mathsf{T}} \ve{x}|} \ve{x …&lt;/div&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;別のことをしているときに、ふと適応的自然勾配学習法を弄ってて、なんとなくIRLSに応用できそうな印象が。
以下のような式でヘッセ行列（というか、重み付きの分散行列）を更新する。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{H} \leftarrow \ve{H} + \frac{1}{|y_{i} - \ve{\beta}^{\mathsf{T}} \ve{x}|} \ve{x} \ve{x}^{\mathsf{T}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;他にも、ICA（独立成分分析）の尖度最大化（優ガウス分布化）の学習がなんか使えないかと考えつつある。でもこれはICAによるノイズ除去にだいぶ近い話になりそう。&lt;/p&gt;
&lt;p&gt;分散行列と自己相関行列、だいぶ定義が近いな…間違ってないかなと思って再確認。分散行列と言ってるものはもしかしたら自己相関行列の誤りかもしれない。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://mathtrain.jp/correlationmatrix"&gt;相関行列の定義と分散共分散行列との関係&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.ip.info.eng.osaka-cu.ac.jp/~kazunori/paper/rcs201610_handout.pdf"&gt;初学者のための無線通信信号処理入門&lt;/a&gt; に明確に定義されてる。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;平均0化していたら分散行列と自己相関行列は同一になりそうな雰囲気。雰囲気じゃだめでちゃんと確認すべき。&lt;/p&gt;
&lt;p&gt;寄り道しすぎたので、改めて結果をまとめていく。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category></entry><entry><title>LMS Filterの挙動観察中(4)</title><link href="/lms-filternoju-dong-guan-cha-zhong-4.html" rel="alternate"></link><published>2020-04-30T11:00:00+09:00</published><updated>2020-04-30T11:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-30:/lms-filternoju-dong-guan-cha-zhong-4.html</id><summary type="html">&lt;p&gt;本日も引き続き発散の原因を追う。
→ステップサイズを小さくしたら発散しなくなった…。職人芸じゃないかこんなの。NLMSみたく発散しない条件がほしいな。&lt;/p&gt;
&lt;p&gt;本当に既存研究がないか、再度調査。&lt;/p&gt;
&lt;p&gt;自然勾配を適応的に計算する方法を試している。無論、定義式通りに計算するのは問題ないことは確かめているが、計算量が気になるのです。&lt;/p&gt;
&lt;p&gt;パラメータを色々といじりつつ、論文も参照してそれなりのパラメータを見つける。
パラメータについては &lt;a class="reference external" href="https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=5&amp;amp;ved=2ahUKEwi4ufHi4o_pAhUY_GEKHd-gDBwQFjAEegQIBRAB&amp;amp;url=https%3A%2F%2Fwww.mdpi.com%2F2076-3417%2F9%2F21%2F4568%2Fpdf&amp;amp;usg=AOvVaw0KgakdcC8U_T71ks8hZKDW"&gt;Adaptive Natural Gradient Method for Learning of Stochastic Neural Networks in Mini-Batch Mode&lt;/a&gt; を皮切りに調査開始。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.8668&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;Adaptive Method of Realizing Natural Gradient Learning for Multilayer Perceptrons&lt;/a&gt; が甘利先生。（福水先生もいるぞ）&lt;ul&gt;
&lt;li&gt;この論文で適応的更新式の導出が述べられる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://bsi-ni.brain.riken.jp/database/file/215/221.pdf"&gt;Adaptive natural gradient learning algorithms for various stochastic models&lt;/a&gt; も甘利先生 …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;本日も引き続き発散の原因を追う。
→ステップサイズを小さくしたら発散しなくなった…。職人芸じゃないかこんなの。NLMSみたく発散しない条件がほしいな。&lt;/p&gt;
&lt;p&gt;本当に既存研究がないか、再度調査。&lt;/p&gt;
&lt;p&gt;自然勾配を適応的に計算する方法を試している。無論、定義式通りに計算するのは問題ないことは確かめているが、計算量が気になるのです。&lt;/p&gt;
&lt;p&gt;パラメータを色々といじりつつ、論文も参照してそれなりのパラメータを見つける。
パラメータについては &lt;a class="reference external" href="https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=5&amp;amp;ved=2ahUKEwi4ufHi4o_pAhUY_GEKHd-gDBwQFjAEegQIBRAB&amp;amp;url=https%3A%2F%2Fwww.mdpi.com%2F2076-3417%2F9%2F21%2F4568%2Fpdf&amp;amp;usg=AOvVaw0KgakdcC8U_T71ks8hZKDW"&gt;Adaptive Natural Gradient Method for Learning of Stochastic Neural Networks in Mini-Batch Mode&lt;/a&gt; を皮切りに調査開始。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.8668&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;Adaptive Method of Realizing Natural Gradient Learning for Multilayer Perceptrons&lt;/a&gt; が甘利先生。（福水先生もいるぞ）&lt;ul&gt;
&lt;li&gt;この論文で適応的更新式の導出が述べられる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://bsi-ni.brain.riken.jp/database/file/215/221.pdf"&gt;Adaptive natural gradient learning algorithms for various stochastic models&lt;/a&gt; も甘利先生。（福水先生もいるぞ）&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://downloads.hindawi.com/archive/2011/407497.pdf"&gt;A Simplified Natural Gradient Learning Algorithm&lt;/a&gt; 更にシンプルにしたもの。2011年。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Toy-problemとして中央値の逐次推定とかアリではと、少しだけ思った。&lt;/p&gt;
</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="LAD"></category></entry><entry><title>LMS Filterの挙動観察中(3)</title><link href="/lms-filternoju-dong-guan-cha-zhong-3.html" rel="alternate"></link><published>2020-04-29T23:40:00+09:00</published><updated>2020-04-29T23:40:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-29:/lms-filternoju-dong-guan-cha-zhong-3.html</id><content type="html">&lt;p&gt;LMSはヘッセ行列の逆行列込みの学習ができているが、Signed-LMSは上手く行かない。分散行列が特異になったり、要素が大きくなりすぎて発散してしまう。。。&lt;/p&gt;
</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="LAD"></category></entry><entry><title>LMS Filterの挙動観察中(2)</title><link href="/lms-filternoju-dong-guan-cha-zhong-2.html" rel="alternate"></link><published>2020-04-28T23:40:00+09:00</published><updated>2020-04-28T23:40:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-28:/lms-filternoju-dong-guan-cha-zhong-2.html</id><summary type="html">&lt;p&gt;つまるところ、以下の計算をどうやるか？に尽きる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\mathrm{E}\left[ \delta(\varepsilon(n)) x(n - m) x(n - k) \right] = \lim_{N \to \infty} \frac{1}{N} \sum_{n = 1, \varepsilon(n) = 0}^{N} x(n - m) x(n - k)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\varepsilon(n)\)&lt;/span&gt; はi.i.d.（独立に同一の分布）から発生しているので、&lt;span class="math"&gt;\(x(n-m), x …&lt;/span&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;つまるところ、以下の計算をどうやるか？に尽きる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\mathrm{E}\left[ \delta(\varepsilon(n)) x(n - m) x(n - k) \right] = \lim_{N \to \infty} \frac{1}{N} \sum_{n = 1, \varepsilon(n) = 0}^{N} x(n - m) x(n - k)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\varepsilon(n)\)&lt;/span&gt; はi.i.d.（独立に同一の分布）から発生しているので、&lt;span class="math"&gt;\(x(n-m), x(n-k)\)&lt;/span&gt; には依存しない（予測係数にも依らず）で勝手に揺れると考える。&lt;/p&gt;
&lt;p&gt;でもそんな計算は見たことがない。そもそもLADの文脈でこの話は出ているはずで、「Laplace Distribution linear regression」で検索掛けていたら、&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://downloads.hindawi.com/journals/jam/2014/856350.pdf"&gt;Robust Mean Change-Point Detecting through Laplace Linear Regression Using EM Algorithm&lt;/a&gt; を見つけた。&lt;ul&gt;
&lt;li&gt;イントロで「 &lt;strong&gt;ラプラス分布は正規分布の混合で表せる&lt;/strong&gt; 」と「 &lt;strong&gt;混合を前提にしたEMアルゴリズムが存在する&lt;/strong&gt; 」というのを見つけて、論文探しが改めて動く。混合ガウス分布をEMアルゴリズムで学習する話はよく聞くから、本質的なのは正規分布の混合で表せていることか。&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://core.ac.uk/download/pdf/16705381.pdf"&gt;ROBUST MIXTURE REGRESSION MODEL FITTING BY LAPLACE DISTRIBUTION&lt;/a&gt; は2013年の論文。印象的なのは、 &lt;strong&gt;IRLSはEMアルゴリズムの一種だということ。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;ved=2ahUKEwi287j_j4rpAhXKA4gKHUlmAIUQFjAAegQIBBAB&amp;amp;url=https%3A%2F%2Fkwansei.repo.nii.ac.jp%2Findex.php%3Faction%3Dpages_view_main%26active_action%3Drepository_action_common_download%26item_id%3D26097%26item_no%3D1%26attribute_id%3D22%26file_no%3D1%26page_id%3D30%26block_id%3D85&amp;amp;usg=AOvVaw0TY8ejg2Duf0nYYdMvrVD_"&gt;ラプラス確率的フロンティアモデルのベイズ推定&lt;/a&gt; は日本語でラプラス分布の混合について述べた論文&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.math.chalmers.se/Stat/Grundutb/GU/MSA220/S16/bayeslasso.pdf"&gt;The Bayesian Lasso&lt;/a&gt; はLASSOを、パラメータの事前分布をラプラス分布としたものとして定式化している。ラプラス分布は直接扱わず、混合を考えている。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;実験で試している、勾配ベクトルに分散行列（ヘッセ行列）の逆行列を掛ける行為は、ウィーナーフィルタに等しい。しかしウィーナーフィルタは観測分散行列 &lt;span class="math"&gt;\(\ve{XX}^{\mathsf{T}}\)&lt;/span&gt; が正則でないと計算できない。そこで、観測分散行列の低ランク近似を行ってその擬似逆行列を使ってフィルタ係数を更新していく手法がある。それを Reduced rank adaptive filters というらしい。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1504.06054.pdf"&gt;A New Approach to Adaptive Signal Processing&lt;/a&gt; で触れていた。この論文は適応フィルタを広汎的に見ており、有益。&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www-users.york.ac.uk/~rcdl500/SPL_JIO_2007.pdf"&gt;Reduced-Rank Adaptive Filtering Based on Joint Iterative Optimization of Adaptive Filters&lt;/a&gt; ではReduced rank adaptive filtersのフィルタバンク版&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;邪念が動いて、パーティクルフィルター（粒子フィルター）でパラメータ決められんか考えてる。でも、LMSは状態空間モデルの範疇に入るのだろうか？（カルマンフィルタの一部だから当てはまったはず）。また、一般の状態空間モデルと違って状態は常に観測できるよな。またパーティクルフィルターもシミュレーションベースなので負荷が高そう。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.allisone.co.jp/html/Notes/DSP/Filter/particle-filter/index.html"&gt;パーティクル・フィルタをやさしく解説&lt;/a&gt; が確かに優しい。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.terrapub.co.jp/journals/jjssj/pdf/4401/44010189.pdf"&gt;粒子フィルタの基礎と応用: フィルタ・平滑化・パラメータ推定&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="mathrm-e-left-delta-varepsilon-n-x-n-m-x-n-k-right"&gt;
&lt;h2&gt;&lt;span class="math"&gt;\(\mathrm{E}\left[ \delta(\varepsilon(n)) x(n - m) x(n - k) \right]\)&lt;/span&gt; の解釈&lt;/h2&gt;
&lt;p&gt;結局 &lt;span class="math"&gt;\(\mathrm{E}\left[ \delta(\varepsilon(n)) x(n - m) x(n - k) \right]\)&lt;/span&gt; の解釈から逃げている...。もう少し考えていたら、残差 &lt;span class="math"&gt;\(\varepsilon\)&lt;/span&gt; は入力ベクトル &lt;span class="math"&gt;\(x\)&lt;/span&gt; と独立であることを思い出した。ここから、次が言える。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\mathrm{E} \left[\delta(\varepsilon(n)) x(n - m) x(n - k) \right] = \mathrm{E} \left[ \delta(\varepsilon(n)) \right] \mathrm{E} \left[ x(n - m) x(n - k) \right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで、 &lt;span class="math"&gt;\(\mathrm{E} \left[ \delta(\varepsilon(n)) \right]\)&lt;/span&gt; はお察しの通りで、以下の通りに、やはり残差が0となる確率が出てくる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\mathrm{E} \left[ \delta(\varepsilon(n)) \right] &amp;amp;= \lim_{N \to \infty} \frac{1}{N} \sum_{n = 1}^{N} \delta(\varepsilon(n)) = \lim_{N \to \infty} \frac{1}{N} \sum_{n = 1, \varepsilon(n) = 0}^{N} 1 \\
&amp;amp;= P(\varepsilon = 0)
\end{align*}
&lt;/div&gt;
&lt;p&gt;よって、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\mathrm{E} \left[\delta(\varepsilon(n)) x(n - m) x(n - k) \right] = P(\varepsilon = 0) \mathrm{E} \left[ x(n - m) x(n - k) \right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(P(\varepsilon = 0)\)&lt;/span&gt; を考える。まず注意したいのは、連続型確率分布においては一点0をとる確率は0ということ（測度0だから）。近似するしかなく、方針としては、&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;残差の閾値を定めて、それ以下の数値を残差0とみなして確率を求める&lt;/li&gt;
&lt;li&gt;離散型確率分布で考える&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ラプラス分布の基本的なことをおさらいすると、確率密度関数 &lt;span class="math"&gt;\(f(x, \mu, \sigma)\)&lt;/span&gt; は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f(x, \mu, \sigma) = \frac{1}{2 \sigma} \exp\left( - \frac{|x - \mu|}{\sigma} \right)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;で、観測 &lt;span class="math"&gt;\(x_{1}, ..., x_{N}\)&lt;/span&gt; が得られた時の尤度関数 &lt;span class="math"&gt;\(L(\mu, \sigma)\)&lt;/span&gt; と対数尤度関数は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
L(\mu, \sigma) &amp;amp;= \prod_{i = 1}^{N} \frac{1}{2 \sigma} \exp\left( - \frac{|x_{i} - \mu|}{\sigma} \right) = \frac{1}{(2 \sigma)^{N}} \prod_{i = 1}^{N} \exp\left( - \frac{|x_{i} - \mu|}{\sigma} \right) \\
\log L(\mu, \sigma) &amp;amp;= -N\log(2\sigma) -\sum_{i = 1}^{N} \frac{|x_{i} - \mu|}{\sigma} = -N\log(2\sigma) - \frac{1}{\sigma}\sum_{i = 1}^{N} |x_{i} - \mu|
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\mu\)&lt;/span&gt; の最尤推定量は標本中央値となる。&lt;span class="math"&gt;\(\mu\)&lt;/span&gt; が求まったとして、次は &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; の最尤推定値を考える。対数尤度関数を &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; で偏微分すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\frac{\partial}{\partial \sigma} \log L(\mu, \sigma) = -2 \frac{N}{2\sigma} + \frac{1}{\sigma^{2}} \sum_{i = 1}^{N} |x_{i} - \mu| = -\frac{N}{\sigma} + \frac{1}{\sigma^{2}} \sum_{i = 1}^{N} |x_{i} - \mu|
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac{\partial}{\partial \sigma} \log L(\mu, \sigma) = 0\)&lt;/span&gt; とおいて &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; について解くと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\frac{N}{\sigma} = \frac{1}{\sigma^{2}} \sum_{i = 1}^{N} |x_{i} - \mu| \Rightarrow \sigma = \frac{1}{N} \sum_{i = 1}^{N} |x_{i} - \mu|
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; の最尤推定値は偏差の絶対値の標本平均となる。次に離散ラプラス分布を考える（ &lt;a class="reference external" href="https://shodhganga.inflibnet.ac.in/bitstream/10603/30871/11/11_chapter%206.pdf"&gt;ここ&lt;/a&gt; を参考にしている）。離散ラプラス分布は次の確率（質量）関数 &lt;span class="math"&gt;\(P\)&lt;/span&gt; を持つ:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
P(X = k) &amp;amp;= \frac{f(k, 0, \sigma)}{\sum_{j = -\infty}^{\infty} f(j, 0, \sigma)} = \frac{\exp\left( -\frac{|k|}{\sigma} \right)}{\sum_{j = -\infty}^{\infty} \exp\left( -\frac{|j|}{\sigma} \right)} \\
&amp;amp;= \frac{\exp\left( -\frac{|k|}{\sigma} \right)}{1 + 2 \sum_{j = 1}^{\infty} \exp\left( -\frac{j}{\sigma} \right)}
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\sum_{j = 1}^{\infty} \exp\left( -\frac{j}{\sigma} \right) = \lim_{n \to \infty} \frac{\exp(-1/\sigma)(1 - \exp(-n/\sigma))}{1 - \exp(-1/\sigma)} = \frac{\exp(-1/\sigma)}{1 - \exp(-1/\sigma)}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;よって、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
P(X = k) &amp;amp;= \frac{\exp\left( -\frac{|k|}{\sigma} \right)}{1 + 2 \frac{\exp(-1/\sigma)}{1 - \exp(-1/\sigma)}} = \frac{1 - \exp(-1/\sigma)}{1 + \exp(-1/\sigma)} \exp\left(-\frac{|k|}{\sigma}\right) \\
&amp;amp;= \frac{1 - p}{1 + p} p^{|k|}, \quad p = \exp(-1/\sigma)
\end{align*}
&lt;/div&gt;
&lt;p&gt;これは離散型確率分布であることに注意。&lt;/p&gt;
&lt;p&gt;連続版かつ &lt;span class="math"&gt;\(\mu=0\)&lt;/span&gt; で、 &lt;span class="math"&gt;\(|x|\)&lt;/span&gt; がある閾値 &lt;span class="math"&gt;\(\delta &amp;gt; 0\)&lt;/span&gt; 以下となる確率は次のように計算できる:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
P(|x| \leq \delta) &amp;amp;= \int^{\delta}_{-\delta} f(x, \mu, \sigma) dx = \frac{1}{2 \sigma} \int^{\delta}_{-\delta} \exp\left(-\frac{|x|}{\sigma} \right) dx \\
&amp;amp;= \frac{2}{2\sigma} \int^{\delta}_{0} \exp\left(-\frac{x}{\sigma} \right) dx = \frac{1}{\sigma} (-\sigma) \int^{\delta}_{0} \left\{ \exp\left(-\frac{x}{\sigma} \right) \right\}^{\prime} dx \\
&amp;amp;= -\left[ \exp\left(-\frac{x}{\sigma} \right) \right]^{\delta}_{0} = \exp(0) - \exp\left( - \frac{\delta}{\sigma} \right) \\
&amp;amp;= 1 - \exp\left( - \frac{\delta}{\sigma} \right)
\end{align*}
&lt;/div&gt;
&lt;p&gt;この式により分散行列にかける係数を決めることを考えると、次が考察される。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\delta\)&lt;/span&gt; が大きい（分散 &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; が小さい）と確率が1に近づき、分散行列はLMSのそれと近くなる。&lt;/li&gt;
&lt;li&gt;逆に &lt;span class="math"&gt;\(\delta\)&lt;/span&gt; が小さい（分散 &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; が大きい）と分散行列に小さいスカラーを乗じる。分散行列の逆行列をとると、大きいスカラーを乗じることになり、勾配ベクトルのノルムが大きくなりそう。&lt;/li&gt;
&lt;li&gt;ノイズレベル（&lt;span class="math"&gt;\(\approx\)&lt;/span&gt; 分散）が小さいときは勾配が小さくなり極値付近を精密に調べ、大きい場合は勾配が大きくなりダイナミックに探索空間を動き回りそう。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="lms"&gt;
&lt;h2&gt;LMSの性能解析に関する文献&lt;/h2&gt;
&lt;p&gt;色々さまよっているうちに出てきた。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.ee.cityu.edu.hk/~hcso/it6303_4.pdf"&gt;Adaptive Filter Theory and Applications&lt;/a&gt; にLMSのステップサイズのとり方に関する記述あり。証明に有益。&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.dsp-book.narod.ru/DSPMW/19.PDF"&gt;Convergence Issues in the LMS Adaptive Filter&lt;/a&gt; も結構有益。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="todo"&gt;
&lt;h3&gt;TODO&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;評価を続ける。評価がまとまったら結果共有に入りたい。&lt;ul&gt;
&lt;li&gt;LMSの適応動作は、単層パーセプトロンの学習にも該当する。NNの観点からも引き続き論文調査を行うべし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;OMPを使う。&lt;/li&gt;
&lt;li&gt;メッセージパッシング使えない？&lt;ul&gt;
&lt;li&gt;何らかの確率モデル化をせよ、というふうに受け取った。&lt;/li&gt;
&lt;li&gt;AMP, Survay-Propagation（三村さん、樺島さん）がありえる。&lt;/li&gt;
&lt;li&gt;→ AMP, Survay-Propagationについて調査すべし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;いろんな論文で自然勾配をどうやって定義しているか要観察。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;優先度低&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;パーティクルフィルター使えない？&lt;ul&gt;
&lt;li&gt;今日検討した結果、ちょっと今は保留。大量のサンプルが必要そうに見える。計算負荷を気にした結果、優先度を低くした。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="LAD"></category><category term="IRLS"></category></entry><entry><title>LMS Filterの挙動観察中(1)</title><link href="/lms-filternoju-dong-guan-cha-zhong-1.html" rel="alternate"></link><published>2020-04-27T23:40:00+09:00</published><updated>2020-04-27T23:40:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-27:/lms-filternoju-dong-guan-cha-zhong-1.html</id><summary type="html">&lt;p&gt;引き続き観察中。勾配の計算ミスがあったりして厳しかった。&lt;/p&gt;
&lt;p&gt;問題は、やはりというかSignLMSでのヘッセ行列。&lt;span class="math"&gt;\(\mathrm{E}[\varepsilon((n))x(n-m)x(n-k)]\)&lt;/span&gt; の計算でインパルス応答の扱いをどうするのか...連続信号では厳密に0を取る確率は0だ。だからといって離散的に考えていいのか？&lt;/p&gt;
&lt;p&gt;誤差の絶対値を取って閾値以下ならば分散行列に加算する処理を入れたが、分散行列が特異になること多し。&lt;/p&gt;
&lt;p&gt;デジタル的に考えれば、残差が0になる確率で重み付けしていいのでは無いかと思う。 またデジタル的に考えた時
残差が0になる確率は、離散ラプラス分布（ &lt;a class="reference external" href="https://shodhganga.inflibnet.ac.in/bitstream/10603/30871/11/11_chapter%206.pdf"&gt;参考資料&lt;/a&gt; ）を元にサンプリング/もしくは重み付けで求める。（サンプリングの場合は[0,1]乱数を発生させて残差が0になる確率よりも小さければ採択する。まじのMC。というか、サンプリングしても重み付けしても同じでは？）分散パラメータは観測分散で求める。&lt;/p&gt;
&lt;p&gt;一旦残差0の重み付けで実験を進めているが、まだ残差0確率が怪しい感じ。（0.93とかいう現実離れした数値。実際の音声では約0.09とかそんなん）&lt;/p&gt;
&lt;p&gt;見やすいようにパラメータを2つにしている。2つにした時でも同じ出力を与える組み合わせがあり、それが直線上に並んでいる事がわかっている。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent …&lt;/script&gt;</summary><content type="html">&lt;p&gt;引き続き観察中。勾配の計算ミスがあったりして厳しかった。&lt;/p&gt;
&lt;p&gt;問題は、やはりというかSignLMSでのヘッセ行列。&lt;span class="math"&gt;\(\mathrm{E}[\varepsilon((n))x(n-m)x(n-k)]\)&lt;/span&gt; の計算でインパルス応答の扱いをどうするのか...連続信号では厳密に0を取る確率は0だ。だからといって離散的に考えていいのか？&lt;/p&gt;
&lt;p&gt;誤差の絶対値を取って閾値以下ならば分散行列に加算する処理を入れたが、分散行列が特異になること多し。&lt;/p&gt;
&lt;p&gt;デジタル的に考えれば、残差が0になる確率で重み付けしていいのでは無いかと思う。 またデジタル的に考えた時
残差が0になる確率は、離散ラプラス分布（ &lt;a class="reference external" href="https://shodhganga.inflibnet.ac.in/bitstream/10603/30871/11/11_chapter%206.pdf"&gt;参考資料&lt;/a&gt; ）を元にサンプリング/もしくは重み付けで求める。（サンプリングの場合は[0,1]乱数を発生させて残差が0になる確率よりも小さければ採択する。まじのMC。というか、サンプリングしても重み付けしても同じでは？）分散パラメータは観測分散で求める。&lt;/p&gt;
&lt;p&gt;一旦残差0の重み付けで実験を進めているが、まだ残差0確率が怪しい感じ。（0.93とかいう現実離れした数値。実際の音声では約0.09とかそんなん）&lt;/p&gt;
&lt;p&gt;見やすいようにパラメータを2つにしている。2つにした時でも同じ出力を与える組み合わせがあり、それが直線上に並んでいる事がわかっている。&lt;/p&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category></entry><entry><title>LMS Filterの挙動観察</title><link href="/lms-filternoju-dong-guan-cha.html" rel="alternate"></link><published>2020-04-24T11:40:00+09:00</published><updated>2020-04-24T11:40:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-24:/lms-filternoju-dong-guan-cha.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;今日はJupyterを使って残差・残差勾配を観察していく。もう夜遅いのでnotebook上げるの挑戦できず。
勾配の計算にミスがあり、残差分布と勾配の結果が一致していなかった…3時間ほど飛ばす。&lt;/p&gt;
&lt;p&gt;ラプラス分布の観測分散が怪しい...&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://math.stackexchange.com/questions/922521/deriving-mean-and-variance-of-laplace-distribution"&gt;Deriving Mean and Variance of Laplace Distribution&lt;/a&gt; に1次元の場合がある。&lt;/li&gt;
&lt;/ul&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false …&lt;/script&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;今日はJupyterを使って残差・残差勾配を観察していく。もう夜遅いのでnotebook上げるの挑戦できず。
勾配の計算にミスがあり、残差分布と勾配の結果が一致していなかった…3時間ほど飛ばす。&lt;/p&gt;
&lt;p&gt;ラプラス分布の観測分散が怪しい...&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://math.stackexchange.com/questions/922521/deriving-mean-and-variance-of-laplace-distribution"&gt;Deriving Mean and Variance of Laplace Distribution&lt;/a&gt; に1次元の場合がある。&lt;/li&gt;
&lt;/ul&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="Hessian"></category></entry><entry><title>古い記事の移行/Jupyterの環境整備</title><link href="/gu-iji-shi-noyi-xing-jupyternohuan-jing-zheng-bei.html" rel="alternate"></link><published>2020-04-23T23:00:00+09:00</published><updated>2020-04-23T23:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-23:/gu-iji-shi-noyi-xing-jupyternohuan-jing-zheng-bei.html</id><content type="html">&lt;p&gt;評価の前に古い記事の移行とPythonの環境整備。
PythonはJupyterを使う。Vimキーバインドで。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://qiita.com/nakasan/items/ec7741f075f1062350f4#jupyterコマンドモードのショートカットキーまとめ"&gt;Jupyterコマンドモードのショートカットキーまとめ&lt;/a&gt; がよくまとまっていた。これ読んで進めていく。&lt;/li&gt;
&lt;/ul&gt;
</content><category term="雑記"></category><category term="Jupyter"></category></entry><entry><title>Signed-LMSの2階微分 その2</title><link href="/signed-lmsno2jie-wei-fen-sono2.html" rel="alternate"></link><published>2020-04-22T11:34:00+09:00</published><updated>2020-04-22T12:10:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-22:/signed-lmsno2jie-wei-fen-sono2.html</id><summary type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;早速既存研究が無いか見ている。二乗誤差最小化のLMSでもヘッセ行列の逆行列の計算負荷が高いから使わん、という論調がほとんど。Signed-LMSについては今の所、微分してるところも見てない。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://pt.slideshare.net/mentelibre/neural-network-widrowhoff-learning-adaline-hagan-lms"&gt;NEURAL NETWORK Widrow-Hoff Learning Adaline Hagan LMS&lt;/a&gt; 観測分散行列がヘッセ行列に一致することが書いてあった。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www1.coe.neu.edu/~erdogmus/publications/J013_NEUNET_SpIssueIJCNN03_EWCLMS_Yadu.pdf"&gt;Stochastic error whitening algorithm for linear filter estimation with noisy data&lt;/a&gt; 評価関数として絶対値が入ったものを使っている。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://faculty.cord.edu/kamel/09S-380/Presentations/LMS.pdf"&gt;The …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;早速既存研究が無いか見ている。二乗誤差最小化のLMSでもヘッセ行列の逆行列の計算負荷が高いから使わん、という論調がほとんど。Signed-LMSについては今の所、微分してるところも見てない。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://pt.slideshare.net/mentelibre/neural-network-widrowhoff-learning-adaline-hagan-lms"&gt;NEURAL NETWORK Widrow-Hoff Learning Adaline Hagan LMS&lt;/a&gt; 観測分散行列がヘッセ行列に一致することが書いてあった。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www1.coe.neu.edu/~erdogmus/publications/J013_NEUNET_SpIssueIJCNN03_EWCLMS_Yadu.pdf"&gt;Stochastic error whitening algorithm for linear filter estimation with noisy data&lt;/a&gt; 評価関数として絶対値が入ったものを使っている。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://faculty.cord.edu/kamel/09S-380/Presentations/LMS.pdf"&gt;The Least Mean Squares Algorithm&lt;/a&gt; 分かりやすめな解説。そうか、ウィーナーフィルタか。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;行列 &lt;span class="math"&gt;\(\ve{X}\ve{X}^{\mathsf{T}}\)&lt;/span&gt; が正則にならない件について、これ正則化すればいいんじゃねと思い立つ。要は &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; を正則化パラメータとして &lt;span class="math"&gt;\(\ve{X}\ve{X}^{\mathsf{T}} + \lambda \ve{I}\)&lt;/span&gt; に対して逆行列を求めていく。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;多分、係数側に正則項を追加することになるはず。&lt;span class="math"&gt;\(\min \mathrm{E}[|\varepsilon(n)|] + \lambda ||\ve{h}||_{2}\)&lt;/span&gt; のような定式化か？&lt;/li&gt;
&lt;li&gt;それでも逆行列 &lt;span class="math"&gt;\((\ve{X}\ve{X}^{\mathsf{T}} + \lambda \ve{I})^{-1}\)&lt;/span&gt; を求めるのは骨が折れそう。そこで、自然勾配学習で使っていた適応的自然勾配学習法（ &lt;a class="reference external" href="https://bsi-ni.brain.riken.jp/database/file/274/280.pdf"&gt;Singularities Affect Dynamics of Learning in Neuromanifolds&lt;/a&gt; より）が使えそう。具体的には、次の式で自然勾配を適応的に求めていく。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{G}_{t+1}^{-1} = (1 + \varepsilon_{t}) \ve{G}_{t}^{-1} - \varepsilon_{t} \ve{G}_{t}^{-1} \parfrac{J(\ve{h})}{\ve{h}} \left( \ve{G}_{t}^{-1} \parfrac{J(\ve{h})}{\ve{h}} \right)^{\mathsf{T}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで &lt;span class="math"&gt;\(\varepsilon_{t}\)&lt;/span&gt; は小さな定数。『情報幾何の新展開』では、カルマンフィルタ由来らしい。うーん、もう試してみたいな。&lt;/p&gt;
&lt;div class="section" id="ve-x-ve-x-mathsf-t-lambda-ve-i"&gt;
&lt;h2&gt;（念の為） &lt;span class="math"&gt;\(\ve{X}\ve{X}^{\mathsf{T}} + \lambda \ve{I}\)&lt;/span&gt; が正則行列になる理由&lt;/h2&gt;
&lt;p&gt;すぐに思い出せなくてヒヤッとしたのでここで示しておく。&lt;span class="math"&gt;\(\ve{X}\ve{X}^{\mathsf{T}}\)&lt;/span&gt; は対称行列だから、直交行列 &lt;span class="math"&gt;\(\ve{P}\)&lt;/span&gt; （&lt;span class="math"&gt;\(\ve{P}^{-1} = \ve{P}^{\mathsf{T}}\)&lt;/span&gt; ）と固有値を並べた対角行列 &lt;span class="math"&gt;\(\ve{\Lambda}\)&lt;/span&gt; を用いて、&lt;span class="math"&gt;\(\ve{X}\ve{X}^{\mathsf{T}} = \ve{P}^{\mathsf{T}} \ve{\Lambda} \ve{P}\)&lt;/span&gt; と対角化できる。よって、&lt;span class="math"&gt;\(\lambda &amp;gt; 0\)&lt;/span&gt; なる定数を用いた時、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ve{X}\ve{X}^{\mathsf{T}} + \lambda \ve{I} &amp;amp;= \ve{P}^{\mathsf{T}} \ve{\Lambda} \ve{P} + \lambda \ve{P}^{\mathsf{T}} \ve{P} \\
&amp;amp;= \ve{P}^{\mathsf{T}} \ve{\Lambda} \ve{P} + \ve{P}^{\mathsf{T}} \lambda \ve{I} \ve{P} \\
&amp;amp;= \ve{P}^{\mathsf{T}} (\ve{\Lambda} + \lambda \ve{I}) \ve{P}
\end{align*}
&lt;/div&gt;
&lt;p&gt;また、任意のベクトル &lt;span class="math"&gt;\(\ve{v}\)&lt;/span&gt; を使った時、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ve{v}^{\mathsf{T}} \ve{X} \ve{X}^{\mathsf{T}} \ve{v} &amp;amp;= (\ve{X}^{\mathsf{T}} \ve{v})^{\mathsf{T}} \ve{X}^{\mathsf{T}} \ve{v} = ||\ve{X}^{\mathsf{T}} \ve{v} ||_{2}^{2} \\
\ve{v}^{\mathsf{T}} \ve{X} \ve{X}^{\mathsf{T}} \ve{v} &amp;amp;= \ve{v}^{\mathsf{T}} \ve{P}^{\mathsf{T}} \ve{\Lambda} \ve{P} \ve{v} = \sum_{i}^{N} \ve{\Lambda}_{ii} (\ve{Pv})_{i}^{2} \\
\Rightarrow ||\ve{X}^{\mathsf{T}} \ve{v} ||_{2}^{2} &amp;amp;= \sum_{i}^{N} \ve{\Lambda}_{ii} (\ve{Pv})_{i}^{2} \geq 0
\end{align*}
&lt;/div&gt;
&lt;p&gt;の関係式が成り立つ。最後の不等式が成り立つには、全ての &lt;span class="math"&gt;\(i\)&lt;/span&gt; に対して &lt;span class="math"&gt;\(\ve{\Lambda}_{ii} \geq 0\)&lt;/span&gt; でなければならない。よって &lt;span class="math"&gt;\(\ve{XX}^{\mathsf{T}}\)&lt;/span&gt; の固有値は全て非負。&lt;/p&gt;
&lt;p&gt;ここで &lt;span class="math"&gt;\(\ve{P}^{\mathsf{T}} (\ve{\Lambda} + \lambda \ve{I}) \ve{P}\)&lt;/span&gt; に注目すると、全ての固有値に &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; が足されていることが分かる。&lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; は正だから、 &lt;span class="math"&gt;\(\ve{X}\ve{X}^{\mathsf{T}} + \lambda \ve{I}\)&lt;/span&gt; の固有値は全て正になり正定値行列となる。正定値行列は正則だから、 &lt;span class="math"&gt;\(\ve{X}\ve{X}^{\mathsf{T}} + \lambda \ve{I}\)&lt;/span&gt; は正則行列。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;フィッシャー情報行列とヘッセ行列と分散行列の絡みについて&lt;/h2&gt;
&lt;p&gt;以下の記事が非常にわかりやすい。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiseodd.github.io/techblog/2018/03/11/fisher-information/"&gt;Fisher Information Matrix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiseodd.github.io/techblog/2018/03/14/natural-gradient/"&gt;Natural Gradient Descent&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;結論、ラプラス分布に従う残差を仮定した最尤推定において、観測分散行列はフィッシャー情報行列に一致し、その逆行列は自然勾配に該当するはず。つうかニュートン法の特殊ケースに見えるがどうなんでしょ。フィッシャー情報行列がヘッセ行列に見えるんだが、定義通り（対数尤度のヘッセ行列）そうだよな。指数族の最尤推定をニュートン法で解こうとしたら全部自然勾配学習法にならね？&lt;/p&gt;
&lt;div class="section" id="todo"&gt;
&lt;h3&gt;TODO&lt;/h3&gt;
&lt;p&gt;評価のことを考えて行きたい。固定した信号（答えが分かっている信号。乱数固定。）を使ったときに、誤差平面と勾配はどうなっている？フィルタの次元は2ぐらいにして、フィルタを固定して各統計量がどうなっているかプロットする。まずは絶対値残差と勾配の観察が重要に思える（もちろん、2次の最小化ケースも重要）。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;評価がまとまったら結果共有に入りたい。&lt;/li&gt;
&lt;li&gt;OMPを使う。&lt;/li&gt;
&lt;li&gt;メッセージパッシング使えない？&lt;ul&gt;
&lt;li&gt;何らかの確率モデル化をせよ、というふうに受け取った。&lt;/li&gt;
&lt;li&gt;AMP, Survay-Propagation（三村さん、樺島さん）がありえる。&lt;/li&gt;
&lt;li&gt;→ AMP, Survay-Propagationについて調査すべし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;いろんな論文で自然勾配をどうやって定義しているか要観察。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category><category term="Fisher Information Matrix"></category><category term="Hessian"></category><category term="Natural Gradient"></category></entry><entry><title>残差勾配 \(\mathrm{E}[\varepsilon(n) x(n - m)]\) の挙動観察/Signed-LMSの目的関数の2階微分</title><link href="/can-chai-gou-pei-mathrmevarepsilonn-xn-m-noju-dong-guan-cha-signed-lmsnomu-de-guan-shu-no2jie-wei-fen.html" rel="alternate"></link><published>2020-04-21T12:10:00+09:00</published><updated>2020-04-21T12:10:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-21:/can-chai-gou-pei-mathrmevarepsilonn-xn-m-noju-dong-guan-cha-signed-lmsnomu-de-guan-shu-no2jie-wei-fen.html</id><summary type="html">&lt;div class="section" id="mathrm-e-varepsilon-n-x-n-m"&gt;
&lt;h2&gt;残差勾配 &lt;span class="math"&gt;\(\mathrm{E}[\varepsilon(n) x(n - m)]\)&lt;/span&gt; の挙動観察&lt;/h2&gt;
&lt;p&gt;&lt;span class="math"&gt;\(m\)&lt;/span&gt; が大きいときは無視できるのでは？ なお、長時間平均値は0に収束していることを見た。
&lt;span class="math"&gt;\(m\)&lt;/span&gt; をずらした時の平均値の様子を見る。どこかで影響が小さくなって打ち切れるはず。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;ガチャガチャ弄ってるってるけど示唆があんまりない。&lt;/li&gt;
&lt;li&gt;低次（〜10）の係数は大きく変動する傾向。しかし、次に述べるピッチなどに影響しているのか、全てに当てはまる傾向ではない。&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathrm{E}[\varepsilon(n) x(n - m)]\)&lt;/span&gt; は &lt;span class="math"&gt;\(m\)&lt;/span&gt; を大きくすれば単調減少するわけではない。音源依存で傾向が異なる。ピッチ？か何かに反応して大きくなる場合がある。&lt;/li&gt;
&lt;li&gt;同一発音区間では、フィルタ係数の符号は同一になる傾向が見られる。単一のsin波を等価させたときはわかりやすい。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="440.0Hzのsin波に対する各タップの平均勾配変化グラフ" src="./images/sin_mean_gradient.png" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;440.0Hzのsin波に対する各タップの平均勾配変化&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="ボイス対する各タップの平均勾配変化グラフ" src="./images/voice_mean_gradient.png" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;ボイス対する各タップの平均勾配変化&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="ピアノ演奏に対する各タップの平均勾配変化グラフ" src="./images/ruriko_mean_gradient.png" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;ピアノ演奏に対する各タップの平均勾配変化&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="signed-lms2"&gt;
&lt;h2&gt;Signed-LMSの目的関数の2階微分&lt;/h2&gt;
&lt;p&gt;勇気を出してやってみる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2 …&lt;/div&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="mathrm-e-varepsilon-n-x-n-m"&gt;
&lt;h2&gt;残差勾配 &lt;span class="math"&gt;\(\mathrm{E}[\varepsilon(n) x(n - m)]\)&lt;/span&gt; の挙動観察&lt;/h2&gt;
&lt;p&gt;&lt;span class="math"&gt;\(m\)&lt;/span&gt; が大きいときは無視できるのでは？ なお、長時間平均値は0に収束していることを見た。
&lt;span class="math"&gt;\(m\)&lt;/span&gt; をずらした時の平均値の様子を見る。どこかで影響が小さくなって打ち切れるはず。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;ガチャガチャ弄ってるってるけど示唆があんまりない。&lt;/li&gt;
&lt;li&gt;低次（〜10）の係数は大きく変動する傾向。しかし、次に述べるピッチなどに影響しているのか、全てに当てはまる傾向ではない。&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathrm{E}[\varepsilon(n) x(n - m)]\)&lt;/span&gt; は &lt;span class="math"&gt;\(m\)&lt;/span&gt; を大きくすれば単調減少するわけではない。音源依存で傾向が異なる。ピッチ？か何かに反応して大きくなる場合がある。&lt;/li&gt;
&lt;li&gt;同一発音区間では、フィルタ係数の符号は同一になる傾向が見られる。単一のsin波を等価させたときはわかりやすい。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="440.0Hzのsin波に対する各タップの平均勾配変化グラフ" src="./images/sin_mean_gradient.png" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;440.0Hzのsin波に対する各タップの平均勾配変化&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="ボイス対する各タップの平均勾配変化グラフ" src="./images/voice_mean_gradient.png" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;ボイス対する各タップの平均勾配変化&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="ピアノ演奏に対する各タップの平均勾配変化グラフ" src="./images/ruriko_mean_gradient.png" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;ピアノ演奏に対する各タップの平均勾配変化&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="signed-lms2"&gt;
&lt;h2&gt;Signed-LMSの目的関数の2階微分&lt;/h2&gt;
&lt;p&gt;勇気を出してやってみる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;符号関数を &lt;span class="math"&gt;\(\tanh(Tx)\)&lt;/span&gt; で近似して微分してみる（&lt;span class="math"&gt;\(T\)&lt;/span&gt; は温度パラメータで、&lt;span class="math"&gt;\(\tanh(Tx)\)&lt;/span&gt; を &lt;span class="math"&gt;\(T \to \infty\)&lt;/span&gt; ならしめれば符号関数に近づく）と、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\frac{d}{dx} \tanh(Tx) = T (\tanh(Tx))^{\prime} = T(1 - \tanh^{2}(Tx))
\end{equation*}
&lt;/div&gt;
&lt;p&gt;さて、 &lt;span class="math"&gt;\(1 - \tanh^{2}(Tx)\)&lt;/span&gt; に注目すると、&lt;span class="math"&gt;\(T\)&lt;/span&gt; の極限では &lt;span class="math"&gt;\(x = 0\)&lt;/span&gt; を除き0を取るが、&lt;span class="math"&gt;\(x = 0\)&lt;/span&gt; において1を取る。よってこれはインパルス関数になる（極限と微分操作を交換したけどやかましいことは暗黙で...）。&lt;/p&gt;
&lt;p&gt;符号関数を微分するとインパルス関数が出てくることについては &lt;a class="reference external" href="https://teenaka.at.webry.info/201301/article_10.html"&gt;超関数的微分_δ関数関連（２）&lt;/a&gt; を見るのが早いかも。以下では、その話に従って、&lt;span class="math"&gt;\(\frac{d}{dx} \mathrm{sign}(x) = 2\delta(x)\)&lt;/span&gt; とする。&lt;/p&gt;
&lt;p&gt;さて、今一度評価関数 &lt;span class="math"&gt;\(\mathrm{E}[|\varepsilon(n)|]\)&lt;/span&gt; の偏微分と2階の偏導関数を考える。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\parfrac{}{h(m)} \mathrm{E}[|\varepsilon(n)|] &amp;amp;= \mathrm{E}\left[ \parfrac{}{h(m)} |\varepsilon(n)| \right] \\
&amp;amp;= \mathrm{E}\left[ \left\{ \parfrac{}{h(m)} \varepsilon(n) \right\} \mathrm{sign}[\varepsilon(n)] \right] \\
&amp;amp;= -\mathrm{E}\left[ \mathrm{sign}[\varepsilon(n)]  x(n - m) \right] \\
\frac{\partial^{2}}{\partial h(m) \partial h(k)} \mathrm{E}[|\varepsilon(n)|] &amp;amp;= - \parfrac{}{h(k)} \mathrm{E}\left[ \mathrm{sign}[\varepsilon(n)]  x(n - m) \right] \\
&amp;amp;= - \mathrm{E}\left[ \left\{ \parfrac{}{h(k)} \varepsilon(n) \right\} 2\delta(\varepsilon(n)) x(n - m) \right] \\
&amp;amp;= 2\mathrm{E}\left[ \delta(\varepsilon(n)) x(n - m) x(n - k) \right]
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで &lt;span class="math"&gt;\(\mathrm{E}\left[ \delta(\varepsilon(n)) x(n - m) x(n - k) \right]\)&lt;/span&gt; に注目する。これは &lt;span class="math"&gt;\(\varepsilon(n) = 0\)&lt;/span&gt; のときだけ和を取る演算だ。&lt;span class="math"&gt;\(\sum\)&lt;/span&gt; を用いると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\mathrm{E}\left[ \delta(\varepsilon(n)) x(n - m) x(n - k) \right] = \lim_{N \to \infty} \frac{1}{N} \sum_{n = 1, \varepsilon(n) = 0}^{N} x(n - m) x(n - k)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;という計算に該当する。厳密計算は &lt;span class="math"&gt;\(\varepsilon(n) = 0\)&lt;/span&gt; なる &lt;span class="math"&gt;\(n\)&lt;/span&gt; を見つけたら足していく感じでいいと思うけど、今は &lt;span class="math"&gt;\(\varepsilon(n)\)&lt;/span&gt; はラプラス分布に従うと仮定している。だからラプラス分布に従って &lt;span class="math"&gt;\(P(\varepsilon(n) = 0) = \frac{1}{2\lambda}\)&lt;/span&gt; （分散 &lt;span class="math"&gt;\(2\lambda^{2}\)&lt;/span&gt; ）の重み付けをして計算してしまって良いように見えるのだがどうなんだろう。なんか怪しくて考え続けている。&lt;/p&gt;
&lt;p&gt;もし適応フィルタに組み込むなら、残差が0になったら上の式に従ってヘッセ行列を更新し、ニュートン法を使い続ける。これは試してみたい。問題はヘッセ行列が逆行列を持つかというところ…4-20で半正定値であることは確認したが正定値とは限らない。共役勾配法を検討する必要があるかも。&lt;span class="math"&gt;\(\ve{X}\ve{X}^{\mathsf{T}}\)&lt;/span&gt; は正則になるとは思えない…。（軽く試したけどすぐにだめな例が見つかった。）&lt;/p&gt;
&lt;div class="section" id="id1"&gt;
&lt;h3&gt;他の頂いたアイディア&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;周波数領域に一旦飛ばすのはあり？&lt;ul&gt;
&lt;li&gt;ありだけど計算量が高い。圧縮率が上がるのであれば大アリ。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;確率的PCAとか使えない？辞書は小さくて済む。&lt;/li&gt;
&lt;li&gt;線形ダイナミクスにより上手く定式化できない？&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="id2"&gt;
&lt;h4&gt;優先度低&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;出す学会については先生に聞くこと。&lt;ul&gt;
&lt;li&gt;相談する機会はどこかで絶対に必要。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;著作権処理済み音源データベースについて相談&lt;ul&gt;
&lt;li&gt;→ 自分で情報をまとめて、申し込んでいいかというところまで進めるべし。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://staff.aist.go.jp/m.goto/PAPER/SIGMUS200205goto.pdf"&gt;RWC 研究用音楽データベース: 音楽ジャンルデータベースと楽器音データベース&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://staff.aist.go.jp/m.goto/RWC-MDB/index-j.html"&gt;RWC研究用音楽データベース&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;→ 進めた。動けるようになったら書類をまとめていく。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Donohoさんなどが圧縮センシングの文脈で既にやりきってない？&lt;ul&gt;
&lt;li&gt;ありえる。調査すべし。&lt;/li&gt;
&lt;li&gt;→ ライス大学では成果をすべて公開しているから見るだけ見たほうが良い。&lt;/li&gt;
&lt;li&gt;→ &lt;a class="reference external" href="http://dsp.rice.edu/cs/"&gt;http://dsp.rice.edu/cs/&lt;/a&gt; を見よ。&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://hal.archives-ouvertes.fr/hal-00424165/document"&gt;Compressed sensing block MAP-LMS adaptive filter for sparse channel estimation and a bayesian Cramer-Rao bound&lt;/a&gt; 残差はガウス分布としてるけどクラメル-ラオ下限との絡みを述べている。何か重要そう。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.dbabacan.info/papers/babacan_CS.pdf"&gt;Bayesian Compressive Sensing Using Laplace Priors&lt;/a&gt; これもパラメータの事前分布にラプラス分布を導入してベイズ推定するもの。残差ではないはず。&lt;/li&gt;
&lt;li&gt;「L1」, 「Laplace」, 「residual」, 「lossless」で検索したけどスパース解を求めるものばかり。今のところはセーフ？&lt;/li&gt;
&lt;li&gt;→ 継続して調査はする。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="SignedLMS"></category></entry><entry><title>IRLSの更新式について</title><link href="/irlsnogeng-xin-shi-nitsuite.html" rel="alternate"></link><published>2020-04-20T14:10:00+09:00</published><updated>2020-04-21T12:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-20:/irlsnogeng-xin-shi-nitsuite.html</id><summary type="html">&lt;p&gt;MathJaxの環境を確認しつつ使用中。プリアンブルが無いけどページ内で一回 &lt;tt class="docutils literal"&gt;newcommand&lt;/tt&gt; を行えばずっと使えるみたい。便利。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;逐次的更新の件について。IRLSでは以下の評価関数 &lt;span class="math"&gt;\(J(\ve{\beta})\)&lt;/span&gt; の最小化を考える。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
J(\ve{\beta}) = \sum^{M}_{i = 1} w_{i} (y_{i} - \innerp …&lt;/div&gt;</summary><content type="html">&lt;p&gt;MathJaxの環境を確認しつつ使用中。プリアンブルが無いけどページ内で一回 &lt;tt class="docutils literal"&gt;newcommand&lt;/tt&gt; を行えばずっと使えるみたい。便利。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;逐次的更新の件について。IRLSでは以下の評価関数 &lt;span class="math"&gt;\(J(\ve{\beta})\)&lt;/span&gt; の最小化を考える。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
J(\ve{\beta}) = \sum^{M}_{i = 1} w_{i} (y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}})^{2}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで &lt;span class="math"&gt;\(M\)&lt;/span&gt; は観測数。これは二次式だから評価関数は凸関数になる。早速 &lt;span class="math"&gt;\(\ve{\beta}\)&lt;/span&gt; で偏微分してみると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\parfrac{}{\ve{\beta}} J(\ve{\beta}) &amp;amp;= \sum^{M}_{i = 1} w_{i} 2 \left(- \frac{\partial}{\partial \ve{\beta}} \innerp{\ve{\beta}}{\ve{x}_{i}} \right) (y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}}) \\
 &amp;amp;= -2 \sum^{M}_{i = 1} w_{i} (y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}}) \ve{x}_{i}
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\parfrac{}{\ve{\beta}} J(\ve{\beta}) = 0\)&lt;/span&gt; とおくと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\sum_{i = 1}^{M} w_{i} \innerp{\ve{\beta}}{\ve{x}_{i}} \ve{x}_{i} &amp;amp;= \sum_{i = 1}^{M} w_{i} y_{i} \ve{x}_{i} \\
\iff
\left[ \ve{x}_{1} ... \ve{x}_{M} \right]
\left[
 \begin{array}{c}
   w_{1} \innerp{\ve{\beta}}{\ve{x}_{1}} \\
   \vdots     \\
   w_{M} \innerp{\ve{\beta}}{\ve{x}_{M}}
 \end{array}
\right]
&amp;amp;=
\left[ \ve{x}_{1} ... \ve{x}_{M} \right]
\left[
 \begin{array}{c}
   w_{1}y_{1} \\
   \vdots     \\
   w_{M}y_{M}
 \end{array}
\right]
\\
\iff
\left[ \ve{x}_{1} ... \ve{x}_{M} \right]
\left[
 \begin{array}{ccc}
   w_{1}  &amp;amp; \dots  &amp;amp; 0      \\
   \vdots &amp;amp; \ddots &amp;amp; \vdots \\
   0      &amp;amp; \dots  &amp;amp; w_{M}
 \end{array}
\right]
\left[
 \begin{array}{c}
   \innerp{\ve{\beta}}{\ve{x}_{1}} \\
   \vdots     \\
   \innerp{\ve{\beta}}{\ve{x}_{M}}
 \end{array}
\right]
&amp;amp;=
\left[ \ve{x}_{1} ... \ve{x}_{M} \right]
\left[
 \begin{array}{ccc}
   w_{1}  &amp;amp; \dots  &amp;amp; 0      \\
   \vdots &amp;amp; \ddots &amp;amp; \vdots \\
   0      &amp;amp; \dots  &amp;amp; w_{M}
 \end{array}
\right]
\left[
 \begin{array}{c}
   y_{1} \\
   \vdots     \\
   y_{M}
 \end{array}
\right]
\\
\iff
\left[ \ve{x}_{1} ... \ve{x}_{M} \right]
\left[
 \begin{array}{ccc}
   w_{1}  &amp;amp; \dots  &amp;amp; 0      \\
   \vdots &amp;amp; \ddots &amp;amp; \vdots \\
   0      &amp;amp; \dots  &amp;amp; w_{M}
 \end{array}
\right]
\left[
 \begin{array}{c}
   \ve{x}_{1}^{\mathsf{T}} \\
   \vdots     \\
   \ve{x}_{M}^{\mathsf{T}}
 \end{array}
\right]
\ve{\beta}
&amp;amp;=
\left[ \ve{x}_{1} ... \ve{x}_{M} \right]
\left[
 \begin{array}{ccc}
   w_{1}  &amp;amp; \dots  &amp;amp; 0      \\
   \vdots &amp;amp; \ddots &amp;amp; \vdots \\
   0      &amp;amp; \dots  &amp;amp; w_{M}
 \end{array}
\right]
\ve{y}
\\
\iff
\ve{X} \ve{W} \ve{X}^{\mathsf{T}} \ve{\beta} &amp;amp;= \ve{X} \ve{W} \ve{y}
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\ve{X}\ve{W}\ve{X}^{\mathsf{T}}\)&lt;/span&gt; が正則（TODO: &lt;span class="math"&gt;\(\ve{X}\)&lt;/span&gt; が行フルランク、かつ &lt;span class="math"&gt;\(\ve{W}\)&lt;/span&gt; が正則なら行けそうに見えるけど本当か？）の場合は閉形式で係数が求まる:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{\beta} = (\ve{X} \ve{W} \ve{X}^{\mathsf{T}})^{-1} \ve{X} \ve{W} \ve{y}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここまでは一般論。さて、更新式に注目する。&lt;span class="math"&gt;\(\beta_{j}\)&lt;/span&gt; だけで偏微分してみると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\parfrac{J(\ve{\beta})}{\beta_{j}} &amp;amp;= \sum_{i = 1}^{M} \parfrac{}{\beta_{j}} w_{i} (y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}})^{2} \\
&amp;amp;= -2 \sum_{i = 1}^{M} w_{i} (\ve{x}_{i})_{j} (y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}})
\end{align*}
&lt;/div&gt;
&lt;p&gt;残差のL1ノルム最小化を考えるときは &lt;span class="math"&gt;\(w_{i} = \frac{1}{|y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}}|}\)&lt;/span&gt; とおくので代入すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{J(\ve{\beta})}{\beta_{j}} = -2 \sum_{i = 1}^{M} (\ve{x}_{i})_{j} \mathrm{sign}(y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;瞬間値（&lt;/strong&gt; &lt;span class="math"&gt;\(M=1\)&lt;/span&gt; &lt;strong&gt;とする）を考えるとSigned-LMSの更新式そのものになっている。&lt;/strong&gt; 和を取ると平均操作に近いから、LMSアルゴリズムと考えていることは同じ。&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\parfrac{J(\ve{\beta})}{\beta_{j}}\)&lt;/span&gt; を更に &lt;span class="math"&gt;\(\beta_{k}\)&lt;/span&gt; で偏微分してみると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\frac{\partial^{2} J(\ve{\beta})}{\partial \beta_{j} \partial \beta_{k}} &amp;amp;= -2 \sum_{i = 1}^{M} w_{i} (\ve{x}_{i})_{j} \parfrac{}{\beta_{k}} (y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}}) \\
&amp;amp;= 2 \sum_{i = 1}^{M} w_{i} (\ve{x}_{i})_{j} (\ve{x}_{i})_{k} \\
&amp;amp;= 2 \left[ (\ve{x}_{1})_{j} \dots (\ve{x}_{M})_{j} \right]
 \left[
  \begin{array}{c}
    w_{1} (\ve{x}_{1})_{k} \\
    \vdots     \\
    w_{M} (\ve{x}_{M})_{k}
  \end{array}
 \right]
 = 2 \left[ (\ve{x}_{1})_{j} \dots (\ve{x}_{M})_{j} \right] \ve{W}
 \left[
  \begin{array}{c}
    (\ve{x}_{1})_{k} \\
    \vdots     \\
    (\ve{x}_{M})_{k}
  \end{array}
 \right]
\end{align*}
&lt;/div&gt;
&lt;p&gt;2次式が出てくるのがわかる（&lt;span class="math"&gt;\(\ve{W}\)&lt;/span&gt; は計量だ）。そして &lt;span class="math"&gt;\((\ve{H})_{jk} = \frac{\partial^{2} J(\ve{\beta})}{\partial \beta_{j} \partial \beta_{k}}\)&lt;/span&gt; なるヘッセ行列 &lt;span class="math"&gt;\(\ve{H}\)&lt;/span&gt; は以下:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{H} = 2 \ve{X} \ve{W} \ve{X}^{\mathsf{T}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ヘッセ行列の性質により関数の最小値・最大値の存在がわかる。対称行列なのは間違いない（&lt;span class="math"&gt;\((\ve{X})_{ij} = (\ve{X})_{ji}\)&lt;/span&gt; は自明）。（固有値分解とは見れない。&lt;span class="math"&gt;\(\ve{H}\)&lt;/span&gt; は &lt;span class="math"&gt;\(N \times N\)&lt;/span&gt; の行列であるのに対して、&lt;span class="math"&gt;\(\ve{X}\)&lt;/span&gt; は &lt;span class="math"&gt;\(N \times M\)&lt;/span&gt; の行列。&lt;span class="math"&gt;\(\ve{X} \ve{X}^{\mathsf{T}}\)&lt;/span&gt; は平均化、除算を抜いた分散共分散行列になり半正定値行列。）また、任意のベクトル &lt;span class="math"&gt;\(\ve{v}\)&lt;/span&gt; に対して、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ve{v}^{\mathsf{T}} \ve{X} \ve{W} \ve{X}^{\mathsf{T}} \ve{v} &amp;amp;= \ve{v}^{\mathsf{T}} \ve{X} \ve{W}^{1/2} \ve{W}^{1/2} \ve{X}^{\mathsf{T}} \ve{v} \\
&amp;amp;= (\ve{W}^{1/2} \ve{X}^{\mathsf{T}} \ve{v})^{\mathsf{T}} \ve{W}^{1/2} \ve{X}^{\mathsf{T}} \ve{v} \\
&amp;amp;= || \ve{W}^{1/2} \ve{X}^{\mathsf{T}} \ve{v} ||_{2}^{2} \geq 0
\end{align*}
&lt;/div&gt;
&lt;p&gt;だから、&lt;span class="math"&gt;\(\ve{W}\)&lt;/span&gt; が半正定値（&lt;span class="math"&gt;\(\iff\)&lt;/span&gt; すべての重みが非負）ならばヘッセ行列は半正定値行列で、極小値が最小値になる。また、&lt;span class="math"&gt;\(J(\ve{\beta})\)&lt;/span&gt; は凸関数（半正定値だから狭義の凸関数ではない）。
もう少しヘッセ行列を見る。ヘッセ行列を上手く使えたらニュートン法で解けそうな気がして。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
(\ve{H})_{jk} = 2 \sum_{i = 1}^{M} w_{i} (\ve{x}_{i})_{j} (\ve{x}_{i})_{k}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;より、スペクトル分解的に見ると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\frac{1}{2} \ve{H} &amp;amp;=
w_{1} \left[
  \begin{array}{ccc}
    (\ve{x}_{1})_{1}^{2}  &amp;amp; \dots &amp;amp; (\ve{x}_{1})_{1} (\ve{x}_{1})_{N} \\
    \vdots &amp;amp; \ddots &amp;amp; \vdots \\
    (\ve{x}_{1})_{N} (\ve{x}_{1})_{1} &amp;amp; \dots &amp;amp; (\ve{x}_{1})_{N}^{2} \\
  \end{array}
 \right]
 + \dots +
 w_{M} \left[
  \begin{array}{ccc}
    (\ve{x}_{M})_{1}^{2}  &amp;amp; \dots &amp;amp; (\ve{x}_{M})_{1} (\ve{x}_{M})_{N} \\
    \vdots &amp;amp; \ddots &amp;amp; \vdots \\
    (\ve{x}_{M})_{N} (\ve{x}_{M})_{1} &amp;amp; \dots &amp;amp; (\ve{x}_{M})_{N}^{2} \\
  \end{array}
 \right] \\
 &amp;amp;= w_{1} \ve{x}_{1} \ve{x}_{1}^{\mathsf{T}} + \dots + w_{M} \ve{x}_{M} \ve{x}_{M}^{\mathsf{T}} \\
 &amp;amp;= \sum_{i = 1}^{M} w_{i} \ve{x}_{i} \ve{x}_{i}^{\mathsf{T}}
\end{align*}
&lt;/div&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;信号処理的には &lt;span class="math"&gt;\(\ve{x}_{1}, \ve{x}_{2}, \dots \ve{x}_{M}\)&lt;/span&gt; は系列で現れる。&lt;/li&gt;
&lt;li&gt;LMSフィルタでは &lt;span class="math"&gt;\(i = 1\)&lt;/span&gt; の時だけを考えていたと考えられれる。 &lt;span class="math"&gt;\(i = 2,\dots,M\)&lt;/span&gt; のときの影響は少ないのではないかと思う。&lt;/li&gt;
&lt;li&gt;FIRフィルタを考えるのならば、各 &lt;span class="math"&gt;\(\ve{x}_{1}\)&lt;/span&gt; は入ってきた1次元信号データを時系列順に並べたものだから、直前のベクトル &lt;span class="math"&gt;\(\ve{x}_{2}\)&lt;/span&gt; を使えそうな構造に見える。&lt;/li&gt;
&lt;li&gt;上の仮定を使ってヘッセ行列の逆行列 &lt;span class="math"&gt;\(\ve{H}^{-1}\)&lt;/span&gt; を逐次近似計算できない？&lt;/li&gt;
&lt;li&gt;分散共分散行列がほぼヘッセ行列になってるけどこれは何？&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.iim.cs.tut.ac.jp/~kanatani/papers/jcov.pdf"&gt;金谷さんの解説&lt;/a&gt; にそれとなく解説がある。フィッシャー情報行列との関連もある。。。クラメル・ラオの下限についてわかりやすい説明あり。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://web.econ.keio.ac.jp/staff/bessho/lecture/09/091014ML.pdf"&gt;最尤法&lt;/a&gt; にもそれとなく解説あり。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://oku.edu.mie-u.ac.jp/~okumura/stat/141115.html"&gt;奥村さん&lt;/a&gt; もあり。観測からヘッセ行列を構成できる？&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;そして自然勾配のアイディアが出てくる。自然勾配を使ったLMSアルゴリズムは…あった…&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://scholarsmine.mst.edu/cgi/viewcontent.cgi?referer=https://www.google.com/&amp;amp;httpsredir=1&amp;amp;article=2780&amp;amp;context=ele_comeng_facwork"&gt;Normalized Natural Gradient Adaptive Filtering for Sparse and Nonsparse Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.7538&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;甘利先生による解説&lt;/a&gt; で、LMSアルゴリズム含めて大まかなところはだいたい言ってる。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.researchgate.net/profile/Ligang_Liu3/publication/44098179_On_Improvement_of_Proportionate_Adaptive_Algorithms_for_Sparse_Impulse_Response/links/00b495315266ab9cfd000000.pdf"&gt;高知工科大学の博論&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ワンチャンスL1残差最小化はやってないかも。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TODO:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;前のMTGで言われたことの整理&lt;/li&gt;
&lt;li&gt;分散行列、ヘッセ行列、フィッシャー情報行列、自然勾配の整理&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiseodd.github.io/techblog/2018/03/11/fisher-information/"&gt;Fisher Information Matrix&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;OMPが気になる。試してみたい。&lt;/li&gt;
&lt;/ul&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="IRLS"></category><category term="L1ノルム"></category><category term="LAD"></category></entry><entry><title>IRLS(Iteratively Reweighted Least Squares) その2</title><link href="/irlsiteratively-reweighted-least-squares-sono2.html" rel="alternate"></link><published>2020-04-19T19:30:00+09:00</published><updated>2020-04-20T14:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-19:/irlsiteratively-reweighted-least-squares-sono2.html</id><summary type="html">&lt;p&gt;理論ばっかり追っていて悶々してきたので、IRLSでL1残差最小化が解けないか実験してみる。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/kibo35/sparse-modeling/blob/master/ch05.ipynb"&gt;第5章 厳密解から近似解へ&lt;/a&gt; に『スパースモデリング』5章のPython実装あり。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://qiita.com/kibo35/items/66ec4479b0899ea4987d#irlsの概要"&gt;スパースモデリング：第3章 追跡アルゴリズム&lt;/a&gt; は『スパースモデリング』3章のPython実装。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;IRLSの実装は &lt;a class="reference external" href="https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;ved=2ahUKEwi4wZXEhe3oAhUZMd4KHZrzDqQQFjAAegQIARAB&amp;amp;url=https%3A%2F%2Fis.cuni.cz%2Fwebapps%2Fzzp%2Fdownload%2F130215341&amp;amp;usg=AOvVaw3Cxgr7_WLuDQqhL1aKQl9f"&gt;カレル大学卒論&lt;/a&gt; を参考に。Pythonで簡単にできた。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;

&lt;span class="c1"&gt;# IRLS法によりPhi @ x = yのスパース解を求める&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;irls_update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Phi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;order&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;EPSILON&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;8.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# 重みの計算&lt;/span&gt;
    &lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Phi&lt;/span&gt; &lt;span class="o"&gt;@&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flatten&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="c1"&gt;# 小さくなりすぎた重みは打ち切る&lt;/span&gt;
    &lt;span class="n"&gt;weight&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;EPSILON&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;EPSILON&lt;/span&gt;
    &lt;span class="c1"&gt;# 対角行列に展開&lt;/span&gt;
    &lt;span class="n"&gt;W&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;diag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weight …&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;理論ばっかり追っていて悶々してきたので、IRLSでL1残差最小化が解けないか実験してみる。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/kibo35/sparse-modeling/blob/master/ch05.ipynb"&gt;第5章 厳密解から近似解へ&lt;/a&gt; に『スパースモデリング』5章のPython実装あり。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://qiita.com/kibo35/items/66ec4479b0899ea4987d#irlsの概要"&gt;スパースモデリング：第3章 追跡アルゴリズム&lt;/a&gt; は『スパースモデリング』3章のPython実装。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;IRLSの実装は &lt;a class="reference external" href="https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;ved=2ahUKEwi4wZXEhe3oAhUZMd4KHZrzDqQQFjAAegQIARAB&amp;amp;url=https%3A%2F%2Fis.cuni.cz%2Fwebapps%2Fzzp%2Fdownload%2F130215341&amp;amp;usg=AOvVaw3Cxgr7_WLuDQqhL1aKQl9f"&gt;カレル大学卒論&lt;/a&gt; を参考に。Pythonで簡単にできた。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;

&lt;span class="c1"&gt;# IRLS法によりPhi @ x = yのスパース解を求める&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;irls_update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Phi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;order&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;EPSILON&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;8.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# 重みの計算&lt;/span&gt;
    &lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Phi&lt;/span&gt; &lt;span class="o"&gt;@&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flatten&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="c1"&gt;# 小さくなりすぎた重みは打ち切る&lt;/span&gt;
    &lt;span class="n"&gt;weight&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;EPSILON&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;EPSILON&lt;/span&gt;
    &lt;span class="c1"&gt;# 対角行列に展開&lt;/span&gt;
    &lt;span class="n"&gt;W&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;diag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;order&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="c1"&gt;# 更新後の係数: Phi.T @ W @ Phi @ x = Phi.T @ W @ y の解&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;solve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Phi&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="o"&gt;@&lt;/span&gt; &lt;span class="n"&gt;W&lt;/span&gt; &lt;span class="o"&gt;@&lt;/span&gt; &lt;span class="n"&gt;Phi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Phi&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="o"&gt;@&lt;/span&gt; &lt;span class="n"&gt;W&lt;/span&gt; &lt;span class="o"&gt;@&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;DIMENSION&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
    &lt;span class="n"&gt;NUM_SAMPLES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
    &lt;span class="n"&gt;NUM_ITERATION&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;

    &lt;span class="c1"&gt;# 解ベクトル&lt;/span&gt;
    &lt;span class="n"&gt;X_ANSWER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;DIMENSION&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;DIMENSION&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;xhistory&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;DIMENSION&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;NUM_ITERATION&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="c1"&gt;# 観測を生成&lt;/span&gt;
    &lt;span class="n"&gt;Phi&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NUM_SAMPLES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;DIMENSION&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Phi&lt;/span&gt; &lt;span class="o"&gt;@&lt;/span&gt; &lt;span class="n"&gt;X_ANSWER&lt;/span&gt;
    &lt;span class="c1"&gt;# 加法的雑音を重畳&lt;/span&gt;
    &lt;span class="c1"&gt;# yrand = y + numpy.random.normal(0, 0.3, (NUM_SAMPLES, 1))&lt;/span&gt;
    &lt;span class="n"&gt;yrand&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;laplace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NUM_SAMPLES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;error&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NUM_ITERATION&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;emp_error&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NUM_ITERATION&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# IRLSを繰り返し適用&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NUM_ITERATION&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;irls_update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Phi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yrand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;xhistory&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Phi&lt;/span&gt; &lt;span class="o"&gt;@&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;ord&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;NUM_SAMPLES&lt;/span&gt;
        &lt;span class="n"&gt;emp_error&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yrand&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Phi&lt;/span&gt; &lt;span class="o"&gt;@&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;ord&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;NUM_SAMPLES&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;実装は楽だったけど、誤差解析が沼。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;誤差を重畳してみると、真の誤差と経験誤差が当然一致しない。&lt;/li&gt;
&lt;li&gt;経験誤差的には局所解に入っている印象。&lt;/li&gt;
&lt;li&gt;サンプル数が少ないと大域最小解に入らないケースあり（経験誤差曲面の最小値が真の誤差の曲面の最小値に不一致）&lt;/li&gt;
&lt;li&gt;経験誤差の曲面は二次曲線に見える。（2次式の最小化を考えているから当然のはず。）&lt;/li&gt;
&lt;li&gt;最小二乗解よりも誤差が悪い時がある。最小二乗解はorder=2とすれば良くて、その時重み行列Wは単位行列になり、普通の最小二乗法と一致。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;思いつき:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;IRLSは評価関数の最小化を考える時閉形式で求まるので何も考えない。パラメータに関してもう一度微分できるのでニュートン法使えそう。&lt;/li&gt;
&lt;li&gt;フィルタのときのように逐次的に求められない？&lt;ul&gt;
&lt;li&gt;パラメータ全てではなく1こずつ。サンプルについても1こずつ。更新していく。評価関数の最小化は平均値の最小化に見受けられるので、逐次的に更新しても良いように見える。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;今日は遅いのでもう寝る。&lt;/p&gt;
</content><category term="雑記"></category><category term="LAD"></category><category term="IRLS"></category><category term="L1ノルム"></category></entry><entry><title>IRLS(Iteratively Reweighted Least Squares)</title><link href="/irlsiteratively-reweighted-least-squares.html" rel="alternate"></link><published>2020-04-18T17:30:00+09:00</published><updated>2020-04-19T00:19:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-18:/irlsiteratively-reweighted-least-squares.html</id><summary type="html">&lt;p&gt;LAD(Least Absolute Deviation)を近似的・逐次的に解く方法としてのIRLSについて調査。そういえば基本的な原理を抑えていなかった。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://retrofocus28.blogspot.com/2015/09/iteratively-reweighted-least-squares.html"&gt;Iteratively Reweighted Least Squares　についてサクッと。&lt;/a&gt; 文字通りサクッとしたまとめ。OMPを使って解いているというのがとても気になる&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://cnx.org/contents/krkDdys0&amp;#64;12/Iterative-Reweighted-Least-Squares"&gt;Iterative Reweighted Least Squares&lt;/a&gt; 導入から解法まで。しかしなぜ解が求まるのかは不明。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://cedar.buffalo.edu/~srihari/CSE574/Chap4/4.3.3-IRLS.pdf"&gt;Iterative Reweighted Least Squares&lt;/a&gt; バッファロー大の講義資料？これも何故解けるのかはちゃんと書いてない。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.maths.lth.se/matematiklth/personal/fredrik/Session3.pdf"&gt;Iterative Reweighted Least Squares&lt;/a&gt; これが一番いいかも。なぜ解けるかもざっくり証明がある。&lt;ul&gt;
&lt;li&gt;そこで出てきたsupergradient（優勾配？劣勾配に対応している？）がよくわからん。資料のすぐ下に解説があったけど。 &lt;a class="reference external" href="http://www.its.caltech.edu/~kcborder/Notes/Supergrad.pdf"&gt;Supergradients&lt;/a&gt; に定義はあったけど幾何学的イメージが欲しい。&lt;/li&gt;
&lt;li&gt;Weiszfeld Algorithmsという幾何中央値を求めるアルゴリズムは &lt;a class="reference external" href="http://users.cecs.anu.edu.au/~trumpf/pubs/aftab_hartley_trumpf_PAMI2014.pdf"&gt;Generalized Weiszfeld Algorithms for Lq Optimization&lt;/a&gt; に解説あり。しかしこの論文いいこと言ってる。「Generalized …&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;LAD(Least Absolute Deviation)を近似的・逐次的に解く方法としてのIRLSについて調査。そういえば基本的な原理を抑えていなかった。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://retrofocus28.blogspot.com/2015/09/iteratively-reweighted-least-squares.html"&gt;Iteratively Reweighted Least Squares　についてサクッと。&lt;/a&gt; 文字通りサクッとしたまとめ。OMPを使って解いているというのがとても気になる&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://cnx.org/contents/krkDdys0&amp;#64;12/Iterative-Reweighted-Least-Squares"&gt;Iterative Reweighted Least Squares&lt;/a&gt; 導入から解法まで。しかしなぜ解が求まるのかは不明。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://cedar.buffalo.edu/~srihari/CSE574/Chap4/4.3.3-IRLS.pdf"&gt;Iterative Reweighted Least Squares&lt;/a&gt; バッファロー大の講義資料？これも何故解けるのかはちゃんと書いてない。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.maths.lth.se/matematiklth/personal/fredrik/Session3.pdf"&gt;Iterative Reweighted Least Squares&lt;/a&gt; これが一番いいかも。なぜ解けるかもざっくり証明がある。&lt;ul&gt;
&lt;li&gt;そこで出てきたsupergradient（優勾配？劣勾配に対応している？）がよくわからん。資料のすぐ下に解説があったけど。 &lt;a class="reference external" href="http://www.its.caltech.edu/~kcborder/Notes/Supergrad.pdf"&gt;Supergradients&lt;/a&gt; に定義はあったけど幾何学的イメージが欲しい。&lt;/li&gt;
&lt;li&gt;Weiszfeld Algorithmsという幾何中央値を求めるアルゴリズムは &lt;a class="reference external" href="http://users.cecs.anu.edu.au/~trumpf/pubs/aftab_hartley_trumpf_PAMI2014.pdf"&gt;Generalized Weiszfeld Algorithms for Lq Optimization&lt;/a&gt; に解説あり。しかしこの論文いいこと言ってる。「Generalized Weiszfeld Algorithms」は圧縮センシングとは異なりスパース表現を求めるわけではない。スパース性は担保されなくても、よりL1ノルムの意味で小さい解を求める。&lt;/li&gt;
&lt;li&gt;なぜ、IRLSとLMSアルゴリズムを結びつける研究がないのか。IRLSの逐次適用によってもフィルタ係数を更新していけそうだけど。試してみるし、類似研究が無いか引き続き調べる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;『スパースモデリング』の5章にも記述はある。しかし残差のL1最小化ではない。&lt;/p&gt;
</content><category term="雑記"></category><category term="LAD"></category><category term="IRLS"></category><category term="L1ノルム"></category></entry><entry><title>LAD(Least Absolute Deviation)</title><link href="/ladleast-absolute-deviation.html" rel="alternate"></link><published>2020-04-17T23:00:00+09:00</published><updated>2020-04-17T23:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-17:/ladleast-absolute-deviation.html</id><summary type="html">&lt;p&gt;LAD(Least Absolute Deviation)を見ている。これは、残差をL1ノルムにした回帰問題一般のこと。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;ved=2ahUKEwi4wZXEhe3oAhUZMd4KHZrzDqQQFjAAegQIARAB&amp;amp;url=https%3A%2F%2Fis.cuni.cz%2Fwebapps%2Fzzp%2Fdownload%2F130215341&amp;amp;usg=AOvVaw3Cxgr7_WLuDQqhL1aKQl9f"&gt;カレル大学卒論&lt;/a&gt; が結構まとまっている。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://core.ac.uk/download/pdf/81785239.pdf"&gt;最尤推定による近似的手法&lt;/a&gt; は軽く読んだ。各傾きと切片を固定して逐次更新していく。更新時は中央値を拾ってくる。うーん中央値だと高速推定が厳しい。。。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ラプラス分布の最尤推定しようとしてもがく。対数尤度とって見てみても、単純な絶対値和が出て止まるし、反復スケーリング法を参考に、パラメータの増分を加えた時の対数尤度の下限を求めようとしたが上手く行かず。4時間飛ばす。&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="最尤推定の計算のあがき" src="./images/IMG_3828.jpg" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;最尤推定の計算のあがき&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;あがいて「A maximum likelihood approach to least absolute deviation regression」を引用している文献を漁ったら辞書学習をL1にしているやつが、やっぱりいた。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://winsty.net/papers/onndl.pdf"&gt;Online Robust Non-negative Dictionary Learning for Visual Tracking&lt;/a&gt; パーティクルフィルターを使っておる。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上の文献で使ってるHuber Loss結構すごくね？この誤差に基づくLMSアルゴリズムねえの？→「Robust Huber adaptive filter」だけど中身を読めず …&lt;/p&gt;</summary><content type="html">&lt;p&gt;LAD(Least Absolute Deviation)を見ている。これは、残差をL1ノルムにした回帰問題一般のこと。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;ved=2ahUKEwi4wZXEhe3oAhUZMd4KHZrzDqQQFjAAegQIARAB&amp;amp;url=https%3A%2F%2Fis.cuni.cz%2Fwebapps%2Fzzp%2Fdownload%2F130215341&amp;amp;usg=AOvVaw3Cxgr7_WLuDQqhL1aKQl9f"&gt;カレル大学卒論&lt;/a&gt; が結構まとまっている。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://core.ac.uk/download/pdf/81785239.pdf"&gt;最尤推定による近似的手法&lt;/a&gt; は軽く読んだ。各傾きと切片を固定して逐次更新していく。更新時は中央値を拾ってくる。うーん中央値だと高速推定が厳しい。。。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ラプラス分布の最尤推定しようとしてもがく。対数尤度とって見てみても、単純な絶対値和が出て止まるし、反復スケーリング法を参考に、パラメータの増分を加えた時の対数尤度の下限を求めようとしたが上手く行かず。4時間飛ばす。&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="最尤推定の計算のあがき" src="./images/IMG_3828.jpg" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;最尤推定の計算のあがき&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;あがいて「A maximum likelihood approach to least absolute deviation regression」を引用している文献を漁ったら辞書学習をL1にしているやつが、やっぱりいた。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://winsty.net/papers/onndl.pdf"&gt;Online Robust Non-negative Dictionary Learning for Visual Tracking&lt;/a&gt; パーティクルフィルターを使っておる。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上の文献で使ってるHuber Loss結構すごくね？この誤差に基づくLMSアルゴリズムねえの？→「Robust Huber adaptive filter」だけど中身を読めず…&lt;/p&gt;
&lt;p&gt;また、 &lt;a class="reference external" href="https://www.ml.uni-saarland.de/Lectures/CVX-SS10/ConvexOptimization-07-07-10.pdf"&gt;Convex Optimization and Modeling&lt;/a&gt; を読んでたらHuber損失はL1とL2の中間的な性質を示すようで、0に集中しなくなりそうな印象を受けた。&lt;/p&gt;
</content><category term="雑記"></category><category term="LAD"></category><category term="L1ノルム"></category></entry><entry><title>LMSフィルターの挙動観察</title><link href="/lmshuirutanoju-dong-guan-cha.html" rel="alternate"></link><published>2020-04-16T23:20:00+09:00</published><updated>2020-04-16T23:20:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-16:/lmshuirutanoju-dong-guan-cha.html</id><summary type="html">&lt;p&gt;&lt;span class="math"&gt;\(\mathrm{E}[\mathrm{sign}[e(n)]x(n-m)]\)&lt;/span&gt; の挙動を追いたい。色々な信号に対して、&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;span class="math"&gt;\(m\)&lt;/span&gt; が十分大きいとき、0に近づくかどうか&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;を知りたい。もし0に近づくならば有効な過程として解法に使える。
しかしその前に、LMSフィルター自体の挙動を追いたい。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;残差はどの様に減る？残差の時系列は？&lt;ul&gt;
&lt;li&gt;ステップサイズにより収束の度合い（残差の分布）が違う...&lt;/li&gt;
&lt;li&gt;当然、フィルタ次数でも収束の度合い（残差の分布）が違う&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;残差分布はどうなってる？Signed-LMSでラプラス分布に近づいてる？&lt;ul&gt;
&lt;li&gt;これは本当のようで、Signed-LMSの方が裾が細い残差分布が得られている。&lt;/li&gt;
&lt;li&gt;単純な正弦波に対してはLMSのほうが残差が小さくなるが、ボイスやピアノ音源に対しては圧倒的にSignLMSの方が性能が良い（残差のヒストグラムを見ると、裾が狭い）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathrm{E}[\mathrm{sign}[e(n)]x(n-m)]\)&lt;/span&gt;, &lt;span class="math"&gt;\(\mathrm{E}[e(n)x(n-m)]\)&lt;/span&gt; は両方とも0。&lt;ul&gt;
&lt;li&gt;逐次計算していったら …&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;&lt;span class="math"&gt;\(\mathrm{E}[\mathrm{sign}[e(n)]x(n-m)]\)&lt;/span&gt; の挙動を追いたい。色々な信号に対して、&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;span class="math"&gt;\(m\)&lt;/span&gt; が十分大きいとき、0に近づくかどうか&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;を知りたい。もし0に近づくならば有効な過程として解法に使える。
しかしその前に、LMSフィルター自体の挙動を追いたい。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;残差はどの様に減る？残差の時系列は？&lt;ul&gt;
&lt;li&gt;ステップサイズにより収束の度合い（残差の分布）が違う...&lt;/li&gt;
&lt;li&gt;当然、フィルタ次数でも収束の度合い（残差の分布）が違う&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;残差分布はどうなってる？Signed-LMSでラプラス分布に近づいてる？&lt;ul&gt;
&lt;li&gt;これは本当のようで、Signed-LMSの方が裾が細い残差分布が得られている。&lt;/li&gt;
&lt;li&gt;単純な正弦波に対してはLMSのほうが残差が小さくなるが、ボイスやピアノ音源に対しては圧倒的にSignLMSの方が性能が良い（残差のヒストグラムを見ると、裾が狭い）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathrm{E}[\mathrm{sign}[e(n)]x(n-m)]\)&lt;/span&gt;, &lt;span class="math"&gt;\(\mathrm{E}[e(n)x(n-m)]\)&lt;/span&gt; は両方とも0。&lt;ul&gt;
&lt;li&gt;逐次計算していったら、音源非依存で0に近づいていく&lt;/li&gt;
&lt;li&gt;当然だよな…そもそもの過程として入力と雑音は無相関と仮定しているのだから。&lt;ul&gt;
&lt;li&gt;仮定しているのだからは正しくなくて、無相関にするようにフィルタ係数を更新しているが正しい。&lt;/li&gt;
&lt;li&gt;無相関になったときに勾配が0で最急勾配法が止まる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;なんか絶対値誤差最小化ってどっかで見たよな…と思っていたら、&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Least_absolute_deviations"&gt;https://en.wikipedia.org/wiki/Least_absolute_deviations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;修士のときに一回戦っていた。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;ved=2ahUKEwi4wZXEhe3oAhUZMd4KHZrzDqQQFjAAegQIARAB&amp;amp;url=https%3A%2F%2Fis.cuni.cz%2Fwebapps%2Fzzp%2Fdownload%2F130215341&amp;amp;usg=AOvVaw3Cxgr7_WLuDQqhL1aKQl9f"&gt;カレル大学卒論&lt;/a&gt; が結構まとまっている。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(L_{1}\)&lt;/span&gt; ノルム最小化を近接オペレータの繰り返し適用で解けんじゃね？と思っている&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://yamagensakam.hatenablog.com/entry/2018/02/14/075106"&gt;近接勾配法とproximal operator&lt;/a&gt; を読んだが、パラメータ正則化だけだな&lt;/li&gt;
&lt;li&gt;パラメータ正則化はあるけど、残差をスパースにするのがない。なんで？&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="LMS"></category><category term="LMS Algorithm"></category></entry><entry><title>続・古いロスレス音声コーデックの調査</title><link href="/sok-gu-irosuresuyin-sheng-kodetsukunodiao-cha.html" rel="alternate"></link><published>2020-04-10T23:18:00+09:00</published><updated>2020-04-10T23:18:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-10:/sok-gu-irosuresuyin-sheng-kodetsukunodiao-cha.html</id><content type="html">&lt;p&gt;古いロスレス音声コーデックと理論の概要を取りまとめた雑誌の特集があった:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.eie.polyu.edu.hk/~enyhchan/ce_ac_p1.pdf"&gt;Lossless Compression of Digital Audio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;理論としてもその通りだし、雑誌発行時点(1998)からさしたるブレークスルーが無いように見える。&lt;/p&gt;
&lt;p&gt;AudioPak, OggSquish, Philips, Sonarc, WAという謎のコーデック現る…。いったい何個あるんだ。&lt;/p&gt;
</content><category term="雑記"></category><category term="Lossless Audio"></category><category term="ロスレス音声"></category></entry><entry><title>古いロスレス音声コーデックの調査/スパース適応フィルタ</title><link href="/gu-irosuresuyin-sheng-kodetsukunodiao-cha-supasushi-ying-huiruta.html" rel="alternate"></link><published>2020-04-08T16:45:00+09:00</published><updated>2020-04-08T23:45:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-08:/gu-irosuresuyin-sheng-kodetsukunodiao-cha-supasushi-ying-huiruta.html</id><summary type="html">&lt;p&gt;ロスレス音声の歴史を探るために古いロスレス音声コーデックの情報を探っている。以下のサイトが &lt;a class="reference external" href="https://wiki.hydrogenaud.io/index.php?title=Lossless_comparison"&gt;Hydrogenaudioでの比較&lt;/a&gt; よりも古い内容を扱っている。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.firstpr.com.au/audiocomp/lossless/index.html"&gt;Lossless Compression of Audio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;見つけたロスレス音声コーデックを一覧する。というかほぼ &lt;a class="reference external" href="https://www.rarewares.org/rrw/about.php"&gt;Really Rare Wares&lt;/a&gt; 様へのリンク。&lt;/p&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;古めのロスレス音声コーデック&lt;/h2&gt;
&lt;div class="section" id="rkau-rk-audio"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://www.rarewares.org/rrw/rkau.php"&gt;RKAU(RK Audio)&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;古い比較において優秀な圧縮率を誇っていた。当時のMonkey's Audioよりも上。サイトを覗いたら exe と dll のみの配布だった。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://web.archive.org/web/20020124045327/http://rksoft.virtualave.net/rkau.html"&gt;RKAUのホームページ（魚拓）&lt;/a&gt; を見ても特に情報なし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="audiozip"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://www.rarewares.org/rrw/audiozip.php"&gt;AudioZip&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;これも圧縮率が比較的優秀。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://web.archive.org/web/20020207080740/http://www.csp.ntu.edu.sg:8000/MMS/MMCProjects.htm"&gt;AudioZipのホームページ（魚拓）&lt;/a&gt; を見てもこちらも特に情報なし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="wavarc"&gt;
&lt;h3&gt;&lt;a class="reference external" href="http://www.firstpr.com.au/audiocomp/lossless/wavarc/0readme.html"&gt;WavArc&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;こちらも最大圧縮率(-c5)を選択するとそれなりに優秀な結果を出していた。このページにexeとドキュメントをまとめたzipもあり。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="wavezip"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://www.rarewares.org/rrw/wavezip.php"&gt;WaveZip&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;圧縮率よりは速度重視のコーデックのようだ。MUSICompress というアルゴリズムの実装。 &lt;a class="reference external" href="https://www.rarewares.org/rrw/files/lossless/musi_txt.txt"&gt;WaveZipのデータシート&lt;/a&gt; によると符号化にはLZ(Lampel-Ziv)を使用しているようだ。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.firstpr.com.au/audiocomp/lossless/index.html#wavezip"&gt;WaveZipの概要&lt;/a&gt; が比較サイトに掲載されていた。どうやら …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;ロスレス音声の歴史を探るために古いロスレス音声コーデックの情報を探っている。以下のサイトが &lt;a class="reference external" href="https://wiki.hydrogenaud.io/index.php?title=Lossless_comparison"&gt;Hydrogenaudioでの比較&lt;/a&gt; よりも古い内容を扱っている。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.firstpr.com.au/audiocomp/lossless/index.html"&gt;Lossless Compression of Audio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;見つけたロスレス音声コーデックを一覧する。というかほぼ &lt;a class="reference external" href="https://www.rarewares.org/rrw/about.php"&gt;Really Rare Wares&lt;/a&gt; 様へのリンク。&lt;/p&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;古めのロスレス音声コーデック&lt;/h2&gt;
&lt;div class="section" id="rkau-rk-audio"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://www.rarewares.org/rrw/rkau.php"&gt;RKAU(RK Audio)&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;古い比較において優秀な圧縮率を誇っていた。当時のMonkey's Audioよりも上。サイトを覗いたら exe と dll のみの配布だった。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://web.archive.org/web/20020124045327/http://rksoft.virtualave.net/rkau.html"&gt;RKAUのホームページ（魚拓）&lt;/a&gt; を見ても特に情報なし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="audiozip"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://www.rarewares.org/rrw/audiozip.php"&gt;AudioZip&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;これも圧縮率が比較的優秀。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://web.archive.org/web/20020207080740/http://www.csp.ntu.edu.sg:8000/MMS/MMCProjects.htm"&gt;AudioZipのホームページ（魚拓）&lt;/a&gt; を見てもこちらも特に情報なし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="wavarc"&gt;
&lt;h3&gt;&lt;a class="reference external" href="http://www.firstpr.com.au/audiocomp/lossless/wavarc/0readme.html"&gt;WavArc&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;こちらも最大圧縮率(-c5)を選択するとそれなりに優秀な結果を出していた。このページにexeとドキュメントをまとめたzipもあり。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="wavezip"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://www.rarewares.org/rrw/wavezip.php"&gt;WaveZip&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;圧縮率よりは速度重視のコーデックのようだ。MUSICompress というアルゴリズムの実装。 &lt;a class="reference external" href="https://www.rarewares.org/rrw/files/lossless/musi_txt.txt"&gt;WaveZipのデータシート&lt;/a&gt; によると符号化にはLZ(Lampel-Ziv)を使用しているようだ。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.firstpr.com.au/audiocomp/lossless/index.html#wavezip"&gt;WaveZipの概要&lt;/a&gt; が比較サイトに掲載されていた。どうやら、入力波形を近似波形と誤差波形に分けて符号化するようだ。WaveZipではHu&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="lpac-ltac"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://www.rarewares.org/rrw/lpac.php"&gt;LPAC/LTAC&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;LPACはMPEG4-ALSの前身。LPACの前身がLTAC。LPACの平均的な圧縮率は優秀なようだ。 &lt;a class="reference external" href="https://web.archive.org/web/20060213124711/http://www.nue.tu-berlin.de/wer/liebchen/lpac.html"&gt;LPAC（魚拓）&lt;/a&gt; に以前公開していたサイトあり。&lt;/p&gt;
&lt;p&gt;LTAC(Lossless Transform Audio Compression)は名前の通り変換符号化に基づくロスレス音声圧縮コーデック、LPAC(Lossless Predictive Audio Compression)は予測に基づくロスレス音声圧縮コーデック。&lt;/p&gt;
&lt;p&gt;LPACに ベルリン工科大学、Real Networks、NTT の改良が加わってMPEG4-ALSが出来上がり、それ以降LPACの開発は停止されている。この経緯については &lt;a class="reference external" href="https://web.archive.org/web/20060212123059/http://www.nue.tu-berlin.de/forschung/projekte/lossless/mp4als.html"&gt;MPEG4-ALS（魚拓）&lt;/a&gt; に記述あり。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="shorten"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://archive.is/Z8k97"&gt;Shorten（魚拓）&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;おそらくロスレス音声の最古参にして基礎。なんと執筆時点（2020-04-08）でも &lt;tt class="docutils literal"&gt;brew&lt;/tt&gt; でインストールできた（ &lt;a class="reference external" href="https://linux.die.net/man/1/shorten"&gt;Shortenのmanページ&lt;/a&gt; もあるから各Linuxディストリビューションで使えるものと想像する）。エンコード速度はピカイチ。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=9797AA37C32F12179AF0803D8C2B22D2?doi=10.1.1.53.7337&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;Shortenの論文&lt;/a&gt; （テクニカルレポート）もある。この論文で、今のロスレス音声につながる重要な事実に幾つか触れている。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;音声信号は準定常（短い区間では定常とみなせる）だからブロックに分けてエンコード/デコードすべき。&lt;/li&gt;
&lt;li&gt;音声のモデル化には線形予測(LPC, Linear Predictive Coding)が使える。&lt;/li&gt;
&lt;li&gt;残差信号はガウス分布よりもラプラス分布に従っていると見える。その符号化にはライス符号を使うのが良い。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;この時点で既にラプラス分布を仮定したパラメータ設定を行っているからかなりの慧眼。他のロスレス音声コーデックはShortenを発展させたものに過ぎないと見える。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;所感&lt;/h2&gt;
&lt;p&gt;どうも2000年代前半までは各自でロスレス音声コーデックを作り、各自で最強を謳っていたらしい。&lt;/p&gt;
&lt;p&gt;歴史を雑にまとめると、1994年にShortenの論文が出てから、それよりも圧縮率の良いもの、圧縮速度（展開速度）が早いものが開発されて混沌に突入し上記のコーデックが現れた。その後、Monkey's Audio, WavPack, FLAC, LPAC（MPEG4-ALS）が生き残り、2000年以降はLa（更新停止）, TAK, TTA, ALAC（更新停止）, WMAL(Windows Media Audio Lossless), 2010年以降はOptimFROGが出現しているようだ。&lt;/p&gt;
&lt;p&gt;気になるのは比較サイトの &lt;a class="reference external" href="http://www.firstpr.com.au/audiocomp/lossless/index.html#rice"&gt;Rice Coding, AKA Rice Packing, Elias Gamma codes and other approaches&lt;/a&gt; である。Rice符号よりも効率の良いとされるPod符号の紹介がある。要観察。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id14"&gt;
&lt;h2&gt;スパース適応フィルタ&lt;/h2&gt;
&lt;p&gt;LPCの定式化をスパースにする試みは多くなされている。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.cs.tut.fi/~tabus/2013GhidoTabus.pdf"&gt;Sparse Modeling for Lossless Audio Compression&lt;/a&gt; : Ghidoさん（OptimFROGの人）の試み&lt;ul&gt;
&lt;li&gt;貪欲法によりスパース解を求めている。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.jstage.jst.go.jp/article/jasj/71/11/71_KJ00010109335/_pdf/-char/ja"&gt;スパース表現に基づく音声音響符号化&lt;/a&gt; : NTTの試み&lt;ul&gt;
&lt;li&gt;最小二乗解を求めるのではなくL1最小化に置き換えた定式化を行う。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;でも、TTAがやっているような適応フィルタをスパース解に近づける手法はまだロスレス音声に対してやっていないように見える。
スパースな解を目指してフィルタ係数を更新する適応フィルタはスパース適応フィルタ(Sparse Adaptive Filters)というようで、2000年代以降に研究が進んでいるようだ。&lt;/p&gt;
&lt;p&gt;最も基本的な適応フィルタであるLMS(Least Mean Square)フィルタは名前の通り二乗誤差最小化に立脚している。
スパース適応フィルタの主な用途はエコーキャンセル、ブラインド話者分離、複数話者特定ではあるが、やはり変換後の分布がスパースになるというのは大きい。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://signal.ee.bilkent.edu.tr/defevent/papers/cr1256.pdf"&gt;スパース適応フィルタの最近のサーベイ論文&lt;/a&gt; を流し読みした。スパース適応フィルタは、変数更新のときに1部の変数だけ更新する方法と、スパース最適化に従って更新するやり方の2つがあった。PNLMS(Proportionate NLMS), IPNLMS(Improved PNLMS)が後者の定式化で興味あり。引き続き見ていく。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1012.5066.pdf"&gt;Regularized Least-Mean-Square Algorithms&lt;/a&gt; には正則化を入れたLMSアルゴリズムの解説あり。LASSOにモチベーションを受けた最適化アルゴリズムが &lt;a class="reference external" href="https://wiki.eecs.umich.edu/global/data/hero/images/7/7b/Yilun-icassp2-09.pdf"&gt;ZA-LMS&lt;/a&gt; や &lt;a class="reference external" href="http://azadproject.ir/wp-content/uploads/2017/01/2018-Online-Sparse-System-Identification-and-Signal-Reconstruction-Using-Projections-.pdf"&gt;APWL1&lt;/a&gt; として提案されている。&lt;/p&gt;
&lt;/div&gt;
</content><category term="雑記"></category><category term="SLA"></category><category term="Lossless Audio"></category><category term="ロスレス音声"></category><category term="スパース符号化"></category></entry><entry><title>ブログ導入</title><link href="/burogudao-ru.html" rel="alternate"></link><published>2020-04-02T18:00:00+09:00</published><updated>2020-04-02T21:34:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-02:/burogudao-ru.html</id><content type="html">&lt;p&gt;GitHub io + Pelican を使ってみた。しばらくこちらで日報を書きたい。
GitHub io + Pelicanは以下の記事を参考にしている。まだあんまり分かってない。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://qiita.com/yusukew62/items/7b01d2370cdbe170b28d"&gt;Python製静的HTMLジェネレータのPelicanでGitHub Pagesを公開する方法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://qiita.com/ririli/items/0e06b21cb709beae4514"&gt;GitHub Pagesで静的サイトを簡単に作る&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://qiita.com/saira/items/71faa202efb4320cb41d"&gt;Python製 Pelican を使ってサクッとブログを公開する&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.pelicanthemes.com"&gt;Pelicanのテーマ集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/getpelican/pelican-themes/issues/460#issuecomment-346652986"&gt;テーマ導入時にハマったので参考にしたissue comment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;今日は（というか3月末）からSLAの高速化作業とまとめをしていた。&lt;/p&gt;
&lt;p&gt;格子型フィルタ演算はどうしても1乗算型にできず。次数演算を4次数にしてSSE演算するのがやっと。
SSE化するときに、スカラー演算とベクトル演算が混じったときに処理負荷が大きく上がってハマった。
&lt;a class="reference external" href="https://stackoverflow.com/questions/10313397/where-does-the-sse-instructions-outperform-normal-instructions"&gt;StackOverFlowの記事&lt;/a&gt; では &lt;cite&gt;_mm_set_epi32&lt;/cite&gt; のコストが高い旨記述あり。 &lt;cite&gt;_mm_loadu_si128&lt;/cite&gt; の使用に置き換えた。
&lt;a class="reference external" href="https://stackoverflow.com/questions/24446516/performance-worsens-when-using-sse-simple-addition-of-integer-arrays"&gt;他の記事&lt;/a&gt; で言及があってようやく分かった。全てをベクトル演算化したところ、処理負荷は4/5倍になった。あんまり早くなっていない。遺憾。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://herumi.in.coocan.jp/prog/gcc-and-vc.html"&gt;gccとVC&lt;/a&gt; にはgccとVisual Studioの挙動の差異について色々と書いてあった。&lt;/p&gt;
</content><category term="雑記"></category><category term="SLA"></category><category term="SSE"></category><category term="test"></category><category term="pelican"></category><category term="githubio"></category></entry></feed>