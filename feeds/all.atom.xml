<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Aiki's Blog</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2020-04-21T12:10:00+09:00</updated><entry><title>2020-04-21</title><link href="/2020-04-21.html" rel="alternate"></link><published>2020-04-21T12:10:00+09:00</published><updated>2020-04-21T12:10:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-21:/2020-04-21.html</id><summary type="html">&lt;div class="section" id="todo"&gt;
&lt;h2&gt;いろいろなTODO&lt;/h2&gt;
&lt;p&gt;優先度が大きい順に。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;残差勾配 &lt;span class="math"&gt;\(\mathrm{E}[\varepsilon(n) x(n - m)]\)&lt;/span&gt; の挙動観察をすべし。&lt;span class="math"&gt;\(m\)&lt;/span&gt; が大きいときは無視できるのでは？&lt;ul&gt;
&lt;li&gt;なお、長時間平均値は0に収束していることを見た。&lt;/li&gt;
&lt;li&gt;→ 確かめるべし。&lt;span class="math"&gt;\(m\)&lt;/span&gt; をずらした時の平均値の様子を見る。どこかで影響が小さくなって打ち切れるはず。&lt;ul&gt;
&lt;li&gt;ガチャガチャ弄ってるってるけど示唆があんまりない。&lt;/li&gt;
&lt;li&gt;低次（〜10）の係数は大きく変動する傾向。しかし、次に述べるピッチなどに影響しているのか、全てに当てはまる傾向ではない。&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathrm{E}[\varepsilon(n) x(n - m)]\)&lt;/span&gt; は &lt;span class="math"&gt;\(m\)&lt;/span&gt; を大きくすれば単調減少するわけではない。音源依存で傾向が異なる。ピッチ？か何かに反応して大きくなる場合がある。&lt;/li&gt;
&lt;li&gt;同一発音区間では、フィルタ係数の符号は同一になる傾向が見られる。単一のsin波を等価させたときはわかりやすい。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="figure"&gt;
&lt;img alt="440.0Hzのsin波に対する各タップの平均勾配変化グラフ" src="./images/sin_mean_gradient.png" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;440.0Hzのsin波に対する各タップの平均勾配変化&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;img alt="ボイス対する各タップの平均勾配変化グラフ" src="./images/voice_mean_gradient.png" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;ボイス対する各タップの平均勾配変化&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;img alt="ピアノ演奏に対する各タップの平均勾配変化グラフ" src="./images/ruriko_mean_gradient.png" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;ピアノ演奏に対する各タップの平均勾配変化&lt;/p&gt;
&lt;/div&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;メッセージパッシング使えない？&lt;ul&gt;
&lt;li&gt;何らかの確率モデル化をせよ、というふうに受け取った。&lt;/li&gt;
&lt;li&gt;AMP …&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="todo"&gt;
&lt;h2&gt;いろいろなTODO&lt;/h2&gt;
&lt;p&gt;優先度が大きい順に。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;残差勾配 &lt;span class="math"&gt;\(\mathrm{E}[\varepsilon(n) x(n - m)]\)&lt;/span&gt; の挙動観察をすべし。&lt;span class="math"&gt;\(m\)&lt;/span&gt; が大きいときは無視できるのでは？&lt;ul&gt;
&lt;li&gt;なお、長時間平均値は0に収束していることを見た。&lt;/li&gt;
&lt;li&gt;→ 確かめるべし。&lt;span class="math"&gt;\(m\)&lt;/span&gt; をずらした時の平均値の様子を見る。どこかで影響が小さくなって打ち切れるはず。&lt;ul&gt;
&lt;li&gt;ガチャガチャ弄ってるってるけど示唆があんまりない。&lt;/li&gt;
&lt;li&gt;低次（〜10）の係数は大きく変動する傾向。しかし、次に述べるピッチなどに影響しているのか、全てに当てはまる傾向ではない。&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathrm{E}[\varepsilon(n) x(n - m)]\)&lt;/span&gt; は &lt;span class="math"&gt;\(m\)&lt;/span&gt; を大きくすれば単調減少するわけではない。音源依存で傾向が異なる。ピッチ？か何かに反応して大きくなる場合がある。&lt;/li&gt;
&lt;li&gt;同一発音区間では、フィルタ係数の符号は同一になる傾向が見られる。単一のsin波を等価させたときはわかりやすい。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="figure"&gt;
&lt;img alt="440.0Hzのsin波に対する各タップの平均勾配変化グラフ" src="./images/sin_mean_gradient.png" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;440.0Hzのsin波に対する各タップの平均勾配変化&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;img alt="ボイス対する各タップの平均勾配変化グラフ" src="./images/voice_mean_gradient.png" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;ボイス対する各タップの平均勾配変化&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;img alt="ピアノ演奏に対する各タップの平均勾配変化グラフ" src="./images/ruriko_mean_gradient.png" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;ピアノ演奏に対する各タップの平均勾配変化&lt;/p&gt;
&lt;/div&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;メッセージパッシング使えない？&lt;ul&gt;
&lt;li&gt;何らかの確率モデル化をせよ、というふうに受け取った。&lt;/li&gt;
&lt;li&gt;AMP, Survay-Propagation（三村さん、樺島さん）がありえる。&lt;/li&gt;
&lt;li&gt;→ AMP, Survay-Propagationについて調査すべし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;周波数領域に一旦飛ばすのはあり？&lt;ul&gt;
&lt;li&gt;ありだけど計算量が高い。圧縮率が上がるのであれば大アリ。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;確率的PCAとか使えない？辞書は小さくて済む。&lt;/li&gt;
&lt;li&gt;線形ダイナミクスにより上手く定式化できない？&lt;/li&gt;
&lt;li&gt;出す学会については HND 先生に聞くこと。&lt;ul&gt;
&lt;li&gt;相談する機会はどこかで絶対に必要。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;優先度低&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;著作権処理済み音源データベースについて相談&lt;ul&gt;
&lt;li&gt;→ 自分で情報をまとめて、申し込んでいいかというところまで進めるべし。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://staff.aist.go.jp/m.goto/PAPER/SIGMUS200205goto.pdf"&gt;RWC 研究用音楽データベース: 音楽ジャンルデータベースと楽器音データベース&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://staff.aist.go.jp/m.goto/RWC-MDB/index-j.html"&gt;RWC研究用音楽データベース&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;→ 進めた。動けるようになったら書類をまとめていく。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Donohoさんなどが圧縮センシングの文脈で既にやりきってない？&lt;ul&gt;
&lt;li&gt;ありえる。調査すべし。&lt;/li&gt;
&lt;li&gt;→ ライス大学では成果をすべて公開しているから見るだけ見たほうが良い。&lt;/li&gt;
&lt;li&gt;→ &lt;a class="reference external" href="http://dsp.rice.edu/cs/"&gt;http://dsp.rice.edu/cs/&lt;/a&gt; を見よ。&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://hal.archives-ouvertes.fr/hal-00424165/document"&gt;Compressed sensing block MAP-LMS adaptive filter for sparse channel estimation and a bayesian Cramer-Rao bound&lt;/a&gt; 残差はガウス分布としてるけどクラメル-ラオ下限との絡みを述べている。何か重要そう。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.dbabacan.info/papers/babacan_CS.pdf"&gt;Bayesian Compressive Sensing Using Laplace Priors&lt;/a&gt; これもパラメータの事前分布にラプラス分布を導入してベイズ推定するもの。残差ではないはず。&lt;/li&gt;
&lt;li&gt;「L1」, 「Laplace」, 「residual」, 「lossless」で検索したけどスパース解を求めるものばかり。今のところはセーフ？&lt;/li&gt;
&lt;li&gt;→ 継続して調査はする。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;分散行列、ヘッセ行列、フィッシャー情報行列、自然勾配&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;ガウス分布の最尤推定で、分散行列の逆行列はフィッシャー情報行列に一致する&lt;ul&gt;
&lt;li&gt;お？じゃあラプラス分布は？&lt;/li&gt;
&lt;li&gt;絶対値関数入ってるけど、NNのデルタ則を導くときみたいに連続関数で近似して微分して後で極限取るみたいなのはできる。式変形チャレンジしてみるべし。符号関数はシグモイド関数で近似できる。後で温度パラメータの極限を取る。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="SLA"></category><category term="Lossless Audio"></category><category term="ロスレス音声"></category><category term="スパース符号化"></category><category term="L1ノルム"></category><category term="LAD"></category><category term="IRLS"></category></entry><entry><title>2020-04-20</title><link href="/2020-04-20.html" rel="alternate"></link><published>2020-04-20T14:10:00+09:00</published><updated>2020-04-21T12:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-20:/2020-04-20.html</id><summary type="html">&lt;div class="section" id="irls"&gt;
&lt;h2&gt;IRLSの更新式について&lt;/h2&gt;
&lt;p&gt;MathJaxの環境を確認しつつ使用中。プリアンブルが無いけどページ内で一回 &lt;tt class="docutils literal"&gt;newcommand&lt;/tt&gt; を行えばずっと使えるみたい。便利。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;逐次的更新の件について。IRLSでは以下の評価関数 &lt;span class="math"&gt;\(J(\ve{\beta})\)&lt;/span&gt; の最小化を考える。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
J(\ve{\beta}) = \sum^{M}_{i = 1} w_{i} (y_{i …&lt;/div&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="irls"&gt;
&lt;h2&gt;IRLSの更新式について&lt;/h2&gt;
&lt;p&gt;MathJaxの環境を確認しつつ使用中。プリアンブルが無いけどページ内で一回 &lt;tt class="docutils literal"&gt;newcommand&lt;/tt&gt; を行えばずっと使えるみたい。便利。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;逐次的更新の件について。IRLSでは以下の評価関数 &lt;span class="math"&gt;\(J(\ve{\beta})\)&lt;/span&gt; の最小化を考える。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
J(\ve{\beta}) = \sum^{M}_{i = 1} w_{i} (y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}})^{2}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで &lt;span class="math"&gt;\(M\)&lt;/span&gt; は観測数。これは二次式だから評価関数は凸関数になる。早速 &lt;span class="math"&gt;\(\ve{\beta}\)&lt;/span&gt; で偏微分してみると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\parfrac{}{\ve{\beta}} J(\ve{\beta}) &amp;amp;= \sum^{M}_{i = 1} w_{i} 2 \left(- \frac{\partial}{\partial \ve{\beta}} \innerp{\ve{\beta}}{\ve{x}_{i}} \right) (y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}}) \\
 &amp;amp;= -2 \sum^{M}_{i = 1} w_{i} (y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}}) \ve{x}_{i}
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\parfrac{}{\ve{\beta}} J(\ve{\beta}) = 0\)&lt;/span&gt; とおくと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\sum_{i = 1}^{M} w_{i} \innerp{\ve{\beta}}{\ve{x}_{i}} \ve{x}_{i} &amp;amp;= \sum_{i = 1}^{M} w_{i} y_{i} \ve{x}_{i} \\
\iff
\left[ \ve{x}_{1} ... \ve{x}_{M} \right]
\left[
 \begin{array}{c}
   w_{1} \innerp{\ve{\beta}}{\ve{x}_{1}} \\
   \vdots     \\
   w_{M} \innerp{\ve{\beta}}{\ve{x}_{M}}
 \end{array}
\right]
&amp;amp;=
\left[ \ve{x}_{1} ... \ve{x}_{M} \right]
\left[
 \begin{array}{c}
   w_{1}y_{1} \\
   \vdots     \\
   w_{M}y_{M}
 \end{array}
\right]
\\
\iff
\left[ \ve{x}_{1} ... \ve{x}_{M} \right]
\left[
 \begin{array}{ccc}
   w_{1}  &amp;amp; \dots  &amp;amp; 0      \\
   \vdots &amp;amp; \ddots &amp;amp; \vdots \\
   0      &amp;amp; \dots  &amp;amp; w_{M}
 \end{array}
\right]
\left[
 \begin{array}{c}
   \innerp{\ve{\beta}}{\ve{x}_{1}} \\
   \vdots     \\
   \innerp{\ve{\beta}}{\ve{x}_{M}}
 \end{array}
\right]
&amp;amp;=
\left[ \ve{x}_{1} ... \ve{x}_{M} \right]
\left[
 \begin{array}{ccc}
   w_{1}  &amp;amp; \dots  &amp;amp; 0      \\
   \vdots &amp;amp; \ddots &amp;amp; \vdots \\
   0      &amp;amp; \dots  &amp;amp; w_{M}
 \end{array}
\right]
\left[
 \begin{array}{c}
   y_{1} \\
   \vdots     \\
   y_{M}
 \end{array}
\right]
\\
\iff
\left[ \ve{x}_{1} ... \ve{x}_{M} \right]
\left[
 \begin{array}{ccc}
   w_{1}  &amp;amp; \dots  &amp;amp; 0      \\
   \vdots &amp;amp; \ddots &amp;amp; \vdots \\
   0      &amp;amp; \dots  &amp;amp; w_{M}
 \end{array}
\right]
\left[
 \begin{array}{c}
   \ve{x}_{1}^{\mathsf{T}} \\
   \vdots     \\
   \ve{x}_{M}^{\mathsf{T}}
 \end{array}
\right]
\ve{\beta}
&amp;amp;=
\left[ \ve{x}_{1} ... \ve{x}_{M} \right]
\left[
 \begin{array}{ccc}
   w_{1}  &amp;amp; \dots  &amp;amp; 0      \\
   \vdots &amp;amp; \ddots &amp;amp; \vdots \\
   0      &amp;amp; \dots  &amp;amp; w_{M}
 \end{array}
\right]
\ve{y}
\\
\iff
\ve{X} \ve{W} \ve{X}^{\mathsf{T}} \ve{\beta} &amp;amp;= \ve{X} \ve{W} \ve{y}
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\ve{X}\ve{W}\ve{X}^{\mathsf{T}}\)&lt;/span&gt; が正則（TODO: &lt;span class="math"&gt;\(\ve{X}\)&lt;/span&gt; が行フルランク、かつ &lt;span class="math"&gt;\(\ve{W}\)&lt;/span&gt; が正則なら行けそうに見えるけど本当か？）の場合は閉形式で係数が求まる:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{\beta} = (\ve{X} \ve{W} \ve{X}^{\mathsf{T}})^{-1} \ve{X} \ve{W} \ve{y}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここまでは一般論。さて、更新式に注目する。&lt;span class="math"&gt;\(\beta_{j}\)&lt;/span&gt; だけで偏微分してみると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\parfrac{J(\ve{\beta})}{\beta_{j}} &amp;amp;= \sum_{i = 1}^{M} \parfrac{}{\beta_{j}} w_{i} (y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}})^{2} \\
&amp;amp;= -2 \sum_{i = 1}^{M} w_{i} (\ve{x}_{i})_{j} (y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}})
\end{align*}
&lt;/div&gt;
&lt;p&gt;残差のL1ノルム最小化を考えるときは &lt;span class="math"&gt;\(w_{i} = \frac{1}{|y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}}|}\)&lt;/span&gt; とおくので代入すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{J(\ve{\beta})}{\beta_{j}} = -2 \sum_{i = 1}^{M} (\ve{x}_{i})_{j} \mathrm{sign}(y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;瞬間値（&lt;/strong&gt; &lt;span class="math"&gt;\(M=1\)&lt;/span&gt; &lt;strong&gt;とする）を考えるとSigned-LMSの更新式そのものになっている。&lt;/strong&gt; 和を取ると平均操作に近いから、LMSアルゴリズムと考えていることは同じ。&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\parfrac{J(\ve{\beta})}{\beta_{j}}\)&lt;/span&gt; を更に &lt;span class="math"&gt;\(\beta_{k}\)&lt;/span&gt; で偏微分してみると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\frac{\partial^{2} J(\ve{\beta})}{\partial \beta_{j} \partial \beta_{k}} &amp;amp;= -2 \sum_{i = 1}^{M} w_{i} (\ve{x}_{i})_{j} \parfrac{}{\beta_{k}} (y_{i} - \innerp{\ve{\beta}}{\ve{x}_{i}}) \\
&amp;amp;= 2 \sum_{i = 1}^{M} w_{i} (\ve{x}_{i})_{j} (\ve{x}_{i})_{k} \\
&amp;amp;= 2 \left[ (\ve{x}_{1})_{j} \dots (\ve{x}_{M})_{j} \right]
 \left[
  \begin{array}{c}
    w_{1} (\ve{x}_{1})_{k} \\
    \vdots     \\
    w_{M} (\ve{x}_{M})_{k}
  \end{array}
 \right]
 = 2 \left[ (\ve{x}_{1})_{j} \dots (\ve{x}_{M})_{j} \right] \ve{W}
 \left[
  \begin{array}{c}
    (\ve{x}_{1})_{k} \\
    \vdots     \\
    (\ve{x}_{M})_{k}
  \end{array}
 \right]
\end{align*}
&lt;/div&gt;
&lt;p&gt;2次式が出てくるのがわかる（&lt;span class="math"&gt;\(\ve{W}\)&lt;/span&gt; は計量だ）。そして &lt;span class="math"&gt;\((\ve{H})_{jk} = \frac{\partial^{2} J(\ve{\beta})}{\partial \beta_{j} \partial \beta_{k}}\)&lt;/span&gt; なるヘッセ行列 &lt;span class="math"&gt;\(\ve{H}\)&lt;/span&gt; は以下:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{H} = 2 \ve{X} \ve{W} \ve{X}^{\mathsf{T}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ヘッセ行列の性質により関数の最小値・最大値の存在がわかる。対称行列なのは間違いない（&lt;span class="math"&gt;\((\ve{X})_{ij} = (\ve{X})_{ji}\)&lt;/span&gt; は自明）。（固有値分解とは見れない。&lt;span class="math"&gt;\(\ve{H}\)&lt;/span&gt; は &lt;span class="math"&gt;\(N \times N\)&lt;/span&gt; の行列であるのに対して、&lt;span class="math"&gt;\(\ve{X}\)&lt;/span&gt; は &lt;span class="math"&gt;\(N \times M\)&lt;/span&gt; の行列。&lt;span class="math"&gt;\(\ve{X} \ve{X}^{\mathsf{T}}\)&lt;/span&gt; は平均化、除算を抜いた分散共分散行列になり半正定値行列。）また、任意のベクトル &lt;span class="math"&gt;\(\ve{v}\)&lt;/span&gt; に対して、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ve{v}^{\mathsf{T}} \ve{X} \ve{W} \ve{X}^{\mathsf{T}} \ve{v} &amp;amp;= \ve{v}^{\mathsf{T}} \ve{X} \ve{W}^{1/2} \ve{W}^{1/2} \ve{X}^{\mathsf{T}} \ve{v} \\
&amp;amp;= (\ve{W}^{1/2} \ve{X}^{\mathsf{T}} \ve{v})^{\mathsf{T}} \ve{W}^{1/2} \ve{X}^{\mathsf{T}} \ve{v} \\
&amp;amp;= || \ve{W}^{1/2} \ve{X}^{\mathsf{T}} \ve{v} ||_{2}^{2} \geq 0
\end{align*}
&lt;/div&gt;
&lt;p&gt;だから、&lt;span class="math"&gt;\(\ve{W}\)&lt;/span&gt; が半正定値（&lt;span class="math"&gt;\(\iff\)&lt;/span&gt; すべての重みが非負）ならばヘッセ行列は半正定値行列で、極小値が最小値になる。また、&lt;span class="math"&gt;\(J(\ve{\beta})\)&lt;/span&gt; は凸関数（半正定値だから狭義の凸関数ではない）。
もう少しヘッセ行列を見る。ヘッセ行列を上手く使えたらニュートン法で解けそうな気がして。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
(\ve{H})_{jk} = 2 \sum_{i = 1}^{M} w_{i} (\ve{x}_{i})_{j} (\ve{x}_{i})_{k}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;より、スペクトル分解的に見ると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\frac{1}{2} \ve{H} &amp;amp;=
w_{1} \left[
  \begin{array}{ccc}
    (\ve{x}_{1})_{1}^{2}  &amp;amp; \dots &amp;amp; (\ve{x}_{1})_{1} (\ve{x}_{1})_{N} \\
    \vdots &amp;amp; \ddots &amp;amp; \vdots \\
    (\ve{x}_{1})_{N} (\ve{x}_{1})_{1} &amp;amp; \dots &amp;amp; (\ve{x}_{1})_{N}^{2} \\
  \end{array}
 \right]
 + \dots +
 w_{M} \left[
  \begin{array}{ccc}
    (\ve{x}_{M})_{1}^{2}  &amp;amp; \dots &amp;amp; (\ve{x}_{M})_{1} (\ve{x}_{M})_{N} \\
    \vdots &amp;amp; \ddots &amp;amp; \vdots \\
    (\ve{x}_{M})_{N} (\ve{x}_{M})_{1} &amp;amp; \dots &amp;amp; (\ve{x}_{M})_{N}^{2} \\
  \end{array}
 \right] \\
 &amp;amp;= w_{1} \ve{x}_{1} \ve{x}_{1}^{\mathsf{T}} + \dots + w_{M} \ve{x}_{M} \ve{x}_{M}^{\mathsf{T}} \\
 &amp;amp;= \sum_{i = 1}^{M} w_{i} \ve{x}_{i} \ve{x}_{i}^{\mathsf{T}}
\end{align*}
&lt;/div&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;信号処理的には &lt;span class="math"&gt;\(\ve{x}_{1}, \ve{x}_{2}, \dots \ve{x}_{M}\)&lt;/span&gt; は系列で現れる。&lt;/li&gt;
&lt;li&gt;LMSフィルタでは &lt;span class="math"&gt;\(i = 1\)&lt;/span&gt; の時だけを考えていたと考えられれる。 &lt;span class="math"&gt;\(i = 2,\dots,M\)&lt;/span&gt; のときの影響は少ないのではないかと思う。&lt;/li&gt;
&lt;li&gt;FIRフィルタを考えるのならば、各 &lt;span class="math"&gt;\(\ve{x}_{1}\)&lt;/span&gt; は入ってきた1次元信号データを時系列順に並べたものだから、直前のベクトル &lt;span class="math"&gt;\(\ve{x}_{2}\)&lt;/span&gt; を使えそうな構造に見える。&lt;/li&gt;
&lt;li&gt;上の仮定を使ってヘッセ行列の逆行列 &lt;span class="math"&gt;\(\ve{H}^{-1}\)&lt;/span&gt; を逐次近似計算できない？&lt;/li&gt;
&lt;li&gt;分散共分散行列がほぼヘッセ行列になってるけどこれは何？&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.iim.cs.tut.ac.jp/~kanatani/papers/jcov.pdf"&gt;金谷さんの解説&lt;/a&gt; にそれとなく解説がある。フィッシャー情報行列との関連もある。。。クラメル・ラオの下限についてわかりやすい説明あり。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://web.econ.keio.ac.jp/staff/bessho/lecture/09/091014ML.pdf"&gt;最尤法&lt;/a&gt; にもそれとなく解説あり。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://oku.edu.mie-u.ac.jp/~okumura/stat/141115.html"&gt;奥村さん&lt;/a&gt; もあり。観測からヘッセ行列を構成できる？&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;そして自然勾配のアイディアが出てくる。自然勾配を使ったLMSアルゴリズムは…あった…&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://scholarsmine.mst.edu/cgi/viewcontent.cgi?referer=https://www.google.com/&amp;amp;httpsredir=1&amp;amp;article=2780&amp;amp;context=ele_comeng_facwork"&gt;Normalized Natural Gradient Adaptive Filtering for Sparse and Nonsparse Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.7538&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;甘利先生による解説&lt;/a&gt; で、LMSアルゴリズム含めて大まかなところはだいたい言ってる。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.researchgate.net/profile/Ligang_Liu3/publication/44098179_On_Improvement_of_Proportionate_Adaptive_Algorithms_for_Sparse_Impulse_Response/links/00b495315266ab9cfd000000.pdf"&gt;高知工科大学の博論&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ワンチャンスL1残差最小化はやってないかも。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TODO:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;前のMTGで言われたことの整理&lt;/li&gt;
&lt;li&gt;分散行列、ヘッセ行列、フィッシャー情報行列、自然勾配の整理&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://wiseodd.github.io/techblog/2018/03/11/fisher-information/"&gt;Fisher Information Matrix&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;OMPが気になる。試してみたい。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="SLA"></category><category term="Lossless Audio"></category><category term="ロスレス音声"></category><category term="スパース符号化"></category><category term="L1ノルム"></category><category term="LAD"></category><category term="IRLS"></category></entry><entry><title>2020-04-19</title><link href="/2020-04-19.html" rel="alternate"></link><published>2020-04-19T19:30:00+09:00</published><updated>2020-04-20T14:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-19:/2020-04-19.html</id><summary type="html">&lt;div class="section" id="irls-iteratively-reweighted-least-squares-2"&gt;
&lt;h2&gt;IRLS(Iteratively Reweighted Least Squares) その2&lt;/h2&gt;
&lt;p&gt;理論ばっかり追っていて悶々してきたので、IRLSでL1残差最小化が解けないか実験してみる。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/kibo35/sparse-modeling/blob/master/ch05.ipynb"&gt;第5章 厳密解から近似解へ&lt;/a&gt; に『スパースモデリング』5章のPython実装あり。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://qiita.com/kibo35/items/66ec4479b0899ea4987d#irlsの概要"&gt;スパースモデリング：第3章 追跡アルゴリズム&lt;/a&gt; は『スパースモデリング』3章のPython実装。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;IRLSの実装は &lt;a class="reference external" href="https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;ved=2ahUKEwi4wZXEhe3oAhUZMd4KHZrzDqQQFjAAegQIARAB&amp;amp;url=https%3A%2F%2Fis.cuni.cz%2Fwebapps%2Fzzp%2Fdownload%2F130215341&amp;amp;usg=AOvVaw3Cxgr7_WLuDQqhL1aKQl9f"&gt;カレル大学卒論&lt;/a&gt; を参考に。Pythonで簡単にできた。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;

&lt;span class="c1"&gt;# IRLS法によりPhi @ x = yのスパース解を求める&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;irls_update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Phi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;order&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;EPSILON&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;8.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# 重みの計算&lt;/span&gt;
    &lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Phi&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flatten&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="c1"&gt;# 小さくなりすぎた重みは打ち切る&lt;/span&gt;
    &lt;span class="n"&gt;weight&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;EPSILON …&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="irls-iteratively-reweighted-least-squares-2"&gt;
&lt;h2&gt;IRLS(Iteratively Reweighted Least Squares) その2&lt;/h2&gt;
&lt;p&gt;理論ばっかり追っていて悶々してきたので、IRLSでL1残差最小化が解けないか実験してみる。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/kibo35/sparse-modeling/blob/master/ch05.ipynb"&gt;第5章 厳密解から近似解へ&lt;/a&gt; に『スパースモデリング』5章のPython実装あり。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://qiita.com/kibo35/items/66ec4479b0899ea4987d#irlsの概要"&gt;スパースモデリング：第3章 追跡アルゴリズム&lt;/a&gt; は『スパースモデリング』3章のPython実装。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;IRLSの実装は &lt;a class="reference external" href="https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;ved=2ahUKEwi4wZXEhe3oAhUZMd4KHZrzDqQQFjAAegQIARAB&amp;amp;url=https%3A%2F%2Fis.cuni.cz%2Fwebapps%2Fzzp%2Fdownload%2F130215341&amp;amp;usg=AOvVaw3Cxgr7_WLuDQqhL1aKQl9f"&gt;カレル大学卒論&lt;/a&gt; を参考に。Pythonで簡単にできた。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;

&lt;span class="c1"&gt;# IRLS法によりPhi @ x = yのスパース解を求める&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;irls_update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Phi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;order&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;EPSILON&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;8.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# 重みの計算&lt;/span&gt;
    &lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Phi&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flatten&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="c1"&gt;# 小さくなりすぎた重みは打ち切る&lt;/span&gt;
    &lt;span class="n"&gt;weight&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;EPSILON&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;EPSILON&lt;/span&gt;
    &lt;span class="c1"&gt;# 対角行列に展開&lt;/span&gt;
    &lt;span class="n"&gt;W&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;diag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;order&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="c1"&gt;# 更新後の係数: Phi.T @ W @ Phi @ x = Phi.T @ W @ y の解&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;solve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Phi&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;W&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;Phi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Phi&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;W&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;DIMENSION&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
    &lt;span class="n"&gt;NUM_SAMPLES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
    &lt;span class="n"&gt;NUM_ITERATION&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;

    &lt;span class="c1"&gt;# 解ベクトル&lt;/span&gt;
    &lt;span class="n"&gt;X_ANSWER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;DIMENSION&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;DIMENSION&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;xhistory&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;DIMENSION&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;NUM_ITERATION&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="c1"&gt;# 観測を生成&lt;/span&gt;
    &lt;span class="n"&gt;Phi&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NUM_SAMPLES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;DIMENSION&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Phi&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;X_ANSWER&lt;/span&gt;
    &lt;span class="c1"&gt;# 加法的雑音を重畳&lt;/span&gt;
    &lt;span class="c1"&gt;# yrand = y + numpy.random.normal(0, 0.3, (NUM_SAMPLES, 1))&lt;/span&gt;
    &lt;span class="n"&gt;yrand&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;laplace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NUM_SAMPLES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;error&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NUM_ITERATION&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;emp_error&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NUM_ITERATION&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# IRLSを繰り返し適用&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NUM_ITERATION&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;irls_update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Phi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yrand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;xhistory&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Phi&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;ord&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;NUM_SAMPLES&lt;/span&gt;
        &lt;span class="n"&gt;emp_error&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yrand&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Phi&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;ord&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;NUM_SAMPLES&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;実装は楽だったけど、誤差解析が沼。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;誤差を重畳してみると、真の誤差と経験誤差が当然一致しない。&lt;/li&gt;
&lt;li&gt;経験誤差的には局所解に入っている印象。&lt;/li&gt;
&lt;li&gt;サンプル数が少ないと大域最小解に入らないケースあり（経験誤差曲面の最小値が真の誤差の曲面の最小値に不一致）&lt;/li&gt;
&lt;li&gt;経験誤差の曲面は二次曲線に見える。（2次式の最小化を考えているから当然のはず。）&lt;/li&gt;
&lt;li&gt;最小二乗解よりも誤差が悪い時がある。最小二乗解はorder=2とすれば良くて、その時重み行列Wは単位行列になり、普通の最小二乗法と一致。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;思いつき:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;IRLSは評価関数の最小化を考える時閉形式で求まるので何も考えない。パラメータに関してもう一度微分できるのでニュートン法使えそう。&lt;/li&gt;
&lt;li&gt;フィルタのときのように逐次的に求められない？&lt;ul&gt;
&lt;li&gt;パラメータ全てではなく1こずつ。サンプルについても1こずつ。更新していく。評価関数の最小化は平均値の最小化に見受けられるので、逐次的に更新しても良いように見える。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;今日は遅いのでもう寝る&lt;/p&gt;
&lt;/div&gt;
</content><category term="雑記"></category><category term="SLA"></category><category term="Lossless Audio"></category><category term="ロスレス音声"></category><category term="スパース符号化"></category><category term="L1ノルム"></category><category term="LAD"></category><category term="IRLS"></category></entry><entry><title>2020-04-18</title><link href="/2020-04-18.html" rel="alternate"></link><published>2020-04-18T17:30:00+09:00</published><updated>2020-04-19T00:19:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-18:/2020-04-18.html</id><summary type="html">&lt;div class="section" id="irls-iteratively-reweighted-least-squares"&gt;
&lt;h2&gt;IRLS(Iteratively Reweighted Least Squares)&lt;/h2&gt;
&lt;p&gt;LAD(Least Absolute Deviation)を近似的・逐次的に解く方法としてのIRLSについて調査。そういえば基本的な原理を抑えていなかった。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://retrofocus28.blogspot.com/2015/09/iteratively-reweighted-least-squares.html"&gt;Iteratively Reweighted Least Squares　についてサクッと。&lt;/a&gt; 文字通りサクッとしたまとめ。OMPを使って解いているというのがとても気になる&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://cnx.org/contents/krkDdys0&amp;#64;12/Iterative-Reweighted-Least-Squares"&gt;Iterative Reweighted Least Squares&lt;/a&gt; 導入から解法まで。しかしなぜ解が求まるのかは不明。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://cedar.buffalo.edu/~srihari/CSE574/Chap4/4.3.3-IRLS.pdf"&gt;Iterative Reweighted Least Squares&lt;/a&gt; バッファロー大の講義資料？これも何故解けるのかはちゃんと書いてない。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.maths.lth.se/matematiklth/personal/fredrik/Session3.pdf"&gt;Iterative Reweighted Least Squares&lt;/a&gt; これが一番いいかも。なぜ解けるかもざっくり証明がある。&lt;ul&gt;
&lt;li&gt;そこで出てきたsupergradient（優勾配？劣勾配に対応している？）がよくわからん。資料のすぐ下に解説があったけど。 &lt;a class="reference external" href="http://www.its.caltech.edu/~kcborder/Notes/Supergrad.pdf"&gt;Supergradients&lt;/a&gt; に定義はあったけど幾何学的イメージが欲しい。&lt;/li&gt;
&lt;li&gt;Weiszfeld Algorithmsという幾何中央値を求めるアルゴリズムは &lt;a class="reference external" href="http://users.cecs.anu.edu.au/~trumpf/pubs/aftab_hartley_trumpf_PAMI2014.pdf"&gt;Generalized Weiszfeld Algorithms for …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="irls-iteratively-reweighted-least-squares"&gt;
&lt;h2&gt;IRLS(Iteratively Reweighted Least Squares)&lt;/h2&gt;
&lt;p&gt;LAD(Least Absolute Deviation)を近似的・逐次的に解く方法としてのIRLSについて調査。そういえば基本的な原理を抑えていなかった。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://retrofocus28.blogspot.com/2015/09/iteratively-reweighted-least-squares.html"&gt;Iteratively Reweighted Least Squares　についてサクッと。&lt;/a&gt; 文字通りサクッとしたまとめ。OMPを使って解いているというのがとても気になる&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://cnx.org/contents/krkDdys0&amp;#64;12/Iterative-Reweighted-Least-Squares"&gt;Iterative Reweighted Least Squares&lt;/a&gt; 導入から解法まで。しかしなぜ解が求まるのかは不明。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://cedar.buffalo.edu/~srihari/CSE574/Chap4/4.3.3-IRLS.pdf"&gt;Iterative Reweighted Least Squares&lt;/a&gt; バッファロー大の講義資料？これも何故解けるのかはちゃんと書いてない。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.maths.lth.se/matematiklth/personal/fredrik/Session3.pdf"&gt;Iterative Reweighted Least Squares&lt;/a&gt; これが一番いいかも。なぜ解けるかもざっくり証明がある。&lt;ul&gt;
&lt;li&gt;そこで出てきたsupergradient（優勾配？劣勾配に対応している？）がよくわからん。資料のすぐ下に解説があったけど。 &lt;a class="reference external" href="http://www.its.caltech.edu/~kcborder/Notes/Supergrad.pdf"&gt;Supergradients&lt;/a&gt; に定義はあったけど幾何学的イメージが欲しい。&lt;/li&gt;
&lt;li&gt;Weiszfeld Algorithmsという幾何中央値を求めるアルゴリズムは &lt;a class="reference external" href="http://users.cecs.anu.edu.au/~trumpf/pubs/aftab_hartley_trumpf_PAMI2014.pdf"&gt;Generalized Weiszfeld Algorithms for Lq Optimization&lt;/a&gt; に解説あり。しかしこの論文いいこと言ってる。「Generalized Weiszfeld Algorithms」は圧縮センシングとは異なりスパース表現を求めるわけではない。スパース性は担保されなくても、よりL1ノルムの意味で小さい解を求める。&lt;/li&gt;
&lt;li&gt;なぜ、IRLSとLMSアルゴリズムを結びつける研究がないのか。IRLSの逐次適用によってもフィルタ係数を更新していけそうだけど。試してみるし、類似研究が無いか引き続き調べる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;『スパースモデリング』の5章にも記述はある。しかし残差のL1最小化ではない。&lt;/p&gt;
&lt;/div&gt;
</content><category term="雑記"></category><category term="SLA"></category><category term="Lossless Audio"></category><category term="ロスレス音声"></category><category term="スパース符号化"></category><category term="L1ノルム"></category><category term="LAD"></category><category term="IRLS"></category></entry><entry><title>2020-04-17</title><link href="/2020-04-17.html" rel="alternate"></link><published>2020-04-17T23:00:00+09:00</published><updated>2020-04-17T23:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-17:/2020-04-17.html</id><summary type="html">&lt;div class="section" id="lad-least-absolute-deviation"&gt;
&lt;h2&gt;LAD(Least Absolute Deviation)&lt;/h2&gt;
&lt;p&gt;LAD(Least Absolute Deviation)を見ている。これは、残差をL1ノルムにした回帰問題一般のこと。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;ved=2ahUKEwi4wZXEhe3oAhUZMd4KHZrzDqQQFjAAegQIARAB&amp;amp;url=https%3A%2F%2Fis.cuni.cz%2Fwebapps%2Fzzp%2Fdownload%2F130215341&amp;amp;usg=AOvVaw3Cxgr7_WLuDQqhL1aKQl9f"&gt;カレル大学卒論&lt;/a&gt; が結構まとまっている。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://core.ac.uk/download/pdf/81785239.pdf"&gt;最尤推定による近似的手法&lt;/a&gt; は軽く読んだ。各傾きと切片を固定して逐次更新していく。更新時は中央値を拾ってくる。うーん中央値だと高速推定が厳しい。。。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ラプラス分布の最尤推定しようとしてもがく。対数尤度とって見てみても、単純な絶対値和が出て止まるし、反復スケーリング法を参考に、パラメータの増分を加えた時の対数尤度の下限を求めようとしたが上手く行かず。4時間飛ばす。&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="最尤推定の計算のあがき" src="./images/IMG_3828.jpg" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;最尤推定の計算のあがき&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;あがいて「A maximum likelihood approach to least absolute deviation regression」を引用している文献を漁ったら辞書学習をL1にしているやつが、やっぱりいた。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://winsty.net/papers/onndl.pdf"&gt;Online Robust Non-negative Dictionary Learning for Visual Tracking&lt;/a&gt; パーティクルフィルターを使っておる。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上の文献で使ってるHuber Loss結構すごくね？この誤差に基づくLMSアルゴリズムねえの？→「Robust …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="lad-least-absolute-deviation"&gt;
&lt;h2&gt;LAD(Least Absolute Deviation)&lt;/h2&gt;
&lt;p&gt;LAD(Least Absolute Deviation)を見ている。これは、残差をL1ノルムにした回帰問題一般のこと。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;ved=2ahUKEwi4wZXEhe3oAhUZMd4KHZrzDqQQFjAAegQIARAB&amp;amp;url=https%3A%2F%2Fis.cuni.cz%2Fwebapps%2Fzzp%2Fdownload%2F130215341&amp;amp;usg=AOvVaw3Cxgr7_WLuDQqhL1aKQl9f"&gt;カレル大学卒論&lt;/a&gt; が結構まとまっている。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://core.ac.uk/download/pdf/81785239.pdf"&gt;最尤推定による近似的手法&lt;/a&gt; は軽く読んだ。各傾きと切片を固定して逐次更新していく。更新時は中央値を拾ってくる。うーん中央値だと高速推定が厳しい。。。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ラプラス分布の最尤推定しようとしてもがく。対数尤度とって見てみても、単純な絶対値和が出て止まるし、反復スケーリング法を参考に、パラメータの増分を加えた時の対数尤度の下限を求めようとしたが上手く行かず。4時間飛ばす。&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="最尤推定の計算のあがき" src="./images/IMG_3828.jpg" style="width: 40%;" /&gt;
&lt;p class="caption"&gt;最尤推定の計算のあがき&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;あがいて「A maximum likelihood approach to least absolute deviation regression」を引用している文献を漁ったら辞書学習をL1にしているやつが、やっぱりいた。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://winsty.net/papers/onndl.pdf"&gt;Online Robust Non-negative Dictionary Learning for Visual Tracking&lt;/a&gt; パーティクルフィルターを使っておる。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上の文献で使ってるHuber Loss結構すごくね？この誤差に基づくLMSアルゴリズムねえの？→「Robust Huber adaptive filter」だけど中身を読めず…&lt;/p&gt;
&lt;p&gt;また、 &lt;a class="reference external" href="https://www.ml.uni-saarland.de/Lectures/CVX-SS10/ConvexOptimization-07-07-10.pdf"&gt;Convex Optimization and Modeling&lt;/a&gt; を読んでたらHuber損失はL1とL2の中間的な性質を示すようで、0に集中しなくなりそうな印象を受けた。&lt;/p&gt;
&lt;/div&gt;
</content><category term="雑記"></category><category term="SLA"></category><category term="Lossless Audio"></category><category term="ロスレス音声"></category><category term="スパース符号化"></category><category term="L1ノルム"></category><category term="LAD"></category></entry><entry><title>2020-04-16</title><link href="/2020-04-16.html" rel="alternate"></link><published>2020-04-16T23:20:00+09:00</published><updated>2020-04-16T23:20:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-16:/2020-04-16.html</id><summary type="html">&lt;div class="section" id="lms"&gt;
&lt;h2&gt;LMSフィルターの挙動観察&lt;/h2&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\mathrm{E}[\mathrm{sign}[e(n)]x(n-m)]\)&lt;/span&gt; の挙動を追いたい。色々な信号に対して、&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;span class="math"&gt;\(m\)&lt;/span&gt; が十分大きいとき、0に近づくかどうか&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;を知りたい。もし0に近づくならば有効な過程として解法に使える。
しかしその前に、LMSフィルター自体の挙動を追いたい。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;残差はどの様に減る？残差の時系列は？&lt;ul&gt;
&lt;li&gt;ステップサイズにより収束の度合い（残差の分布）が違う...&lt;/li&gt;
&lt;li&gt;当然、フィルタ次数でも収束の度合い（残差の分布）が違う&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;残差分布はどうなってる？Signed-LMSでラプラス分布に近づいてる？&lt;ul&gt;
&lt;li&gt;これは本当のようで、Signed-LMSの方が裾が細い残差分布が得られている。&lt;/li&gt;
&lt;li&gt;単純な正弦波に対してはLMSのほうが残差が小さくなるが、ボイスやピアノ音源に対しては圧倒的にSignLMSの方が性能が良い（残差のヒストグラムを見ると、裾が狭い）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathrm{E}[\mathrm{sign}[e(n)]x(n-m)]\)&lt;/span&gt;, &lt;span class="math"&gt;\(\mathrm{E}[e(n)x(n-m)]\)&lt;/span&gt; は両方とも0 …&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="lms"&gt;
&lt;h2&gt;LMSフィルターの挙動観察&lt;/h2&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\mathrm{E}[\mathrm{sign}[e(n)]x(n-m)]\)&lt;/span&gt; の挙動を追いたい。色々な信号に対して、&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;span class="math"&gt;\(m\)&lt;/span&gt; が十分大きいとき、0に近づくかどうか&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;を知りたい。もし0に近づくならば有効な過程として解法に使える。
しかしその前に、LMSフィルター自体の挙動を追いたい。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;残差はどの様に減る？残差の時系列は？&lt;ul&gt;
&lt;li&gt;ステップサイズにより収束の度合い（残差の分布）が違う...&lt;/li&gt;
&lt;li&gt;当然、フィルタ次数でも収束の度合い（残差の分布）が違う&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;残差分布はどうなってる？Signed-LMSでラプラス分布に近づいてる？&lt;ul&gt;
&lt;li&gt;これは本当のようで、Signed-LMSの方が裾が細い残差分布が得られている。&lt;/li&gt;
&lt;li&gt;単純な正弦波に対してはLMSのほうが残差が小さくなるが、ボイスやピアノ音源に対しては圧倒的にSignLMSの方が性能が良い（残差のヒストグラムを見ると、裾が狭い）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathrm{E}[\mathrm{sign}[e(n)]x(n-m)]\)&lt;/span&gt;, &lt;span class="math"&gt;\(\mathrm{E}[e(n)x(n-m)]\)&lt;/span&gt; は両方とも0。&lt;ul&gt;
&lt;li&gt;逐次計算していったら、音源非依存で0に近づいていく&lt;/li&gt;
&lt;li&gt;当然だよな…そもそもの過程として入力と雑音は無相関と仮定しているのだから。&lt;ul&gt;
&lt;li&gt;仮定しているのだからは正しくなくて、無相関にするようにフィルタ係数を更新しているが正しい。&lt;/li&gt;
&lt;li&gt;無相関になったときに勾配が0で最急勾配法が止まる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;なんか絶対値誤差最小化ってどっかで見たよな…と思っていたら、&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Least_absolute_deviations"&gt;https://en.wikipedia.org/wiki/Least_absolute_deviations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;修士のときに一回戦っていた。&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;ved=2ahUKEwi4wZXEhe3oAhUZMd4KHZrzDqQQFjAAegQIARAB&amp;amp;url=https%3A%2F%2Fis.cuni.cz%2Fwebapps%2Fzzp%2Fdownload%2F130215341&amp;amp;usg=AOvVaw3Cxgr7_WLuDQqhL1aKQl9f"&gt;カレル大学卒論&lt;/a&gt; が結構まとまっている。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(L_{1}\)&lt;/span&gt; ノルム最小化を近接オペレータの繰り返し適用で解けんじゃね？と思っている&lt;ul&gt;
&lt;li&gt;&lt;a class="reference external" href="https://yamagensakam.hatenablog.com/entry/2018/02/14/075106"&gt;近接勾配法とproximal operator&lt;/a&gt; を読んだが、パラメータ正則化だけだな&lt;/li&gt;
&lt;li&gt;パラメータ正則化はあるけど、残差をスパースにするのがない。なんで？&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="雑記"></category><category term="SLA"></category><category term="Lossless Audio"></category><category term="ロスレス音声"></category><category term="スパース符号化"></category></entry><entry><title>2020-04-10</title><link href="/2020-04-10.html" rel="alternate"></link><published>2020-04-10T23:18:00+09:00</published><updated>2020-04-10T23:18:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-10:/2020-04-10.html</id><content type="html">&lt;div class="section" id="id2"&gt;
&lt;h2&gt;続・古いロスレス音声コーデックの調査&lt;/h2&gt;
&lt;p&gt;古いロスレス音声コーデックと理論の概要を取りまとめた雑誌の特集があった:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.eie.polyu.edu.hk/~enyhchan/ce_ac_p1.pdf"&gt;Lossless Compression of Digital Audio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;理論としてもその通りだし、雑誌発行時点(1998)からさしたるブレークスルーが無いように見える。&lt;/p&gt;
&lt;p&gt;AudioPak, OggSquish, Philips, Sonarc, WAという謎のコーデック現る…。いったい何個あるんだ。&lt;/p&gt;
&lt;/div&gt;
</content><category term="雑記"></category><category term="SLA"></category><category term="Lossless Audio"></category><category term="ロスレス音声"></category><category term="スパース符号化"></category></entry><entry><title>2020-04-08</title><link href="/2020-04-08.html" rel="alternate"></link><published>2020-04-08T16:45:00+09:00</published><updated>2020-04-08T23:45:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-08:/2020-04-08.html</id><summary type="html">&lt;div class="section" id="id2"&gt;
&lt;h2&gt;古いロスレス音声コーデックの調査&lt;/h2&gt;
&lt;p&gt;ロスレス音声の歴史を探るために古いロスレス音声コーデックの情報を探っている。以下のサイトが &lt;a class="reference external" href="https://wiki.hydrogenaud.io/index.php?title=Lossless_comparison"&gt;Hydrogenaudioでの比較&lt;/a&gt; よりも古い内容を扱っている。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.firstpr.com.au/audiocomp/lossless/index.html"&gt;Lossless Compression of Audio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;見つけたロスレス音声コーデックを一覧する。というかほぼ &lt;a class="reference external" href="https://www.rarewares.org/rrw/about.php"&gt;Really Rare Wares&lt;/a&gt; 様へのリンク。&lt;/p&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;古めのロスレス音声コーデック&lt;/h3&gt;
&lt;div class="section" id="rkau-rk-audio"&gt;
&lt;h4&gt;&lt;a class="reference external" href="https://www.rarewares.org/rrw/rkau.php"&gt;RKAU(RK Audio)&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;古い比較において優秀な圧縮率を誇っていた。当時のMonkey's Audioよりも上。サイトを覗いたら exe と dll のみの配布だった。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://web.archive.org/web/20020124045327/http://rksoft.virtualave.net/rkau.html"&gt;RKAUのホームページ（魚拓）&lt;/a&gt; を見ても特に情報なし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="audiozip"&gt;
&lt;h4&gt;&lt;a class="reference external" href="https://www.rarewares.org/rrw/audiozip.php"&gt;AudioZip&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;これも圧縮率が比較的優秀。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://web.archive.org/web/20020207080740/http://www.csp.ntu.edu.sg:8000/MMS/MMCProjects.htm"&gt;AudioZipのホームページ（魚拓）&lt;/a&gt; を見てもこちらも特に情報なし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="wavarc"&gt;
&lt;h4&gt;&lt;a class="reference external" href="http://www.firstpr.com.au/audiocomp/lossless/wavarc/0readme.html"&gt;WavArc&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;こちらも最大圧縮率(-c5)を選択するとそれなりに優秀な結果を出していた。このページにexeとドキュメントをまとめたzipもあり。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="wavezip"&gt;
&lt;h4&gt;&lt;a class="reference external" href="https://www.rarewares.org/rrw/wavezip.php"&gt;WaveZip&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;圧縮率よりは速度重視のコーデックのようだ。MUSICompress というアルゴリズムの実装。 &lt;a class="reference external" href="https://www.rarewares.org/rrw/files/lossless/musi_txt.txt"&gt;WaveZipのデータシート&lt;/a&gt; によると符号化にはLZ(Lampel-Ziv)を使用しているようだ。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.firstpr.com.au/audiocomp/lossless/index.html#wavezip"&gt;WaveZipの概要&lt;/a&gt; が比較サイトに掲載されていた …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="id2"&gt;
&lt;h2&gt;古いロスレス音声コーデックの調査&lt;/h2&gt;
&lt;p&gt;ロスレス音声の歴史を探るために古いロスレス音声コーデックの情報を探っている。以下のサイトが &lt;a class="reference external" href="https://wiki.hydrogenaud.io/index.php?title=Lossless_comparison"&gt;Hydrogenaudioでの比較&lt;/a&gt; よりも古い内容を扱っている。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.firstpr.com.au/audiocomp/lossless/index.html"&gt;Lossless Compression of Audio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;見つけたロスレス音声コーデックを一覧する。というかほぼ &lt;a class="reference external" href="https://www.rarewares.org/rrw/about.php"&gt;Really Rare Wares&lt;/a&gt; 様へのリンク。&lt;/p&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;古めのロスレス音声コーデック&lt;/h3&gt;
&lt;div class="section" id="rkau-rk-audio"&gt;
&lt;h4&gt;&lt;a class="reference external" href="https://www.rarewares.org/rrw/rkau.php"&gt;RKAU(RK Audio)&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;古い比較において優秀な圧縮率を誇っていた。当時のMonkey's Audioよりも上。サイトを覗いたら exe と dll のみの配布だった。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://web.archive.org/web/20020124045327/http://rksoft.virtualave.net/rkau.html"&gt;RKAUのホームページ（魚拓）&lt;/a&gt; を見ても特に情報なし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="audiozip"&gt;
&lt;h4&gt;&lt;a class="reference external" href="https://www.rarewares.org/rrw/audiozip.php"&gt;AudioZip&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;これも圧縮率が比較的優秀。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://web.archive.org/web/20020207080740/http://www.csp.ntu.edu.sg:8000/MMS/MMCProjects.htm"&gt;AudioZipのホームページ（魚拓）&lt;/a&gt; を見てもこちらも特に情報なし。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="wavarc"&gt;
&lt;h4&gt;&lt;a class="reference external" href="http://www.firstpr.com.au/audiocomp/lossless/wavarc/0readme.html"&gt;WavArc&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;こちらも最大圧縮率(-c5)を選択するとそれなりに優秀な結果を出していた。このページにexeとドキュメントをまとめたzipもあり。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="wavezip"&gt;
&lt;h4&gt;&lt;a class="reference external" href="https://www.rarewares.org/rrw/wavezip.php"&gt;WaveZip&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;圧縮率よりは速度重視のコーデックのようだ。MUSICompress というアルゴリズムの実装。 &lt;a class="reference external" href="https://www.rarewares.org/rrw/files/lossless/musi_txt.txt"&gt;WaveZipのデータシート&lt;/a&gt; によると符号化にはLZ(Lampel-Ziv)を使用しているようだ。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.firstpr.com.au/audiocomp/lossless/index.html#wavezip"&gt;WaveZipの概要&lt;/a&gt; が比較サイトに掲載されていた。どうやら、入力波形を近似波形と誤差波形に分けて符号化するようだ。WaveZipではHu&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="lpac-ltac"&gt;
&lt;h4&gt;&lt;a class="reference external" href="https://www.rarewares.org/rrw/lpac.php"&gt;LPAC/LTAC&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;LPACはMPEG4-ALSの前身。LPACの前身がLTAC。LPACの平均的な圧縮率は優秀なようだ。 &lt;a class="reference external" href="https://web.archive.org/web/20060213124711/http://www.nue.tu-berlin.de/wer/liebchen/lpac.html"&gt;LPAC（魚拓）&lt;/a&gt; に以前公開していたサイトあり。&lt;/p&gt;
&lt;p&gt;LTAC(Lossless Transform Audio Compression)は名前の通り変換符号化に基づくロスレス音声圧縮コーデック、LPAC(Lossless Predictive Audio Compression)は予測に基づくロスレス音声圧縮コーデック。&lt;/p&gt;
&lt;p&gt;LPACに ベルリン工科大学、Real Networks、NTT の改良が加わってMPEG4-ALSが出来上がり、それ以降LPACの開発は停止されている。この経緯については &lt;a class="reference external" href="https://web.archive.org/web/20060212123059/http://www.nue.tu-berlin.de/forschung/projekte/lossless/mp4als.html"&gt;MPEG4-ALS（魚拓）&lt;/a&gt; に記述あり。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="shorten"&gt;
&lt;h4&gt;&lt;a class="reference external" href="https://archive.is/Z8k97"&gt;Shorten（魚拓）&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;おそらくロスレス音声の最古参にして基礎。なんと執筆時点（2020-04-08）でも &lt;tt class="docutils literal"&gt;brew&lt;/tt&gt; でインストールできた（ &lt;a class="reference external" href="https://linux.die.net/man/1/shorten"&gt;Shortenのmanページ&lt;/a&gt; もあるから各Linuxディストリビューションで使えるものと想像する）。エンコード速度はピカイチ。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=9797AA37C32F12179AF0803D8C2B22D2?doi=10.1.1.53.7337&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;Shortenの論文&lt;/a&gt; （テクニカルレポート）もある。この論文で、今のロスレス音声につながる重要な事実に幾つか触れている。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;音声信号は準定常（短い区間では定常とみなせる）だからブロックに分けてエンコード/デコードすべき。&lt;/li&gt;
&lt;li&gt;音声のモデル化には線形予測(LPC, Linear Predictive Coding)が使える。&lt;/li&gt;
&lt;li&gt;残差信号はガウス分布よりもラプラス分布に従っていると見える。その符号化にはライス符号を使うのが良い。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;この時点で既にラプラス分布を仮定したパラメータ設定を行っているからかなりの慧眼。他のロスレス音声コーデックはShortenを発展させたものに過ぎないと見える。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;所感&lt;/h3&gt;
&lt;p&gt;どうも2000年代前半までは各自でロスレス音声コーデックを作り、各自で最強を謳っていたらしい。&lt;/p&gt;
&lt;p&gt;歴史を雑にまとめると、1994年にShortenの論文が出てから、それよりも圧縮率の良いもの、圧縮速度（展開速度）が早いものが開発されて混沌に突入し上記のコーデックが現れた。その後、Monkey's Audio, WavPack, FLAC, LPAC（MPEG4-ALS）が生き残り、2000年以降はLa（更新停止）, TAK, TTA, ALAC（更新停止）, WMAL(Windows Media Audio Lossless), 2010年以降はOptimFROGが出現しているようだ。&lt;/p&gt;
&lt;p&gt;気になるのは比較サイトの &lt;a class="reference external" href="http://www.firstpr.com.au/audiocomp/lossless/index.html#rice"&gt;Rice Coding, AKA Rice Packing, Elias Gamma codes and other approaches&lt;/a&gt; である。Rice符号よりも効率の良いとされるPod符号の紹介がある。要観察。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id15"&gt;
&lt;h2&gt;スパース適応フィルタ&lt;/h2&gt;
&lt;p&gt;LPCの定式化をスパースにする試みは多くなされている。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.cs.tut.fi/~tabus/2013GhidoTabus.pdf"&gt;Sparse Modeling for Lossless Audio Compression&lt;/a&gt; : Ghidoさん（OptimFROGの人）の試み&lt;ul&gt;
&lt;li&gt;貪欲法によりスパース解を求めている。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.jstage.jst.go.jp/article/jasj/71/11/71_KJ00010109335/_pdf/-char/ja"&gt;スパース表現に基づく音声音響符号化&lt;/a&gt; : NTTの試み&lt;ul&gt;
&lt;li&gt;最小二乗解を求めるのではなくL1最小化に置き換えた定式化を行う。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;でも、TTAがやっているような適応フィルタをスパース解に近づける手法はまだロスレス音声に対してやっていないように見える。
スパースな解を目指してフィルタ係数を更新する適応フィルタはスパース適応フィルタ(Sparse Adaptive Filters)というようで、2000年代以降に研究が進んでいるようだ。&lt;/p&gt;
&lt;p&gt;最も基本的な適応フィルタであるLMS(Least Mean Square)フィルタは名前の通り二乗誤差最小化に立脚している。
スパース適応フィルタの主な用途はエコーキャンセル、ブラインド話者分離、複数話者特定ではあるが、やはり変換後の分布がスパースになるというのは大きい。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://signal.ee.bilkent.edu.tr/defevent/papers/cr1256.pdf"&gt;スパース適応フィルタの最近のサーベイ論文&lt;/a&gt; を流し読みした。スパース適応フィルタは、変数更新のときに1部の変数だけ更新する方法と、スパース最適化に従って更新するやり方の2つがあった。PNLMS(Proportionate NLMS), IPNLMS(Improved PNLMS)が後者の定式化で興味あり。引き続き見ていく。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1012.5066.pdf"&gt;Regularized Least-Mean-Square Algorithms&lt;/a&gt; には正則化を入れたLMSアルゴリズムの解説あり。LASSOにモチベーションを受けた最適化アルゴリズムが &lt;a class="reference external" href="https://wiki.eecs.umich.edu/global/data/hero/images/7/7b/Yilun-icassp2-09.pdf"&gt;ZA-LMS&lt;/a&gt; や &lt;a class="reference external" href="http://azadproject.ir/wp-content/uploads/2017/01/2018-Online-Sparse-System-Identification-and-Signal-Reconstruction-Using-Projections-.pdf"&gt;APWL1&lt;/a&gt; として提案されている。&lt;/p&gt;
&lt;/div&gt;
</content><category term="雑記"></category><category term="SLA"></category><category term="Lossless Audio"></category><category term="ロスレス音声"></category><category term="スパース符号化"></category></entry><entry><title>2020-04-02</title><link href="/2020-04-02.html" rel="alternate"></link><published>2020-04-02T18:00:00+09:00</published><updated>2020-04-02T21:34:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-02:/2020-04-02.html</id><content type="html">&lt;p&gt;GitHub io + Pelican を使ってみた。しばらくこちらで日報を書きたい。
GitHub io + Pelicanは以下の記事を参考にしている。まだあんまり分かってない。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://qiita.com/yusukew62/items/7b01d2370cdbe170b28d"&gt;Python製静的HTMLジェネレータのPelicanでGitHub Pagesを公開する方法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://qiita.com/ririli/items/0e06b21cb709beae4514"&gt;GitHub Pagesで静的サイトを簡単に作る&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://qiita.com/saira/items/71faa202efb4320cb41d"&gt;Python製 Pelican を使ってサクッとブログを公開する&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.pelicanthemes.com"&gt;Pelicanのテーマ集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/getpelican/pelican-themes/issues/460#issuecomment-346652986"&gt;テーマ導入時にハマったので参考にしたissue comment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;今日は（というか3月末）からSLAの高速化作業とまとめをしていた。&lt;/p&gt;
&lt;p&gt;格子型フィルタ演算はどうしても1乗算型にできず。次数演算を4次数にしてSSE演算するのがやっと。
SSE化するときに、スカラー演算とベクトル演算が混じったときに処理負荷が大きく上がってハマった。
&lt;a class="reference external" href="https://stackoverflow.com/questions/10313397/where-does-the-sse-instructions-outperform-normal-instructions"&gt;StackOverFlowの記事&lt;/a&gt; では &lt;cite&gt;_mm_set_epi32&lt;/cite&gt; のコストが高い旨記述あり。 &lt;cite&gt;_mm_loadu_si128&lt;/cite&gt; の使用に置き換えた。
&lt;a class="reference external" href="https://stackoverflow.com/questions/24446516/performance-worsens-when-using-sse-simple-addition-of-integer-arrays"&gt;他の記事&lt;/a&gt; で言及があってようやく分かった。全てをベクトル演算化したところ、処理負荷は4/5倍になった。あんまり早くなっていない。遺憾。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://herumi.in.coocan.jp/prog/gcc-and-vc.html"&gt;gccとVC&lt;/a&gt; にはgccとVisual Studioの挙動の差異について色々と書いてあった。&lt;/p&gt;
</content><category term="雑記"></category><category term="SLA"></category><category term="SSE"></category><category term="test"></category><category term="pelican"></category><category term="githubio"></category></entry></feed>