<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Aiki's Blog - 記事</title><link href="/" rel="alternate"></link><link href="/feeds/ji-shi.atom.xml" rel="self"></link><id>/</id><updated>2020-06-05T18:00:00+09:00</updated><entry><title>陰関数定理とその応用</title><link href="/yin-guan-shu-ding-li-tosonoying-yong.html" rel="alternate"></link><published>2020-06-05T18:00:00+09:00</published><updated>2020-06-05T18:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-06-05:/yin-guan-shu-ding-li-tosonoying-yong.html</id><summary type="html">&lt;p class="first last"&gt;陰関数定理の成り立ちとその応用として逆写像定理と制約付き極値問題まで。&lt;/p&gt;
</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\dfrac[2]{\frac{\mathrm{d} #1}{\mathrm{d} #2}}
\newcommand\mean[2]{\mathrm{E}_{#1} \left[ #2 \right]}
\newcommand\KL[2]{\mathrm{KL} \left[ #1 \ \middle| \middle| \ #2 \right]}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;逆写像定理をちゃんと振り返ろうとしたら、ついでに色々出てきてまとめる必要があるなと感じた。
記述は笠原皓司「微分積分学」を大幅に参考にしている。&lt;/p&gt;
&lt;div class="contents local topic" id="id2"&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id17"&gt;準備&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id18"&gt;多変数関数の微分と偏微分&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id19"&gt;偏導関数の連続性による微分可能性の条件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id20"&gt;写像の微分と偏微分&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id21"&gt;積分公式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id22"&gt;連続関数の集合の完備性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id23"&gt;不動点定理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id24"&gt;陰関数定理&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id25"&gt;多変数の場合&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id12" id="id26"&gt;陰関数定理の応用&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id13" id="id27"&gt;逆写像定理&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id14" id="id28"&gt;多変数の場合&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id15" id="id29"&gt;制約付き極値問題&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id16" id="id30"&gt;ラグランジュの未定乗数法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#kkt" id="id31"&gt;KKT 条件&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id17"&gt;準備&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id18"&gt;多変数関数の微分と偏微分&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;1 変数関数のグラフは一般に曲線で、それに接線が引けるときに関数は微分可能と言った。2 変数以上を持つ関数のグラフは一般に曲面になる。この関数が微分可能というときは、接平面が構築できれば良い。これを数学的にもう少し詳しく述べると次のようになる。&lt;/p&gt;
&lt;p&gt;2 変数関数 &lt;span class="math"&gt;\(z = f(x, y)\)&lt;/span&gt; のグラフの一点 &lt;span class="math"&gt;\(\ve{x}_{0} = (x_{0}, y_{0})\)&lt;/span&gt; における &lt;span class="math"&gt;\(f({x}_{0}, y_{0})\)&lt;/span&gt; の接平面を考える。今、接平面ができたとしてその方程式を考えると、定数 &lt;span class="math"&gt;\(\alpha, \beta\)&lt;/span&gt; を用いて&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
z - f(x_{0}, y_{0}) = \alpha (x - x_{0}) + \beta (y - y_{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表せる。点 &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; とその近傍の点 &lt;span class="math"&gt;\(\ve{x} = (x, y)\)&lt;/span&gt; において、この平面上の &lt;span class="math"&gt;\(z\)&lt;/span&gt; の値と &lt;span class="math"&gt;\(f(x, y)\)&lt;/span&gt; の誤差は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
g(x, y) = f(x, y) - z = f(x, y) - \left\{ f(x_{0}, y_{0}) + \alpha (x - x_{0}) + \beta (y - y_{0}) \right\}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となる。接平面であるときには、この誤差 &lt;span class="math"&gt;\(g(x, y)\)&lt;/span&gt; が &lt;span class="math"&gt;\(|\ve{x} - \ve{x}_{0}| = \sqrt{(x - x_{0})^{2} + (y - y_{0})^{2}}\)&lt;/span&gt; に対して無視できる程小さいことが必要である。即ち、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\lim_{\ve{x} \to \ve{x}_{0}} \frac{g(x, y)}{|\ve{x} - \ve{x}_{0}|} = 0
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たせば良い。このとき、 &lt;span class="math"&gt;\(f(x, y)\)&lt;/span&gt; は点 &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; において微分可能という。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;2 変数関数の微分&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(z = f(x, y)\)&lt;/span&gt; が点 &lt;span class="math"&gt;\(\ve{x}_{0} = (x_{0}, y_{0})\)&lt;/span&gt; で微分可能とは、ある定数 &lt;span class="math"&gt;\(\alpha, \beta\)&lt;/span&gt; があって&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{cases}
f(x, y) = f(x_{0}, y_{0}) + \alpha (x - x_{0}) + \beta (y - y_{0}) + g(x, y) \\
\displaystyle \lim_{\ve{x} \to \ve{x}_{0}} \frac{g(x, y)}{|\ve{x} - \ve{x}_{0}|} = 0 \quad (\ve{x} \neq \ve{x}_{0})
\end{cases}
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;と表せることである。&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;2 変数関数の偏導関数&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(f(x, y)\)&lt;/span&gt; が &lt;span class="math"&gt;\(\ve{x}_{0} = (x_{0}, y_{0})\)&lt;/span&gt; で微分可能なら、&lt;span class="math"&gt;\(\alpha, \beta\)&lt;/span&gt; はそれぞれ以下の式で求まる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\alpha = \lim_{x \to x_{0}} \frac{f(x, y_{0}) - f(x_{0}, y_{0})}{x - x_{0}} \\
\beta = \lim_{y \to y_{0}} \frac{f(x_{0}, y) - f(x_{0}, y_{0})}{y - y_{0}}
\end{align*}
&lt;/div&gt;
&lt;p&gt;（証明）&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{cases}
f(x, y) = f(x_{0}, y_{0}) + \alpha (x - x_{0}) + \beta (y - y_{0}) + g(x, y) \\
\displaystyle \lim_{\ve{x} \to \ve{x}_{0}} \frac{g(x, y)}{|\ve{x} - \ve{x}_{0}|} = 0 \quad (\ve{x} \neq \ve{x}_{0})
\end{cases}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;だから、 &lt;span class="math"&gt;\(y = y_{0}\)&lt;/span&gt; とすると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f(x, y_{0}) = f(x_{0}, y_{0}) + \alpha (x - x_{0}) + g(x, y_{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;これは、&lt;span class="math"&gt;\(y = y_{0}\)&lt;/span&gt; と固定したときに、 &lt;span class="math"&gt;\(f(x, y_{0})\)&lt;/span&gt; が &lt;span class="math"&gt;\(x\)&lt;/span&gt; で微分可能であることを示している。また、 &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; について解くと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\alpha &amp;amp;= \frac{f(x, y_{0}) - f(x_{0}, y_{0})}{x - x_{0}} + \frac{g(x, y_{0})}{x - x_{0}} \\
\implies \lim_{x \to x_{0}} \alpha &amp;amp;= \alpha = \lim_{x \to x_{0}} \frac{f(x, y_{0}) - f(x_{0}, y_{0})}{x - x_{0}}
\end{align*}
&lt;/div&gt;
&lt;p class="last"&gt;&lt;span class="math"&gt;\(\beta\)&lt;/span&gt; についても同様に &lt;span class="math"&gt;\(x = x_{0}\)&lt;/span&gt; として求められる。（証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;この &lt;span class="math"&gt;\(\alpha, \beta\)&lt;/span&gt; を偏微分係数といい、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\alpha = \parfrac{f}{x}(x_{0}, y_{0}) = f_{x}(x_{0}, y_{0}) \\
\beta = \parfrac{f}{y}(x_{0}, y_{0}) = f_{y}(x_{0}, y_{0})
\end{align*}
&lt;/div&gt;
&lt;p&gt;と書く。2 変数以上の場合も全く同様の考えにより微分が定義できる。冗長だが述べると、&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;多変数関数の微分&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(z = f(\ve{x}) = f(x_{1}, ..., x_{n})\)&lt;/span&gt; が点 &lt;span class="math"&gt;\(\ve{x}_{0} = (x_{1}^{0}, ..., x_{n}^{0})\)&lt;/span&gt; で微分可能であるとは、ある定数 &lt;span class="math"&gt;\(\alpha_{1}, ..., \alpha_{n}\)&lt;/span&gt; が存在して、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{cases}
\displaystyle f(\ve{x}) = f(\ve{x}_{0}) + \sum_{i = 1}^{n} \alpha_{i} (x_{i} - x_{i}^{0}) + g(\ve{x}) \\
\displaystyle \lim_{\ve{x} \to \ve{x}_{0}} \frac{g(\ve{x})}{|\ve{x} - \ve{x}_{0}|} = 0 \quad (\ve{x} \neq \ve{x}_{0})
\end{cases}
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;と表せることである。&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;多変数関数の偏導関数&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(f(\ve{x})\)&lt;/span&gt; が点 &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で微分可能なら、 &lt;span class="math"&gt;\(\alpha_{i}\ (i = 1,...,n)\)&lt;/span&gt; はそれぞれ以下の式で求められる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\alpha_{i} = \lim_{x_{i} \to x_{i}^{0}} \frac{f(x_{1}^{0}, ..., x_{i}, ..., x_{n}^{0}) - f(\ve{x}_{0})}{x_{i} - x_{i}^{0}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;（証明）微分可能性の定義式において &lt;span class="math"&gt;\(x_{j} = x_{j}^{0}\ (j \neq i)\)&lt;/span&gt; とおくと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
f(x_{1}^{0}, ..., x_{i}, ..., x_{n}^{0}) &amp;amp;= f(\ve{x}_{0}) + \alpha_{i}(x_{i} - x_{i}^{0}) + g(x_{1}^{0}, ..., x_{i}, ..., x_{n}^{0}) \\
\implies \alpha_{i} &amp;amp;= \frac{f(x_{1}^{0}, ..., x_{i}, ..., x_{n}^{0}) - f(\ve{x}_{0})}{x_{i} - x_{i}^{0}} + \frac{g(x_{1}^{0}, ..., x_{i}, ..., x_{n}^{0})}{x_{i} - x_{i}^{0}} \\
\implies \lim_{x_{i} \to x_{i}^{0}} \alpha_{i} = \alpha_{i} &amp;amp;= \lim_{x_{i} \to x_{i}^{0}} \frac{f(x_{1}^{0}, ..., x_{i}, ..., x_{n}^{0}) - f(\ve{x}_{0})}{x_{i} - x_{i}^{0}}
\end{align*}
&lt;/div&gt;
&lt;p class="last"&gt;（証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;やはり、この &lt;span class="math"&gt;\(\alpha_{i}\ (i = 1,...,n)\)&lt;/span&gt; を偏微分係数と呼び、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\alpha_{i} = \parfrac{f}{x_{i}}(\ve{x}_{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と書く。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id19"&gt;偏導関数の連続性による微分可能性の条件&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span class="math"&gt;\(f(x, y)\)&lt;/span&gt; が &lt;span class="math"&gt;\(\ve{x}_{0} = (x_{0}, y_{0})\)&lt;/span&gt; において微分可能であれば、 &lt;span class="math"&gt;\(x, y\)&lt;/span&gt; によって偏微分可能であるが、その逆（偏微分可能ならば微分可能）は成り立たない。しかし、以下の定理により、偏導関数に連続性を付与すれば、微分可能であることが示せる。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;偏導関数の連続性による微分可能性の条件&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(f(x, y)\)&lt;/span&gt; が点 &lt;span class="math"&gt;\(\ve{x}_{0} = (x_{0}, y_{0})\)&lt;/span&gt; で偏微分可能であり、かつ、&lt;span class="math"&gt;\(x, y\)&lt;/span&gt; どちらかの偏導関数が &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で連続であるならば、 &lt;span class="math"&gt;\(f(x, y)\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で微分可能である。&lt;/p&gt;
&lt;p&gt;（証明） &lt;span class="math"&gt;\(\parfrac{f}{y}(x,y)\)&lt;/span&gt; が &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; の近傍で存在し、かつ &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で連続と仮定して証明する（ &lt;span class="math"&gt;\(\parfrac{f}{x}\)&lt;/span&gt; が &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で連続としても同様に示せる）。 &lt;span class="math"&gt;\(f\)&lt;/span&gt; は &lt;span class="math"&gt;\(x\)&lt;/span&gt; について偏微分可能だから、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\parfrac{f}{x}(x_{0}, y_{0}) &amp;amp;= \frac{f(x, y_{0}) - f(x_{0}, y_{0})}{x - x_{0}} + \frac{g(x)}{x - x_{0}} \\
\implies f(x, y_{0}) &amp;amp;= f(x_{0}, y_{0}) + \parfrac{f}{x}(x_{0}, y_{0})(x - x_{0}) + g(x) \tag{1} \\
\lim_{x \to x_{0}} \frac{g(x)}{x - x_{0}} &amp;amp;= 0
\end{align*}
&lt;/div&gt;
&lt;p&gt;なる &lt;span class="math"&gt;\(g(x)\)&lt;/span&gt; が存在する。一方、 &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; の近傍で &lt;span class="math"&gt;\(f\)&lt;/span&gt; は &lt;span class="math"&gt;\(y\)&lt;/span&gt; について偏微分可能だから、平均（中間）値の定理により、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f(x, y) - f(x, y_{0}) = \parfrac{f}{y}(x, \eta)(y - y_{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たす &lt;span class="math"&gt;\(\eta\)&lt;/span&gt; が &lt;span class="math"&gt;\(y_{0}\)&lt;/span&gt; と &lt;span class="math"&gt;\(y\)&lt;/span&gt; の間に存在する。上式を (1) に代入すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
f(x, y) &amp;amp;= f(x_{0}, y_{0}) + \parfrac{f}{x}(x_{0}, y_{0})(x - x_{0}) + \parfrac{f}{y}(x, \eta)(y - y_{0}) + g(x) \\
&amp;amp;= f(x_{0}, y_{0}) + \parfrac{f}{x}(x_{0}, y_{0})(x - x_{0}) + \parfrac{f}{y}(x_{0}, y_{0})(y - y_{0}) + \left\{ \parfrac{f}{y}(x, \eta) - \parfrac{f}{y}(x_{0}, y_{0}) \right\} (y - y_{0}) + g(x) \\
&amp;amp;= f(x_{0}, y_{0}) + \parfrac{f}{x}(x_{0}, y_{0})(x - x_{0}) + \parfrac{f}{y}(x_{0}, y_{0})(y - y_{0}) + h(x, y)
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
h(x, y) = \left\{ \parfrac{f}{y}(x, \eta) - \parfrac{f}{y}(x_{0}, y_{0}) \right\} (y - y_{0}) + g(x)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とおいている。そして &lt;span class="math"&gt;\(h(x, y)\)&lt;/span&gt; は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\frac{h(x, y)}{|\ve{x} - \ve{x}_{0}|} = \left\{ \parfrac{f}{y}(x, \eta) - \parfrac{f}{y}(x_{0}, y_{0}) \right\} \frac{y - y_{0}}{|\ve{x} - \ve{x}_{0}|} + \frac{x - x_{0}}{|\ve{x} - \ve{x}_{0}|} \frac{g(x)}{x - x_{0}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と変形でき、 &lt;span class="math"&gt;\(|\ve{x} - \ve{x}_{0}| = \sqrt{(x - x_{0})^{2} + (y - y_{0})^{2}}\)&lt;/span&gt; より &lt;span class="math"&gt;\(\frac{y - y_{0}}{|\ve{x} - \ve{x}_{0}|} \leq \frac{|y - y_{0}|}{|\ve{x} - \ve{x}_{0}|} \leq 1\)&lt;/span&gt; と &lt;span class="math"&gt;\(\frac{x - x_{0}}{|\ve{x} - \ve{x}_{0}|} \leq \frac{|x - x_{0}|}{|\ve{x} - \ve{x}_{0}|} \leq 1\)&lt;/span&gt; が成り立つ。また、 &lt;span class="math"&gt;\(\ve{x} \to \ve{x}_{0}\)&lt;/span&gt; のとき &lt;span class="math"&gt;\((x, \eta) \to (x_{0}, y_{0})\)&lt;/span&gt; となるが、仮定より &lt;span class="math"&gt;\(\parfrac{f}{y}(x, y)\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で連続だから、 &lt;span class="math"&gt;\(\parfrac{f}{y}(x, \eta) - \parfrac{f}{y}(x_{0}, y_{0}) \to 0\)&lt;/span&gt; となる。従って、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\lim_{\ve{x} \to \ve{x}_{0}} \frac{h(x, y)}{|\ve{x} - \ve{x}_{0}|} = 0
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;これは &lt;span class="math"&gt;\(f(x, y)\)&lt;/span&gt; が &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で微分可能であることを示している。（証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;上記は最も単純な 2 変数の場合の証明だが、一般の多変数においても同様の定理が成り立つ。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;偏導関数の連続性による微分可能性の条件（多変数）&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(\ve{x} = (x_{1}, ..., x_{p}),\ \ve{y} = (y_{1}, ..., y_{n})\)&lt;/span&gt; とするとき、&lt;span class="math"&gt;\(p + n\)&lt;/span&gt; 変数の関数 &lt;span class="math"&gt;\(f(\ve{X}) = f(\ve{x}, \ve{y}) = f(x_{1}, ..., x_{p}, y_{1}, ..., y_{n})\)&lt;/span&gt; が点 &lt;span class="math"&gt;\(\ve{X}_{0} = (\ve{x}_{0}, \ve{y}_{0}) = (x_{1}^{0}, ..., x_{p}^{0}, y_{1}^{0}, ..., y_{n}^{0})\)&lt;/span&gt; で &lt;span class="math"&gt;\(\ve{x}\)&lt;/span&gt; に関して微分可能であり、かつ &lt;span class="math"&gt;\(\ve{y}\)&lt;/span&gt; に関する偏導関数が &lt;span class="math"&gt;\(\ve{X}_{0}\)&lt;/span&gt; の近傍で存在し、しかも偏導関数が &lt;span class="math"&gt;\(\ve{X}_{0}\)&lt;/span&gt; で連続ならば、 &lt;span class="math"&gt;\(f(\ve{x}, \ve{y})\)&lt;/span&gt; は &lt;span class="math"&gt;\((\ve{x}_{0}, \ve{y}_{0})\)&lt;/span&gt; で微分可能である。&lt;/p&gt;
&lt;p&gt;（証明）2 変数の場合とほぼ同様。 &lt;span class="math"&gt;\(f\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{x}\)&lt;/span&gt; について微分可能だから、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{cases}
  \displaystyle f(\ve{x}, \ve{y}_{0}) = f(\ve{x}_{0}, \ve{y}_{0}) + \sum_{i = 1}^{p} \parfrac{f}{x_{i}}(\ve{x}_{0}, \ve{y}_{0})(x_{i} - x_{i}^{0}) + g(\ve{x}) \tag{2} \\
  \displaystyle \lim_{\ve{x} \to \ve{x}_{0}} \frac{g(\ve{x})}{|\ve{x} - \ve{x}_{0}|} = 0
\end{cases}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;一方、 &lt;span class="math"&gt;\((\ve{x}_{0}, \ve{y}_{0})\)&lt;/span&gt; において、 &lt;span class="math"&gt;\(f\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{y}\)&lt;/span&gt; について偏微分可能だから、平均値の定理より&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f(\ve{x}, \ve{y}) - f(\ve{x}, \ve{y}_{0}) = \sum_{i = 0}^{n} \parfrac{f}{y_{i}} (\ve{x}, \ve{\eta}) (y_{i} - y_{i}^{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たす &lt;span class="math"&gt;\(\ve{\eta}\)&lt;/span&gt; が &lt;span class="math"&gt;\(\ve{y}_{0}\)&lt;/span&gt; と &lt;span class="math"&gt;\(\ve{y}\)&lt;/span&gt; の間に存在する。(2) へ代入すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
f(\ve{x}, \ve{y}) &amp;amp;= f(\ve{x}_{0}, \ve{y}_{0}) + \sum_{i = 1}^{p} \parfrac{f}{x_{i}}(\ve{x}_{0}, \ve{y}_{0})(x_{i} - x_{i}^{0}) + \sum_{i = 1}^{n} \parfrac{f}{y_{i}}(\ve{x}, \ve{\eta})(y_{i} - y_{i}^{0}) + g(\ve{x}) \\
&amp;amp;= f(\ve{x}_{0}, \ve{y}_{0}) + \sum_{i = 1}^{p} \parfrac{f}{x_{i}}(\ve{x}_{0}, \ve{y}_{0})(x_{i} - x_{i}^{0}) + \sum_{i = 1}^{n} \parfrac{f}{y_{i}}(\ve{x}_{0}, \ve{y}_{0})(y_{i} - y_{i}^{0}) + \sum_{i = 1}^{n} \left\{ \parfrac{f}{y_{i}}(\ve{x}, \ve{\eta}) - \parfrac{f}{y_{i}}(\ve{x}_{0}, \ve{y}_{0}) \right\}(y_{i} - y_{i}^{0}) + g(\ve{x}) \\
&amp;amp;= f(\ve{x}_{0}, \ve{y}_{0}) + \sum_{i = 1}^{p} \parfrac{f}{x_{i}}(\ve{x}_{0}, \ve{y}_{0})(x_{i} - x_{i}^{0}) + \sum_{i = 1}^{n} \parfrac{f}{y_{i}}(\ve{x}_{0}, \ve{y}_{0})(y_{i} - y_{i}^{0}) + h(\ve{x}, \ve{y})
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(h(\ve{x}, \ve{y})\)&lt;/span&gt; を &lt;span class="math"&gt;\(|\ve{X} - \ve{X}_{0}| = \sqrt{ \sum_{i = 1}^{p} (x_{i} - x_{i}^{0})^{2} + \sum_{i = 1}^{n} (y_{i} - y_{i}^{0})^{2} }\)&lt;/span&gt; で割ると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\frac{h(\ve{x}, \ve{y})}{|\ve{X} - \ve{X}_{0}|} = \sum_{i = 1}^{n} \left\{ \parfrac{f}{y_{i}}(\ve{x}, \ve{\eta}) - \parfrac{f}{y_{i}}(\ve{x}_{0}, \ve{y}_{0}) \right\} \frac{y_{i} - y_{i}^{0}}{|\ve{X} - \ve{X}_{0}|} + \frac{|\ve{x} - \ve{x}_{0}|}{|\ve{X} - \ve{X}_{0}|}\frac{g(\ve{x})}{|\ve{x} - \ve{x}_{0}|}
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;となる。やはり &lt;span class="math"&gt;\(\ve{X} \to \ve{X}_{0}\)&lt;/span&gt; のとき &lt;span class="math"&gt;\(\lim_{\ve{X} \to \ve{X}_{0}} \frac{h(\ve{x}, \ve{y})}{|\ve{X} - \ve{X}_{0}|} = 0\)&lt;/span&gt; だから、 &lt;span class="math"&gt;\(f\)&lt;/span&gt; は &lt;span class="math"&gt;\((\ve{x}_{0}, \ve{y}_{0})\)&lt;/span&gt; において微分可能である。（証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id20"&gt;写像の微分と偏微分&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\mathbb{R}^{n}\)&lt;/span&gt; の領域 &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; から &lt;span class="math"&gt;\(\mathbb{R}^{m}\)&lt;/span&gt; への写像 &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; を考える。 &lt;span class="math"&gt;\(\ve{x} = [x_{1}, ..., x_{n}]^{\mathsf{T}} \in \Omega\)&lt;/span&gt; に対して &lt;span class="math"&gt;\(\ve{f}(\ve{x}) = [ f_{1}(\ve{x}), ..., f_{m}(\ve{x}) ]^{\mathsf{T}} \in \mathbb{R}^{m}\)&lt;/span&gt; と書けるから、 &lt;span class="math"&gt;\(f_{1}(\ve{x}), ..., f_{m}(\ve{x})\)&lt;/span&gt; が &lt;span class="math"&gt;\(\ve{x}_{0} = [ x_{1}^{0}, ..., x_{n}^{0} ]^{\mathsf{T}}\)&lt;/span&gt; で連続な時、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\left\{ \begin{array}{ll}
\displaystyle f_{1}(\ve{x}) = f_{1}(\ve{x}_{0}) + \sum_{i = 1}^{n} \parfrac{f_{1}}{x_{i}} (x_{i} - x_{i}^{0}) + g_{1}(\ve{x}) &amp;amp; \\
\displaystyle f_{2}(\ve{x}) = f_{2}(\ve{x}_{0}) + \sum_{i = 1}^{n} \parfrac{f_{2}}{x_{i}} (x_{i} - x_{i}^{0}) + g_{2}(\ve{x}) &amp;amp; \\
\vdots &amp;amp; \\
\displaystyle f_{m}(\ve{x}) = f_{m}(\ve{x}_{0}) + \sum_{i = 1}^{n} \parfrac{f_{m}}{x_{i}} (x_{i} - x_{i}^{0}) + g_{m}(\ve{x}) &amp;amp; \\
\displaystyle \lim_{\ve{x} \to \ve{x}_{0}} \frac{g_{i}(\ve{x})}{|\ve{x} - \ve{x}_{0}|} = 0 &amp;amp; (i = 1, ..., m)
\end{array} \right.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成り立つ。ここで、次の &lt;strong&gt;ヤコビ行列（関数行列）&lt;/strong&gt;&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{M}(\ve{x}_{0}) = \parfrac{\ve{f}}{\ve{x}}(\ve{x}_{0}) =
\left[ \begin{array}{cccc}
\parfrac{f_{1}}{x_{1}}(\ve{x}_{0}) &amp;amp; \parfrac{f_{1}}{x_{2}}(\ve{x}_{0}) &amp;amp; \dots  &amp;amp; \parfrac{f_{1}}{x_{n}}(\ve{x}_{0}) \\
\parfrac{f_{2}}{x_{1}}(\ve{x}_{0}) &amp;amp; \parfrac{f_{2}}{x_{2}}(\ve{x}_{0}) &amp;amp; \dots  &amp;amp; \parfrac{f_{2}}{x_{n}}(\ve{x}_{0}) \\
\vdots                             &amp;amp; \vdots                             &amp;amp; \ddots &amp;amp; \vdots                             \\
\parfrac{f_{m}}{x_{n}}(\ve{x}_{0}) &amp;amp; \parfrac{f_{m}}{x_{n}}(\ve{x}_{0}) &amp;amp; \dots  &amp;amp; \parfrac{f_{m}}{x_{n}}(\ve{x}_{0}) \\
\end{array} \right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を使えば、次のようにまとめられる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{cases}
\ve{f}(\ve{x}) = \ve{f}(\ve{x}_{0}) + \ve{M}(\ve{x}_{0}) (\ve{x} - \ve{x}_{0}) + \ve{g}(\ve{x}) \\
\displaystyle \lim_{\ve{x} \to \ve{x}_{0}} \frac{\ve{g}(\ve{x})}{|\ve{x} - \ve{x}_{0}|} = \ve{0}
\end{cases}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで、 &lt;span class="math"&gt;\(\ve{g}(\ve{x}) = [ g_{1}(\ve{x}), ..., g_{m}(\ve{x}) ]^{\mathsf{T}}\)&lt;/span&gt; である。そして行列 &lt;span class="math"&gt;\(\ve{M}(\ve{x}_{0})\)&lt;/span&gt; が存在するとき、写像 &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で微分可能であるという。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;写像の微分可能性の必要十分条件&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;写像 &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; が &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で微分可能であるための必要十分条件は、 &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; の近傍で定義され、かつ &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で連続な関数を要素とする行列 &lt;span class="math"&gt;\(\ve{M}(\ve{x})\)&lt;/span&gt; があって、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{f}(\ve{x}) = \ve{f}(\ve{x}_{0}) + \ve{M}(\ve{x})(\ve{x} - \ve{x}_{0}) \tag{3}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たすことである。また、このとき &lt;span class="math"&gt;\(\parfrac{\ve{f}}{\ve{x}}(\ve{x}_{0}) = \ve{M}(\ve{x}_{0})\)&lt;/span&gt; 。&lt;/p&gt;
&lt;p&gt;（ &lt;span class="math"&gt;\(\Rightarrow\)&lt;/span&gt; の証明） &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; が &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で微分可能とする。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ve{f}(\ve{x}) &amp;amp;= \ve{f}(\ve{x}_{0}) + \parfrac{\ve{f}}{\ve{x}}(\ve{x}_{0})(\ve{x} - \ve{x}_{0}) + \ve{g}(\ve{x}) \\
&amp;amp;= \ve{f}(\ve{x}_{0}) + \left\{ \parfrac{\ve{f}}{\ve{x}}(\ve{x}_{0}) + \frac{\ve{g}(\ve{x})}{|\ve{x} - \ve{x}_{0}|^{2}} (\ve{x} - \ve{x}_{0})^{\mathsf{T}} \right\} (\ve{x} - \ve{x}_{0})
\end{align*}
&lt;/div&gt;
&lt;p&gt;の観察から、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{M}(\ve{x}) =
\left\{ \begin{array}{ll}
\parfrac{\ve{f}}{\ve{x}}(\ve{x}_{0}) + \frac{\ve{g}(\ve{x})}{|\ve{x} - \ve{x}_{0}|^{2}} (\ve{x} - \ve{x}_{0})^{\mathsf{T}} &amp;amp; (\ve{x} \neq \ve{x}_{0}) \\
\parfrac{\ve{f}}{\ve{x}}(\ve{x}_{0}) &amp;amp; (\ve{x} = \ve{x}_{0})
\end{array} \right.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とおけば、この &lt;span class="math"&gt;\(\ve{M}(\ve{x})\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で連続であり、(3) 式が得られることがわかる。（ &lt;span class="math"&gt;\(\Rightarrow\)&lt;/span&gt; の証明終）&lt;/p&gt;
&lt;p&gt;（ &lt;span class="math"&gt;\(\Leftarrow\)&lt;/span&gt; の証明） (3) 式から、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ve{f}(\ve{x}) &amp;amp;= \ve{f}(\ve{x}_{0}) + \ve{M}(\ve{x})(\ve{x} - \ve{x}_{0}) \\
&amp;amp;= \ve{f}(\ve{x}_{0}) + \ve{M}(\ve{x}_{0})(\ve{x} - \ve{x}_{0}) + \left\{ \ve{M}(\ve{x}) - \ve{M}(\ve{x}_{0}) \right\} (\ve{x} - \ve{x}_{0})
\end{align*}
&lt;/div&gt;
&lt;p&gt;となり、今、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{g}(\ve{x}) = \left\{ \ve{M}(\ve{x}) - \ve{M}(\ve{x}_{0}) \right\} (\ve{x} - \ve{x}_{0})
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;とおくと、 &lt;span class="math"&gt;\(\ve{M}(\ve{x})\)&lt;/span&gt; の &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; における連続性から &lt;span class="math"&gt;\(\frac{|\ve{g}(\ve{x})|}{|\ve{x} - \ve{x}_{0}|} = |\ve{M}(\ve{x}) - \ve{M}(\ve{x}_{0})| \to 0\ (\ve{x} \to \ve{x}_{0})\)&lt;/span&gt; より &lt;span class="math"&gt;\(\lim_{\ve{x} \to \ve{x}_{0}} \frac{\ve{g}(\ve{x})}{|\ve{x} - \ve{x}_{0}|} = \ve{0}\)&lt;/span&gt; が成立する。よって &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; において微分可能。（ &lt;span class="math"&gt;\(\Leftarrow\)&lt;/span&gt; の証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;上記の必要十分条件を用いることで、合成写像に対する微分公式が簡単に得られる。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;合成写像の微分&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(\ve{y} = \ve{f}(\ve{x})\)&lt;/span&gt; は &lt;span class="math"&gt;\(\mathbb{R}^{n}\)&lt;/span&gt; から &lt;span class="math"&gt;\(\mathbb{R}^{m}\)&lt;/span&gt; への写像、 &lt;span class="math"&gt;\(\ve{z} = \ve{g}(\ve{y})\)&lt;/span&gt; は &lt;span class="math"&gt;\(\mathbb{R}^{m}\)&lt;/span&gt; から &lt;span class="math"&gt;\(\mathbb{R}^{l}\)&lt;/span&gt; への写像で、 &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; が &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で、 &lt;span class="math"&gt;\(\ve{g}\)&lt;/span&gt; が &lt;span class="math"&gt;\(\ve{y}_{0} = \ve{f}(\ve{x}_{0})\)&lt;/span&gt; でそれぞれ微分可能なら、 &lt;span class="math"&gt;\(\ve{g}(\ve{f}(\ve{x}))\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で微分可能で、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{\ve{z}}{\ve{x}}(\ve{x}_{0}) = \parfrac{\ve{z}}{\ve{y}} (\ve{y}_{0}) \parfrac{\ve{y}}{\ve{x}}(\ve{x}_{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;（証明）&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{cases}
  \ve{f}(\ve{x}) = \ve{f}(\ve{x}_{0}) + \ve{M}(\ve{x})(\ve{x} - \ve{x}_{0}) \\
  \ve{g}(\ve{y}) = \ve{g}(\ve{y}_{0}) + \ve{N}(\ve{y})(\ve{y} - \ve{y}_{0})
\end{cases}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と書けるから、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ve{z} = \ve{g}(\ve{f}(\ve{x})) &amp;amp;= \ve{g}(\ve{f}(\ve{x}_{0}) + \ve{M}(\ve{x})(\ve{x} - \ve{x}_{0})) \\
&amp;amp;= \ve{g}(\ve{y}_{0}) + \ve{N}(\ve{f}(\ve{x})) \left\{ \ve{f}(\ve{x}_{0}) + \ve{M}(\ve{x})(\ve{x} - \ve{x}_{0}) - \ve{y}_{0} \right\} \\
&amp;amp;= \ve{g}(\ve{y}_{0}) + \ve{N}(\ve{f}(\ve{x})) \ve{M}(\ve{x})(\ve{x} - \ve{x}_{0})
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで &lt;span class="math"&gt;\(\ve{N}(\ve{f}(\ve{x}))\ve{M}(\ve{x})\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で連続だから、 &lt;span class="math"&gt;\(\ve{g}(\ve{f}(\ve{x}))\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で微分可能で、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{\ve{z}}{\ve{x}}(\ve{x}_{0}) = \ve{N}(\ve{f}(\ve{x}_{0})) \ve{M}(\ve{x}_{0}) = \parfrac{\ve{z}}{\ve{y}}(\ve{y}_{0}) \parfrac{\ve{y}}{\ve{x}}(\ve{x}_{0})
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;（証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id21"&gt;積分公式&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;平均値の定理を応用した便利な公式。以下の証明で頻繁に使用するため証明を与える。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;積分公式&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; を &lt;span class="math"&gt;\(\mathbb{R}^{n}\)&lt;/span&gt; の領域 &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; から &lt;span class="math"&gt;\(\mathbb{R}^{n}\)&lt;/span&gt; への &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級写像とする。 &lt;span class="math"&gt;\(\ve{x}_{0}, \ve{x} \in \Omega\)&lt;/span&gt; とこの 2 点を結ぶ線分が &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; に属するとき、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{f}(\ve{x}) - \ve{f}(\ve{x}_{0}) = \left\{ \int_{0}^{1} \parfrac{\ve{f}}{\ve{x}} (\ve{x}_{0} + t (\ve{x} - \ve{x}_{0})) \mathrm{d}t \right\} (\ve{x} - \ve{x}_{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで、 &lt;span class="math"&gt;\(\{ \}\)&lt;/span&gt; の中身は &lt;span class="math"&gt;\(n \times n\)&lt;/span&gt; の行列になっていることに注意。&lt;/p&gt;
&lt;p&gt;（証明） &lt;span class="math"&gt;\(\ve{\varphi}(t) = \ve{f}(\ve{x}_{0} + t (\ve{x} - \ve{x}_{0}))\)&lt;/span&gt; とおくと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ve{f}(\ve{x}) - \ve{f}(\ve{x}_{0}) &amp;amp;= \ve{\varphi}(1) - \ve{\varphi}(0) = \int_{0}^{1} \dfrac{\ve{\varphi}(t)}{t} \mathrm{d}t \\
&amp;amp;= \int_{0}^{1} \parfrac{\ve{f}}{\ve{x}} (\ve{x}_{0} + t (\ve{x} - \ve{x}_{0})) \dfrac{}{t} \left\{ \ve{x}_{0} + t (\ve{x} - \ve{x}_{0}) \right\} \mathrm{d}t \quad (\because \text{ 合成関数の微分 }) \\
&amp;amp;= \int_{0}^{1} \parfrac{\ve{f}}{\ve{x}} (\ve{x}_{0} + t (\ve{x} - \ve{x}_{0})) (\ve{x} - \ve{x}_{0}) \mathrm{d}t \\
&amp;amp;= \left\{ \int_{0}^{1} \parfrac{\ve{f}}{\ve{x}} (\ve{x}_{0} + t (\ve{x} - \ve{x}_{0})) \mathrm{d}t \right\} (\ve{x} - \ve{x}_{0})
\end{align*}
&lt;/div&gt;
&lt;p class="last"&gt;（証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="id8"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id22"&gt;連続関数の集合の完備性&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;かなり基礎的だが、以下の証明に必要なため書く。区間 &lt;span class="math"&gt;\(I\)&lt;/span&gt; で連続な関数の集合を &lt;span class="math"&gt;\(C^{0}(I)\)&lt;/span&gt; と書く。 &lt;span class="math"&gt;\(f \in C^{0}(I)\)&lt;/span&gt; に対して、関数の &amp;quot; 大きさ &amp;quot; を次のノルムとして定義する。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;関数のノルム&lt;/dt&gt;
&lt;dd&gt;&lt;span class="math"&gt;\(|| f ||_{0} = \sup_{x \in I} |f(x)|\)&lt;/span&gt; を関数 &lt;span class="math"&gt;\(f\)&lt;/span&gt; のノルムという。&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;ノルムは一般に次の 3 つの満たしている。&lt;/p&gt;
&lt;ol class="lowerroman simple"&gt;
&lt;li&gt;&lt;span class="math"&gt;\(|| f ||_{0} \geq 0\)&lt;/span&gt; （等号成立は &lt;span class="math"&gt;\(f(x) = 0\ (x \in I)\)&lt;/span&gt; に限る）&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(|| \lambda f ||_{0} = |\lambda| || f ||_{0}\)&lt;/span&gt; （ &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; は定数）&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(|| f + g ||_{0} \leq || f ||_{0} + || g ||_{0}\)&lt;/span&gt; （ &lt;strong&gt;三角不等式&lt;/strong&gt; と呼ぶ）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;関数のノルムにより、&lt;span class="math"&gt;\(C^{0}(I)\)&lt;/span&gt; 上の関数列 &lt;span class="math"&gt;\(\{ f_{n}(x) \}\)&lt;/span&gt; が &lt;span class="math"&gt;\(I\)&lt;/span&gt; において &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; に一様収束することを&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
|| f_{n} - f ||_{0} \to 0 \quad (n \to \infty)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表せる。&lt;/p&gt;
&lt;p&gt;次に、連続関数のノルムについて一様収束列とコーシー列が同値であることを見ていく。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;連続関数の一様収束列とコーシー列&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(C^{0}(I)\)&lt;/span&gt; の関数列 &lt;span class="math"&gt;\(\{ f_{n}(x) \}\)&lt;/span&gt; が一様収束列であるための必要十分条件は、 &lt;span class="math"&gt;\(\{ f_{n}(x) \}\)&lt;/span&gt; がノルムに関してコーシー列であることである。ここで、ノルムに関するコーシー列とは、任意の &lt;span class="math"&gt;\(\varepsilon &amp;gt; 0\)&lt;/span&gt; に対して自然数 &lt;span class="math"&gt;\(N\)&lt;/span&gt; を適当に選べば、 &lt;span class="math"&gt;\(p, q \geq N\)&lt;/span&gt; に対して、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
|| f_{p} - f_{q} ||_{0} &amp;lt; \varepsilon
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成立することを言う。&lt;/p&gt;
&lt;p&gt;（ &lt;span class="math"&gt;\(\Rightarrow\)&lt;/span&gt; の証明） &lt;span class="math"&gt;\(\{ f_{n}(x) \}\)&lt;/span&gt; が &lt;span class="math"&gt;\(f \in C^{0}(I)\)&lt;/span&gt; に一様収束すれば、任意の &lt;span class="math"&gt;\(\varepsilon &amp;gt; 0\)&lt;/span&gt; に対して自然数 &lt;span class="math"&gt;\(N\)&lt;/span&gt; を適当に大きく選んで &lt;span class="math"&gt;\(|| f_{n} - f ||_{0} &amp;lt; \varepsilon / 2\ (n \geq N)\)&lt;/span&gt; とできるから、 &lt;span class="math"&gt;\(p, q \geq N\)&lt;/span&gt; なる &lt;span class="math"&gt;\(p, q\)&lt;/span&gt; について&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
|| f_{p} - f_{q} ||_{0} &amp;amp;= || f_{p} - f - ( f_{q} - f ) ||_{0} \\
&amp;amp;\leq || f_{p} - f ||_{0} + || -( f_{q} - f ) ||_{0} \quad (\because \text{ 三角不等式 }) \\
&amp;amp;= || f_{p} - f ||_{0} + || f_{q} - f ||_{0} \\
&amp;amp;&amp;lt; \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon
\end{align*}
&lt;/div&gt;
&lt;p&gt;これは &lt;span class="math"&gt;\(\{ f_{n}(x) \}\)&lt;/span&gt; がコーシー列をなしていることを示している。（ &lt;span class="math"&gt;\(\Rightarrow\)&lt;/span&gt; の証明終）&lt;/p&gt;
&lt;p&gt;（ &lt;span class="math"&gt;\(\Leftarrow\)&lt;/span&gt; の証明） コーシー列は収束列（本稿では省略！！）だから、極限値があり、それを &lt;span class="math"&gt;\(f\)&lt;/span&gt; とおく。任意の &lt;span class="math"&gt;\(\varepsilon &amp;gt; 0\)&lt;/span&gt; に対して、自然数 &lt;span class="math"&gt;\(N\)&lt;/span&gt; を適当に大きく選び、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
|f_{p}(x) - f_{q}(x)| \leq || f_{p} - f_{q} ||_{0} &amp;lt; \varepsilon \quad (p,q \geq N, \ x \in I)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とできる。ここで、 &lt;span class="math"&gt;\(q \to \infty\)&lt;/span&gt; とすると、 &lt;span class="math"&gt;\(\lim_{q \to \infty} f_{q}(x) = f(x)\)&lt;/span&gt; だから、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
|f_{p}(x) - f(x)| \leq || f_{p} - f || &amp;lt; \varepsilon \quad (p \geq N)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となる。これは、 &lt;span class="math"&gt;\(\{ f_{n}(x) \}\)&lt;/span&gt; が &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; への一様収束列であることを示している。
最後に &lt;span class="math"&gt;\(f \in C^{0}(I)\)&lt;/span&gt;、即ち &lt;span class="math"&gt;\(f\)&lt;/span&gt; が &lt;span class="math"&gt;\(I\)&lt;/span&gt; で連続であることを示す。任意の点 &lt;span class="math"&gt;\(x_{0} \in I\)&lt;/span&gt; に対して、収束列の元 &lt;span class="math"&gt;\(f_{n}\)&lt;/span&gt; を使うと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
|f(x) - f(x_{0})| &amp;amp;= |f(x) - f_{n}(x) + f_{n}(x) - f_{n}(x_{0}) + f_{n}(x_{0}) - f(x_{0}) | \\
&amp;amp;\leq |f(x) - f_{n}(x)| + |f_{n}(x) - f_{n}(x_{0})| + |f_{n}(x_{0}) - f(x)| \\
&amp;amp;\leq || f_{n} - f ||_{0} + |f_{n}(x) - f_{n}(x_{0})| + || f_{n} - f ||_{0}
\end{align*}
&lt;/div&gt;
&lt;p&gt;まず、 &lt;span class="math"&gt;\(\{ f_{n}(x) \}\)&lt;/span&gt; の一様収束性により、任意の &lt;span class="math"&gt;\(\varepsilon &amp;gt; 0\)&lt;/span&gt; に対して &lt;span class="math"&gt;\(n\)&lt;/span&gt; を十分大きく取れば &lt;span class="math"&gt;\(|| f_{n} - f ||_{0} &amp;lt; \varepsilon / 3\)&lt;/span&gt; とできる。また、 &lt;span class="math"&gt;\(f_{n}\)&lt;/span&gt; は &lt;span class="math"&gt;\(I\)&lt;/span&gt; で連続だから、ある &lt;span class="math"&gt;\(\delta &amp;gt; 0\)&lt;/span&gt; があって &lt;span class="math"&gt;\(|f_{n}(x) - f_{n}(x_{0})| &amp;lt; \varepsilon / 3\ (|x - x_{0}| &amp;lt; \delta)\)&lt;/span&gt; とできる。まとめると、任意の &lt;span class="math"&gt;\(\varepsilon &amp;gt; 0\)&lt;/span&gt; と &lt;span class="math"&gt;\(x_{0} \in I\)&lt;/span&gt; に対して、 ある &lt;span class="math"&gt;\(\delta &amp;gt; 0\)&lt;/span&gt; があって、任意の &lt;span class="math"&gt;\(x \in I\)&lt;/span&gt; で&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
|f(x) - f(x_{0})| &amp;lt; \frac{\varepsilon}{3} + \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \varepsilon \quad (|x - x_{0}| &amp;lt; \delta)
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;が成立している。これは、 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; が &lt;span class="math"&gt;\(I\)&lt;/span&gt; で連続であることを示しており、 &lt;span class="math"&gt;\(f \in C^{0}(I)\)&lt;/span&gt; が言える。（ &lt;span class="math"&gt;\(\Leftarrow\)&lt;/span&gt; の証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;一般に、コーシー列が必ず収束列になるとき、その集合を &lt;strong&gt;完備&lt;/strong&gt; であるという。直感的には、集合上にコーシー列を構成したときに、極限値がその集合から飛び出ることがないことを指す。 &lt;span class="math"&gt;\(C^{0}(I)\)&lt;/span&gt; はノルムに関して完備な集合である。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id23"&gt;不動点定理&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;本稿では（「微分積分学」を参考に）陰関数の存在を示すために不動点定理を使用する。本節では不動点定理について説明する。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;縮小写像&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;関数集合 &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; から &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; への写像 &lt;span class="math"&gt;\(\Phi(f)\)&lt;/span&gt; がノルム &lt;span class="math"&gt;\(||f||_{0} = \sup_{\ve{x}} |f(\ve{x})|\)&lt;/span&gt; に関して &lt;strong&gt;縮小写像&lt;/strong&gt; であるとは、ある定数 &lt;span class="math"&gt;\(\rho \in [0, 1)\)&lt;/span&gt; があって、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
||\Phi(f) - \Phi(g)||_{0} \leq \rho ||f - g||_{0}
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;が任意の &lt;span class="math"&gt;\(f, g \in \mathcal{F}\)&lt;/span&gt; について成立することを言う。&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;縮小写像 &lt;span class="math"&gt;\(\Phi\)&lt;/span&gt; によって写像した関数間の距離は、写像する前よりも小さくなることを言っている。この縮小写像を繰り返し適用することで、ある関数（極限関数）に一様収束するとき、それを不動点という。定理の形で述べると次のようになる。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;不動点定理&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(\Phi(f)\)&lt;/span&gt; を &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; から &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; への縮小写像とし、 &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; は &lt;span class="math"&gt;\(C^{0}(\Omega)\)&lt;/span&gt; （定義域 &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; の &lt;span class="math"&gt;\(C^{0}\)&lt;/span&gt; 級すなわち連続関数の集合）において完備な集合とする。このとき、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f = \Phi(f)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たす関数 &lt;span class="math"&gt;\(f \in \mathcal{F}\)&lt;/span&gt; が唯一つ存在する。この様な &lt;span class="math"&gt;\(f\)&lt;/span&gt; を &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; における &lt;span class="math"&gt;\(\Phi\)&lt;/span&gt; の不動点という。&lt;/p&gt;
&lt;p&gt;（証明） &lt;span class="math"&gt;\(f_{0} \in \mathcal{F}\)&lt;/span&gt; を任意に一つ取って、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f_{n} = \Phi(f_{n-1}) \quad n = 1, 2, ...
\end{equation*}
&lt;/div&gt;
&lt;p&gt;によって関数列 &lt;span class="math"&gt;\(\{ f_{n} \}\)&lt;/span&gt; を作り、これがノルム &lt;span class="math"&gt;\(||\cdot||_{0}\)&lt;/span&gt; に関してコーシー列を作っていることを確かめる。 &lt;span class="math"&gt;\(\Phi\)&lt;/span&gt; は縮小写像だから、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
|| f_{n + 1} - f_{n} ||_{0} &amp;amp;= || \Phi(f_{n}) - \Phi(f_{n-1}) ||_{0} \\
&amp;amp;\leq \rho || f_{n} - f_{n-1} ||_{0} = \rho || \Phi(f_{n-1}) - \Phi(f_{n-2}) ||_{0} \\
&amp;amp;\leq \rho^{2} || f_{n-1} - f_{n-2} ||_{0} = \rho^{2} || \Phi(f_{n-2}) - \Phi(f_{n-1}) ||_{0} \\
&amp;amp;\vdots \\
&amp;amp;\leq \rho^{n} || f_{1} - f_{0} ||_{0}
\end{align*}
&lt;/div&gt;
&lt;p&gt;従って、&lt;span class="math"&gt;\(p \leq q\)&lt;/span&gt; を満たす任意の添字について、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
|| f_{p} - f_{q} ||_{0} &amp;amp;= || f_{p} - f_{p+1} + f_{p+1} - f_{p+2} + f_{p+2} + ... + f_{q-1} + f_{q} ||_{0} \\
&amp;amp;\leq || f_{p} - f_{p+1} ||_{0} + || f_{p+1} - f_{p+2} ||_{0} +  ... + || f_{q-1} + f_{q} ||_{0} \quad (\because \text{ 三角不等式 }) \\
&amp;amp;\leq \rho^{p} || f_{1} - f_{0} ||_{0} + \rho^{p+1} || f_{1} - f_{0} ||_{0} + ... + \rho^{q-1} || f_{1} - f_{0} ||_{0} \\
&amp;amp;= \rho^{p}(1 + \rho + ... + \rho^{q-1-p}) || f_{1} - f_{0} ||_{0} \\
&amp;amp;= \frac{\rho^{p}(1 - \rho^{q-1-p})}{1 - \rho} || f_{1} - f_{0} ||_{0} \quad (\because \text{ 等比級数の和の公式 }) \\
&amp;amp;\leq \frac{\rho^{p}}{1 - \rho} || f_{1} - f_{0} ||_{0}
\end{align*}
&lt;/div&gt;
&lt;p&gt;最後の式は &lt;span class="math"&gt;\(p\)&lt;/span&gt; を大きくしていくといくらでも小さくなる。従って、 &lt;span class="math"&gt;\(\{ f_{n} \}\)&lt;/span&gt; はコーシー列である。更に、 &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; は完備な集合だから &lt;span class="math"&gt;\(\{ f_{n} \}\)&lt;/span&gt; は収束列であり、ある &lt;span class="math"&gt;\(f \in \mathcal{F}\)&lt;/span&gt; があって、 &lt;span class="math"&gt;\(f_{n}\)&lt;/span&gt; は 領域 &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; において &lt;span class="math"&gt;\(f\)&lt;/span&gt; に一様収束する（ &lt;span class="math"&gt;\(\because\)&lt;/span&gt; コーシーの収束定理）。
従って、 &lt;span class="math"&gt;\(f_{n} = \Phi(f_{n-1})\)&lt;/span&gt; の &lt;span class="math"&gt;\(n\)&lt;/span&gt; を大きくしていくと、極限において&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f = \Phi(f)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成立する。従って、 &lt;span class="math"&gt;\(f\)&lt;/span&gt; は &lt;span class="math"&gt;\(\Phi\)&lt;/span&gt; の不動点である。
次に唯一性を示す。仮に不動点が 2 つあったとして、それらを &lt;span class="math"&gt;\(f, g\)&lt;/span&gt; を書くと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
|| f - g ||_{0} = || \Phi(f) - \Phi(g) ||_{0} \leq \rho || f - g ||_{0} &amp;lt; || f - g ||_{0}
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;となるが、これは &lt;span class="math"&gt;\(|| f - g ||_{0} &amp;gt; 0\)&lt;/span&gt; である限り &lt;span class="math"&gt;\(|| f - g ||_{0} &amp;lt; || f - g ||_{0}\)&lt;/span&gt; となって矛盾。従って &lt;span class="math"&gt;\(|| f - g ||_{0} = 0\)&lt;/span&gt; でなければならず、これは &lt;span class="math"&gt;\(f\)&lt;/span&gt; と &lt;span class="math"&gt;\(g\)&lt;/span&gt; が同一の不動点であることを意味する。（証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id24"&gt;陰関数定理&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;まずは 2 変数 &lt;span class="math"&gt;\(x, y\)&lt;/span&gt; で考えてみる。 &lt;span class="math"&gt;\(x^{2} + y^{2} - 2 = 0\)&lt;/span&gt; のように &lt;span class="math"&gt;\(y = f(x)\)&lt;/span&gt; が陽に分からない場合がある。この 2 変数関数 &lt;span class="math"&gt;\(F(x, y)\)&lt;/span&gt; による等式 &lt;span class="math"&gt;\(F(x, y) = 0\)&lt;/span&gt; を陰関数表示という。 &lt;span class="math"&gt;\(F(x, y) = 0\)&lt;/span&gt; に対して、何らかの関数 &lt;span class="math"&gt;\(y = f(x)\)&lt;/span&gt; （もしくは &lt;span class="math"&gt;\(x = h(y)\)&lt;/span&gt; ）の存在を保証するのが陰関数定理である。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;陰関数定理（2 変数）&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(\mathbb{R}^{2}\)&lt;/span&gt; のある領域（開部分集合） &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; で &lt;span class="math"&gt;\(F(x, y)\)&lt;/span&gt; は連続とし、 &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; の 1 点 &lt;span class="math"&gt;\((x_{0}, y_{0})\)&lt;/span&gt; の近傍 &lt;span class="math"&gt;\(U\)&lt;/span&gt; で &lt;span class="math"&gt;\(y\)&lt;/span&gt; について偏微分可能かつ &lt;span class="math"&gt;\(F_{y}(x, y) = \parfrac{F}{y}(x, y)\)&lt;/span&gt; は &lt;span class="math"&gt;\(U\)&lt;/span&gt; で連続とする。このとき、次の 1 - 4 が成り立つ。&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;もし、 &lt;span class="math"&gt;\(F(x_{0}, y_{0}) = 0,\ F_{y}(x_{0}, y_{0}) \neq 0\)&lt;/span&gt; ならば、 &lt;span class="math"&gt;\((x_{0}, y_{0})\)&lt;/span&gt; の十分小さい近傍 &lt;span class="math"&gt;\(V\)&lt;/span&gt; において&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;
\begin{equation*}
y_{0} = f(x_{0}), \ F(x, f(x)) = 0
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たす連続関数 &lt;span class="math"&gt;\(y = f(x)\ ((x, y) \in V)\)&lt;/span&gt; が唯一つ存在する。（ &lt;span class="math"&gt;\(x\)&lt;/span&gt; と &lt;span class="math"&gt;\(y\)&lt;/span&gt; の関係を入れ替えても成立する。即ち &lt;span class="math"&gt;\(F(x_{0}, y_{0}) = 0,\ F_{x}(x_{0}, y_{0}) \neq 0\)&lt;/span&gt; ならば、 &lt;span class="math"&gt;\((x_{0}, y_{0})\)&lt;/span&gt; の近傍で &lt;span class="math"&gt;\(x_{0} = h(y_{0}), \ F(h(y), y) = 0\)&lt;/span&gt; を満たす連続関数 &lt;span class="math"&gt;\(h\)&lt;/span&gt; が存在する）。&lt;/p&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;1 が成り立つとき、 &lt;span class="math"&gt;\(F\)&lt;/span&gt; が &lt;span class="math"&gt;\((x_{0}, y_{0})\)&lt;/span&gt; において &lt;span class="math"&gt;\(x\)&lt;/span&gt; について偏微分可能なら、 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; は &lt;span class="math"&gt;\(x_{0}\)&lt;/span&gt; において微分可能で、&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;
\begin{equation*}
\dfrac{f}{x}(x_{0}) = - \frac{F_{x}(x_{0}, y_{0})}{F_{y}(x_{0}, y_{0})}
\end{equation*}
&lt;/div&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;2 が成り立つとき、 &lt;span class="math"&gt;\(F\)&lt;/span&gt; が &lt;span class="math"&gt;\(U\)&lt;/span&gt; 上で &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級なら、 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; も &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級で、&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;
\begin{equation*}
\dfrac{f}{x}(x) = - \frac{F_{x}(x, y)}{F_{y}(x, y)} \quad (x, f(x)) \in V
\end{equation*}
&lt;/div&gt;
&lt;ol class="arabic simple" start="4"&gt;
&lt;li&gt;3 が成り立つとき、 &lt;span class="math"&gt;\(F\)&lt;/span&gt; が &lt;span class="math"&gt;\(U\)&lt;/span&gt; 上で &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級なら、 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; も &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;（1. の証明） &lt;span class="math"&gt;\(x_{0}\)&lt;/span&gt; の近傍 &lt;span class="math"&gt;\(U_{1}\)&lt;/span&gt; と &lt;span class="math"&gt;\(y_{0}\)&lt;/span&gt; の近傍 &lt;span class="math"&gt;\(U_{2}\)&lt;/span&gt; を適当に選んで &lt;span class="math"&gt;\(U_{1} \times U_{2} \subset U\)&lt;/span&gt; となるようにしておく。 &lt;span class="math"&gt;\(M = F_{y}(x_{0}, y_{0})\)&lt;/span&gt; とおく。 &lt;span class="math"&gt;\(F_{y}\)&lt;/span&gt; は仮定より連続だから、 &lt;span class="math"&gt;\(\rho \in (0, 1)\)&lt;/span&gt; なる &lt;span class="math"&gt;\(\rho\)&lt;/span&gt; を 1 つ取り、これに応じて &lt;span class="math"&gt;\(U_{1}, U_{2}\)&lt;/span&gt; を小さく取り直して&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
|M - F_{y}(x, y)| &amp;lt; \rho |M| \quad (x \in U_{1}, y \in U_{2})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とできる。更に、 &lt;span class="math"&gt;\(F\)&lt;/span&gt; は連続だから、 &lt;span class="math"&gt;\(U_{2} = [ y_{0} - \delta, y_{0} + \delta ]\)&lt;/span&gt; と閉区間を取ったとき、 &lt;span class="math"&gt;\(\delta\)&lt;/span&gt; に応じて &lt;span class="math"&gt;\(U_{1}\)&lt;/span&gt; を小さく取り直し、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
|F(x, y_{0}) - F(x_{0}, y_{0})| = |F(x, y_{0})| &amp;lt; (1 - \rho)|M|\delta \quad (x \in U_{1})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とできる。次に、関数の集合 &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; として、 &lt;span class="math"&gt;\(U_{1}\)&lt;/span&gt; 上で連続で、 &lt;span class="math"&gt;\(y_{0} = \varphi(x_{0})\)&lt;/span&gt; となり、かつ &lt;span class="math"&gt;\(x \in U_{1}\)&lt;/span&gt; において &lt;span class="math"&gt;\(\varphi(x) \in U_{2}\)&lt;/span&gt; となるような関数 &lt;span class="math"&gt;\(\varphi\)&lt;/span&gt; の全体をとる。 &lt;span class="math"&gt;\(U_{1}\)&lt;/span&gt; 上で連続な関数の集合を &lt;span class="math"&gt;\(C^{0}(U_{1})\)&lt;/span&gt; とかくと、&lt;span class="math"&gt;\(\mathcal{F} \subset C^{0}(U_{1})\)&lt;/span&gt; が成立する。今、写像 &lt;span class="math"&gt;\(\Phi(\varphi)\)&lt;/span&gt; として、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\Phi(\varphi)(x) = \varphi(x) - \frac{1}{M} F(x, \varphi(x))
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とおいた時、これが &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; から &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; への縮小写像であって、かつ &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; が完備であることを示す。まず、 &lt;span class="math"&gt;\(\varphi \in \mathcal{F}\)&lt;/span&gt; を任意に取ったときに、 &lt;span class="math"&gt;\(\Phi(\varphi) \in \mathcal{F}\)&lt;/span&gt; となることを示す。平均値の定理により、 &lt;span class="math"&gt;\(\varphi(x)\)&lt;/span&gt; と &lt;span class="math"&gt;\(y_{0}\)&lt;/span&gt; の間に &lt;span class="math"&gt;\(\xi_{1}(x)\)&lt;/span&gt; を適当に選び、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F(x, \varphi(x)) = F(x, y_{0}) + F_{y}(x, \xi_{1}(x))(\varphi(x) - y_{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とできるから、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
|\Phi(\varphi)(x) - y_{0}| &amp;amp;= |\varphi(x) - \frac{1}{M}F(x, \varphi(x)) - y_{0}| \\
&amp;amp;= |\varphi(x) - y_{0} - \frac{1}{M}F(x, y_{0}) - \frac{1}{M}F(x, \xi_{1}(x))(\varphi(x) - y_{0})| \\
&amp;amp;= \left| \left\{ \varphi(x) - y_{0} \right\} \left\{ 1 - \frac{1}{M}F(x, \xi_{1}(x)) \right\} - \frac{1}{M}F(x, \varphi(x)) \right| \\
&amp;amp;\leq |\varphi(x) - y_{0}|\left| 1 - \frac{1}{M}F(x, \xi_{1}(x)) \right| + \left| \frac{1}{M}F(x, \varphi(x)) \right| \quad (\because \text{ 三角不等式 }) \\
&amp;amp;&amp;lt; \rho |\varphi(x) - y_{0}| + (1 - \rho)\delta \\
&amp;amp;\leq \rho \delta + (1 - \rho)\delta \quad (\because \varphi(x) \in U_{2} = [y_{0} - \delta, y_{0} + \delta]) \\
&amp;amp;= \delta
\end{align*}
&lt;/div&gt;
&lt;p&gt;よって、 &lt;span class="math"&gt;\(\Phi(\varphi)(x) \in U_{2}\)&lt;/span&gt; だから、 &lt;span class="math"&gt;\(\Phi(\varphi) \in \mathcal{F}\)&lt;/span&gt; 。次に、 &lt;span class="math"&gt;\(\varphi, \psi \in \mathcal{F}\)&lt;/span&gt; をとると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\Phi(\varphi)(x) - \Phi(\psi)(x) &amp;amp;= \varphi(x) - \frac{1}{M} F(x, \varphi(x)) - \left\{ \psi(x) - \frac{1}{M} F(x, \psi(x)) \right\} \\
&amp;amp;= \varphi(x) - \psi(x) - \frac{1}{M} \left\{ F(x, \varphi(x)) - F(x, \psi(x)) \right\}
\end{align*}
&lt;/div&gt;
&lt;p&gt;再び平均値の定理より、 &lt;span class="math"&gt;\(\varphi(x)\)&lt;/span&gt; と &lt;span class="math"&gt;\(\psi(x)\)&lt;/span&gt; の間に &lt;span class="math"&gt;\(\xi_{2}(x)\)&lt;/span&gt; を適当に選び、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F(x, \varphi(x)) = F(x, \psi(x)) + F_{y}(x, \xi_{2}(x))(\varphi(x) - \psi(x))
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とできるから、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\Phi(\varphi)(x) - \Phi(\psi)(x) &amp;amp;= \varphi(x) - \psi(x) - \frac{1}{M} \left\{ F_{y}(x, \xi_{2}(x))(\varphi(x) - \psi(x)) \right\} \\
&amp;amp;= \left\{ 1 - \frac{1}{M} F_{y} (x, \xi_{2}(x)) \right\} (\varphi(x) - \psi(x))
\end{align*}
&lt;/div&gt;
&lt;p&gt;となる。 &lt;span class="math"&gt;\(\xi_{2}(x) \in U_{2}\)&lt;/span&gt; だから、 &lt;span class="math"&gt;\(|M - F_{y}(x, \xi_{2}(x))| &amp;lt; \rho |M|\)&lt;/span&gt; が成り立ち、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
|\Phi(\varphi)(x) - \Phi(\psi)(x)| &amp;lt; \rho |\varphi(x) - \psi(x)| \leq \rho || \varphi - \psi ||_{0}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;これが任意の &lt;span class="math"&gt;\(x \in U_{1}\)&lt;/span&gt; で成り立つから、&lt;span class="math"&gt;\(\rho || \varphi - \psi ||_{0}\)&lt;/span&gt; は &lt;span class="math"&gt;\(|\Phi(\varphi)(\ve{x}) - \Phi(\psi)(\ve{x})|\)&lt;/span&gt; の上限を与えており、 &lt;span class="math"&gt;\(|| \Phi(\varphi) - \Phi(\psi) ||_{0} \leq \rho || \varphi - \psi ||_{0}\)&lt;/span&gt; が言える。従って &lt;span class="math"&gt;\(\Phi\)&lt;/span&gt; は縮小写像である。&lt;/p&gt;
&lt;p&gt;次に、 &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; が完備であることを示す。 &lt;span class="math"&gt;\(\mathcal{F} \subset C^{0}(U_{1})\)&lt;/span&gt; で &lt;span class="math"&gt;\(C^{0}(U_{1})\)&lt;/span&gt; は完備だから、 &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; の中のコーシー列は &lt;span class="math"&gt;\(C^{0}(U_{1})\)&lt;/span&gt; の中での収束列である。写像 &lt;span class="math"&gt;\(\Phi\)&lt;/span&gt; による極限関数 &lt;span class="math"&gt;\(f\)&lt;/span&gt; は、 &lt;span class="math"&gt;\(\Phi\)&lt;/span&gt; の作り方により、 &lt;span class="math"&gt;\(U_{1}\)&lt;/span&gt; 上で連続で、 &lt;span class="math"&gt;\(y_{0} = f(x_{0})\)&lt;/span&gt; を満たす。また、各点収束として考えると（コーシー列は一様収束性を述べているので可能）、極限関数 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; は閉区間 &lt;span class="math"&gt;\(U_{2}\)&lt;/span&gt; に属するから、 &lt;span class="math"&gt;\(f \in \mathcal{F}\)&lt;/span&gt; である。即ち &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; は完備。&lt;/p&gt;
&lt;p&gt;以上より不動点定理が使える。即ち、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f(x) = \Phi(f)(x) \quad (x \in U_{1})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たす関数が &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; の中に唯一存在する。これは、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\Phi(f)(x) = f(x) - \frac{1}{M} F(x, f(x))
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と合わせると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F(x, f(x)) = 0 \quad (x \in U_{1})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が得られるから、定理 1 が示された。（1. の証明終）&lt;/p&gt;
&lt;p&gt;（2. の証明） &lt;span class="math"&gt;\(F\)&lt;/span&gt; は &lt;span class="math"&gt;\((x_{0}, y_{0})\)&lt;/span&gt; で偏微分可能で &lt;span class="math"&gt;\(F_{y}(x, y)\)&lt;/span&gt; は &lt;span class="math"&gt;\(U\)&lt;/span&gt; で連続だから、 &lt;span class="math"&gt;\(F(x, y)\)&lt;/span&gt; は全微分可能である（ &lt;span class="math"&gt;\(\because\)&lt;/span&gt; 準備）。従って &lt;span class="math"&gt;\(U\)&lt;/span&gt; において、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F(x, y) = F(x_{0}, y_{0}) + \alpha(x, y)(x - x_{0}) + \beta(x, y)(y - y_{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とかける（ &lt;span class="math"&gt;\(\alpha, \beta\)&lt;/span&gt; は &lt;span class="math"&gt;\((x_{0}, y_{0})\)&lt;/span&gt; で連続な関数で、かつ &lt;span class="math"&gt;\(\alpha(x_{0}, y_{0}) = F_{x}(x_{0}, y_{0}), \beta(x_{0},\ y_{0}) = F_{y}(x_{0}, y_{0}) \neq 0\)&lt;/span&gt;）。&lt;span class="math"&gt;\(x \in V\)&lt;/span&gt; に対して &lt;span class="math"&gt;\(y = f(x)\)&lt;/span&gt; を代入すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
F(x, f(x)) = 0 &amp;amp;= F(x_{0}, f(x_{0})) + \alpha(x, f(x))(x - x_{0}) + \beta(x, f(x))(f(x) - y_{0}) \\
&amp;amp;= \alpha(x, f(x))(x - x_{0}) + \beta(x, f(x))(f(x) - y_{0}) \\
\implies f(x) &amp;amp;= y_{0} - \frac{\alpha(x, f(x))}{\beta(x, f(x))}(x - x_{0})
\end{align*}
&lt;/div&gt;
&lt;p&gt;両辺を &lt;span class="math"&gt;\(x - x_{0}\)&lt;/span&gt; で割ってから &lt;span class="math"&gt;\(x \to x_{0}\)&lt;/span&gt; としてみると、&lt;span class="math"&gt;\(-\alpha(x, f(x)) / \beta(x, f(x))\)&lt;/span&gt; は &lt;span class="math"&gt;\(x_{0}\)&lt;/span&gt; において（連続関数の商になっているので）連続だから極限値をもつ。即ち &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; は &lt;span class="math"&gt;\(x_{0}\)&lt;/span&gt; で微分可能で、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\dfrac{f}{x}(x_{0}) = - \frac{\alpha(x_{0}, f(x_{0}))}{\beta(x_{0}, f(x_{0}))} = - \frac{F_{x}(x_{0}, y_{0})}{F_{y}(x_{0}, y_{0})} \tag{4}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;（2. の証明終）&lt;/p&gt;
&lt;p&gt;（3. の証明） &lt;span class="math"&gt;\(F\)&lt;/span&gt; が &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級ならば (4) の右辺は &lt;span class="math"&gt;\((x_{0}, y_{0})\)&lt;/span&gt; で連続だから、 &lt;span class="math"&gt;\(y_{0} = f(x_{0})\)&lt;/span&gt; を代入したものも &lt;span class="math"&gt;\(x_{0}\)&lt;/span&gt; で連続である。即ち、 &lt;span class="math"&gt;\(\dfrac{f}{x}(x)\)&lt;/span&gt; は連続関数（ &lt;span class="math"&gt;\(C^{0}\)&lt;/span&gt; 級）だから、 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; は &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級。（3. の証明終）&lt;/p&gt;
&lt;p&gt;（4. の証明） &lt;span class="math"&gt;\(F\)&lt;/span&gt; が &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級ならば &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; も &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級であることを示す。 &lt;span class="math"&gt;\(m = 1\)&lt;/span&gt; の場合は 3. より成立する。 &lt;span class="math"&gt;\(m - 1\)&lt;/span&gt; の場合に成立すると仮定して、もし、 &lt;span class="math"&gt;\(F\)&lt;/span&gt; が &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級ならば、同時に &lt;span class="math"&gt;\(F\)&lt;/span&gt; は &lt;span class="math"&gt;\(C^{m-1}\)&lt;/span&gt; 級だから、 仮定より &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; も &lt;span class="math"&gt;\(C^{m-1}\)&lt;/span&gt; 級である。従って、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\dfrac{f}{x}(x) = - \frac{F_{x}(x, f(x))}{F_{y}(x, f(x))}
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;の右辺は &lt;span class="math"&gt;\(C^{m-1}\)&lt;/span&gt; 級の関数 &lt;span class="math"&gt;\(F_{x}, F_{y}\)&lt;/span&gt; に &lt;span class="math"&gt;\(C^{m-1}\)&lt;/span&gt; 級の関数 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; を代入したもので、合成関数の微分法から右辺は &lt;span class="math"&gt;\(C^{m-1}\)&lt;/span&gt; 級である。 &lt;span class="math"&gt;\(\dfrac{f}{x}(x)\)&lt;/span&gt; が &lt;span class="math"&gt;\(C^{m-1}\)&lt;/span&gt; 級だから、 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; は &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級。（4. の証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;div class="section" id="id11"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id25"&gt;多変数の場合&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;3 変数 &lt;span class="math"&gt;\(x, y, z\)&lt;/span&gt; による連立陰関数&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{cases}
  F(x, y, z) = 0 \\
  G(x, y, z) = 0
\end{cases}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たす連続関数 &lt;span class="math"&gt;\(y=f(x),\ z = g(x)\)&lt;/span&gt; を求める問題を考える。 &lt;span class="math"&gt;\(F(x_{0}, y_{0}, z_{0}) = 0,\ F_{y}(x_{0}, y_{0}, z_{0}) \neq 0\)&lt;/span&gt; とすると、陰関数定理により、 &lt;span class="math"&gt;\((x_{0}, y_{0}, z_{0})\)&lt;/span&gt; の近傍で &lt;span class="math"&gt;\(y = Y(x, z)\)&lt;/span&gt; という陰関数が存在する。これを &lt;span class="math"&gt;\(G\)&lt;/span&gt; に代入すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
G(x, Y(x, z), z) = H(x, z) = 0
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となるが、もし、 &lt;span class="math"&gt;\(G(x_{0}, y_{0}, z_{0}) = 0,\ H_{z}(x_{0}, z_{0}) \neq 0\)&lt;/span&gt; ならば、これから &lt;span class="math"&gt;\(z = g(x)\)&lt;/span&gt; という陰関数が存在する。これを &lt;span class="math"&gt;\(y = Y(x, z)\)&lt;/span&gt; に代入して、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
y = f(x) = Y(x, g(x))
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とおけば、2 つの陰関数が求められる。今、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
H_{z}(x, z) &amp;amp;= G_{z}(x, Y(x, z), z) \\
&amp;amp;= \parfrac{G}{z} + \parfrac{G}{y} \dfrac{Y}{z} \quad (\because \text{ 合成関数の微分 }) \\
&amp;amp;= G_{z} - G_{y}\frac{F_{z}}{F_{y}} \quad (\because \text{ 陰関数定理 }) \\
&amp;amp;= \frac{1}{F_{y}} \det
\left[
\begin{array}{cc}
  F_{y} &amp;amp; F_{z} \\
  G_{y} &amp;amp; G_{z}
\end{array}
\right]
\end{align*}
&lt;/div&gt;
&lt;p&gt;だから、 &lt;span class="math"&gt;\(H_{z}(x_{0}, z_{0}) \neq 0\)&lt;/span&gt; は、行列&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{F}{\ve{y}} =
\left[
\begin{array}{cc}
  F_{y} &amp;amp; F_{z} \\
  G_{y} &amp;amp; G_{z}
\end{array}
\right]
\quad
\left(
\ve{F} =
\left[
\begin{array}{c}
F \\
G
\end{array}
\right],\
\ve{y} =
\left[
\begin{array}{c}
y \\
z
\end{array}
\right]
\right)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が &lt;span class="math"&gt;\((x_{0}, y_{0}, z_{0})\)&lt;/span&gt; で正則という条件と同値になる。従って、&lt;span class="math"&gt;\(\parfrac{F}{\ve{y}}\)&lt;/span&gt; が正則であれば陰関数を持つことが分かる（ &lt;span class="math"&gt;\(\parfrac{F}{\ve{y}}\)&lt;/span&gt; が正則ならば、 &lt;span class="math"&gt;\(F_{y}, F_{z}\)&lt;/span&gt; のいずれかは &lt;span class="math"&gt;\(0\)&lt;/span&gt; ではないから、 &lt;span class="math"&gt;\(F_{y}(x_{0}, y_{0}, z_{0}) \neq 0\)&lt;/span&gt; という条件をおいても良い）。これを一般化した定理を以下に示す。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;陰関数定理（多変数）&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(\mathbb{R}^{p} \times \mathbb{R}^{n}\)&lt;/span&gt; の領域 &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; で、 &lt;span class="math"&gt;\(n\)&lt;/span&gt; 次元写像&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{F}(\ve{x}, \ve{y}) =
\left[ \begin{array}{c}
F_{1}(x_{1}, ..., x_{p}, y_{1}, ..., y_{n}) \\
F_{2}(x_{1}, ..., x_{p}, y_{1}, ..., y_{n}) \\
\vdots \\
F_{n}(x_{1}, ..., x_{p}, y_{1}, ..., y_{n})
\end{array} \right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;は連続として、1 点 &lt;span class="math"&gt;\((\ve{x}_{0}, \ve{y}_{0})^{\mathsf{T}} = (x_{1}^{0}, ..., x_{p}^{0}, y_{1}^{0}, ..., y_{n}^{0})^{\mathsf{T}}\)&lt;/span&gt; の近傍 &lt;span class="math"&gt;\(U\)&lt;/span&gt; でサイズ &lt;span class="math"&gt;\(n \times n\)&lt;/span&gt; の正方行列関数&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{\ve{F}}{\ve{y}}(\ve{x}, \ve{y}) =
\left[ \begin{array}{cccc}
\parfrac{F_{1}}{y_{1}} &amp;amp; \parfrac{F_{1}}{y_{2}} &amp;amp;  \dots &amp;amp; \parfrac{F_{1}}{y_{n}} \\
\parfrac{F_{2}}{y_{1}} &amp;amp; \parfrac{F_{2}}{y_{2}} &amp;amp;  \dots &amp;amp; \parfrac{F_{2}}{y_{n}} \\
\vdots                 &amp;amp; \vdots                 &amp;amp; \ddots &amp;amp; \vdots                 \\
\parfrac{F_{n}}{y_{1}} &amp;amp; \parfrac{F_{n}}{y_{2}} &amp;amp;  \dots &amp;amp; \parfrac{F_{n}}{y_{n}}
\end{array} \right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;は連続な正則行列とする。とのとき、次の 1 - 4 が成り立つ。&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;もし &lt;span class="math"&gt;\(\ve{F}(\ve{x}_{0}, \ve{y}_{0}) = \ve{0}\)&lt;/span&gt; ならば、 &lt;span class="math"&gt;\((\ve{x}_{0}, \ve{y}_{0})\)&lt;/span&gt; の十分小さい近傍 &lt;span class="math"&gt;\(V\)&lt;/span&gt; があって&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{y}_{0} = \ve{f}(\ve{x}_{0}), \ \ve{F}(\ve{x}, \ve{f}(\ve{x})) = \ve{0} \quad (\ve{x}, \ve{f}(\ve{x})) \in V
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たす &lt;span class="math"&gt;\(n\)&lt;/span&gt; 次元ベクトル値連続関数 &lt;span class="math"&gt;\(\ve{f}(\ve{x})\)&lt;/span&gt; が唯一存在する。&lt;/p&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;1 が成り立つとき、 &lt;span class="math"&gt;\(\ve{F}\)&lt;/span&gt; が &lt;span class="math"&gt;\((\ve{x}_{0}, \ve{y}_{0})\)&lt;/span&gt; において &lt;span class="math"&gt;\(\ve{x}\)&lt;/span&gt; について微分可能なら、 &lt;span class="math"&gt;\(\ve{f}(\ve{x})\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; において微分可能で、&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{\ve{f}}{\ve{x}}(\ve{x}_{0}) = - \left[ \parfrac{\ve{F}}{\ve{y}}(\ve{x}_{0}, \ve{y}_{0}) \right]^{-1} \parfrac{\ve{F}}{\ve{x}}(\ve{x}_{0}, \ve{y}_{0})
\end{equation*}
&lt;/div&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;2 が成り立つとき、 &lt;span class="math"&gt;\(\ve{F}\)&lt;/span&gt; が &lt;span class="math"&gt;\(U\)&lt;/span&gt; 上で &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級なら、 &lt;span class="math"&gt;\(\ve{f}(\ve{x})\)&lt;/span&gt; も &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級で、&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{\ve{f}}{\ve{x}}(\ve{x}) = - \left[ \parfrac{\ve{F}}{\ve{y}}(\ve{x}, \ve{y}) \right]^{-1} \parfrac{\ve{F}}{\ve{x}}(\ve{x}, \ve{y})
\end{equation*}
&lt;/div&gt;
&lt;ol class="arabic simple" start="4"&gt;
&lt;li&gt;3 が成り立つとき、 &lt;span class="math"&gt;\(\ve{F}\)&lt;/span&gt; が &lt;span class="math"&gt;\(U\)&lt;/span&gt; 上で &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級なら、 &lt;span class="math"&gt;\(\ve{f}(\ve{x})\)&lt;/span&gt; も &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級である。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;証明については 2 変数と同様に考える。&lt;/p&gt;
&lt;p&gt;（1. の証明） &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; の近傍 &lt;span class="math"&gt;\(U_{1}\)&lt;/span&gt; と &lt;span class="math"&gt;\(\ve{y}_{0}\)&lt;/span&gt; の近傍 &lt;span class="math"&gt;\(U_{2}\)&lt;/span&gt; を適当に選んで &lt;span class="math"&gt;\(U_{1} \times U_{2} \subset U\)&lt;/span&gt; となるようにしておく。次に、行列 &lt;span class="math"&gt;\(\ve{M}\)&lt;/span&gt; として&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{M} = \parfrac{\ve{F}}{\ve{y}}(\ve{x}_{0}, \ve{y}_{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とおく。 &lt;span class="math"&gt;\(\ve{M}\)&lt;/span&gt; は仮定より正則行列である。 &lt;span class="math"&gt;\(\rho \in (0, 1)\)&lt;/span&gt; なる &lt;span class="math"&gt;\(\rho\)&lt;/span&gt; を 1 つ取り、これに応じて &lt;span class="math"&gt;\(U_{1}, U_{2}\)&lt;/span&gt; を小さく取り直して&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\left| \ve{M} - \parfrac{\ve{F}}{\ve{y}}(\ve{x}, \ve{y}) \right| &amp;lt; \frac{\rho}{|\ve{M}^{-1}|} \quad (\ve{x}, \ve{y}) \in U_{1} \times U_{2}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となる様にしておく（ &lt;span class="math"&gt;\(|\ve{M}| = \sup_{|\ve{x}| = 1} |\ve{M}\ve{x}|\)&lt;/span&gt; : 行列ノルム）。 &lt;span class="math"&gt;\(U_{2}\)&lt;/span&gt; は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
U_{2} = \left\{ \ve{y} | |\ve{y} - \ve{y}_{0}| \leq \delta \right\}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と閉集合にとり、この &lt;span class="math"&gt;\(\delta\)&lt;/span&gt; に応じて &lt;span class="math"&gt;\(U_{1}\)&lt;/span&gt; を更に小さく取り直し、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
|\ve{F}(\ve{x}, \ve{y}_{0})| &amp;lt; (1 - \rho)\frac{\delta}{|\ve{M}^{-1}|} \quad \ve{x} \in U_{1}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成り立つようにしておく（これは、&lt;span class="math"&gt;\(\ve{F}(\ve{x}_{0}, \ve{y}_{0}) = \ve{0}\)&lt;/span&gt; かつ &lt;span class="math"&gt;\(\ve{F}\)&lt;/span&gt; の連続性により可能）。&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\ve{x}\)&lt;/span&gt; の関数の集合 &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; として、 &lt;span class="math"&gt;\(U_{1}\)&lt;/span&gt; 上で連続で、 &lt;span class="math"&gt;\(\ve{y}_{0} = \ve{\varphi}(\ve{x}_{0})\)&lt;/span&gt; となり、かつ、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{\varphi}(\ve{x}) \in U_{2} \quad \ve{x} \in U_{1}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となるような写像 &lt;span class="math"&gt;\(\ve{\varphi}(\ve{x})\)&lt;/span&gt; の全体をとる。そして写像 &lt;span class="math"&gt;\(\ve{\Phi}(\ve{\varphi})\)&lt;/span&gt; として、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{\Phi}(\ve{\varphi})(\ve{x}) = \ve{\varphi}(\ve{x}) - \ve{M}^{-1} \ve{F}(\ve{x}, \ve{\varphi}(\ve{x}))
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とおく。上で述べた積分公式より、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{F}(\ve{x}, \ve{\varphi}(\ve{x})) = \ve{F}(\ve{x}, \ve{y}_{0}) + \int_{0}^{1} \parfrac{\ve{F}}{\ve{y}} (\ve{x}, \ve{y}_{0} + t (\ve{\varphi}(\ve{x}) - \ve{y}_{0})) \mathrm{d} t (\ve{\varphi}(\ve{x}) - \ve{y}_{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;だから、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ve{\Phi}(\ve{\varphi})(\ve{x}) - \ve{y}_{0} &amp;amp;= \ve{\varphi}(\ve{x}) - \ve{y}_{0} - \ve{M}^{-1} \ve{F}(\ve{x}, \ve{\varphi}(\ve{x})) \\
&amp;amp;= \ve{\varphi}(\ve{x}) - \ve{y}_{0} - \ve{M}^{-1} \ve{F}(\ve{x}, \ve{y}_{0}) - \ve{M}^{-1} \int_{0}^{1} \parfrac{\ve{F}}{\ve{y}} (\ve{x}, \ve{y}_{0} + t (\ve{\varphi}(\ve{x}) - \ve{y}_{0})) \mathrm{d} t (\ve{\varphi}(\ve{x}) - \ve{y}_{0}) \\
&amp;amp;= \left\{ \ve{I} - \ve{M}^{-1} \int_{0}^{1} \parfrac{\ve{F}}{\ve{y}} (\ve{x}, \ve{y}_{0} + t (\ve{\varphi}(\ve{x}) - \ve{y}_{0})) \mathrm{d} t \right\} \left\{ \ve{\varphi}(\ve{x}) - \ve{y}_{0} \right\} - \ve{M}^{-1}\ve{F}(\ve{x}, \ve{y}_{0}) \\
\implies |\ve{\Phi}(\ve{\varphi})(\ve{x}) - \ve{y}_{0}| &amp;amp;\leq \left| \ve{I} - \ve{M}^{-1} \int_{0}^{1} \parfrac{\ve{F}}{\ve{y}} (\ve{x}, \ve{y}_{0} + t (\ve{\varphi}(\ve{x}) - \ve{y}_{0})) \mathrm{d} t \right||\ve{\varphi}(\ve{x}) - \ve{y}_{0}| + |\ve{M}^{-1}\ve{F}(\ve{x}, \ve{y}_{0})|
\end{align*}
&lt;/div&gt;
&lt;p&gt;となる。ここで、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\left| \ve{I} - \ve{M}^{-1} \int_{0}^{1} \parfrac{\ve{F}}{\ve{y}} \mathrm{d} t \right| &amp;amp;= \left| \ve{M}^{-1}\left( \ve{M} - \int_{0}^{1} \parfrac{\ve{F}}{\ve{y}} \mathrm{d} t \right) \right| \\
&amp;amp;\leq |\ve{M}^{-1}| \int_{0}^{1} \left| \ve{M} - \parfrac{\ve{F}}{\ve{y}} \right| \mathrm{d} t \\
&amp;amp;&amp;lt; |\ve{M}^{-1}| \int_{0}^{1} \frac{\rho}{|\ve{M}^{-1}|} \mathrm{d} t = \rho
\end{align*}
&lt;/div&gt;
&lt;p&gt;が成り立つ。更に、 &lt;span class="math"&gt;\(\ve{\varphi}(\ve{x}) \in U_{2}\)&lt;/span&gt; より、 &lt;span class="math"&gt;\(|\ve{\varphi}(\ve{x}) - \ve{y}_{0}| \leq \delta\)&lt;/span&gt; 。しかも、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
|\ve{M}^{-1}\ve{F}(\ve{x}, \ve{y}_{0})| \leq |\ve{M}^{-1}||\ve{F}(\ve{x}, \ve{y}_{0})| &amp;lt; (1 - \rho) \delta
\end{equation*}
&lt;/div&gt;
&lt;p&gt;だから、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
|\ve{\Phi}(\ve{\varphi})(\ve{x}) - \ve{y}_{0}| &amp;lt; \rho \delta + (1 - \rho) \delta = \delta
\end{equation*}
&lt;/div&gt;
&lt;p&gt;従って &lt;span class="math"&gt;\(\ve{\Phi}(\ve{\varphi}) \in \mathcal{F}\)&lt;/span&gt; である。&lt;/p&gt;
&lt;p&gt;次に、 &lt;span class="math"&gt;\(\ve{\varphi}, \ve{\psi} \in \mathcal{F}\)&lt;/span&gt; に対し、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{\Phi}(\ve{\varphi})(\ve{x}) - \ve{\Phi}(\ve{\psi})(\ve{x}) = \ve{\varphi}(\ve{x}) - \ve{\psi}(\ve{x}) - \ve{M}^{-1} ( \ve{F}(\ve{x}, \ve{\varphi}(\ve{x})) - \ve{F}(\ve{x}, \ve{\psi}(\ve{x})) )
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成立するが、ここで積分公式&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{F}(\ve{x}, \ve{\varphi}(\ve{x})) - \ve{F}(\ve{x}, \ve{\psi}(\ve{x})) = \int_{0}^{1} \parfrac{\ve{F}}{\ve{y}} (\ve{x}, \ve{y}_{0} + t (\ve{\varphi}(\ve{x}) - \ve{\psi}(\ve{x}))) \mathrm{d} t (\ve{\varphi}(\ve{x}) - \ve{\psi}(\ve{x}))
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を用いると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ve{\Phi}(\ve{\varphi})(\ve{x}) - \ve{\Phi}(\ve{\psi})(\ve{x}) &amp;amp;= \ve{\varphi}(\ve{x}) - \ve{\psi}(\ve{x}) - \ve{M}^{-1} \int_{0}^{1} \parfrac{\ve{F}}{\ve{y}} (\ve{x}, \ve{\varphi}(\ve{x}) + t (\ve{\varphi}(\ve{x}) - \ve{\psi}(\ve{x}))) \mathrm{d} t (\ve{\varphi}(\ve{x}) - \ve{\psi}(\ve{x})) \\
&amp;amp;= \left\{ \ve{I} - \ve{M}^{-1} \int_{0}^{1} \parfrac{\ve{F}}{\ve{y}} (\ve{x}, \ve{\varphi}(\ve{x}) + t (\ve{\varphi}(\ve{x}) - \ve{\psi}(\ve{x}))) \mathrm{d} t \right\} (\ve{\varphi}(\ve{x}) - \ve{\psi}(\ve{x})) \\
\implies |\ve{\Phi}(\ve{\varphi})(\ve{x}) - \ve{\Phi}(\ve{\psi})(\ve{x})| &amp;amp;= \left| \ve{I} - \ve{M}^{-1} \int_{0}^{1} \parfrac{\ve{F}}{\ve{y}} (\ve{x}, \ve{\varphi}(\ve{x}) + t (\ve{\varphi}(\ve{x}) - \ve{\psi}(\ve{x}))) \mathrm{d} t \right| |\ve{\varphi}(\ve{x}) - \ve{\psi}(\ve{x})| \\
&amp;amp;&amp;lt; \rho |\ve{\varphi}(\ve{x}) - \ve{\psi}(\ve{x})| \leq \rho ||\ve{\varphi}(\ve{x}) - \ve{\psi}(\ve{x})||_{0}
\end{align*}
&lt;/div&gt;
&lt;p&gt;が任意の &lt;span class="math"&gt;\(\ve{x} \in U_{1}\)&lt;/span&gt; で成り立つから、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
||\ve{\Phi}(\ve{\varphi})(\ve{x}) - \ve{\Phi}(\ve{\psi})(\ve{x})||_{0} \leq \rho ||\ve{\varphi}(\ve{x}) - \ve{\psi}(\ve{x})||_{0}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;よって &lt;span class="math"&gt;\(\ve{\Phi}\)&lt;/span&gt; は縮小写像。&lt;/p&gt;
&lt;p&gt;次に &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; が完備であることを示す。まず、 &lt;span class="math"&gt;\(\mathcal{F} \subset C^{0}(U_{1})\)&lt;/span&gt; で &lt;span class="math"&gt;\(C^{0}(U_{1})\)&lt;/span&gt; は完備だから、 &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; の中で作ったコーシー列は &lt;span class="math"&gt;\(C^{0}(U_{1})\)&lt;/span&gt; の中で収束列となる。極限関数 &lt;span class="math"&gt;\(\ve{f} = \lim_{n \to \infty} \ve{\Phi}(\ve{f}_{n})\)&lt;/span&gt; が &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; に属することを示す。 &lt;span class="math"&gt;\(\ve{\Phi}\)&lt;/span&gt; の定義より、 &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; は &lt;span class="math"&gt;\(U_{1}\)&lt;/span&gt; 上で連続で、 &lt;span class="math"&gt;\(\ve{y}_{0} = \ve{f}(\ve{x}_{0})\)&lt;/span&gt; を満たす。各点収束としてみると、 &lt;span class="math"&gt;\(\ve{f}(\ve{x})\)&lt;/span&gt; は 区間 &lt;span class="math"&gt;\(U_{1}\)&lt;/span&gt; で閉区間 &lt;span class="math"&gt;\(U_{2}\)&lt;/span&gt; に属するから、 &lt;span class="math"&gt;\(\ve{f} \in \mathcal{F}\)&lt;/span&gt; である。即ち &lt;span class="math"&gt;\(\mathcal{F}\)&lt;/span&gt; は完備。&lt;/p&gt;
&lt;p&gt;不動点定理により、 &lt;span class="math"&gt;\(\ve{f}(\ve{x}) = \ve{\Phi}(\ve{f})(\ve{x})\)&lt;/span&gt; を満たす &lt;span class="math"&gt;\(\ve{f}(\ve{x}) \in \mathcal{F}\)&lt;/span&gt; が唯一存在する。この写像 &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{f}(\ve{x}) = \ve{\Phi}(\ve{f})(\ve{x}) = \ve{f}(\ve{x}) - \ve{M}^{-1}\ve{F}(\ve{x}, \ve{f}(\ve{x}))\)&lt;/span&gt; を満たすので、&lt;span class="math"&gt;\(\ve{F}(\ve{x}, \ve{f}(\ve{x})) = \ve{0}\)&lt;/span&gt; が成り立っている。（1. の証明終）&lt;/p&gt;
&lt;p&gt;（2. の証明） &lt;span class="math"&gt;\(\ve{F}\)&lt;/span&gt; は &lt;span class="math"&gt;\((\ve{x}_{0}, \ve{y}_{0})\)&lt;/span&gt; で偏微分可能で、しかも連続だから微分可能で（ &lt;span class="math"&gt;\(\because\)&lt;/span&gt; 上述）であり、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{F}(\ve{x}, \ve{y}) = \ve{F}(\ve{x}_{0}, \ve{y}_{0}) + \ve{A}(\ve{x}, \ve{y})(\ve{x} - \ve{x}_{0}) + \ve{B}(\ve{x}, \ve{y})(\ve{y} - \ve{y}_{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と書ける（ &lt;span class="math"&gt;\(\ve{A}, \ve{B}\)&lt;/span&gt; は &lt;span class="math"&gt;\((\ve{x}_{0}, \ve{y}_{0})\)&lt;/span&gt; で連続な行列関数で、 &lt;span class="math"&gt;\(\ve{A}(\ve{x}_{0}, \ve{y}_{0}) = \parfrac{\ve{F}}{\ve{x}}(\ve{x}_{0}, \ve{y}_{0}),\ \ve{B}(\ve{x}_{0}, \ve{y}_{0}) = \parfrac{\ve{F}}{\ve{y}}(\ve{x}_{0}, \ve{y}_{0})\)&lt;/span&gt; ）。この式に &lt;span class="math"&gt;\(\ve{y} = \ve{f}(\ve{x})\)&lt;/span&gt; を代入すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ve{F}(\ve{x}, \ve{f}(\ve{x})) = \ve{0} &amp;amp;= \ve{F}(\ve{x}_{0}, \ve{f}(\ve{x}_{0})) + \ve{A}(\ve{x}, \ve{f}(\ve{x}))(\ve{x} - \ve{x}_{0}) + \ve{B}(\ve{x}, \ve{f}(\ve{x}))(\ve{f}(\ve{x}) - \ve{f}(\ve{x}_{0})) \\
\implies \ve{B}(\ve{x}, \ve{f}(\ve{x})) \ve{f}(\ve{x}) &amp;amp;= \ve{B}(\ve{x}, \ve{f}(\ve{x})) \ve{f}(\ve{x}_{0}) - \ve{A}(\ve{x}, \ve{f}(\ve{x}))(\ve{x} - \ve{x}_{0}) \\
\implies \ve{f}(\ve{x}) &amp;amp;= \ve{f}(\ve{x}_{0}) - \ve{B}(\ve{x}, \ve{f}(\ve{x}))^{-1} \ve{A}(\ve{x}, \ve{f}(\ve{x}))(\ve{x} - \ve{x}_{0}) \quad (\because \parfrac{\ve{F}}{\ve{y}} \text{ は正則 })
\end{align*}
&lt;/div&gt;
&lt;p&gt;行列 &lt;span class="math"&gt;\(\ve{B}(\ve{x}, \ve{f}(\ve{x}))^{-1} \ve{A}(\ve{x}, \ve{f}(\ve{x}))\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; において連続だから、 &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; において微分可能で、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{\ve{f}}{\ve{x}}(\ve{x}_{0}) = \ve{B}(\ve{x}_{0}, \ve{f}(\ve{x}_{0}))^{-1} \ve{A}(\ve{x}_{0}, \ve{f}(\ve{x}_{0})) = -\left[ \parfrac{\ve{F}}{\ve{y}} (\ve{x}_{0}, \ve{y}_{0}) \right]^{-1} \parfrac{\ve{F}}{\ve{x}} (\ve{x}_{0}, \ve{y}_{0}) \tag{5}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;（2. の証明終）&lt;/p&gt;
&lt;p&gt;（3. の証明） &lt;span class="math"&gt;\(\ve{F}\)&lt;/span&gt; が &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級ならば (5) 式の右辺は &lt;span class="math"&gt;\((\ve{x}_{0}, \ve{y}_{0})\)&lt;/span&gt; で連続だから、 &lt;span class="math"&gt;\(\ve{y}_{0} = \ve{f}(\ve{x}_{0})\)&lt;/span&gt; を代入したものも &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; で連続である。即ち、 &lt;span class="math"&gt;\(\parfrac{\ve{f}}{\ve{x}}(\ve{x})\)&lt;/span&gt; は &lt;span class="math"&gt;\(U\)&lt;/span&gt; で連続であり、 &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; は &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級。（3. の証明終）&lt;/p&gt;
&lt;p&gt;（4. の証明） &lt;span class="math"&gt;\(\ve{F}\)&lt;/span&gt; が &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級ならば、 &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; も &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級であることを示す。 &lt;span class="math"&gt;\(m = 1\)&lt;/span&gt; の場合は、3. により成立する。 &lt;span class="math"&gt;\(m-1\)&lt;/span&gt; の場合に成立するとして、もし、 &lt;span class="math"&gt;\(\ve{F}\)&lt;/span&gt; が &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級ならば、同時に &lt;span class="math"&gt;\(\ve{F}\)&lt;/span&gt; は &lt;span class="math"&gt;\(C^{m-1}\)&lt;/span&gt; 級だから、仮定より &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; も &lt;span class="math"&gt;\(C^{m-1}\)&lt;/span&gt; 級である。よって、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{\ve{f}}{\ve{x}}(\ve{x}) = \ve{B}(\ve{x}, \ve{f}(\ve{x}))^{-1} \ve{A}(\ve{x}, \ve{f}(\ve{x})) = -\left[ \parfrac{\ve{F}}{\ve{y}} (\ve{x}, \ve{y}) \right]^{-1} \parfrac{\ve{F}}{\ve{x}} (\ve{x}, \ve{y})
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;の右辺は &lt;span class="math"&gt;\(C^{m-1}\)&lt;/span&gt; 級の写像 &lt;span class="math"&gt;\(\parfrac{\ve{F}}{\ve{y}},\ \parfrac{\ve{F}}{\ve{x}}\)&lt;/span&gt; に &lt;span class="math"&gt;\(C^{m-1}\)&lt;/span&gt; 級の写像 &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; を代入したものだから、合成関数の微分法により、右辺は &lt;span class="math"&gt;\(C^{m-1}\)&lt;/span&gt; 級になる。 &lt;span class="math"&gt;\(\parfrac{f}{x}(\ve{x})\)&lt;/span&gt; が &lt;span class="math"&gt;\(C^{m-1}\)&lt;/span&gt; 級だから、 &lt;span class="math"&gt;\(\ve{f}(\ve{x})\)&lt;/span&gt; は &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級。（4. の証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id12"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id26"&gt;陰関数定理の応用&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id13"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id27"&gt;逆写像定理&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;2 変数を例に取って考える。 &lt;span class="math"&gt;\(\mathbb{R}^{2}\)&lt;/span&gt; から &lt;span class="math"&gt;\(\mathbb{R}^{2}\)&lt;/span&gt; への写像&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{cases}
  x = f(s, t) \\
  y = g(s, t)
\end{cases}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が与えられたとき、その逆写像が存在するかどうかを考える。今、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{cases}
  F(x, y, s, t) = f(s, t) - x \\
  G(x, y, s, t) = g(s, t) - y
\end{cases}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とおくと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F(x, y, s, t) = G(x, y, s, t) = 0
\end{equation*}
&lt;/div&gt;
&lt;p&gt;から陰関数 &lt;span class="math"&gt;\(s = h(x, y),\ t = k(x, y)\)&lt;/span&gt; が決まるか？という問題に帰着できる。
この問題は陰関数定理より解決できる。すなわち、行列&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\left[ \begin{array}{cc}
  \parfrac{F}{s} &amp;amp; \parfrac{F}{t} \\
  \parfrac{G}{s} &amp;amp; \parfrac{G}{t}
\end{array} \right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;がある点 &lt;span class="math"&gt;\((x_{0}, y_{0}, s_{0}, t_{0})\)&lt;/span&gt; の近傍で連続かつ正則であればよい。また、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{F}{s} = \parfrac{f}{s},\ \parfrac{F}{t} = \parfrac{f}{t},\ \parfrac{G}{s} = \parfrac{g}{s},\ \parfrac{G}{t} = \parfrac{g}{t}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;だから、上の条件は写像 &lt;span class="math"&gt;\((f(s, t), g(s, t))^{\mathsf{T}}\)&lt;/span&gt; のヤコビ行列&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\left[ \begin{array}{cc}
  \parfrac{f}{s} &amp;amp; \parfrac{f}{t} \\
  \parfrac{g}{s} &amp;amp; \parfrac{g}{t}
\end{array} \right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が &lt;span class="math"&gt;\((s_{0}, t_{0})\)&lt;/span&gt; の近傍で連続かつ正則であることを示している。&lt;/p&gt;
&lt;div class="section" id="id14"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id28"&gt;多変数の場合&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;上記の議論を一般の &lt;span class="math"&gt;\(n\)&lt;/span&gt; 変数に拡張したのが次の &lt;strong&gt;逆写像定理&lt;/strong&gt; である。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;逆写像定理&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(\mathbb{R}^{n}\)&lt;/span&gt; の領域 &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; から &lt;span class="math"&gt;\(\mathbb{R}^{n}\)&lt;/span&gt; への写像 &lt;span class="math"&gt;\(\ve{y} = \ve{f}(\ve{x})\)&lt;/span&gt; が &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; の 1 点 &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; の近傍で &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級かつヤコビ行列 &lt;span class="math"&gt;\(\parfrac{\ve{f}}{\ve{x}}(\ve{x})\)&lt;/span&gt; が正則ならば、逆写像 &lt;span class="math"&gt;\(\ve{x} = \ve{h}(\ve{y})\)&lt;/span&gt; が &lt;span class="math"&gt;\(\ve{y}_{0} = \ve{f}(\ve{x}_{0})\)&lt;/span&gt; の十分小さい近傍で存在し &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級である。その導関数は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{\ve{h}}{\ve{y}}(\ve{y}) = \left[ \parfrac{\ve{f}}{\ve{x}}(\ve{h}(\ve{y})) \right]^{-1}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;である。また、 &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; が &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級ならば &lt;span class="math"&gt;\(\ve{h}\)&lt;/span&gt; も &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級である。&lt;/p&gt;
&lt;p&gt;（証明）陰関数定理を &lt;span class="math"&gt;\(\ve{F}(\ve{x}, \ve{y}) = \ve{f}(\ve{x}) - \ve{y}\)&lt;/span&gt; に適用すれば良い。 &lt;span class="math"&gt;\(\ve{F}(\ve{x}, \ve{y})\)&lt;/span&gt; は連続で、 &lt;span class="math"&gt;\(\parfrac{\ve{F}}{\ve{x}} = \parfrac{\ve{f}}{\ve{x}}\)&lt;/span&gt; は &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; の近傍で連続な正則関数だから、陰関数定理により &lt;span class="math"&gt;\(\ve{y}_{0}\)&lt;/span&gt; の近傍で &lt;span class="math"&gt;\(\ve{x}_{0} = \ve{h}(\ve{y}_{0}),\ \ve{F}(\ve{h}(\ve{y}), \ve{y}) = \ve{0}\)&lt;/span&gt; を満たす連続な写像 &lt;span class="math"&gt;\(\ve{h}\)&lt;/span&gt; が唯一存在する。 &lt;span class="math"&gt;\(\ve{h}(\ve{y})\)&lt;/span&gt; の導関数は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\parfrac{\ve{h}}{\ve{y}}(\ve{y}) &amp;amp;= - \left[ \parfrac{\ve{F}}{\ve{x}} (\ve{x}, \ve{y}) \right]^{-1} \parfrac{\ve{F}}{\ve{y}}(\ve{x}, \ve{y}) \\
&amp;amp;= - \left[ \parfrac{\ve{f}}{\ve{x}} (\ve{x}, \ve{y}) \right]^{-1} (- \ve{I}) \\
&amp;amp;= \left[ \parfrac{\ve{f}}{\ve{x}}(\ve{h}(\ve{y})) \right]^{-1}
\end{align*}
&lt;/div&gt;
&lt;p class="last"&gt;また、 &lt;span class="math"&gt;\(\ve{f}\)&lt;/span&gt; が &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級であれば、 &lt;span class="math"&gt;\(\ve{F}\)&lt;/span&gt; も &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級であり、陰関数定理の 4. より &lt;span class="math"&gt;\(\ve{h}\)&lt;/span&gt; も &lt;span class="math"&gt;\(C^{m}\)&lt;/span&gt; 級となる。（証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id15"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id29"&gt;制約付き極値問題&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="id16"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id30"&gt;ラグランジュの未定乗数法&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;ラグランジュの未定乗数法も、勾配の図を用いた直感に頼るのではなく陰関数定理により説明が可能である。&lt;/p&gt;
&lt;p&gt;やはり例として 2 変数 &lt;span class="math"&gt;\(x, y\)&lt;/span&gt; で考える。 &lt;span class="math"&gt;\(\mathbb{R}^{2}\)&lt;/span&gt; のある領域 &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; 上で、2 つの 2 変数関数 &lt;span class="math"&gt;\(f(x, y),\ g(x, y)\)&lt;/span&gt; が与えたられたとき、 &lt;span class="math"&gt;\(g(x, y) = 0\)&lt;/span&gt; という条件下で &lt;span class="math"&gt;\(f(x, y)\)&lt;/span&gt; の極値を求めることを考える。&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(g(x, y) = 0\)&lt;/span&gt; と交わる &lt;span class="math"&gt;\(f(x, y) = a\)&lt;/span&gt; の交点が極値をとるならば、その点で &lt;span class="math"&gt;\(f(x, y) = a\)&lt;/span&gt; と &lt;span class="math"&gt;\(g(x, y) = 0\)&lt;/span&gt; のグラフは接しなければならない。その様な点では、法線ベクトル &lt;span class="math"&gt;\(\parfrac{f}{\ve{x}}, \parfrac{f}{\ve{x}}\)&lt;/span&gt; は同じ方向を向いているから、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{f}{\ve{x}} = \lambda \parfrac{f}{\ve{x}} \iff \parfrac{f}{x} - \lambda \parfrac{g}{x} = 0,\ \parfrac{f}{y} - \lambda \parfrac{g}{y} = 0,\ g(x, y) = 0
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たす定数 &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; が存在する。この式は形式上、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F(x, y, \lambda) = f(x, y) - \lambda g(x, y)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;の 3 変数関数の極値問題と同様の形をしている。より詳しい証明は以下。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;ラグランジュの未定乗数法&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;領域 &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; 上で 2 つの関数 &lt;span class="math"&gt;\(f(x, y),\ g(x, y)\)&lt;/span&gt; は &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級とし、曲線 &lt;span class="math"&gt;\(g(x, y) = 0\)&lt;/span&gt; 上で &lt;span class="math"&gt;\(\parfrac{g}{\ve{x}} \neq \ve{0}\)&lt;/span&gt; とする。 &lt;span class="math"&gt;\(g(x, y) = 0\)&lt;/span&gt; 上の点 &lt;span class="math"&gt;\(\ve{x}_{0} = (x_{0}, y_{0})\)&lt;/span&gt; が条件付き極値問題における極値点ならば、ある定数 &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; が存在して、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{f}{\ve{x}}(\ve{x}_{0}) = \lambda \parfrac{g}{\ve{x}}(\ve{x}_{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;（証明） 仮定の &lt;span class="math"&gt;\(\parfrac{g}{\ve{x}} \neq \ve{0}\)&lt;/span&gt; より &lt;span class="math"&gt;\(\parfrac{g}{y}(\ve{x}_{0}) \neq 0\)&lt;/span&gt; が成立している。 &lt;span class="math"&gt;\(g(x, y) = 0\)&lt;/span&gt; を陰関数表示だと思うと、陰関数定理により、 &lt;span class="math"&gt;\(\ve{x}_{0} = (x_{0}, y_{0})\)&lt;/span&gt; の近傍において &lt;span class="math"&gt;\(y_{0} = \varphi(x_{0}),\ \dfrac{\varphi}{x}(x) = -g_{x}(x, \varphi(x)) / g_{y}(x, \varphi(x))\)&lt;/span&gt; を満たす &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級の関数 &lt;span class="math"&gt;\(y = \varphi(x)\)&lt;/span&gt; が存在する。 &lt;span class="math"&gt;\(z = f(x, \varphi(x))\)&lt;/span&gt; の導関数を考えると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\dfrac{z}{x} &amp;amp;= \parfrac{f}{x} (x, \varphi(x)) + \parfrac{f}{y}(x, \varphi(x)) \dfrac{\varphi}{x}(x) \quad (\because \text{ 合成関数の微分 }) \\
&amp;amp;= f_{x}(x, \varphi(x)) + f_{y}(x, \varphi(x)) \left\{ - \frac{g_{x}(x, \varphi(x))}{g_{y}(x, \varphi(x))} \right\} \\
&amp;amp;= \frac{1}{g_{y}} (f_{x} g_{y} - f_{y} g_{x})
\end{align*}
&lt;/div&gt;
&lt;p class="last"&gt;点 &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; においてこれが &lt;span class="math"&gt;\(0\)&lt;/span&gt; になるから、 &lt;span class="math"&gt;\(f_{x}g_{y} - f_{y}g_{x} = 0\)&lt;/span&gt; 。従って &lt;span class="math"&gt;\(f_{x}/g_{x} = f_{y}/g_{y} = \lambda\)&lt;/span&gt; とおくと、&lt;span class="math"&gt;\(f_{x} = \lambda g_{x},\ f_{y} = \lambda g_{y}\)&lt;/span&gt; が得られ、まとめると &lt;span class="math"&gt;\(\parfrac{f}{\ve{x}}(\ve{x}_{0}) = \lambda \parfrac{g}{\ve{x}}(\ve{x}_{0})\)&lt;/span&gt; が得られる。（証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;制約条件が &lt;span class="math"&gt;\(g_{i}(\ve{x}) = 0\ (i = 1, ..., m)\)&lt;/span&gt; と増えた場合も同様に考えられる。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;ラグランジュの未定乗数法（複数制約）&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(\mathbb{R}^{n}\)&lt;/span&gt; の領域 &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; 上で &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級の関数 &lt;span class="math"&gt;\(f(\ve{x}),\ g_{i}(\ve{x})\ (i = 1, ..., m)\)&lt;/span&gt; が与えられ、 &lt;span class="math"&gt;\(n-m\)&lt;/span&gt; 次元曲面 &lt;span class="math"&gt;\(S = \{ \ve{x} | g_{i}(\ve{x}) = 0, \ i = 1,...,m \}\)&lt;/span&gt; 上で行列 &lt;span class="math"&gt;\(\parfrac{\ve{g}}{\ve{x}} = \left( \parfrac{g_{i}}{x_{j}} \right)\)&lt;/span&gt; の階数（行列ランク）は常に &lt;span class="math"&gt;\(m\)&lt;/span&gt; であるとする。&lt;span class="math"&gt;\(S\)&lt;/span&gt; 上の点 &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; が &lt;span class="math"&gt;\(f(\ve{x})\)&lt;/span&gt; の &lt;span class="math"&gt;\(S\)&lt;/span&gt; の極値点ならば、 &lt;span class="math"&gt;\(m\)&lt;/span&gt; 個の定数 &lt;span class="math"&gt;\(\lambda_{1}, ..., \lambda_{m}\)&lt;/span&gt; があって、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{f}{\ve{x}}(\ve{x}_{0}) = \sum_{i = 1}^{m} \lambda_{i} \parfrac{g_{i}}{\ve{x}}(\ve{x}_{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;（証明） &lt;span class="math"&gt;\(\parfrac{\ve{g}}{\ve{x}}\)&lt;/span&gt; の階数は &lt;span class="math"&gt;\(m\)&lt;/span&gt; だから、 &lt;span class="math"&gt;\(\ve{x}^{\prime} = [x_{1}, ..., x_{n - m}],\ \ve{x}^{\prime\prime} = [x_{n - m + 1}, ..., x_{n}]\)&lt;/span&gt; として、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{\ve{g}}{\ve{x}^{\prime\prime}} =
\left[ \begin{array}{cccc}
\parfrac{g_{1}}{x_{n-m+1}} &amp;amp; \parfrac{g_{1}}{x_{n-m+2}} &amp;amp; \dots  &amp;amp; \parfrac{g_{1}}{x_{n}} \\
\parfrac{g_{2}}{x_{n-m+1}} &amp;amp; \parfrac{g_{2}}{x_{n-m+2}} &amp;amp; \dots  &amp;amp; \parfrac{g_{2}}{x_{n}} \\
\vdots                     &amp;amp; \vdots                     &amp;amp; \ddots &amp;amp; \vdots                 \\
\parfrac{g_{m}}{x_{n-m+1}} &amp;amp; \parfrac{g_{m}}{x_{n-m+2}} &amp;amp; \dots  &amp;amp; \parfrac{g_{m}}{x_{n}} \\
\end{array} \right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;は正則であると仮定して良い（正則になるように &lt;span class="math"&gt;\(\ve{x}^{\prime\prime}\)&lt;/span&gt; を選べば良い）。 &lt;span class="math"&gt;\(\ve{g}(\ve{x}) = \ve{0}\)&lt;/span&gt; を陰関数表示と見ると、陰関数定理により &lt;span class="math"&gt;\(x_{n-m+1} = \varphi_{1}(\ve{x}^{\prime}), ..., x_{n} = \varphi_{m}(\ve{x}^{\prime})\)&lt;/span&gt; 、即ち &lt;span class="math"&gt;\(\ve{x}^{\prime\prime} = \ve{\varphi}(\ve{x}^{\prime})\)&lt;/span&gt; を満たす &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級の写像 &lt;span class="math"&gt;\(\ve{\varphi} = [\varphi_{1}, ..., \varphi_{m}]\)&lt;/span&gt; が存在し、また、 &lt;span class="math"&gt;\(\parfrac{\ve{\varphi}}{\ve{x}^{\prime}} = -\left(\parfrac{\ve{g}}{\ve{x}^{\prime\prime}}\right)^{-1}\left(\parfrac{\ve{g}}{\ve{x}^{\prime}}\right)\)&lt;/span&gt; が成り立つ。&lt;span class="math"&gt;\(\ve{\varphi}\)&lt;/span&gt; を &lt;span class="math"&gt;\(y = f(\ve{x}) = f(\ve{x}^{\prime}, \ve{x}^{\prime\prime})\)&lt;/span&gt; に代入すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
y = F(\ve{x}^{\prime}) = f(\ve{x}^{\prime}, \ve{\varphi}(\ve{x}^{\prime}))
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が得られる。上記 &lt;span class="math"&gt;\(y\)&lt;/span&gt; についての極値問題を考える。 &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; において、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\parfrac{F}{\ve{x}^{\prime}} &amp;amp;= \parfrac{f}{\ve{x}^{\prime}} + \parfrac{f}{\ve{x}^{\prime\prime}} \parfrac{\ve{\varphi}}{\ve{x}^{\prime}} \quad (\because \text{ 連鎖律 }) \\
&amp;amp;= \parfrac{f}{\ve{x}^{\prime}} - \parfrac{f}{\ve{x}^{\prime\prime}} \left(\parfrac{\ve{g}}{\ve{x}^{\prime\prime}}\right)^{-1} \parfrac{\ve{g}}{\ve{x}^{\prime}} = \ve{0}
\end{align*}
&lt;/div&gt;
&lt;p&gt;が極値となるための必要条件だから、今、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
[\lambda_{1}, ..., \lambda_{m}] = \parfrac{f}{\ve{x}^{\prime\prime}} \left(\parfrac{\ve{g}}{\ve{x}^{\prime\prime}}\right)^{-1}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とおけば、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{f}{\ve{x}^{\prime\prime}}(\ve{x}_{0}) = [\lambda_{1}, ..., \lambda_{m}] \parfrac{\ve{g}}{\ve{x}^{\prime\prime}}(\ve{x}_{0}),\ \parfrac{f}{\ve{x}^{\prime}}(\ve{x}_{0}) = [\lambda_{1}, ..., \lambda_{m}] \parfrac{\ve{g}}{\ve{x}^{\prime}}(\ve{x}_{0})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成立しているから、まとめると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{f}{\ve{x}}(\ve{x}_{0}) = [\lambda_{1}, ..., \lambda_{m}] \parfrac{\ve{g}}{\ve{x}}(\ve{x}_{0}) = \sum_{i = 1}^{m} \lambda_{i} \parfrac{g_{i}}{\ve{x}}(\ve{x}_{0})
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;が得られる。（証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="kkt"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id31"&gt;KKT 条件&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;不等式制約 &lt;span class="math"&gt;\(g(x, y) \geq 0\)&lt;/span&gt; の条件下で &lt;span class="math"&gt;\(f(x, y)\)&lt;/span&gt; の極値を見つける問題を考える。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;簡単な例 : &lt;span class="math"&gt;\(g(x, y) = y \geq 0\)&lt;/span&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(y \geq 0\)&lt;/span&gt; の領域の内部であれば、極大点の候補は &lt;span class="math"&gt;\(\parfrac{f}{x} = \parfrac{f}{y} = 0\)&lt;/span&gt; で求められる。一方、境界上（ &lt;span class="math"&gt;\(y = 0\)&lt;/span&gt; ）では、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{f}{x}(x_{0}, 0) = 0,\ \parfrac{f}{y}(x_{0}, 0) \leq 0
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たす &lt;span class="math"&gt;\(x_{0}\)&lt;/span&gt; が候補となる（ &lt;span class="math"&gt;\(\parfrac{f}{y}(x_{0}, 0) &amp;gt; 0\)&lt;/span&gt; とすると、それは &lt;span class="math"&gt;\(y\)&lt;/span&gt; を正方向に増やしたときに &lt;span class="math"&gt;\(f\)&lt;/span&gt; が更に増加することを意味するから、その点は極大点ではない）。これらの条件をまとめると、極点 &lt;span class="math"&gt;\((x_{0}, y_{0})\)&lt;/span&gt; は次の条件を満たす必要がある。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{f}{x}(x_{0}, y_{0}) = 0,\ \parfrac{f}{y}(x_{0}, y_{0}) \leq 0,\ y_{0} \parfrac{f}{y}(x_{0}, y_{0}) = 0
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;最後の条件は、 &lt;span class="math"&gt;\(y_{0} = 0\)&lt;/span&gt; あるいは &lt;span class="math"&gt;\(\parfrac{f}{y}(x_{0}, y_{0}) = 0\)&lt;/span&gt; を要請している。&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;次に一般の条件式 &lt;span class="math"&gt;\(g(x, y) \leq 0\)&lt;/span&gt; を考える。今、新しい変数 &lt;span class="math"&gt;\(z\)&lt;/span&gt; として&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
g(x, y) = z,\ z \geq 0
\end{equation*}
&lt;/div&gt;
&lt;p&gt;をおけば、元の問題を &lt;span class="math"&gt;\(z \geq 0\)&lt;/span&gt; における等式制約の条件付き極値問題に変換できる。よって、ラグランジュの未定乗数法により、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F(x, y, z, \lambda) = f(x, y) - \lambda (g(x, y) - z)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;の &lt;span class="math"&gt;\(z \geq 0\)&lt;/span&gt; における極値を求めれば良い。これは、簡単な例の観察を元に、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{F}{x} = 0,\ \parfrac{F}{y} = 0,\ \parfrac{F}{\lambda} = 0,\ \parfrac{F}{z} \leq 0,\ z\parfrac{F}{z} = 0,\ z \geq 0
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たす &lt;span class="math"&gt;\((x, y, z, \lambda)\)&lt;/span&gt; を求める問題になる。偏微分を行うと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{f}{x} = \lambda \parfrac{g}{x},\ \parfrac{f}{y} = \lambda \parfrac{g}{y},\ g(x, y) = z,\ \lambda \leq 0,\ \lambda z = 0,\ z \geq 0
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となり、後ろの 4 条件をまとめると、以下の条件が得られる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{f}{x} = \lambda \parfrac{g}{x},\ \parfrac{f}{y} = \lambda \parfrac{g}{y},\ g(x, y) \geq 0,\ \lambda \leq 0,\ \lambda g(x, y) = 0
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とまとめられる。極小値を求める場合は、 &lt;span class="math"&gt;\(-f(x, y)\)&lt;/span&gt; の極大値を求めれば良い。この場合の条件は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{f}{x} = -\lambda \parfrac{g}{x},\ \parfrac{f}{y} = -\lambda \parfrac{g}{y},\ g(x, y) = z,\ \lambda \leq 0,\ \lambda z = 0,\ z \geq 0
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となり、 &lt;span class="math"&gt;\(-\lambda\)&lt;/span&gt; を &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; に置き換えることで必要条件が得られる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\parfrac{f}{x} = \lambda \parfrac{g}{x},\ \parfrac{f}{y} = \lambda \parfrac{g}{y},\ g(x, y) \geq 0,\ \lambda \geq 0,\ \lambda g(x, y) = 0
\end{equation*}
&lt;/div&gt;
&lt;p&gt;制約条件が増えても同様に考えれば良いから、次の定理が成立する。これを一般に KKT 条件（Karush-Kuhn-Tucker condition）と呼ぶ。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;KKT 条件&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(f(\ve{x}), g_{i}(\ve{x})\ (i = 1, ..., m)\)&lt;/span&gt; は &lt;span class="math"&gt;\(C^{1}\)&lt;/span&gt; 級とする。 &lt;span class="math"&gt;\(g_{i}(\ve{x}) \geq 0\ (i = 1,...,m)\)&lt;/span&gt; という条件の下で、 &lt;span class="math"&gt;\(f(\ve{x})\)&lt;/span&gt; の極大点 &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; は次の条件を満たさなければならない :&lt;/p&gt;
&lt;p&gt;ある定数 &lt;span class="math"&gt;\(\lambda_{1}, ..., \lambda_{m}\)&lt;/span&gt; があって、 &lt;span class="math"&gt;\(\ve{x}_{0}\)&lt;/span&gt; において&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{cases}
\displaystyle \parfrac{f}{\ve{x}}(\ve{x}_{0}) = \sum_{i = 1}^{m} \lambda_{i} \parfrac{g_{i}}{\ve{x}}(\ve{x}_{0}) \\
\lambda_{i} g_{i}(\ve{x}_{0}) = 0,\ g_{i}(\ve{x}_{0}) \geq 0,\ \lambda_{i} \leq 0 \quad (i = 1, ..., m)
\end{cases}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;（証明）変数 &lt;span class="math"&gt;\(z_{i}\ (i = 1, ..., m)\)&lt;/span&gt; を用いて&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
g_{i}(\ve{x}) = z_{i},\ z_{i} \geq 0 \quad (i = 1,...,m)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とおく。定数を &lt;span class="math"&gt;\(\lambda_{1}, ..., \lambda_{m}\)&lt;/span&gt; としてラグランジュの未定乗数法を適用すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F(\ve{x}, \ve{z}, \ve{\lambda}) = f(\ve{x}) - \sum_{i = 1}^{m} \lambda_{i} \left\{ g_{i}(\ve{x}) - z_{i} \right\}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;であり、極値条件は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\left\{ \begin{array}{ll}
\displaystyle \parfrac{F}{\ve{x}}(\ve{x}_{0}, \ve{z}, \ve{\lambda}) = \parfrac{f}{\ve{x}}(\ve{x}_{0}) - \sum_{i = 1}^{m} \lambda_{i} \parfrac{g_{i}}{\ve{x}}(\ve{x}_{0}) = \ve{0} &amp;amp; \\
\displaystyle \parfrac{F}{z_{i}}(\ve{x}_{0}, \ve{z}, \ve{\lambda}) = \lambda_{i} \leq 0 &amp;amp; (i = 1,...,m) \\
\displaystyle \parfrac{F}{\lambda_{i}}(\ve{x}_{0}, \ve{z}, \ve{\lambda}) = -g_{i}(\ve{x}_{0}) + z_{i} = 0 &amp;amp; (i = 1,...,m) \\
\displaystyle z_{i} \parfrac{F}{z_{i}}(\ve{x}_{0}, \ve{z}, \ve{\lambda}) = z_{i}\lambda_{i} = 0 &amp;amp; (i = 1,...,m) \\
z_{i} \geq 0 &amp;amp; (i = 1,...,m)
\end{array} \right.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(z_{i} = g_{i}(\ve{x})\)&lt;/span&gt; を元に条件をまとめ直すと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{cases}
\displaystyle \parfrac{f}{\ve{x}}(\ve{x}_{0}) = \sum_{i = 1}^{m} \lambda_{i} \parfrac{g_{i}}{\ve{x}}(\ve{x}_{0}) \\
\lambda_{i} g_{i}(\ve{x}_{0}) = 0,\ g_{i}(\ve{x}_{0}) \geq 0,\ \lambda_{i} \leq 0 \quad (i = 1, ..., m)
\end{cases}
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;（証明終）&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="記事"></category><category term="基礎"></category></entry><entry><title>自然勾配法の概観</title><link href="/zi-ran-gou-pei-fa-nogai-guan.html" rel="alternate"></link><published>2020-05-23T11:40:00+09:00</published><updated>2020-05-23T11:40:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-05-23:/zi-ran-gou-pei-fa-nogai-guan.html</id><summary type="html">&lt;p class="first last"&gt;自然勾配法の概略。だいたい &lt;a class="reference external" href="https://wiseodd.github.io/techblog/2018/03/11/fisher-information/"&gt;Fisher Information Matrix&lt;/a&gt; と &lt;a class="reference external" href="https://wiseodd.github.io/techblog/2018/03/14/natural-gradient/"&gt;Natural Gradient Descent&lt;/a&gt; から持ってきている。&lt;/p&gt;
</summary><content type="html">&lt;div class="math"&gt;
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\mean[2]{\mathrm{E}_{#1} \left[ #2 \right]}
\newcommand\KL[2]{\mathrm{KL} \left[ #1 \ \middle| \middle| \ #2 \right]}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;自然勾配法の概略。だいたい &lt;a class="reference external" href="https://wiseodd.github.io/techblog/2018/03/11/fisher-information/"&gt;Fisher Information Matrix&lt;/a&gt; と &lt;a class="reference external" href="https://wiseodd.github.io/techblog/2018/03/14/natural-gradient/"&gt;Natural Gradient Descent&lt;/a&gt; から持ってきている。&lt;/p&gt;
&lt;p&gt;パラメタベクトル &lt;span class="math"&gt;\(\ve{\theta}\)&lt;/span&gt; を持つ確率密度関数 &lt;span class="math"&gt;\(p(\ve{x}|\ve{\theta})\)&lt;/span&gt; を考える。対数尤度関数 &lt;span class="math"&gt;\(\log p(\ve{x}|\ve{\theta})\)&lt;/span&gt; の &lt;span class="math"&gt;\(\ve{\theta}\)&lt;/span&gt; におけるへッシアン &lt;span class="math"&gt;\(\ve{H}_{\ve{\theta}}\)&lt;/span&gt; は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ve{H}_{\ve{\theta}} \log p(\ve{x} | \ve{\theta}) &amp;amp;= \left(\parfrac{}{\ve{\theta}} \right) \left(\parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \log p(\ve{x} | \ve{\theta}) \\
&amp;amp;= \left(\parfrac{}{\ve{\theta}} \right) \frac{\left(\parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})} \\
&amp;amp;= \frac{\left\{ \left(\parfrac{}{\ve{\theta}} \right) \left(\parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} p(\ve{x} | \ve{\theta}) \right\} p(\ve{x} | \ve{\theta}) - \left(\parfrac{}{\ve{\theta}} \right) p(\ve{x} | \ve{\theta}) \left(\parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} p(\ve{x} | \ve{\theta}) }{p(\ve{x} | \ve{\theta})^{2}} \\
&amp;amp;= \frac{\ve{H}_{\ve{\theta}} p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})} - \left\{ \frac{\left(\parfrac{}{\ve{\theta}} \right) p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})} \right\} \left\{ \frac{\left(\parfrac{}{\ve{\theta}} \right) p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})} \right\}^{\mathsf{T}} \\
&amp;amp;= \frac{\ve{H}_{\ve{\theta}} p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})} - \left( \parfrac{}{\ve{\theta}} \log p(\ve{x} | \ve{\theta}) \right) \left( \parfrac{}{\ve{\theta}} \log p(\ve{x} | \ve{\theta}) \right)^{\mathsf{T}}
\end{align*}
&lt;/div&gt;
&lt;p&gt;両辺分布 &lt;span class="math"&gt;\(p(\ve{x}|\ve{\theta})\)&lt;/span&gt; について平均をとる。このとき右辺第二項はスコア関数の分散になりフィッシャー情報行列 &lt;span class="math"&gt;\(\ve{F}\)&lt;/span&gt; そのものになることに注意すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\mean{p(\ve{x}|\ve{\theta})}{\ve{H}_{\ve{\theta}} \log p(\ve{x} | \ve{\theta})} &amp;amp;= \mean{p(\ve{x}|\ve{\theta})}{\frac{\ve{H}_{\ve{\theta}} p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})}} - \mean{p(\ve{x}|\ve{\theta})}{\left( \parfrac{}{\ve{\theta}} \log p(\ve{x} | \ve{\theta}) \right) \left( \parfrac{}{\ve{\theta}} \log p(\ve{x} | \ve{\theta}) \right)^{\mathsf{T}}} \\
&amp;amp;= \mean{p(\ve{x}|\ve{\theta})}{\frac{\ve{H}_{\ve{\theta}} p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})}} - \ve{F} \\
&amp;amp;= \int p(\ve{x}|\ve{\theta}) \frac{\ve{H}_{\ve{\theta}} p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})} \mathrm{d}\ve{x} - \ve{F} = \int \ve{H}_{\ve{\theta}} p(\ve{x} | \ve{\theta}) \mathrm{d}\ve{x} - \ve{F} \\
&amp;amp;= \ve{H}_{\ve{\theta}} \int p(\ve{x} | \ve{\theta}) \mathrm{d}\ve{x} - \ve{F} \quad(\because \text{ 微分と積分の入れ替えを可能（正則条件）とする }) \\
&amp;amp;= \ve{H}_{\ve{\theta}} 1 - \ve{F} \\
&amp;amp;= - \ve{F}
\end{align*}
&lt;/div&gt;
&lt;p&gt;従って、 &lt;strong&gt;対数尤度関数のへッシアンの平均に負号をつけるとフィッシャー情報行列に一致する。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;つぎに、異なるパラメタ &lt;span class="math"&gt;\(\ve{\theta}, \ve{\theta}^{\prime}\)&lt;/span&gt; をもつ確率分布 &lt;span class="math"&gt;\(p(\ve{x}|\ve{\theta}), p(\ve{x}|\ve{\theta}^{\prime})\)&lt;/span&gt; 間の違いを測るダイバージェンスとして KL ダイバージェンスを使ったとき、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta}^{\prime})} &amp;amp;= \int p(\ve{x}|\ve{\theta}) \log \left( \frac{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta}^{\prime})} \right) \mathrm{d}\ve{x} \\
&amp;amp;= \mean{p(\ve{x}|\ve{\theta})}{\log p(\ve{x}|\ve{\theta})} - \mean{p(\ve{x}|\ve{\theta})}{\log p(\ve{x}|\ve{\theta}^{\prime})}
\end{align*}
&lt;/div&gt;
&lt;p&gt;となる。 &lt;span class="math"&gt;\(\ve{\theta}\)&lt;/span&gt; を固定し、パラメタ &lt;span class="math"&gt;\(\ve{\theta}^{\prime}\)&lt;/span&gt; に関するへッシアン &lt;span class="math"&gt;\(\ve{H}_{\ve{\theta}^{\prime}}\)&lt;/span&gt; を求めると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ve{H}_{\ve{\theta}^{\prime}} \KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta}^{\prime})} &amp;amp;= \left( \parfrac{}{\ve{\theta}^{\prime}} \right) \left( \parfrac{}{\ve{\theta}^{\prime}} \right)^{\mathsf{T}} \KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta}^{\prime})} \\
&amp;amp;= \left( \parfrac{}{\ve{\theta}^{\prime}} \right) \left\{ \left( \parfrac{}{\ve{\theta}^{\prime}} \right)^{\mathsf{T}} \mean{p(\ve{x}|\ve{\theta})}{\log p(\ve{x}|\ve{\theta})} - \left( \parfrac{}{\ve{\theta}^{\prime}} \right)^{\mathsf{T}} \mean{p(\ve{x}|\ve{\theta})}{\log p(\ve{x}|\ve{\theta}^{\prime})}\right\} \\
&amp;amp;= - \left( \parfrac{}{\ve{\theta}^{\prime}} \right) \mean{p(\ve{x}|\ve{\theta})}{\left( \parfrac{}{\ve{\theta}^{\prime}} \right)^{\mathsf{T}} \log p(\ve{x}|\ve{\theta}^{\prime})} = - \mean{p(\ve{x}|\ve{\theta})}{\left( \parfrac{}{\ve{\theta}^{\prime}} \right)\left( \parfrac{}{\ve{\theta}^{\prime}} \right)^{\mathsf{T}} \log p(\ve{x}|\ve{\theta}^{\prime})} \\
&amp;amp;= -\mean{p(\ve{x}|\ve{\theta})}{\ve{H}_{\ve{\theta}^{\prime}} \log p(\ve{x}|\ve{\theta}^{\prime})}
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで &lt;span class="math"&gt;\(\ve{\theta}^{\prime} \to \ve{\theta}\)&lt;/span&gt; と近づけていくと、最後の式はフィッシャー情報行列 &lt;span class="math"&gt;\(\ve{F}\)&lt;/span&gt; にいくらでも近づく。よって、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\lim_{\ve{\theta}^{\prime} \to \ve{\theta}} \ve{H}_{\ve{\theta}^{\prime}} \KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta}^{\prime})} = \ve{F}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;次に、 &lt;span class="math"&gt;\(\ve{\theta}\)&lt;/span&gt; 近傍での対数尤度関数の挙動を見ていく。 &lt;span class="math"&gt;\(\ve{h}\)&lt;/span&gt; を微小なベクトルとして、 &lt;span class="math"&gt;\(\log p(\ve{x}|\ve{\theta} + \ve{h})\)&lt;/span&gt; を 2 次の項までテイラー展開すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\log p(\ve{x}|\ve{\theta} + \ve{h}) &amp;amp;\approx \log p(\ve{x} | \ve{\theta}) + \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \log p(\ve{x} | \ve{\theta})  \ve{h} + \frac{1}{2} \ve{h}^{\mathsf{T}} \left( \parfrac{}{\ve{\theta}} \right) \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \log p(\ve{x} | \ve{\theta}) \ve{h} \\
\Rightarrow \log p(\ve{x}|\ve{\theta} + \ve{h}) - \log p(\ve{x} | \ve{\theta}) &amp;amp;\approx \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \log p(\ve{x} | \ve{\theta})  \ve{h} + \frac{1}{2} \ve{h}^{\mathsf{T}} \left( \parfrac{}{\ve{\theta}} \right) \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \log p(\ve{x} | \ve{\theta}) \ve{h} \\
&amp;amp;= \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \log p(\ve{x} | \ve{\theta}) \ve{h} + \frac{1}{2} \ve{h}^{\mathsf{T}} \ve{H}_{\ve{\theta}} \log p(\ve{x} | \ve{\theta}) \ve{h}
\end{align*}
&lt;/div&gt;
&lt;p&gt;両辺 &lt;span class="math"&gt;\(p(\ve{x}|\ve{\theta})\)&lt;/span&gt; について平均をとると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\mean{p(\ve{x}|\ve{\theta})}{\log p(\ve{x}|\ve{\theta} + \ve{h}) - \log p(\ve{x} | \ve{\theta})} &amp;amp;= \mean{p(\ve{x}|\ve{\theta})}{\log\left( \frac{p(\ve{x}|\ve{\theta} + \ve{h})}{p(\ve{x} | \ve{\theta})} \right)} \\
&amp;amp;= \int p(\ve{x}|\ve{\theta}) \log\left[ \frac{p(\ve{x}|\ve{\theta} + \ve{h})}{p(\ve{x} | \ve{\theta})} \right] \mathrm{d}\ve{x} = -\int p(\ve{x}|\ve{\theta}) \log\left[ \frac{p(\ve{x} | \ve{\theta})}{p(\ve{x}|\ve{\theta} + \ve{h})} \right] \mathrm{d}\ve{x} \\
&amp;amp;= -\KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta} + \ve{h})} \\
\mean{p(\ve{x}|\ve{\theta})}{\left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \log p(\ve{x} | \ve{\theta}) \ve{h}} &amp;amp;= \int p(\ve{x}|\ve{\theta}) \frac{\left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta})} \mathrm{d}\ve{x}\ \ve{h} \\
&amp;amp;= \int \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} p(\ve{x}|\ve{\theta}) \mathrm{d}\ve{x}\  \ve{h} = \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \int p(\ve{x}|\ve{\theta}) \mathrm{d}\ve{x}\  \ve{h} \quad (\because \text{ 正則条件 }) \\
&amp;amp;= \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} 1 \ve{h} \\
&amp;amp;= 0 \\
\mean{p(\ve{x}|\ve{\theta})}{\frac{1}{2} \ve{h}^{\mathsf{T}} \ve{H}_{\ve{\theta}} \log p(\ve{x} | \ve{\theta}) \ve{h}} &amp;amp;= \frac{1}{2} \ve{h}^{\mathsf{T}} \mean{p(\ve{x}|\ve{\theta})}{\ve{H}_{\ve{\theta}} \log p(\ve{x} | \ve{\theta})} \ve{h} \\
&amp;amp;= -\frac{1}{2} \ve{h}^{\mathsf{T}} \ve{F} \ve{h}
\end{align*}
&lt;/div&gt;
&lt;p&gt;よって、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta} + \ve{h})} \approx \frac{1}{2} \ve{h}^{\mathsf{T}} \ve{F} \ve{h}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\ve{\theta}\)&lt;/span&gt; の近傍においてはフィッシャー情報行列が支配的になっていることがわかる。また、これにより確率分布のなす多様体のリーマン計量はフィッシャー情報行列であることがわかり、ここから情報幾何学が始まっていく。&lt;/p&gt;
&lt;p&gt;以上の議論を基に、確率分布間の違いを KL ダイバージェンスで測ったとき、損失関数 &lt;span class="math"&gt;\(l(\ve{\theta})\)&lt;/span&gt; を最も減らす方向を考える。それは次の方向 &lt;span class="math"&gt;\(\ve{h}^{\ast}\)&lt;/span&gt; を見つけることに等しい：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{h}^{\ast} = \underset{\ve{h}\ \mathrm{s.t.} \KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta} + \ve{h})} = c}{\mathrm{argmin}} l(\ve{\theta} + \ve{h})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;式の気持ちとしては、「KL ダイバージェンスが定数 &lt;span class="math"&gt;\(c\)&lt;/span&gt; を取る中で、最も &lt;span class="math"&gt;\(l(\ve{\theta})\)&lt;/span&gt; を減らすベクトル &lt;span class="math"&gt;\(\ve{h}\)&lt;/span&gt; 」 である。これは制約付き最適化問題だから、ラグランジェの未定定数法により解くことを考える。ラグランジアン &lt;span class="math"&gt;\(\mathcal{L}\)&lt;/span&gt; は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\mathcal{L} &amp;amp;= l(\ve{\theta} + \ve{h}) + \lambda \left\{ \KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta} + \ve{h})} - c \right\} \\
&amp;amp;\approx l(\ve{\theta}) + \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} l(\ve{\theta}) \ve{h} + \lambda \left\{ \KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta} + \ve{h})} - c \right\} \quad \text{（1 次の項までテイラー展開）} \\
&amp;amp;\approx l(\ve{\theta}) + \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} l(\ve{\theta}) \ve{h} + \lambda \left\{ \frac{1}{2} \ve{h}^{\mathsf{T}} \ve{F} \ve{h} - c \right\}
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\mathcal{L}\)&lt;/span&gt; を &lt;span class="math"&gt;\(\ve{h}\)&lt;/span&gt; で偏微分すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\parfrac{}{\ve{h}} \mathcal{L} &amp;amp;\approx \parfrac{}{\ve{h}} l(\ve{\theta}) + \parfrac{}{\ve{h}} \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} l(\ve{\theta}) \ve{h} + \lambda  \left\{ \parfrac{}{\ve{h}} \frac{1}{2} \ve{h}^{\mathsf{T}} \ve{F} \ve{h} - \parfrac{}{\ve{h}} c \right\} \\
&amp;amp;= \parfrac{}{\ve{\theta}} l(\ve{\theta}) + \lambda \ve{F} \ve{h}
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\parfrac{}{\ve{h}} \mathcal{L} = \ve{0}\)&lt;/span&gt; とおいて &lt;span class="math"&gt;\(\ve{h}\)&lt;/span&gt; について解くと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\ve{h}^{\ast} = - \frac{1}{\lambda} \ve{F}^{-1} \parfrac{}{\ve{\theta}} l(\ve{\theta})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が得られる。 &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; はスカラーだからベクトルの方向を変えない。よって、 &lt;span class="math"&gt;\(\ve{F}^{-1} \parfrac{}{\ve{\theta}} l(\ve{\theta})\)&lt;/span&gt; が最急勾配であることが分かる。この勾配を &lt;strong&gt;自然勾配 (Natural Gradient)&lt;/strong&gt; という。&lt;/p&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;ニュートン法と何が違うのか？&lt;/h2&gt;
&lt;p&gt;「 &lt;a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.8668&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;Adaptive Method of Realizing Natural Gradient Learning for Multilayer Perceptrons&lt;/a&gt; 」によると、
ニュートン法は教師信号を明示的に含んだ損失関数のへッシアンを使うが、自然勾配法は近似対象の標的関数とは独立した確率分布の空間 S の計量を使っているところが違うらしい。しかし一方で、対数尤度を損失関数、かつモデルが最適パラメタによって生成された教師信号 y を生成するときはフィッシャー情報行列はヘッセ行列に一致する。このため、最適点において自然勾配法はニュートン法に一致する。とある。&lt;/p&gt;
&lt;p&gt;自分なりの解釈として線形回帰問題を考える。
誤差が ◯◯ 分布に従って発生すると考えた瞬間に確率分布の空間が定まり、この空間の計量たるフィッシャー情報行列に従って学習するのが自然勾配学習法。一方、各点の損失関数のヘッセ行列（2 階微分）を求めて最適化を進めるのがニュートン法。でいいのか？
恐らく、各点の損失関数を計算できるのならばニュートン法の方が優れている。&lt;/p&gt;
&lt;p&gt;発想としても差異があって、ニュートン法は損失関数の 2 次のテイラー展開から最適な勾配を求めるのに対し、自然勾配法は KL ダイバージェンスが一定という制約のもとで最適な勾配を求めている（自然勾配法を導出するとき、損失関数の 1 次の項までしかテイラー展開していないのがミソ。2 次まで展開すると損失関数のへッシアンが出てきてニュートン法と変わらない）。&lt;/p&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="記事"></category><category term="機械学習"></category><category term="情報幾何"></category></entry><entry><title>デジタル信号処理の礎</title><link href="/dezitaruxin-hao-chu-li-nochu.html" rel="alternate"></link><published>2020-04-23T18:00:00+09:00</published><updated>2020-04-23T18:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-23:/dezitaruxin-hao-chu-li-nochu.html</id><summary type="html">&lt;p class="first last"&gt;デジタル信号処理の基礎理論をグダグダ述べたポエム。&lt;/p&gt;
</summary><content type="html">&lt;div class="section" id="id2"&gt;
&lt;h2&gt;まえがき&lt;/h2&gt;
&lt;p&gt;本稿はデジタル信号処理の礎となる理論を固めるべく書かれた。&lt;/p&gt;
&lt;!-- デジタル信号処理は以下の分野を包括している :

.. - 集合論
.. - 線型代数
.. - 関数解析
.. - 複素関数
.. - 確率・統計 --&gt;
&lt;!-- 実用の工学上では、これらの分野の理論を深く扱うことはない。しかし、その基礎は確かに以上の分野の深い知識を動員している。 --&gt;
&lt;div class="math"&gt;
\begin{equation*}
\def\vector#1{\mbox{\boldmath $#1$}}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand{\rev}[1]{\frac{1}{#1}}
\newcommand{\pdiff}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\ddiff}[2]{\frac{d#1}{d#2}}
\newcommand{\vvec}[1]{\left[\begin{array}{c}#1\end{array}\right]}
\newcommand{\dmatrix}[2]{\left|\begin{array}{#1}#2\end{array}\right|}
\newcommand{\inversion}[1]{#1^{\!\mbox{\sf\tiny T}}}
\newcommand{\ifdiv}[2]{\left\{\begin{array}{#1}#2\end{array}\right.}
\end{equation*}
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h2&gt;フーリエ変換について&lt;/h2&gt;
&lt;p&gt;フーリエ変換が天下りに与えられて次の言明に対して違和感を抱いたことは無いだろうか？&lt;/p&gt;
&lt;pre class="literal-block"&gt;
任意の周期関数は三角関数の和で表現できる
&lt;/pre&gt;
&lt;p&gt;といった手合いである。この言明に対しては、次の疑問が浮かぶかもしれない :&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;任意の周期関数に対して成り立つのか？&lt;/li&gt;
&lt;li&gt;何故三角関数を用いる必要があるのか？三角関数である必然性は？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本稿では、この疑問に対して数学的に一応の解答を与えたい。細かい解説は後にして、解答としては次の様になる。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;任意の区分的になめらかな周期関数は三角関数の和で表現できる&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;三角関数は連続関数を表現できる能力を持っている&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下、これらの項目の証明を試みる。&lt;/p&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;関数はベクトル&lt;/h3&gt;
&lt;p&gt;形式的に見れば、 &lt;strong&gt;関数はベクトル&lt;/strong&gt; である。関数は入力と出力を決める規則であることから、 &lt;a class="reference internal" href="#id6"&gt;式 1&lt;/a&gt; の様に、その出力を並べることで、関数をベクトルとして見ることが出来る。&lt;/p&gt;
&lt;div class="math" id="id6"&gt;
\begin{align*}
 f(x) = \vvec{ f(-\infty) \\ \vdots \\ f(0) \\ \vdots \\ f(\infty) } \tag{1}
\end{align*}
&lt;/div&gt;
&lt;p&gt;関数をベクトルとみなすと、そこに線型代数の知見を持ち込むことができる。まず、関数による基底（関数基底）によって空間を張ることができる。関数によって張られた空間は特に &lt;strong&gt;関数空間&lt;/strong&gt; と呼ばれる。
また、2 つの関数 &lt;span class="math"&gt;\(f,g\)&lt;/span&gt; の &lt;strong&gt;内積&lt;/strong&gt; &lt;span class="math"&gt;\(\innerp{f}{g}\)&lt;/span&gt; を式 &lt;a class="reference internal" href="#id7"&gt;式 2&lt;/a&gt; の様に積分を用いて表すことが出来る。&lt;/p&gt;
&lt;div class="math" id="id7"&gt;
\begin{align*}
 \innerp{f}{g} &amp;amp;=
   \left[ f(-L) \dots f(0) \dots f(L) \right]
   \vvec{ g(-L) \\ \vdots \\ g(0) \\ \vdots \\ g(L) } \\
 &amp;amp;= f(-L)g(-L) + \dots + f(0)g(0) + \dots + f(L)g(L) \\
 &amp;amp;= \int_{-L}^{L} f(x)g(x) dx \tag{2}
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで &lt;span class="math"&gt;\(L\)&lt;/span&gt; は積分範囲を決める定数である &lt;a class="footnote-reference" href="#functioninnerprodrange" id="id8"&gt;[1]&lt;/a&gt;。また、関数自分自身の内積 &lt;span class="math"&gt;\(\innerp{f}{f}\)&lt;/span&gt; を &lt;strong&gt;ノルム&lt;/strong&gt; という &lt;a class="footnote-reference" href="#functioninnerprodnorm" id="id9"&gt;[2]&lt;/a&gt;。&lt;/p&gt;
&lt;table class="docutils footnote" frame="void" id="functioninnerprodrange" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id8"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;形式的に見た際には積分範囲は無限 &lt;span class="math"&gt;\([-\infty,\infty]\)&lt;/span&gt; になることが多いが、定数関数同士の内積を考えれば分かるように、内積値が発散してしまう場合がある。その場合は、積分範囲を限定して議論を行う。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="functioninnerprodnorm" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id9"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;span class="math"&gt;\(L\)&lt;/span&gt; に基づいてノルム値を &lt;span class="math"&gt;\(1\)&lt;/span&gt; にする操作を行うことがある。この操作を &lt;strong&gt;正規化&lt;/strong&gt; という。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h3&gt;三角関数の直交性&lt;/h3&gt;
&lt;p&gt;関数をベクトルとして考えた時、異なる周波数を持つ三角関数は互いに直交（&lt;span class="math"&gt;\(\iff\)&lt;/span&gt; 内積値が &lt;span class="math"&gt;\(0\)&lt;/span&gt; になる）する。この事を計算により確かめていく。&lt;/p&gt;
&lt;p&gt;尚、内積計算時の積分範囲は全て &lt;span class="math"&gt;\([-\pi, \pi]\)&lt;/span&gt; とする。何故なら、周期関数が直交しているかどうかを判定するには 1 周期分の内積を取り、その結果が &lt;span class="math"&gt;\(0\)&lt;/span&gt; になるかどうかを見れば良いからである。またその周期は、周波数を決める定数は全て整数であることにより決まり、最長の周波数は &lt;span class="math"&gt;\(\sin(x), \cos(x)\)&lt;/span&gt; が持つ &lt;span class="math"&gt;\(2\pi\)&lt;/span&gt; である。積分範囲を &lt;span class="math"&gt;\([-\pi, \pi]\)&lt;/span&gt; とすれば、一番長い周期を加味して内積を計算できる。&lt;/p&gt;
&lt;div class="section" id="sin"&gt;
&lt;h4&gt;正弦波（sin）の直交性&lt;/h4&gt;
&lt;p&gt;素直に内積を計算する。三角関数の和の公式&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\cos\{(n+m)x\} &amp;amp;= \cos(nx)\cos(mx) - \sin(nx)\sin(mx) \\
\cos\{(n-m)x\} &amp;amp;= \cos(nx)\cos(mx) + \sin(nx)\sin(mx) \\
\implies \sin(nx)\sin(mx) &amp;amp;= \frac{\cos\{(n-m)x\} - \cos\{(n+m)x\}}{2}
\end{align*}
&lt;/div&gt;
&lt;p&gt;を用いて &lt;span class="math"&gt;\(\sin\)&lt;/span&gt; の積を &lt;span class="math"&gt;\(\cos\)&lt;/span&gt; の和に分割して積分を行うのがポイントである。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\innerp{\sin(nx)}{\sin(mx)}
&amp;amp;= \int_{-\pi}^{\pi} \sin(nx) \sin(mx) dx \\
&amp;amp;= \int_{-\pi}^{\pi} \frac{\cos\{(n-m)x\} - \cos\{(n+m)x\}}{2} dx \\
&amp;amp;= \frac{1}{2(n-m)} \left[ \sin\{(n-m)x\} \right]_{-\pi}^{\pi} - \frac{1}{2(n+m)} \left[ \sin\{(n+m)x\} \right]_{-\pi}^{\pi} \\
&amp;amp;= \frac{1}{2(n-m)} \left[ \sin\{(n-m)\pi\} - \sin\{-(n-m)\pi\} \right] - \frac{1}{2(n+m)} \left[ \sin\{(n+m)\pi\} - \sin\{-(n+m)\pi\} \right] \\
&amp;amp;= \frac{\sin\{(n-m)\pi\}}{n-m} - \frac{\sin\{(n+m)\pi\}}{n+m}
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで、最後の結果の右辺第二項は、&lt;span class="math"&gt;\(n+m\)&lt;/span&gt; が整数になることから &lt;span class="math"&gt;\(0\)&lt;/span&gt; になる。一方の右辺第一項は &lt;span class="math"&gt;\(n \neq m\)&lt;/span&gt; の時は右辺第二項と同様に &lt;span class="math"&gt;\(0\)&lt;/span&gt; となる。 &lt;span class="math"&gt;\(n = m\)&lt;/span&gt; の時は、 &lt;span class="math"&gt;\(n-m \to 0\)&lt;/span&gt; なる極限を考えることで計算結果が確かめられる :&lt;/p&gt;
&lt;div class="math" id="id11"&gt;
\begin{align*}
\lim_{(n-m) \to 0} \frac{\sin\{(n-m)\pi\}}{n-m}
&amp;amp;= \lim_{\alpha \to 0} \frac{\sin\alpha\pi}{\alpha} \\
&amp;amp;= \lim_{\alpha \to 0} \frac{\ddiff{\sin\alpha\pi}{\alpha}}{\ddiff{\alpha}{\alpha}} = \lim_{\alpha \to 0} \pi \cos\alpha\pi \\
&amp;amp;= \pi \tag{3}
\end{align*}
&lt;/div&gt;
&lt;p&gt;以上の結果をまとめると、&lt;/p&gt;
&lt;div class="math" id="id12"&gt;
\begin{align*}
\innerp{\sin(nx)}{\sin(mx)} = \ifdiv{cc}{ 0 &amp;amp; (n \neq m) \\ \pi &amp;amp; (n = m) } \tag{4}
\end{align*}
&lt;/div&gt;
&lt;p&gt;この結果は、2 つの意味で重要である。&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;（今確かめている様に、）異なる周波数を持つ正弦波は互いに直交する。&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(n=m\)&lt;/span&gt; の時の結果は、 &lt;span class="math"&gt;\(\sin\)&lt;/span&gt; のノルム値は &lt;span class="math"&gt;\(\pi\)&lt;/span&gt; であることを示している。&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="cos"&gt;
&lt;h4&gt;余弦波（cos）の直交性&lt;/h4&gt;
&lt;p&gt;計算方針は &lt;span class="math"&gt;\(\sin\)&lt;/span&gt; の時と同様である。三角関数の和の公式より、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\cos(mx)\cos(nx) = \frac{\cos\{(n-m)x\} + \cos\{(n+m)x\}}{2}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成立するため、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\innerp{\cos(nx)}{\cos(mx)}
&amp;amp;= \int_{-\pi}^{\pi} \cos(nx) \cos(mx) dx \\
&amp;amp;= \int_{-\pi}^{\pi} \frac{\cos\{(n-m)x\} + \cos\{(n+m)x\}}{2} dx \\
&amp;amp;= \frac{1}{2(n-m)} \left[ \sin\{(n-m)\pi\} - \sin\{-(n-m)\pi\} \right] + \frac{1}{2(n+m)} \left[ \sin\{(n+m)\pi\} - \sin\{-(n+m)\pi\} \right] \\
&amp;amp;= \frac{\sin\{(n-m)\pi\}}{n-m} + \frac{\sin\{(n+m)\pi\}}{n+m}
\end{align*}
&lt;/div&gt;
&lt;p&gt;と、&lt;span class="math"&gt;\(\sin\)&lt;/span&gt; の内積計算時とほぼ同様の結果が得られる。最終結果の第一項に関しては式 &lt;a class="reference internal" href="#id11"&gt;式 3&lt;/a&gt; と同様に考えることで、次の結果が得られる。&lt;/p&gt;
&lt;div class="math" id="id13"&gt;
\begin{align*}
\innerp{\cos(nx)}{\cos(mx)} = \ifdiv{cc}{ 0 &amp;amp; (n \neq m) \\ \pi &amp;amp; (n = m) } \tag{5}
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\cos\)&lt;/span&gt; のノルムも &lt;span class="math"&gt;\(\sin\)&lt;/span&gt; と同様 &lt;span class="math"&gt;\(\pi\)&lt;/span&gt; であることが示されている。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id14"&gt;
&lt;h4&gt;正弦波と余弦波の直交性&lt;/h4&gt;
&lt;p&gt;最後に &lt;span class="math"&gt;\(\sin\)&lt;/span&gt; と &lt;span class="math"&gt;\(\cos\)&lt;/span&gt; の直交性を確かめる。
三角関数の和の公式により、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\sin\{(n+m)x\} &amp;amp;= \sin(nx)\cos(mx) + \cos(nx)\sin(mx) \\
\sin\{(n-m)x\} &amp;amp;= \sin(nx)\cos(mx) - \cos(nx)\sin(mx) \\
\implies \sin(nx)\cos(mx) &amp;amp;= \frac{\sin\{(n+m)x\} + \sin\{(n-m)x\}}{2}
\end{align*}
&lt;/div&gt;
&lt;p&gt;が成立するため、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\innerp{\sin(mx)}{\cos(mx)}
&amp;amp;= \int_{-\pi}^{\pi} \sin(nx) \cos(mx) dx \\
&amp;amp;= \int_{-\pi}^{\pi} \frac{\sin\{(n+m)x\} + \sin\{(n-m)x\}}{2} dx \\
&amp;amp;= \frac{1}{2(n+m)} \left[ \cos\{(n+m)\pi\} - \cos\{-(n+m)\pi\} \right] + \frac{1}{2(n-m)} \left[ \cos\{(n-m)\pi\} - \cos\{-(n-m)\pi\} \right] \\
&amp;amp;= 0
\end{align*}
&lt;/div&gt;
&lt;p&gt;従って、如何なる周波数に対しても正弦波と余弦波は直交していること&lt;/p&gt;
&lt;div class="math" id="id15"&gt;
\begin{equation*}
\innerp{\sin(nx)}{\cos(mx)} = 0 \tag{6}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が確かめられた。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id16"&gt;
&lt;h3&gt;フーリエ係数&lt;/h3&gt;
&lt;p&gt;次の様に信号 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; がフーリエ級数展開されていたとする。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f(x) = \frac{1}{2} a_{0} + \sum_{k=1}^{\infty} a_{k} \cos(kx) + \sum_{k=1}^{\infty} b_{k} \sin(kx)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;上式における係数 &lt;span class="math"&gt;\(a_{0}, a_{1}, ..., b_{1}, b_{2}, ...\)&lt;/span&gt; はフーリエ級数と呼ばれる。
フーリエ係数は、周波数成分への重み付けと説明される事が多い。一方、上記のように関数をベクトルとみなすと、信号を三角関数基底で表した際の一次結合係数とも捉え直す事ができる。&lt;/p&gt;
&lt;p&gt;係数を取り出すには、上記の直交性（ &lt;a class="reference internal" href="#id12"&gt;式 4&lt;/a&gt;, &lt;a class="reference internal" href="#id13"&gt;式 5&lt;/a&gt;, &lt;a class="reference internal" href="#id15"&gt;式 6&lt;/a&gt; ）を使用すれば良い。&lt;span class="math"&gt;\(\innerp{f(x)}{\sin(nx)} \ n \in \mathbb{N}\)&lt;/span&gt; を計算すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\innerp{f(x)}{\sin(nx)}
&amp;amp;= \innerp{\frac{1}{2} a_{0} + \sum_{k=1}^{\infty} a_{k} \cos(kx) + \sum_{k=1}^{\infty} b_{k}\sin(kx)}{\sin(nx)} \\
&amp;amp;= \innerp{\frac{1}{2} a_{0}}{\sin(nx)} + \innerp{\sum_{k=1}^{\infty} a_{k} \cos(kx)}{\sin(nx)} + \innerp{\sum_{k=1}^{\infty} b_{k}\sin(kx)}{\sin(nx)} \quad (\because 内積の線形性 ) \\
&amp;amp;= \frac{1}{2} a_{0} \innerp{1}{\sin(nx)} + \sum_{k=1}^{\infty} \innerp{a_{k}\cos(kx)}{\sin(nx)} + \sum_{k=1}^{\infty} \innerp{b_{k}\sin(kx)}{\sin(nx)} \quad (\because 内積の線形性 ) \\
&amp;amp;= \frac{1}{2} a_{0} \innerp{\cos(0)}{\sin(nx)} + \sum_{k=1}^{\infty} a_{k} \innerp{\cos(kx)}{\sin(nx)} + \sum_{k=1}^{\infty} b_{k} \innerp{\sin(kx)}{\sin(nx)} \\
&amp;amp;= \pi b_{n} \quad (\because 三角関数の直交性 )
\end{align*}
&lt;/div&gt;
&lt;p&gt;よって、&lt;/p&gt;
&lt;div class="math" id="id17"&gt;
\begin{equation*}
b_{n} = \frac{1}{\pi} \innerp{f(x)}{\sin(nx)} \tag{7}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;全く同様にして &lt;span class="math"&gt;\(\innerp{f(x)}{\cos(nx)} \ n \in \mathbb{N}\)&lt;/span&gt; を計算することで、次の結果が得られる &lt;a class="footnote-reference" href="#fouriorcoefwhendc" id="id18"&gt;[3]&lt;/a&gt; 。&lt;/p&gt;
&lt;div class="math" id="id19"&gt;
\begin{equation*}
a_{n} = \frac{1}{\pi} \innerp{f(x)}{\cos(nx)}  \tag{8}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;a class="reference internal" href="#id17"&gt;式 7&lt;/a&gt;, &lt;a class="reference internal" href="#id19"&gt;式 8&lt;/a&gt; の結果を見ると、 &lt;strong&gt;係数を取り出すには、関数基底と内積を取って、基底のノルムで割れば良い&lt;/strong&gt; 事が分かる。&lt;/p&gt;
&lt;table class="docutils footnote" frame="void" id="fouriorcoefwhendc" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id18"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;span class="math"&gt;\(a_{0}\)&lt;/span&gt; を求める際には、&lt;span class="math"&gt;\(\cos(0)=1\)&lt;/span&gt; と &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; の内積を取れば良い。&lt;span class="math"&gt;\(\int_{-\pi}^{\pi} {1} dx = 2\pi\)&lt;/span&gt; により、&lt;span class="math"&gt;\(a_{0}\)&lt;/span&gt; に乗じられている &lt;span class="math"&gt;\(\frac{1}{2}\)&lt;/span&gt; が実は無意味では無いことが分かるだろう。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="section" id="id20"&gt;
&lt;h3&gt;収束定理&lt;/h3&gt;
&lt;p&gt;いよいよ問題の核心について考えることが出来る。上記までの議論で、三角関数は基底をなすことが示された &lt;a class="footnote-reference" href="#abouttrianglefuncorthonarity" id="id21"&gt;[4]&lt;/a&gt;。それでは、三角関数によって構築された基底（三角関数基底）は、如何なる関数でも表現できるのだろうか？というのが次の疑問となる。&lt;/p&gt;
&lt;p&gt;この疑問に対する答えがフーリエ級数の &lt;strong&gt;収束定理&lt;/strong&gt; （以下、単純に収束定理）である。収束定理とは、次の有限項のフーリエ級数展開&lt;/p&gt;
&lt;div class="math" id="id22"&gt;
\begin{equation*}
S_{N}(x) = \frac{1}{2} a_{0} + \sum_{n=1}^{N} \left\{ a_{n} \cos(nx) + b_{n} \sin(nx) \right\} \tag{9}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を用いて信号 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; を近似（&lt;span class="math"&gt;\(S_{N}(x) \approx f(x)\)&lt;/span&gt; ）することを考え、&lt;span class="math"&gt;\(N\)&lt;/span&gt; の極限 &lt;span class="math"&gt;\(N \to \infty\)&lt;/span&gt; を取った時に、&lt;span class="math"&gt;\(S_{N}(x)\)&lt;/span&gt; と &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; が一致する、というものである。&lt;/p&gt;
&lt;div class="math" id="id23"&gt;
\begin{equation*}
\lim_{N \to \infty} \left\{ S_{N}(x) - f(x) \right\} = 0 \tag{10}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;cite&gt;式 10&lt;/cite&gt; が証明されれば、理論的観点から、安心してフーリエ級数を使用できると言って良い。ここで、予め注意してほしいのが、&lt;cite&gt;式 10&lt;/cite&gt; の &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; は任意の関数では成立せず、定理が成り立つための制約条件が存在することである。&lt;/p&gt;
&lt;p&gt;以下、収束定理の証明及び、 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; に課すべき制約条件を見ていく。&lt;/p&gt;
&lt;table class="docutils footnote" frame="void" id="abouttrianglefuncorthonarity" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id21"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;この事実は自明ではない。全く適当に選んだ関数の集合（関数族）が基底になることはまず無い。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class="section" id="id24"&gt;
&lt;h4&gt;ディリクレ核&lt;/h4&gt;
&lt;p&gt;収束定理 &lt;a class="reference internal" href="#id23"&gt;式 10&lt;/a&gt; が成立することを示すため、まず有限項のフーリエ級数展開の &lt;a class="reference internal" href="#id22"&gt;式 9&lt;/a&gt; に注目する。 &lt;a class="reference internal" href="#id22"&gt;式 9&lt;/a&gt; の各フーリエ係数 &lt;span class="math"&gt;\(a_{0}, a_{1}, ..., b_{1}, b_{2}, ...\)&lt;/span&gt; は、 &lt;a class="reference internal" href="#id17"&gt;式 7&lt;/a&gt;, &lt;a class="reference internal" href="#id19"&gt;式 8&lt;/a&gt; により、近似対象の関数 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; によって表すことが出来る。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
S_{N}(x)
&amp;amp;= \frac{1}{2} a_{0} + \sum_{n=1}^{N} \left\{ a_{n} \cos(nx) + b_{n} \sin(nx) \right\} \\
&amp;amp;= \frac{1}{2} \frac{1}{\pi} \innerp{1}{f(x)} + \sum_{n=1}^{N} \left\{ \frac{1}{\pi} \innerp{\cos(ny)}{f(y)} \cos(nx) + \frac{1}{\pi} \innerp{\sin(ny)}{f(y)} \sin(nx) \right\} \\
&amp;amp;= \frac{1}{2\pi} \int_{-\pi}^{\pi} f(y) dy + \sum_{n=1}^{N} \left\{ \frac{1}{\pi} \int_{-\pi}^{\pi} \cos(ny)f(y) dy \cos(nx) + \frac{1}{\pi} \int_{-\pi}^{\pi} \sin(ny)f(y) dy \sin(nx) \right\} \\
&amp;amp;= \frac{1}{\pi} \int_{-\pi}^{\pi} f(y) \left[ \frac{1}{2} + \sum_{n=1}^{N} \left\{ \cos(ny)\cos(nx) + \sin(ny)\sin(nx) \right\} \right] dy \\
&amp;amp;= \frac{1}{\pi} \int_{-\pi}^{\pi} f(y) \left[ \frac{1}{2} + \sum_{n=1}^{N} \cos\left\{n(y-x)\right\} \right] dy \quad (\because \cos の加法定理を使用 )
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで、 &lt;span class="math"&gt;\(z=y-x\)&lt;/span&gt; と積分の変数変換を行う。積分範囲は &lt;span class="math"&gt;\([-\pi,\pi]\)&lt;/span&gt; から &lt;span class="math"&gt;\([-\pi-x,\pi-x]\)&lt;/span&gt; に変化するが、周期関数を 1 周期分積分している状態で、積分範囲を左右にずらしても積分の結果は変わらないため、次の結果が得られる。&lt;/p&gt;
&lt;div class="math" id="id25"&gt;
\begin{align*}
S_{N}(x)
&amp;amp;= \frac{1}{\pi} \int_{-\pi}^{\pi} f(z+x) \left[ \frac{1}{2} + \sum_{n=1}^{N} \cos(nz) \right] dz \\
&amp;amp;= \frac{1}{\pi} \int_{-\pi}^{\pi} f(z+x) D_{N}(z) dz \tag{11}
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;cite&gt;式 11&lt;/cite&gt; で導入した&lt;/p&gt;
&lt;div class="math" id="id26"&gt;
\begin{equation*}
D_{N}(x) = \frac{1}{2} + \sum_{n=1}^{N} \cos(nx) \tag{12}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を &lt;strong&gt;ディリクレ核 (Dirichlet kernel)&lt;/strong&gt; という。以下に述べるように、ディリクレ核にはいくつか重要な性質がある。&lt;/p&gt;
&lt;div class="section" id="id27"&gt;
&lt;h5&gt;ディリクレ核の一周期分の積分&lt;/h5&gt;
&lt;p&gt;定義 &lt;a class="reference internal" href="#id26"&gt;式 12&lt;/a&gt; より明らかにディリクレ核は周期関数である。周期 &lt;span class="math"&gt;\(2\pi\)&lt;/span&gt; の積分を実行すると、&lt;/p&gt;
&lt;div class="math" id="id28"&gt;
\begin{align*}
\int_{-\pi}^{\pi} D_{N}(x) dx
&amp;amp;= \int_{-\pi}^{\pi} \left\{ \frac{1}{2} + \sum_{n=1}^{N} \cos(nx) \right\} dx \\
&amp;amp;= \int_{-\pi}^{\pi} \frac{1}{2} dx + \int_{-\pi}^{\pi} \sum_{n=1}^{N} \cos(nx) dx
= \int_{-\pi}^{\pi} \frac{1}{2} dx + \sum_{n=1}^{N} \int_{-\pi}^{\pi} \cos(nx) dx \\
&amp;amp;= \int_{-\pi}^{\pi} \frac{1}{2} dx \quad (\because 三角関数の一周期分の積分値は 0) \\
&amp;amp;= \frac{2\pi}{2} = \pi \tag{13}
\end{align*}
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id29"&gt;
&lt;h5&gt;ディリクレ核の sin 関数による表現&lt;/h5&gt;
&lt;p&gt;ディリクレ核は、若干技巧的ではあるが、和を持たない形式に変形することができる。&lt;span class="math"&gt;\(D_{N}(x)\)&lt;/span&gt; の左から &lt;span class="math"&gt;\(2\sin\left(\frac{1}{2}x\right)\)&lt;/span&gt; を乗じると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
2\sin\left(\frac{1}{2}x\right) D_{N}(x)
&amp;amp;= 2\sin\left(\frac{1}{2}x\right) \left[ \frac{1}{2} + \sum_{n=1}^{N} \cos(nx) \right] \\
&amp;amp;= \sin\left(\frac{1}{2}x\right) + 2\sin\left(\frac{1}{2}x\right) \cos(x) + 2\sin\left(\frac{1}{2}x\right) \cos(2x) + ... + 2\sin\left(\frac{1}{2}x\right) \cos(Nx)
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで、三角関数の和の公式 &lt;span class="math"&gt;\(\sin(nx)\cos(mx) = \frac{\sin\{(n+m)x\} + \sin\{(n-m)x\}}{2}\)&lt;/span&gt; を用いれば、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
2\sin\left(\frac{1}{2}x\right) D_{N}(x)
&amp;amp;= \sin\left(\frac{1}{2}x\right) + \left[ \sin\left\{\left(\frac{1}{2} - 1\right)x\right\} + \sin\left\{\left(\frac{1}{2} + 1\right)x\right\} \right] \\
&amp;amp;\quad + \left[ \sin\left\{\left(\frac{1}{2} - 2\right)x\right\} + \sin\left\{\left(\frac{1}{2} + 2\right)x\right\} \right] + ... + \left[ \sin\left\{\left(\frac{1}{2} - N\right)x\right\} + \sin\left\{\left(\frac{1}{2} + N\right)x\right\} \right] \\
&amp;amp;= \sin\left(\frac{1}{2}x\right) + \sin\left(-\frac{1}{2}x\right) + \sin\left(\frac{3}{2}x\right) \\
&amp;amp;\quad + \sin\left(-\frac{3}{2}x\right) + \sin\left(\frac{5}{2}x\right) + ... + \sin\left\{\left(\frac{1}{2} - N\right)x\right\} + \sin\left\{\left(\frac{1}{2} + N\right)x\right\} \\
&amp;amp;= \sin\left\{\left(\frac{1}{2} + N\right)x\right\}
\end{align*}
&lt;/div&gt;
&lt;p&gt;従って、ディリクレ核を &lt;span class="math"&gt;\(\sin\)&lt;/span&gt; のみで表現することが出来る :&lt;/p&gt;
&lt;div class="math" id="id30"&gt;
\begin{equation*}
D_{N}(x) = \frac{\sin\left\{\left(\frac{1}{2} + N\right)x\right\}}{2\sin\left(\frac{1}{2}x\right)} \tag{14}
\end{equation*}
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id31"&gt;
&lt;h5&gt;ディリクレ核の畳み込み&lt;/h5&gt;
&lt;p&gt;&lt;cite&gt;式 11&lt;/cite&gt; を改めて眺めると、この式は積分範囲 &lt;span class="math"&gt;\([-\pi,\pi]\)&lt;/span&gt; において &lt;strong&gt;関数にディリクレ核を畳み込んでいる&lt;/strong&gt; 式に捉え直せる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
S_{N}(x) = \frac{1}{\pi} \ f(x) \ast D_{N}(x)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;先取りして収束定理が成り立つと仮定すると、&lt;span class="math"&gt;\(N\)&lt;/span&gt; の極限 &lt;span class="math"&gt;\(N \to \infty\)&lt;/span&gt; に於いて次が成り立つ :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\lim_{N \to \infty} S_{N}(x) &amp;amp;= \lim_{N \to \infty} \frac{1}{\pi} \ f(x) \ast D_{N}(x) = f(x) \\
\therefore \lim_{N \to \infty} f(x) \ast D_{N}(x) &amp;amp;= \pi f(x)
\end{align*}
&lt;/div&gt;
&lt;p&gt;畳み込みの結果、畳込み対象の関数 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; が表れている。即ちこの結果は、 &lt;span class="math"&gt;\(N\)&lt;/span&gt; の極限においてディリクレ関数はインパルス関数に近い振る舞いをすることを示している。&lt;/p&gt;
&lt;!-- 他にもディリクレ核には種々の性質が成り立つため、後に補足を行う。 --&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id32"&gt;
&lt;h4&gt;リーマン・ルベーグの補題&lt;/h4&gt;
&lt;p&gt;収束定理の証明のためには、もう一つ &lt;strong&gt;リーマン・ルベーグの補題&lt;/strong&gt; なる命題が必要である。この節では、リーマン・ルベーグの補題の証明を行う。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;リーマン・ルベーグの補題&lt;/dt&gt;
&lt;dd&gt;&lt;blockquote class="first"&gt;
区分的に連続な関数 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; と &lt;span class="math"&gt;\(\sin(Nx)\)&lt;/span&gt; の積を積分区間  &lt;span class="math"&gt;\([a,b]\)&lt;/span&gt; で積分したものは、&lt;span class="math"&gt;\(N \to \infty\)&lt;/span&gt; とすると &lt;span class="math"&gt;\(0\)&lt;/span&gt; に収束する。&lt;/blockquote&gt;
&lt;div class="last math" id="id33"&gt;
\begin{equation*}
\lim_{N \to \infty} \int_{a}^{b} f(x) \sin(Nx) dx = 0 \tag{15}
\end{equation*}
&lt;/div&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;（証明）部分積分を用いることにより、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\int_{a}^{b} f(x) \sin(Nx) dx
&amp;amp;= \int_{a}^{b} f(x) \left\{ -\frac{1}{N} \cos(Nx) \right\}^{\prime} dx \\
&amp;amp;= \left[ -\frac{1}{N} f(x) \cos(Nx) \right]_{a}^{b} - \int_{a}^{b} -\frac{1}{N} f^{\prime}(x) \cos(Nx) dx \quad (\because 部分積分 ) \\
&amp;amp;= -\frac{1}{N} \left[ f(x) \cos(Nx) \right]_{a}^{b} + \frac{1}{N} \int_{a}^{b} f^{\prime}(x) \cos(Nx) dx
\end{align*}
&lt;/div&gt;
&lt;p&gt;と変形できる。このまま &lt;span class="math"&gt;\(N \to \infty\)&lt;/span&gt; なる極限をとれば、いずれの項も &lt;span class="math"&gt;\(0\)&lt;/span&gt; に収束するように見える。しかしそれは &lt;strong&gt;関数&lt;/strong&gt; &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; &lt;strong&gt;の微分&lt;/strong&gt; &lt;span class="math"&gt;\(f^{\prime}(x)\)&lt;/span&gt; &lt;strong&gt;が区間&lt;/strong&gt; &lt;span class="math"&gt;\([a,b]\)&lt;/span&gt; &lt;strong&gt;で発散しない（区分的なめらかな）ときのみ&lt;/strong&gt; 真である。この条件を関数 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; に付加した時、命題は成立する。&lt;/p&gt;
&lt;p&gt;では一般に、 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; が区分的に連続であること &lt;strong&gt;のみ&lt;/strong&gt; を仮定して証明を行う。この時は区分的なめらかな関数 &lt;span class="math"&gt;\(g(x)\)&lt;/span&gt; を用いて命題が成立することを用いて、&lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; を &lt;span class="math"&gt;\(g(x)\)&lt;/span&gt; に近づけることで命題の成立を示す。積分区間 &lt;span class="math"&gt;\([a,b]\)&lt;/span&gt; を &lt;span class="math"&gt;\(M\)&lt;/span&gt; 分割し、区間の小さい方から順に &lt;span class="math"&gt;\(x_{1}, x_{2}, ..., x_{M}\)&lt;/span&gt; となるようにする（当然 &lt;span class="math"&gt;\(x_{1} = a, x_{M} = b\)&lt;/span&gt; が成立する）。この上で &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; を次のように構成する :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f(x) = g(x_{k+1}) \quad (k = 1,...,M-1, \ x_{k} \leq x \leq x_{k+1})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;構成法から見えるように、分割数 &lt;span class="math"&gt;\(M\)&lt;/span&gt; を増やしていけば、&lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; と &lt;span class="math"&gt;\(g(x)\)&lt;/span&gt; の差は小さくなっていくのが分かる（TODO: 図を書こう）。即ち、任意の &lt;span class="math"&gt;\(\varepsilon &amp;gt; 0\)&lt;/span&gt; に対して、 &lt;span class="math"&gt;\(|f(x) - g(x)| &amp;lt; \varepsilon\)&lt;/span&gt; を成立させる &lt;span class="math"&gt;\(M\)&lt;/span&gt; が存在する。&lt;/p&gt;
&lt;p&gt;そしてこの &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; を用いたとき、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\left| \int_{a}^{b} f(x) \sin(Nx) dx \right|
&amp;amp;= \left| \int_{a}^{b} \left\{ f(x) - g(x) + g(x) \right\} \sin(Nx) dx \right| \\
&amp;amp;\leq \left| \int_{a}^{b} \left\{ f(x) - g(x) \right\} \sin(Nx) dx \right| + \left| \int_{a}^{b} g(x) \sin(Nx) dx \right| \\
&amp;amp;\leq \int_{a}^{b} \left| f(x) - g(x) \right| \left| \sin(Nx) \right| dx + \left| \int_{a}^{b} g(x) \sin(Nx) dx \right| \\
&amp;amp;\leq \int_{a}^{b} \left| f(x) - g(x) \right| dx + \left| \int_{a}^{b} g(x) \sin(Nx) dx \right| \\
&amp;amp;&amp;lt; \int_{a}^{b} \varepsilon dx + \left| \int_{a}^{b} g(x) \sin(Nx) dx \right| = \varepsilon(b - a) + \left| \int_{a}^{b} g(x) \sin(Nx) dx \right|
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで、 &lt;span class="math"&gt;\(\displaystyle\left| \int_{a}^{b} g(x) \sin(Nx) dx \right| &amp;lt; \varepsilon\)&lt;/span&gt; となる様に &lt;span class="math"&gt;\(N\)&lt;/span&gt; を十分大きく取る（ &lt;span class="math"&gt;\(g(x)\)&lt;/span&gt; は区分的なめらかなので成立する）と、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\left| \int_{a}^{b} f(x) \sin(Nx) dx \right|  &amp;lt; \varepsilon(b-a) + \varepsilon = \varepsilon(b - a + 1)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;即ち、任意の &lt;span class="math"&gt;\(\varepsilon\)&lt;/span&gt; に対して上式を成り立たせる &lt;span class="math"&gt;\(N\)&lt;/span&gt; が存在するので、 &lt;a class="reference internal" href="#id34"&gt;式 16&lt;/a&gt; が成り立つ。&lt;/p&gt;
&lt;div class="math" id="id34"&gt;
\begin{equation*}
\lim_{N \to \infty} \left| \int_{a}^{b} f(x) \sin(Nx) dx \right| = 0 \tag{16}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;a class="reference internal" href="#id34"&gt;式 16&lt;/a&gt; は、リーマン・ルベーグの補題（ &lt;a class="reference internal" href="#id33"&gt;式 15&lt;/a&gt; ）が成立していることをそのまま示している。何故なら、ある関数の絶対値が &lt;span class="math"&gt;\(0\)&lt;/span&gt; に収束することと、関数が &lt;span class="math"&gt;\(0\)&lt;/span&gt; に収束することは同値だからである。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id35"&gt;
&lt;h4&gt;収束定理の証明&lt;/h4&gt;
&lt;p&gt;ここまでの結果を利用して、収束定理を示そう。まず &lt;a class="reference internal" href="#id25"&gt;式 11&lt;/a&gt; より、ディリクレ核を使用して &lt;span class="math"&gt;\(S_{N}(x)\)&lt;/span&gt; を書き直すと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
S_{N}(x) - f(x) = \frac{1}{\pi} \int_{-\pi}^{\pi} f(x+z) D_{N}(x) dx - f(x)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで、ディリクレ核の性質（ &lt;a class="reference internal" href="#id28"&gt;式 13&lt;/a&gt;, &lt;a class="reference internal" href="#id30"&gt;式 14&lt;/a&gt; ）を用いると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
S_{N}(x) - f(x)
&amp;amp;= \frac{1}{\pi} \int_{-\pi}^{\pi} f(x+z) D_{N}(z) dz - 1 \times f(x) \\
&amp;amp;= \frac{1}{\pi} \int_{-\pi}^{\pi} f(x+z) D_{N}(z) dz - \frac{1}{\pi} \int_{-\pi}^{\pi} D_{N}(z) dz f(x) \\
&amp;amp;= \frac{1}{\pi} \int_{-\pi}^{\pi} \left\{ f(x+z) - f(x) \right\} D_{N}(z) dz \\
&amp;amp;= \frac{1}{\pi} \int_{-\pi}^{\pi} \left\{ f(x+z) - f(x) \right\} \frac{\sin\left\{\left( \frac{1}{2} + N \right)z\right\}}{2\sin\left(\frac{1}{2}z\right)} dz \\
&amp;amp;= \frac{1}{\pi} \int_{-\pi}^{\pi} \frac{ f(x+z) - f(x) }{2\sin\left(\frac{1}{2}z\right)} \sin\left\{\left( \frac{1}{2} + N \right)z\right\} dz
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここでリーマン・ルベーグの補題を用いる。ただし、そのためには、&lt;span class="math"&gt;\(\displaystyle\frac{ f(x+z) - f(x) }{2\sin\left(\frac{1}{2}z\right)}\)&lt;/span&gt; が区分的に連続でなければならない。この分数は &lt;span class="math"&gt;\(z = 0\)&lt;/span&gt; の時、分母 &lt;span class="math"&gt;\(2\sin\left(\frac{1}{2}z\right)\)&lt;/span&gt; が &lt;span class="math"&gt;\(0\)&lt;/span&gt; になるので、&lt;span class="math"&gt;\(z=0\)&lt;/span&gt; においても発散しないことを示す必要がある。以下の極限を考えると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\lim_{z \to 0} \frac{ f(x+z) - f(x) }{2\sin\left(\frac{1}{2}z\right)}
&amp;amp;= \lim_{z \to 0} \frac{ f(x+z) - f(x) }{z} \frac{z}{2\sin\left(\frac{1}{2}z\right)} \\
&amp;amp;= \lim_{z \to 0} \frac{ f(x+z) - f(x) }{z} \lim_{z \to 0} \frac{\ddiff{z}{z}}{\ddiff{2\sin\left(\frac{1}{2}z\right)}{z}} \quad (\because ロピタルの定理 ) \\
&amp;amp;= \lim_{z \to 0} \frac{ f(x+z) - f(x) }{z} \frac{1}{2\frac{1}{2}} \\
&amp;amp;= f^{\prime}(x)
\end{align*}
&lt;/div&gt;
&lt;p&gt;より、 &lt;span class="math"&gt;\(f^{\prime}(x)\)&lt;/span&gt; が発散しない、即ち &lt;strong&gt;関数&lt;/strong&gt; &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; &lt;strong&gt;が区分的になめらか&lt;/strong&gt; であれば、リーマン・ルベーグの補題を使用することで、収束定理&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\lim_{N \to \infty} \left\{ S_{N}(x) - f(x) \right\} = 0
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成立する。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id36"&gt;
&lt;h3&gt;三角関数の完全性&lt;/h3&gt;
&lt;p&gt;フーリエ級数の収束定理を用いることで、三角関数基底によって基底は全て揃うのか？という問に答えを与える事ができる。この性質を、 &lt;strong&gt;三角関数の完全性&lt;/strong&gt; という。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;三角関数の完全性&lt;/dt&gt;
&lt;dd&gt;定数、&lt;span class="math"&gt;\(\sin\)&lt;/span&gt; 、&lt;span class="math"&gt;\(\cos\)&lt;/span&gt; によって全ての関数基底が揃っている。&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;証明は背理法による。&lt;/p&gt;
&lt;p&gt;（証明）基底が揃っていない場合には次の仮定が成り立つ。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;仮定&lt;/dt&gt;
&lt;dd&gt;定数、&lt;span class="math"&gt;\(\sin\)&lt;/span&gt; 、&lt;span class="math"&gt;\(\cos\)&lt;/span&gt; の全てに直交している連続関数基底が存在する。&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;この命題の矛盾を導くことで、三角関数基底の完全性を示す。&lt;/p&gt;
&lt;p&gt;まず、「定数、sin、cos の全てに直交している連続関数」を &lt;span class="math"&gt;\(h(x)\)&lt;/span&gt; とおく。その定義から、以下が成り立つ：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ifdiv{ll}{
   \innerp{h(x)}{1} = \displaystyle\int_{-\pi}^{\pi} h(x) dx = 0 &amp;amp; \\
   \innerp{h(x)}{\cos(nx)} = \displaystyle\int_{-\pi}^{\pi} h(x) \cos(nx) dx = 0 &amp;amp; (n \in \mathbb{N}) \\
   \innerp{h(x)}{\sin(nx)} = \displaystyle\int_{-\pi}^{\pi} h(x) \sin(nx) dx = 0 &amp;amp; (n \in \mathbb{N})
}
\end{align*}
&lt;/div&gt;
&lt;p&gt;これらの条件を満たす自明な関数に &lt;span class="math"&gt;\(h(x) = 0\)&lt;/span&gt; があるが、 &lt;span class="math"&gt;\(h(x) = 0\)&lt;/span&gt; は関数空間の零ベクトルに対応し空間を生成しない（この関数をスカラー倍しても同じ関数しか出てこない）ため、基底とはならない。従って、 &lt;span class="math"&gt;\(h(x) = 0\)&lt;/span&gt; 以外の関数で考える。&lt;/p&gt;
&lt;p&gt;この前提の上で、&lt;span class="math"&gt;\(h(x)\)&lt;/span&gt; をフーリエ係数展開 &lt;span class="math"&gt;\(S_{N}(x)\)&lt;/span&gt; によって表現すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
S_{N}(x)
&amp;amp;= \frac{1}{2} a_{0} + \sum_{n=1}^{N} \left\{ a_{n} \cos(nx) + b_{n} \sin(nx) \right\} \\
&amp;amp;= \frac{1}{2} \frac{1}{\pi} \innerp{1}{h(x)} + \sum_{n=1}^{N} \left\{ \frac{1}{\pi} \innerp{\cos(ny)}{h(y)} \cos(nx) + \frac{1}{\pi} \innerp{\sin(ny)}{h(y)} \sin(nx) \right\} \\
&amp;amp;= \frac{1}{2\pi} \int_{-\pi}^{\pi} h(y) dy + \sum_{n=1}^{N} \left\{ \frac{1}{\pi} \int_{-\pi}^{\pi} \cos(ny)h(y) dy \cos(nx) + \frac{1}{\pi} \int_{-\pi}^{\pi} \sin(ny)h(y) dy \sin(nx) \right\} \\
&amp;amp;= 0
\end{align*}
&lt;/div&gt;
&lt;p&gt;フーリエ級数の収束定理を用いると、 &lt;span class="math"&gt;\(\displaystyle\lim_{N \to \infty} S_{N} = h(x) = 0\)&lt;/span&gt; 。この結果は、 &lt;span class="math"&gt;\(h(x) = 0\)&lt;/span&gt; 以外の関数で考えていることに矛盾する。従って、冒頭で述べた三角関数の完全性が成り立つ。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id37"&gt;
&lt;h3&gt;フーリエ変換&lt;/h3&gt;
&lt;p&gt;周期 &lt;span class="math"&gt;\(T\)&lt;/span&gt; の実関数 &lt;span class="math"&gt;\(f : \mathbb{R} \to \mathbb{R}\)&lt;/span&gt; に対して、 （複素）フーリエ級数展開は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\left\{ \begin{array}{l}
  f(t)  = \displaystyle\sum_{n = -\infty}^{\infty} c_{n} \exp(j n\omega_{0}t) \\
  c_{n} = \displaystyle\frac{1}{T} \int^{T/2}_{-T/2} f(t) \exp(-j n\omega_{0} t) dt
  \end{array} \right.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となる。 ここで &lt;span class="math"&gt;\(j\)&lt;/span&gt; は虚数単位（&lt;span class="math"&gt;\(j = \sqrt{-1}\)&lt;/span&gt; ）、 &lt;span class="math"&gt;\(\omega_{0} = 2\pi/T\)&lt;/span&gt; である。 フーリエ級数展開により、 様々な周期関数 &lt;span class="math"&gt;\(f\)&lt;/span&gt; は周波数領域（異なる周波数を持つ三角関数の和）で表現できることは周知である。 今、 &lt;span class="math"&gt;\(c_{n}\)&lt;/span&gt; を消去すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f(t) = \sum_{n=-\infty}^{\infty} \frac{1}{T} \left\{ \int^{T/2}_{-T/2} f(t) \exp(-jn\omega_{0}t)dt \right\} \exp(jn\omega_{0}t)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;更に、 &lt;span class="math"&gt;\(F(n\omega_{0}) = \displaystyle\int^{T/2}_{-T/2} f(t) \exp(-jn\omega_{0}t) dt\)&lt;/span&gt; とおくと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f(t) = \sum_{n=-\infty}^{\infty} \frac{1}{T} F(n\omega_{0}) \exp(jn\omega_{0}t) = \frac{1}{2\pi} \sum_{n=-\infty}^{\infty} \omega_{0} F(n\omega_{0}) \exp(j n \omega_{0}t)
\end{equation*}
&lt;/div&gt;
&lt;!-- &amp;=&amp; \frac{1}{2\pi} \sum^{\infty}_{n = -\infty} \omega_{0} F(\omega) \exp(j \omega t) \quad (\omega = n \omega_{0}) --&gt;
&lt;p&gt;となる。 今、 &lt;span class="math"&gt;\(T \to \infty\)&lt;/span&gt; ならしめ周期を無限大にすると &lt;span class="math"&gt;\(\omega_{0}\)&lt;/span&gt; は &lt;span class="math"&gt;\(0\)&lt;/span&gt; に収束するので、&lt;span class="math"&gt;\(\omega_{0}\)&lt;/span&gt; を区間幅とした区分求積法により、 次の積分と等しくなる :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\left\{ \begin{array}{l}
  f(t)  = \displaystyle\frac{1}{2\pi}\int_{-\infty}^{\infty} F(\omega) \exp(j \omega t) d\omega \\
  F(\omega) = \displaystyle \int^{\infty}_{-\infty} f(t) \exp(-j\omega t) dt
  \end{array} \right.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで &lt;span class="math"&gt;\(F(\omega)\)&lt;/span&gt; は &lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; のフーリエ変換、 &lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; は &lt;span class="math"&gt;\(F(\omega)\)&lt;/span&gt; のフーリエ逆変換（逆フーリエ変換）と呼ばれる。 非周期的な関数は周期無限の関数とも考えられるので、 フーリエ変換によって、 様々な関数の周波数領域表現を得る事ができる。 但し、&lt;span class="math"&gt;\(F(\omega)\)&lt;/span&gt; の収束を保証するため、 &lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; は絶対可積分 :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\int_{-\infty}^{\infty} |f(t)| dt &amp;lt; \infty \quad （(-\infty、 \infty) における積分値が有界）
\end{equation*}
&lt;/div&gt;
&lt;p&gt;でなくてはならない。 もし、 上の積分が有界な値を取るならば、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
F(\omega)
&amp;amp;= \int^{\infty}_{-\infty} f(t) \exp(-j\omega t) dt \\
&amp;amp;&amp;lt; \int^{\infty}_{-\infty} |f(t) \exp(-j\omega t)| dt &amp;lt; \int^{\infty}_{-\infty} |f(t)||\exp(-j\omega t)| dt \\
&amp;amp;= \int^{\infty}_{-\infty} |f(t)| dt \quad （\because オイラーの公式より |\exp(-j\omega t)| = \sqrt{\cos^{2} \omega t + \sin^{2} \omega t} = 1）
\end{align*}
&lt;/div&gt;
&lt;p&gt;となって &lt;span class="math"&gt;\(F(\omega)\)&lt;/span&gt; もまた有界である事が分かる。&lt;/p&gt;
&lt;div class="section" id="id38"&gt;
&lt;h4&gt;ラプラス変換&lt;/h4&gt;
&lt;p&gt;実関数 &lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; に収束因子 &lt;span class="math"&gt;\(\exp(-\sigma t)\)&lt;/span&gt; （&lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; は非負実数）を乗じた関数 &lt;span class="math"&gt;\(f(t)\exp(-\sigma t)\)&lt;/span&gt; のフーリエ変換&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\int^{\infty}_{-\infty} f(t)\exp(-\sigma t) \exp(-j\omega t) dt = \displaystyle \int^{\infty}_{-\infty} f(t)\exp(-st) dt = F(s) \quad （s = \sigma + j\omega）
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を &lt;strong&gt;（両側）ラプラス変換&lt;/strong&gt; と呼ぶ。 ラプラス変換は、 &lt;span class="math"&gt;\(s\)&lt;/span&gt; が複素数であることにより、 周波数領域だけ（&lt;span class="math"&gt;\(\sigma = 0\)&lt;/span&gt; とした時。 フーリエ変換と等価となる）でなく、 複素数領域で過渡的な（振動の減衰 / 増大）現象をも解析の対象とすることができる。 また、&lt;span class="math"&gt;\(F(s)\)&lt;/span&gt; から &lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; に変換するラプラス逆変換（逆ラプラス変換）は、 次の式で定義される :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f(t) = \frac{1}{2\pi j} \lim_{\omega \to \infty} \int^{c + j\omega}_{c - j\omega} F(s) \exp(st) ds
\end{equation*}
&lt;/div&gt;
&lt;p&gt;以後、 実関数 &lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; のラプラス変換を &lt;span class="math"&gt;\(\mathcal{L}[f(t)]( = F(s))\)&lt;/span&gt; 、&lt;span class="math"&gt;\(F(s)\)&lt;/span&gt; のラプラス逆変換を &lt;span class="math"&gt;\(\mathcal{L}^{-1}[F(s)]( = f(t))\)&lt;/span&gt; と表す。&lt;/p&gt;
&lt;p&gt;工学的な応用の場面では、 ラプラス変換の積分範囲は &lt;span class="math"&gt;\([0, \infty)\)&lt;/span&gt; とする事が多い :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F(s) = \int^{\infty}_{0} f(t)\exp(-st) dt
\end{equation*}
&lt;/div&gt;
&lt;p&gt;これを特に片側ラプラス変換と呼ぶ。 ラプラス変換は演算子法の一種であり、 様々な関数の変換結果（ラプラス変換対）をまとめたラプラス変換表を参照しながら、 微分方程式を代数的、 かつ簡易に解くことができる。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id39"&gt;
&lt;h4&gt;伝達関数&lt;/h4&gt;
&lt;p&gt;1 つの入力かつ 1 つの出力があるシステム（一入力一出力システム）を考える。 入力の振る舞いを表す実関数を &lt;span class="math"&gt;\(x(t)\)&lt;/span&gt; 、 それに対する出力も実関数 &lt;span class="math"&gt;\(y(t)\)&lt;/span&gt; と表せるとする。 ここで `` 振る舞いを表す実関数 '' とは、 線形微分方程式で記述されているラプラス変換可能な関数を意味する。 従って &lt;span class="math"&gt;\(x(t), y(t)\)&lt;/span&gt; のラプラス変換 &lt;span class="math"&gt;\(X(s)、 Y(s)\)&lt;/span&gt; は、 微分演算子の存在によりそれぞれ &lt;span class="math"&gt;\(s\)&lt;/span&gt; の多項式で表現できる事が分かる。&lt;/p&gt;
&lt;!-- :math:`x(t), y(t)` それぞれのラプラス変換の結果を :math:`{\cal L}[x(t)] = X(s)` 、 :math:`{\cal L}[y(t)] = Y(s)` とした時、 --&gt;
&lt;p&gt;そして、 出力と入力のラプラス変換の比を &lt;strong&gt;伝達関数 (Transfer function)&lt;/strong&gt; と呼ぶ。  伝達関数を &lt;span class="math"&gt;\(G(s)\)&lt;/span&gt; とすると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
G(s) = \frac{Y(s)}{X(s)}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表すことができる。 伝達関数 &lt;span class="math"&gt;\(G(s)\)&lt;/span&gt; は入力と出力の関係をひとまとめにし、 システムの特性（性質）を代表している事が分かる。 出力 &lt;span class="math"&gt;\(y(t)\)&lt;/span&gt; の振る舞いは &lt;span class="math"&gt;\(Y(s) = G(s)X(s)\)&lt;/span&gt; から両辺ラプラス逆変換を施すことにより求めることができる。 また、 &lt;span class="math"&gt;\(G(s)\)&lt;/span&gt; 自体の様子（分母分子の多項式の係数）から、 システムの安定性を判定することもできる。 この様に、 伝達関数はシステムの特性を観察する際に大いに役立ち、 古典制御理論の中心をなす概念となっている。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id40"&gt;
&lt;h4&gt;安定性解析の概要&lt;/h4&gt;
&lt;p&gt;伝達関数からシステムの安定性を解析する事を考える。 まず、 システムが &lt;strong&gt;安定 (stable)&lt;/strong&gt; であるとは、 任意の時間で有界な任意の入力 &lt;span class="math"&gt;\(x(t)\)&lt;/span&gt; （&lt;span class="math"&gt;\({}^{\forall} t. |x(t)| &amp;lt; \infty\)&lt;/span&gt; ）に対して、 その出力 &lt;span class="math"&gt;\(y(t)\)&lt;/span&gt; もまた任意の時間で有界である時を言う &lt;a class="footnote-reference" href="#aboutstatibility" id="id41"&gt;[5]&lt;/a&gt; 。&lt;/p&gt;
&lt;table class="docutils footnote" frame="void" id="aboutstatibility" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id41"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;厳密には、 リペアノフの意味で安定と言う。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;逆に安定で無い、 即ち出力が有界でない時間がある（&lt;span class="math"&gt;\({}^{\exists} t. |y(t)| = \infty\)&lt;/span&gt; ）システムを不安定 (unstable) と言う。 任意の入力 &lt;span class="math"&gt;\(x(t)\)&lt;/span&gt; に対してその出力 &lt;span class="math"&gt;\(y(t)\)&lt;/span&gt; の挙動を調べる事は不可能だが、 実際には、 入力 &lt;span class="math"&gt;\(x(t)\)&lt;/span&gt; を単位ステップ関数&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
x(t) =
\left\{ \begin{array}{ll}
  0 &amp;amp; t &amp;lt; 0 \\
  1 &amp;amp; t \geq 0
\end{array} \right.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とした時の出力 &lt;span class="math"&gt;\(y(t)\)&lt;/span&gt; が有界な値に収束すれば安定となる事が示されている。&lt;/p&gt;
&lt;p&gt;それでは伝達関数 &lt;span class="math"&gt;\(G(s)\)&lt;/span&gt; からシステムの安定性を判定する事を考える。 入力 &lt;span class="math"&gt;\(x(t)\)&lt;/span&gt; 、 出力 &lt;span class="math"&gt;\(y(t)\)&lt;/span&gt; それぞれのラプラス変換の結果を &lt;span class="math"&gt;\(\mathcal{L}[x(t)] = X(s)\)&lt;/span&gt; 、 &lt;span class="math"&gt;\({\cal L}[y(t)] = Y(s)\)&lt;/span&gt; とした時、 伝達関数は &lt;span class="math"&gt;\(s\)&lt;/span&gt; の多項式の比なので、一般に次の形で表せる :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
G(s)
&amp;amp;= \frac{Y(s)}{X(s)} = \frac{b_{m}s^{m} + b_{m-1}s^{m-1} + \dots + b_{1}s + b_{0}}{s^{n} + a_{n-1}s^{n-1} + \dots + a_{1}s + a_{0}} \\
&amp;amp;= \frac{b_{m}(s-z_{1})(s-z_{2})\dots(s-z_{m})}{(s-p_{1})(s-p_{2})\dots(s-p_{n})}
\end{align*}
&lt;/div&gt;
&lt;p&gt;（現実には &lt;span class="math"&gt;\(n \geq m\)&lt;/span&gt; であることが多く、 その場合 &lt;strong&gt;プロパー&lt;/strong&gt; であると呼ばれる）。 ここで、 &lt;span class="math"&gt;\(Y(s) = 0\)&lt;/span&gt; の根 &lt;span class="math"&gt;\(z_{1}, \dots, z_{m}\)&lt;/span&gt; をこのシステムの零点 (zero)、 &lt;span class="math"&gt;\(X(s)=0\)&lt;/span&gt; の根 &lt;span class="math"&gt;\(p_{1}、\dots、p_{n}\)&lt;/span&gt; をこのシステムの極 (pole) と呼ぶ &lt;a class="footnote-reference" href="#aboutsystemcharapoly" id="id42"&gt;[6]&lt;/a&gt; 。&lt;/p&gt;
&lt;table class="docutils footnote" frame="void" id="aboutsystemcharapoly" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id42"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;span class="math"&gt;\(X(s)\)&lt;/span&gt; 自身をそのシステムの特性多項式 (characteristic polynominal)、 また &lt;span class="math"&gt;\(X(s)=0\)&lt;/span&gt; を特性方程式 (characteristic equation) と呼ぶ&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;安定性の判定の為入力を単位ステップ関数とすると、 出力のラプラス変換 &lt;span class="math"&gt;\(Y(s)\)&lt;/span&gt; は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
Y(s) = G(s)X(s) = G(s)\frac{1}{s} = \frac{b_{m}(s-z_{1})(s-z_{2})\dots(s-z_{m})}{s(s-p_{1})(s-p_{2})\dots(s-p_{n})}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となり、 この式を部分分数分解すると、 一般に&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
Y(s) = \frac{A}{s} + \sum_{k=1}^{n} \frac{B_{k}}{s-p_{k}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表わすことができ（&lt;span class="math"&gt;\(A、 B_{k}\)&lt;/span&gt; : 係数）、 これを両辺ラプラス逆変換することで、 出力の一般解&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
y(t) = A + \sum_{k=1}^{n} B_{k} \exp(p_{k}t)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を得る。 更に &lt;span class="math"&gt;\(p_{k}\)&lt;/span&gt; は一般に複素数なので、 実数係数 &lt;span class="math"&gt;\(\sigma_{k}, \omega_{k}\)&lt;/span&gt; を用いて &lt;span class="math"&gt;\(p_{k} = \sigma_{k} + j \omega_{k}\)&lt;/span&gt; と表し &lt;span class="math"&gt;\(y(t)\)&lt;/span&gt; を変形すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
y(t)
&amp;amp;= A + \sum_{k=1}^{n} B_{k} \exp[(\sigma_{k} + j \omega_{k})t] \\
&amp;amp;= A + \sum_{k=1}^{n} B_{k} \exp(\sigma_{k}t) (\cos\omega_{k}t + j\sin\omega_{k}t) \quad （\because オイラーの公式）
\end{align*}
&lt;/div&gt;
&lt;p&gt;となる。 今、 ある &lt;span class="math"&gt;\(\sigma_{i}\ (i=1, \dots, n)\)&lt;/span&gt; が一つでも正ならば、 時間の極限 &lt;span class="math"&gt;\(t\to \infty\)&lt;/span&gt; をとると &lt;span class="math"&gt;\(y(t)\)&lt;/span&gt; は発散してしまい、 システムが不安定となることが分かる。
従って &lt;strong&gt;システムが安定となる為には全ての極の実数部が負&lt;/strong&gt; （&lt;span class="math"&gt;\({}^{\forall} k. \sigma_{k} &amp;lt; 0\)&lt;/span&gt; ） &lt;strong&gt;となる事が必要十分&lt;/strong&gt; であることが分かる。この時は特に &lt;span class="math"&gt;\(y(t)\)&lt;/span&gt; は &lt;span class="math"&gt;\(A\)&lt;/span&gt; に収束する（&lt;span class="math"&gt;\(\displaystyle\lim_{t \to \infty} y(t) = A\)&lt;/span&gt; ）ので、 システムは &lt;strong&gt;漸近安定&lt;/strong&gt; であると言う。&lt;/p&gt;
&lt;p&gt;伝達関数に基づくシステムの安定性解析は、 本質的には以上の様に極の実部を調べることにより行われる。 しかし実際複雑な（&lt;span class="math"&gt;\(n, m\)&lt;/span&gt; が大きい）システムでは方程式を解き極を計算するのが困難となるので、 方程式を解かずともシステムの安定 / 不安定を判別する手法が存在する &lt;a class="footnote-reference" href="#aboutstatibilitycheck" id="id43"&gt;[7]&lt;/a&gt; 。&lt;/p&gt;
&lt;table class="docutils footnote" frame="void" id="aboutstatibilitycheck" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id43"&gt;[7]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;伝達関数の係数から判定する手法として、 ラウスの安定判別法や、 フルビッツの安定判別法がある&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id44"&gt;
&lt;h3&gt;ギブス現象&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;ギブス現象 (Gibbs phenomenon)&lt;/strong&gt; とは、 不連続な点を含む周期関数のフーリエ級数近似において、 不連続点付近では級数和の絶対値が原関数のとる値の絶対値よりも大きくなってしまう現象のことである。 その原因は、 不連続な関数を連続な関数基底で近似してしまう事による。&lt;/p&gt;
&lt;p&gt;ギブス現象の例を数式で観察してみる。 今、不連続点を含む、区分的に連続微分可能な周期 &lt;span class="math"&gt;\(T\)&lt;/span&gt; の実関数 &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; を考える。 その &lt;span class="math"&gt;\(N\)&lt;/span&gt; 次までの複素フーリエ級数近似 &lt;span class="math"&gt;\(S_{N}(x)\)&lt;/span&gt; は :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
S_{N}(x)
&amp;amp;= \sum^{N}_{n = -N} c_{n} \exp(jn\omega_{0}x)\quad (\omega_{0} = \frac{2\pi}{T}) \\
c_{n}
&amp;amp;= \frac{1}{T} \int^{T/2}_{-T/2} f(t)\exp(-jn\omega_{0}t) {\rm dt}
\end{align*}
&lt;/div&gt;
&lt;p&gt;となる。 ところで、 ギブス現象は不連続点付近で &lt;span class="math"&gt;\(S_{N}(x)\)&lt;/span&gt; が飛び出る事によって認知される。 &lt;span class="math"&gt;\(S_{N}(x)\)&lt;/span&gt; が三角関数の和で表現されている事に注目すると、 その飛び出た点は、&lt;span class="math"&gt;\(S_{N}(x)\)&lt;/span&gt; の極値であると捉える事ができる。 従って、 &lt;span class="math"&gt;\(S_{N}(x)\)&lt;/span&gt; を &lt;span class="math"&gt;\(x\)&lt;/span&gt; によって微分すると :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ddiff{}{x}S_{N}(x)
&amp;amp;= \sum_{n = -N}^{N} c_{n} \ddiff{}{x}\exp(jn\omega_{0}x) \quad (\because 項別微分 ) \\
&amp;amp;= j \omega_{0} \sum^{N}_{n = -N} n c_{n} \exp(jn\omega_{0}x) \\
&amp;amp;= j \omega_{0} \sum^{N}_{n = -N} n c_{n} \left\{ \cos(n\omega_{0}x) + j \sin(n\omega_{0}x) \right\} \quad (\because オイラーの公式 ) \\
&amp;amp;= j \omega_{0} \sum^{N}_{n = -N} n c_{n} \cos(n\omega_{0}x) - \omega_{0} \sum^{N}_{n = -N} n c_{n} \sin(n\omega_{0}x)
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(c_{n}\)&lt;/span&gt; の実部を &lt;span class="math"&gt;\({\rm Re}[c_{n}]\)&lt;/span&gt; 、 虚部を &lt;span class="math"&gt;\({\rm Im}[c_{n}]\)&lt;/span&gt; と表すと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ddiff{}{x}S_{N}(x)
&amp;amp;= - \omega_{0} \left[ \sum^{N}_{n = -N} n \left\{ {\rm Im}[c_{n}]\cos(n\omega_{0}x) + {\rm Re}[c_{n}]\sin(n\omega_{0}x) \right\} \right. \\
\ &amp;amp; \quad - \left. j \sum^{N}_{n = -N} n \left\{ {\rm Re}[c_{n}]\cos(n\omega_{0}x) + {\rm Im}[c_{n}]\sin(n\omega_{0}x) \right\} \right]
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで、 &lt;span class="math"&gt;\(c_{-n} = c_{n}^{\ast}\)&lt;/span&gt; (&lt;span class="math"&gt;\(c_{n}\)&lt;/span&gt; の複素共役 ) を用いると、 &lt;span class="math"&gt;\({\rm Im}[c_{-n}] = -{\rm Im}[c_{n}]\)&lt;/span&gt; 、 &lt;span class="math"&gt;\({\rm Re}[c_{-n}] = {\rm Re}[c_{n}]\)&lt;/span&gt; であることより、 以下の様に、 虚部を含まない形に整理できる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\ddiff{}{x}S_{N}(x)
&amp;amp;= - \omega_{0} \left[ \sum^{N}_{n = 1} n \left\{ {\rm Im}[c_{n}]\cos(n\omega_{0}x) + {\rm Re}[c_{n}]\sin(n\omega_{0}x) \right\} \right. \\
\ &amp;amp; \quad + \sum^{N}_{k = 1} (-k) \left\{ {\rm Im}[c_{-k}]\cos(k\omega_{0}x) - {\rm Re}[c_{-k}]\sin(k\omega_{0}x) \right\} \\
\ &amp;amp; \quad - j \sum^{N}_{n = 1} n    \left\{ {\rm Re}[c_{n}]\cos(n\omega_{0}x) - {\rm Im}[c_{n}]\sin(n\omega_{0}x) \right\} \\
\ &amp;amp; \quad - j \left. \sum^{N}_{k = 1} (-k) \left\{ {\rm Re}[c_{-k}]\cos(k\omega_{0}x) + {\rm Im}[c_{-k}]\sin(k\omega_{0}x) \right\} \right] \\
&amp;amp;= -2\omega_{0} \sum^{N}_{n=1} n \left\{ {\rm Im}[c_{n}]\cos(n\omega_{0}x) + {\rm Re}[c_{n}]\sin(n\omega_{0}x) \right\}
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\displaystyle\ddiff{}{x}S_{N}(x)\)&lt;/span&gt; を &lt;span class="math"&gt;\(0\)&lt;/span&gt; とおくと、 &lt;span class="math"&gt;\(n &amp;gt; 0\)&lt;/span&gt; より、 極値条件の一つとして&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
{\rm Im}[c_{n}]\cos(n\omega_{0}x) + {\rm Re}[c_{n}]\sin(n\omega_{0}x) = 0 \quad (n = 1, \cdots, N)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;があり、 これを &lt;span class="math"&gt;\(x\)&lt;/span&gt; について解くと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
x = -\frac{1}{n\omega_{0}} \tan^{-1}\left( \frac{ {\rm Im}[c_{n}] }{ {\rm Re}[c_{n}] } \right) \quad (n = 1, \cdots, N)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が得られる。&lt;/p&gt;
&lt;p&gt;ギブス現象の例として、 今、&lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; として周期 &lt;span class="math"&gt;\(2\pi\)&lt;/span&gt; の矩形波を仮定する :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f(t) =
\left\{
  \begin{array}{ll}
    1  &amp;amp; (0 \leq x &amp;lt; \pi) \\
    -1 &amp;amp; (\pi \leq x &amp;lt; 2\pi)
  \end{array}
\right.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;定義のとおり、&lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; は奇関数であるため &lt;span class="math"&gt;\({\rm Re}[c_{n}] = 0\)&lt;/span&gt; であり、 また &lt;span class="math"&gt;\({\rm Im}[c_{n}]\)&lt;/span&gt; は :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
{\rm Im}[c_{n}]
&amp;amp;= - \frac{1}{2\pi} \int^{\pi}_{-\pi} f(t) \sin(nt) {\rm dt} \quad (\omega_{0} = \frac{2\pi}{2\pi} = 1) \\
&amp;amp;= \frac{1}{n\pi} \left[ \cos(nx) \right]^{\pi}_{0} = - \frac{1}{n\pi} \left\{ 1 - (-1)^{n} \right\}
\end{align*}
&lt;/div&gt;
&lt;p&gt;この結果より &lt;span class="math"&gt;\(\tan^{-1}({\rm Im}[c_{n}]/{\rm Re}[c_{n}])\)&lt;/span&gt; を考えると、 &lt;span class="math"&gt;\({\rm Im}[c_{n}]/{\rm Re}[c_{n}] \to -\infty\)&lt;/span&gt; より、 極値条件は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
x = - \frac{1}{n} \left( - \frac{\pi}{2} \right) = \frac{\pi}{2n} \quad (n = 1、\cdots、N)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となる。 この結果を用いて、 不連続点 &lt;span class="math"&gt;\(x = 0\)&lt;/span&gt; における近似 &lt;span class="math"&gt;\(S_{N}(x)\)&lt;/span&gt; の値を計算する事を考える。 &lt;span class="math"&gt;\(x = 0\)&lt;/span&gt; に最も近い極値を与える &lt;span class="math"&gt;\(x\)&lt;/span&gt; の値は、 &lt;span class="math"&gt;\(n = N\)&lt;/span&gt; の時、 即ち &lt;span class="math"&gt;\(x = \displaystyle\frac{\pi}{2N}\)&lt;/span&gt; となるので、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
S_{N}\left(\frac{\pi}{2N}\right)
&amp;amp;= \sum_{n = -N}^{N} c_{n} \exp\left(j\frac{n\pi}{2N}\right) \\
&amp;amp;= \frac{2}{\pi} \sum_{n = 1}^{N} \frac{1}{n} \{ 1 - (-1)^{n} \} \sin\left(\frac{n\pi}{2N}\right) \\
&amp;amp;= \frac{4}{\pi} \sum_{k = 1}^{N} \frac{1}{2k-1} \sin\left(\frac{2k-1}{2N}\pi \right) \quad(n = 2k - 1) \\
&amp;amp;= \frac{2}{\pi} \frac{\pi}{N} \sum_{k = 1}^{N} \frac{1}{\frac{2k-1}{2N}\pi} \sin\left(\frac{2k-1}{2N}\pi \right)
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで区分求積法を用いる。 分割幅 &lt;span class="math"&gt;\(|\Delta|\)&lt;/span&gt; を &lt;span class="math"&gt;\(\displaystyle\frac{\pi}{N}\)&lt;/span&gt; とすると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
S_{N}\left(\frac{\pi}{2N}\right)
&amp;amp;= \frac{2}{\pi} |\Delta| \sum_{k=1}^{N}\frac{1}{\frac{2k-1}{2}|\Delta|}\sin\left(\frac{2k-1}{2}|\Delta|\right) \\
\therefore \lim_{N\to \infty} S_{N}\left( \frac{\pi}{2N} \right)
&amp;amp;= \frac{2}{\pi} \int^{\pi}_{0} \frac{\sin(y)}{y} {\rm dy} \approx 1.17834\cdots
\end{align*}
&lt;/div&gt;
&lt;p&gt;従って、 &lt;span class="math"&gt;\(N\)&lt;/span&gt; の極限をとっても目標値 &lt;span class="math"&gt;\(1\)&lt;/span&gt; に収束できない事が確認できた。  ここで、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\int^{\pi}_{0} \frac{\sin(y)}{y} {\rm dy} = 1.851937052\cdots
\end{equation*}
&lt;/div&gt;
&lt;p&gt;の結果はギブス定数を用いている。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id45"&gt;
&lt;h3&gt;エイリアシング（折り返し歪み）&lt;/h3&gt;
&lt;p&gt;エイリアシングは、 連続値（アナログ）信号を PC で扱うために離散（デジタル）化する A/D 変換を行った際や、 デジタル化した画像に縮小処理などのフィルターに掛けた際に発生しうる現象であり、
本来音声や画像には見られなかった干渉縞（偽解像、 モアレ）が発生してしまう。&lt;/p&gt;
&lt;p&gt;この現象は、 A/D 変換においては標本化（サンプリング）の周波数設定、 フィルター処理においてはフィルターそのものが原因である。&lt;/p&gt;
&lt;p&gt;A/D 変換におけるエイリアシングの発生の概要を見ていく。 そもそも標本化とは、 連続値信号 &lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; をある間隔（サンプリング周期） &lt;span class="math"&gt;\(T\)&lt;/span&gt; での（ディラック）インパルス関数で表現する事を指す（ &lt;a class="reference internal" href="#id46"&gt;図 1&lt;/a&gt; ）。&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="sampling.png" id="id46" src="images/sampling.png" /&gt;
&lt;p class="caption"&gt;周期インパルス関数による標本化&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;インパルス関数 &lt;span class="math"&gt;\(\delta(t)\)&lt;/span&gt; は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\int^{\infty}_{-\infty} f(t)\delta(t) {\rm dt} = f(0)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たす超関数であり、 標本化信号 &lt;span class="math"&gt;\(g(t)\)&lt;/span&gt; は、 &lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; とインパルス関数を周期 &lt;span class="math"&gt;\(T\)&lt;/span&gt; で並べた周期的デルタ関数 &lt;span class="math"&gt;\(\delta_{T}(t)\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\delta_{T}(t) = \sum^{\infty}_{n = -\infty} \delta(t - nT)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;との積で表現できる :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
g(t) = f(t)\delta_{T}(t) = \sum^{\infty}_{n=-\infty}f(t)\delta(t-nT)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;数値計算上、 和の無限は扱うことができないので、 ここで信号 &lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; は、 標本化する区間で周期性を持つと仮定する。 ここでは、 &lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; はサンプリング間隔の &lt;span class="math"&gt;\(N\)&lt;/span&gt; 倍の周期 &lt;span class="math"&gt;\(NT\)&lt;/span&gt; を持つとする :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
g(t) = \sum^{N-1}_{n=0}f(t)\delta(t-nT)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;その仮定の基で、 標本化信号 &lt;span class="math"&gt;\(g(t)\)&lt;/span&gt; のフーリエ変換 &lt;span class="math"&gt;\(\mathcal{F}[g(t)]\)&lt;/span&gt; を求めると :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\mathcal{F}[g(t)]
&amp;amp;= \int^{\infty}_{-\infty} f(t) \delta_{T}(t) \exp(-j\omega t) {\rm dt} \\
&amp;amp;= \sum^{N-1}_{n = 0} \int^{\infty}_{-\infty} f(t)\delta(t - nT) \exp(-j\omega t) {\rm dt} \\
&amp;amp;= \sum^{N-1}_{n = 0} f(nT) \exp(-jn\omega T)
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで $j$ は虚数単位、 &lt;span class="math"&gt;\(\omega\)&lt;/span&gt; は角周波数であり、 この式は離散フーリエ変換 (DFT) の式に他ならない。&lt;/p&gt;
&lt;p&gt;また、 &lt;span class="math"&gt;\(g(t)\)&lt;/span&gt; の周波数特性を見やすくするために、 &lt;span class="math"&gt;\(\delta_{T}(t)\)&lt;/span&gt; をフーリエ級数展開する。 &lt;span class="math"&gt;\(\delta_{T}(t)\)&lt;/span&gt; の複素フーリエ級数展開の式は :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\delta_{T}(t)
&amp;amp;= \sum^{\infty}_{n = -\infty} c_{n} \exp(jn\omega_{0}t) \quad (\omega_{0} = \frac{2\pi}{T}) \\
c_{n}
&amp;amp;= \frac{1}{T} \int^{T/2}_{-T/2} \delta_{T}(t)\exp(-jn\omega_{0}t) {\rm dt}
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(c_{n}\)&lt;/span&gt; を計算するとき、 積分範囲には唯一つのインパルスが存在する事に留意すると、 次のようになる :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
c_{n}
&amp;amp;= \frac{1}{T} \int^{T/2}_{-T/2} \delta(t)\exp(-jn\omega_{0}t) {\rm dt} \\
&amp;amp;= \frac{1}{T} \exp(0) = \frac{1}{T} \\
\therefore \delta_{T}(t) &amp;amp;=
\frac{1}{T} \sum^{\infty}_{n = -\infty} \exp(jn\omega_{0} t)
\end{align*}
&lt;/div&gt;
&lt;p&gt;この結果から &lt;span class="math"&gt;\(g(t)\)&lt;/span&gt; の周波数特性を計算する。 &lt;span class="math"&gt;\(\mathcal{F}[f(t)] = F(\omega)\)&lt;/span&gt; と書くと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\mathcal{F}[g(t)]
&amp;amp;= \mathcal{F}[f(t) \frac{1}{T} \sum^{\infty}_{n = -\infty} \exp(jn\omega_{0} t)] \\
&amp;amp;= \frac{1}{T} \sum^{\infty}_{n = -\infty} \mathcal{F}[f(t)\exp(jn\omega_{0}t)] \quad (\because フーリエ変換の線形性 ) \\
&amp;amp;= \frac{1}{T} \sum^{\infty}_{n = -\infty} \int^{\infty}_{-\infty} f(t) \exp\left[ -j(\omega - n\omega_{0})t \right] {\rm dt} \\
&amp;amp;= \frac{1}{T} \sum^{\infty}_{n = -\infty} F(\omega - n\omega_{0})
\end{align*}
&lt;/div&gt;
&lt;p&gt;従って、 &lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; の周波数特性 &lt;span class="math"&gt;\(F(\omega)\)&lt;/span&gt; を &lt;span class="math"&gt;\(\omega_{0}\)&lt;/span&gt; ずつずらして和をとったものとなる。 典型的な信号の周波数は高周波成分になるに従って振幅（パワー、 ゲイン）が減衰する事が知られているので、 原信号と離散化信号の周波数スペクトル &lt;span class="math"&gt;\(|F(\omega)|\)&lt;/span&gt; の概要図は &lt;a class="reference internal" href="#id47"&gt;図 2&lt;/a&gt; のようになる。&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="tenkei_spectral.png" id="id47" src="images/tenkei_spectral.png" /&gt;
&lt;p class="caption"&gt;典型的な信号のスペクトルの例&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(|F(\omega)|\)&lt;/span&gt; は明らかに偶関数であり、 この時、 &lt;span class="math"&gt;\(|{\cal F}[g(t)]|\)&lt;/span&gt; のある山 &lt;span class="math"&gt;\(|F(\omega - i\omega_{0})|(i \in \mathbb{Z})\)&lt;/span&gt; において、 隣の山 &lt;span class="math"&gt;\(|F(\omega - (i \pm 1) \omega_{0})|\)&lt;/span&gt; と交差する周波数は &lt;span class="math"&gt;\(\displaystyle \frac{\omega_{0}}{2}k (k: 奇数 )\)&lt;/span&gt; となる。&lt;/p&gt;
&lt;p&gt;すると、 &lt;span class="math"&gt;\(|{\cal F}[g(t)]|\)&lt;/span&gt; はそれらの山の和を取るので、 結果 &lt;span class="math"&gt;\(\displaystyle \frac{\omega_{0}}{2}k \pm \beta\)&lt;/span&gt; の周波数成分のパワーが隣の山のスペクトルと区別できなくなってしまう（ &lt;a class="reference internal" href="#id48"&gt;図 3&lt;/a&gt; ）。 特に、原信号 &lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; では弱かった高周波成分のスペクトルが強調されてしまい、 離散化後の信号においてそれが干渉縞等によって現れてしまう。 この現象をエイリアシングと呼ぶ。&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="aliasing_occur.png" id="id48" src="images/aliasing_occur.png" /&gt;
&lt;p class="caption"&gt;エイリアシングが発生してしまうサンプリングの例&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;エイリアシングを防ぐには、原理的には、原信号 &lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; の周波数 &lt;span class="math"&gt;\(\omega_{f} = \displaystyle\frac{2\pi}{NT}\)&lt;/span&gt; の 2 倍以上の周波数成分をローパスフィルターなどでカットし、かつ、サンプリング周波数を &lt;span class="math"&gt;\(2\omega_{f}\)&lt;/span&gt; （ナイキストレート）より大きくとれば良い（ &lt;a class="reference internal" href="#id49"&gt;図 4&lt;/a&gt; ）&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="escape_aliasing.png" id="id49" src="images/escape_aliasing.png" /&gt;
&lt;p class="caption"&gt;エイリアシングを回避したサンプリングの例&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id50"&gt;
&lt;h3&gt;信号の復元&lt;/h3&gt;
&lt;p&gt;フーリエ変換対の結果から、標本化した波形をアナログ信号に一意に復元する結果が得られる。
改めてフーリエ逆変換の結果&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f(t) = \frac{1}{2\pi} \int^{\infty}_{-\infty} F(\omega) \exp(j\omega t) d\omega
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を眺め、その意味をもう一度立ち戻って考えてみると、これは無限の周波数帯域を使用して信号を復元している式にも見える。
この式をサンプリング周波数で帯域制限して信号を復元する事を考えることで、標本化した信号をアナログ信号に復元する式が得られる。&lt;/p&gt;
&lt;p&gt;まず フーリエ変換の結果 &lt;span class="math"&gt;\(F(\omega)\)&lt;/span&gt; を標本化信号によって表すことを考える。区分求積法の援用により、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
F(\omega) &amp;amp;= \int^{\infty}_{-\infty} f(t) \exp(-j\omega t) dt \\
&amp;amp;= \lim_{f_{s} \to \infty} \sum_{n=-\infty}^{\infty} \frac{1}{f_{s}} f\left(\frac{n}{f_{s}}\right) \exp\left(-j\omega\frac{n}{f_{s}}\right)
\end{align*}
&lt;/div&gt;
&lt;p&gt;と形式的に表すことが出来る。ここで、&lt;span class="math"&gt;\(f_{s}\)&lt;/span&gt; はサンプリング周波数（サンプリングレート）である。この結果をフーリエ逆変換の式に代入すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
f(t) &amp;amp;= \frac{1}{2\pi} \int^{\infty}_{-\infty} F(\omega) \exp(j\omega t) d\omega \\
&amp;amp;= \frac{1}{2\pi} \int^{\infty}_{-\infty} \left\{ \lim_{f_{s} \to \infty} \sum_{n=-\infty}^{\infty} \frac{1}{f_{s}} f\left(\frac{n}{f_{s}}\right) \exp\left(-j\omega\frac{n}{f_{s}}\right) \right\} \exp(j\omega t) d\omega \\
&amp;amp;= \frac{1}{2\pi} \lim_{f_{s} \to \infty} \sum_{n=-\infty}^{\infty} \frac{1}{f_{s}} f\left(\frac{n}{f_{s}}\right) \int^{\infty}_{-\infty} \exp\left[j\omega \left( t - \frac{n}{f_{s}} \right) \right] d\omega
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで、最後の式変形の所で積分演算の線形性を用いて、和の順序を交換している。得られた最後の結果の積分&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\int^{\infty}_{-\infty} \exp\left[j\omega \left( t - \frac{n}{f_{s}} \right) \right] d\omega
\end{equation*}
&lt;/div&gt;
&lt;p&gt;に注目する。積分範囲 &lt;span class="math"&gt;\([-\infty, \infty]\)&lt;/span&gt; は無限になっているが、実際に得られるスペクトルは、標本化の結果 &lt;span class="math"&gt;\([-\omega_{0}/2, \omega_{0}/2]\)&lt;/span&gt; の範囲に制限されていなければならない。従って、帯域制限を加味して積分を計算すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\int^{\omega_{0}/2}_{-\omega_{0}/2} \exp\left[j\omega \left( t - \frac{n}{f_{s}} \right) \right] d\omega &amp;amp;= \frac{1}{j\left( t - \frac{n}{f_{s}} \right)} \left[ \exp \left\{ j\omega\left( t - \frac{n}{f_{s}} \right) \right\} \right]^{\omega_{0}/2}_{-\omega_{0}/2} \\
&amp;amp;= \frac{1}{j\left( t - \frac{n}{f_{s}} \right)} \left[ \exp \left\{ j\frac{\omega_{0}}{2} \left( t - \frac{n}{f_{s}} \right) \right\} - \exp \left\{ -j\frac{\omega_{0}}{2} \left( t - \frac{n}{f_{s}} \right) \right\} \right] \\
&amp;amp;= \frac{1}{j\left( t - \frac{n}{f_{s}} \right)} j2 \sin \left[ \frac{\omega_{0}}{2} \left( t - \frac{n}{f_{s}} \right) \right] = \frac{2 \sin \left[ \pi f_{s} \left( t - \frac{n}{f_{s}} \right) \right]}{t - \frac{n}{f_{s}}}
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで、最後の式変形の所でオイラーの公式&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\exp(jx) - \exp(-jx) = \cos(x) + j\sin(x) - \left\{ \cos(x) - j\sin(x) \right\} = j2\sin(x)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を用いている。続けて、帯域制限を加味した積分結果を代入する。 極限 &lt;span class="math"&gt;\(\displaystyle\lim_{f_{s} \to \infty}\)&lt;/span&gt; は帯域制限の結果考慮する必要が無くなる事に留意すると、&lt;/p&gt;
&lt;div class="math" id="id51"&gt;
\begin{align*}
f(t) &amp;amp;= \frac{1}{2\pi} \sum_{n=-\infty}^{\infty} \frac{1}{f_{s}} f\left(\frac{n}{f_{s}}\right) \frac{2 \sin \left[ \pi f_{s} \left( t - \frac{n}{f_{s}} \right) \right]}{t - \frac{n}{f_{s}}} \\
&amp;amp;= \sum_{n=-\infty}^{\infty} f\left(\frac{n}{f_{s}}\right) \frac{\sin \left[ \pi f_{s} \left( t - \frac{n}{f_{s}} \right) \right]}{ \pi f_{s} \left( t - \frac{n}{f_{s}} \right)} \\
&amp;amp;= \sum_{n=-\infty}^{\infty} f\left(\frac{n}{f_{s}}\right) \mathrm{sinc} \left[ f_{s} \left( t - \frac{n}{f_{s}} \right) \right] \tag{17}
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\mathrm{sinc}(x) = \frac{\sin(\pi x)}{\pi x}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;は &lt;strong&gt;シンク関数 (Sinc function)&lt;/strong&gt; と呼ばれる。シンク関数の概形は次のようになっており、 &lt;span class="math"&gt;\(x=0\)&lt;/span&gt; で最大値 &lt;span class="math"&gt;\(1\)&lt;/span&gt; をとる（ &lt;span class="math"&gt;\(\because\)&lt;/span&gt; ロピタルの定理より、 &lt;span class="math"&gt;\(\displaystyle \lim_{x \to 0} \frac{\sin(\pi x)}{\pi x} = \lim_{x \to 0} \frac{\frac{d \sin(\pi x)}{dx}}{\frac{d \pi x}{dx}} = \lim_{x \to 0} \frac{\pi \cos(\pi x)}{\pi} = 1\)&lt;/span&gt; ）。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference internal" href="#id51"&gt;式 17&lt;/a&gt; の結果から、 元のアナログ信号 &lt;span class="math"&gt;\(f(t)\)&lt;/span&gt; はシンク関数の畳み込み演算によって完全に復元される事 &lt;a class="footnote-reference" href="#noteonsignalreconstruction" id="id52"&gt;[8]&lt;/a&gt; が示された。&lt;/p&gt;
&lt;table class="docutils footnote" frame="void" id="noteonsignalreconstruction" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id52"&gt;[8]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;と言っても、無限和 &lt;span class="math"&gt;\(\sum_{n=-\infty}^{\infty}\)&lt;/span&gt; は計算機で計算できないため、現実的には完全な復元は不可能である。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id53"&gt;
&lt;h2&gt;参考文献&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;『フーリエ変換・ FFT 入門』 &lt;a class="reference external" href="http://www.maroon.dti.ne.jp/koten-kairo/works/fft/fft_start.html"&gt;http://www.maroon.dti.ne.jp/koten-kairo/works/fft/fft_start.html&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;この記事は、上記記事の補足に過ぎないと思われる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="記事"></category><category term="ポエム"></category></entry><entry><title>パーセプトロン昔話</title><link href="/paseputoronxi-hua.html" rel="alternate"></link><published>2020-04-23T15:30:00+09:00</published><updated>2020-04-23T15:30:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-23:/paseputoronxi-hua.html</id><summary type="html">&lt;p class="first last"&gt;パーセプトロンについての昔話。形式ニューロンからはじめ、単層パーセプトロンと、逆誤差伝播法による学習まで。&lt;/p&gt;
</summary><content type="html">&lt;p&gt;&lt;strong&gt;ニューラルネットワーク（Neural Network,
以下NN）&lt;/strong&gt;は機械学習の歴史と共に歩んできたと言っても過言ではない.
戦後間もないウィーナーの時代 &lt;a class="footnote-reference" href="#id25" id="id2"&gt;[1]&lt;/a&gt; からモデルが構築され始め,
幾つかの冬の時代（挫折）を超えて,
そして現在流行りのディープラーニング（深層学習）は多層構造のNNによって構成されている.
ここでは, NNの歴史に少しずつ触れながら,
多層パーセプトロンの学習則（逆誤差伝搬）までを解説していく.
本稿は主に &lt;a class="footnote-reference" href="#id26" id="id3"&gt;[2]&lt;/a&gt;, &lt;a class="footnote-reference" href="#id27" id="id4"&gt;[3]&lt;/a&gt; を参照している.&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\newcommand{\bvec}[1]{\boldsymbol{#1}}
\newcommand{\tvec}[1]{\bvec{#1}^{\mathsf{T}}}
\newcommand{\ve}[1]{\bvec{#1}}
\newcommand{\inpro}[2]{{\left\langle #1 , #2 \right\rangle}}
\newcommand{\norm}[1]{{\left\| #1 \right\|}}
\newcommand{\dint}[2]{\int\!\!\!\int_{#1} #2 }
\newcommand{\tint}[2]{\int\!\!\!\int\!\!\!\int_{#1} #2 }
\newcommand{\dif}[3]{\frac{d^{#1}#2}{d #3^{#1}}}
\newcommand{\pard}[3]{\frac{\partial^{#1}#2}{\partial #3^{#1}}}
\newcommand{\difrac}[2]{{\frac{d #1}{d #2}}}
\newcommand{\parfrac}[2]{{\frac{\partial #1}{\partial #2}}}
\newcommand{\tparfrac}[2]{{\tfrac{\partial #1}{\partial #2}}}
\newcommand{\Div}{{\rm div}}
\newcommand{\Rot}{{\rm rot}}
\newcommand{\Curl}{{\rm curl}}
\newcommand{\innprod}[2]{\langle #1, #2 \rangle}
\newcommand{\n}{\ \\}
\newcommand{\cm}{{\  , \ }}
\def\diag{\mathop{\rm diag}\nolimits}
\def\sign{\mathop{\rm sign}\nolimits}
\end{align*}
&lt;/div&gt;
&lt;div class="contents local topic" id="id5"&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id38"&gt;脳機能のモデル化&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id39"&gt;活性化関数の例&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id40"&gt;形式ニューロン&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id41"&gt;単純パーセプトロンと単層パーセプトロン（パーセプトロン）&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id42"&gt;単層パーセプトロンの学習則 - ヘブ則とデルタ則&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id13" id="id43"&gt;ヘブ則&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id18" id="id44"&gt;デルタ則&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id22" id="id45"&gt;多層パーセプトロン&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id24" id="id46"&gt;多層パーセプトロンの学習則 - 逆誤差伝搬法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id38"&gt;脳機能のモデル化&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;NNは脳の神経回路網を数学的なモデルで表現したものである. その為,
理論の出発点は生理学となる. その知識によると,
神経回路の構成要素であるニューロン（神経細胞）はシナプスを介して他の細胞と結合しており,
電気信号によって情報を伝達しあっている.
1つのニューロンは外部からの電気的刺激を受けると膜電位（細胞内外の電位差）を上昇させていき,
刺激の総量がある一定値（閾値）を超えると瞬間的に電位パルス（インパルス,
スパイク）を放出する.
放出したパルスは他のニューロンに影響を与えることができる.
この相互作用を大域的に見ることで脳活動が実現されると考えられている.&lt;/p&gt;
&lt;p&gt;上記の生理学の知見をを事実として受け入れてみると,
次の単純なモデル化が考えられる. 1つのニューロンにおいて,
他のニューロンからの刺激（入力）の総量を&lt;span class="math"&gt;\(u\)&lt;/span&gt;と表し,
その入力を受けて出力を決める&lt;strong&gt;活性化関数（activation
function）&lt;/strong&gt;&lt;span class="math"&gt;\(f\)&lt;/span&gt;をおき, 出力を&lt;span class="math"&gt;\(y = f(u)\)&lt;/span&gt;と表す.
また総入力&lt;span class="math"&gt;\(u\)&lt;/span&gt;は他のニューロンからの刺激の重ねあわせによって決まるので,
単純に入力に重みを掛け合わせ和をとった総量と考えられる. 即ち,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  u = \sum_{i=1}^{n} w_{i}x_{i} + b = \ve{w}^{\mathsf{T}} \ve{x} + b\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表せるものとする. ここで,
&lt;span class="math"&gt;\(\ve{x} = [x_{1},\dots,x_{n}]^{\mathsf{T}}\)&lt;/span&gt;は入力（他のニューロンからの出力）ベクトル,
&lt;span class="math"&gt;\(\ve{w} = [w_{1},\dots,w_{n}]^{\mathsf{T}}\)&lt;/span&gt;は入力の重み（係数）ベクトルであり,
生理学的にはシナプスの結合の強さ（影響の度合い）を表している.
そして&lt;span class="math"&gt;\(-b\)&lt;/span&gt;はニューロン発火の条件を与える&lt;strong&gt;しきい値（bias,
threshold）&lt;/strong&gt;を表している.
以上によってモデル化されるニューロンの機能の単位は図にまとめられ,
&lt;strong&gt;ユニット（unit）&lt;/strong&gt;と呼ばれる &lt;a class="footnote-reference" href="#id28" id="id7"&gt;[4]&lt;/a&gt; .&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="NNを構成する単位：ユニット" src="./images/unit.eps" /&gt;
&lt;p class="caption"&gt;NNを構成する単位：ユニット&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id8"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id39"&gt;活性化関数の例&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;実際に良く使われる活性化関数&lt;span class="math"&gt;\(f\)&lt;/span&gt;としては, 次が挙げられる:&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;単位ステップ関数（ハードリミタ）&lt;span class="math"&gt;\(U(u)\)&lt;/span&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(0\)&lt;/span&gt;か&lt;span class="math"&gt;\(1\)&lt;/span&gt;かを出力し, 決定的な識別を行う:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
      f(u) =
      \left\{ \begin{array}{ll}
        0 &amp;amp; u &amp;lt; 0 \\
        1 &amp;amp; u &amp;gt; 0
      \end{array} \right.
    \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;&lt;span class="math"&gt;\(u=0\)&lt;/span&gt;で不連続となり, &lt;span class="math"&gt;\(U(u)\)&lt;/span&gt;等で参照される事がある.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;符号関数&lt;span class="math"&gt;\(\sign(u)\)&lt;/span&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;二値のみを出力するのは単位ステップ関数と同じだが,
&lt;span class="math"&gt;\(-1\)&lt;/span&gt;か&lt;span class="math"&gt;\(1\)&lt;/span&gt;を出力する:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
      f(u) =
      \left\{ \begin{array}{ll}
        -1 &amp;amp; u &amp;lt; 0 \\
        1  &amp;amp; u &amp;gt; 0
      \end{array} \right.
    \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;単位ステップ関数とは表現を変えたい文脈で用いられる.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;線形関数&lt;span class="math"&gt;\(u\)&lt;/span&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;入力をそのまま出力する線形関数も活性化関数に用いられる事がある:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
      f(u) = u
    \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;入力が有界でない場合出力が発散する場合がある.
線形関数は微分可能なので学習規則の導出の際に役立つ.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;シグモイド（ロジスティック）関数&lt;span class="math"&gt;\(\varphi(u)\)&lt;/span&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;div class="first math"&gt;
\begin{equation*}
\begin{aligned}
      f(u) = \frac{1}{1 + \exp(-u)}
    \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;明らかに&lt;span class="math"&gt;\((0,1)\)&lt;/span&gt;で単調増加する関数である.
グラフが単位ステップ関数に類似し, 関数の形が単純であり,
しかも微分可能である事から非常に重要な関数である. 実際,
&lt;span class="math"&gt;\(u\)&lt;/span&gt;で微分してみると,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
       \difrac{ }{u} f(u) &amp;amp;= - \frac{-\exp(-u)}{\{1+\exp(-u)\}^{2}} = \frac{1}{1 + \exp(-u)}\left( 1 - \frac{1}{1 + \exp(-u)} \right)  \\
       &amp;amp;= f(u) (1-f(u))
     \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;となって微分も簡易に計算できることも高評価の理由である.
シグモイド関数は文献によっては&lt;span class="math"&gt;\(\varphi(u)\)&lt;/span&gt;で参照される事がある.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;&lt;span class="math"&gt;\(\tanh\)&lt;/span&gt;（タンジェントハイパボリック）関数&lt;span class="math"&gt;\(\tanh(u)\)&lt;/span&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;div class="first math"&gt;
\begin{equation*}
\begin{aligned}
      f(u) = \tanh(u) = \frac{\exp(u) - \exp(-u)}{\exp(u) + \exp(-u)}
    \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;これは&lt;span class="math"&gt;\((-1,1)\)&lt;/span&gt;で単調増加する関数であり,
値域を&lt;span class="math"&gt;\((0,1)\)&lt;/span&gt;とする為に&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
      f(u) = \frac{\tanh(u) + 1}{2}
    \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とする場合がある. &lt;span class="math"&gt;\(\tanh\)&lt;/span&gt;の微分値も簡潔に表現できる:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
      \difrac{ }{u} f(u) &amp;amp;= \frac{\{\exp(u)+\exp(-u)\}^{2} - \{\exp(u)-\exp(-u)\}^{2}}{\{\exp(u)+\exp(-u)\}^{2}} \\
      &amp;amp;= 1 - \tanh^{2}(u) = 1 - f^{2}(u)
    \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;また,
上述のシグモイド関数は&lt;span class="math"&gt;\(\tanh\)&lt;/span&gt;を用いて表すこともできる:&lt;/p&gt;
&lt;div class="last math"&gt;
\begin{equation*}
\begin{aligned}
      \frac{1}{1 + \exp(-u)} &amp;amp;= \frac{1}{2} \frac{2 \exp(u/2)}{\exp(u/2) + \exp(-u/2)} \\
      &amp;amp;= \frac{1}{2} \left( \frac{\exp(u/2) + \exp(-u/2)}{\exp(u/2) + \exp(-u/2)} + \frac{\exp(u/2) - \exp(-u/2)}{\exp(u/2) + \exp(-u/2)} \right) \\
      &amp;amp;= \frac{1}{2} (1 + \tanh(u/2))
    \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;図に関数のグラフを示す.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="よく使われる活性化関数のグラフ" src="./images/act_funcs.eps" /&gt;
&lt;p class="caption"&gt;よく使われる活性化関数のグラフ&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id40"&gt;形式ニューロン&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;最初にニューロンをモデル化して研究を行ったのはMcCulloch-Pitts（ウォーレン・マカロック-ウォルター・ピッツ）であり,
彼らは1943年に&lt;strong&gt;形式ニューロン（formal neuron）&lt;/strong&gt;を提案した.
形式ニューロンでは活性化関数は単にステップ関数&lt;span class="math"&gt;\(U(u)\)&lt;/span&gt;となる:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  U(u) =
  \left\{ \begin{array}{ll}
    1 &amp;amp; u &amp;gt; 0 \\
    0 &amp;amp; u &amp;lt; 0
  \end{array} \right.\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;これによって入力および出力は&lt;span class="math"&gt;\(0\)&lt;/span&gt;か&lt;span class="math"&gt;\(1\)&lt;/span&gt;（all-or-none）となる.
形式ニューロンでは, 重みと閾値の組み合わせによって論理素子を実現できる:&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;NOT&lt;/dt&gt;
&lt;dd&gt;&lt;span class="math"&gt;\(U(-x_{1} + 0.5)\)&lt;/span&gt;&lt;/dd&gt;
&lt;dt&gt;AND&lt;/dt&gt;
&lt;dd&gt;&lt;span class="math"&gt;\(U(x_{1} + x_{2} - 1.5)\)&lt;/span&gt;&lt;/dd&gt;
&lt;dt&gt;OR&lt;/dt&gt;
&lt;dd&gt;&lt;span class="math"&gt;\(U(x_{1} + x_{2} - 0.5)\)&lt;/span&gt;&lt;/dd&gt;
&lt;dt&gt;NAND&lt;/dt&gt;
&lt;dd&gt;&lt;span class="math"&gt;\(U(-x_{1} -x_{2} + 1.5)\)&lt;/span&gt;&lt;/dd&gt;
&lt;dt&gt;XOR&lt;/dt&gt;
&lt;dd&gt;&lt;span class="math"&gt;\(U(x_{1} + x_{2} - 2U(x_{1} + x_{2} - 1.5) - 0.5)\)&lt;/span&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;実際に入力値に値を代入して真理値表U 作ると,
ユニットが正しく動作する事を確かめられる.
この素子の組み合わせによって任意の（フリップフロップを含めた）論理回路が実現できるのはもちろんのこと,
形式ニューロンはチューリングマシンと同等の計算能力（チューリング完全）を持つ事が示されている.
形式ニューロンはニューロンの最初のモデルとしてNNの大本の基礎となったが,
現在のNNにあるような学習能力を持ちあわせてはいない. しかし,
重みや閾値を変更することでユニットの動作が変わるという観察から,
それらを能動的に変更することで学習が実現されうるという示唆は既に生まれていたものと考えられる.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id41"&gt;単純パーセプトロンと単層パーセプトロン（パーセプトロン）&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;1957年にRosenblatt（ローゼンブラッド）は形式ニューロンを入力層（Sensory
Layer, S層）, 中間層（Associative Layer, A層）, 出力層（Response Layer,
R層）の3つに分けて階層的に結合し,
図&lt;a class="reference external" href="#fig:simple_perceptron"&gt;1&lt;/a&gt;の構造を持つ&lt;strong&gt;単純パーセプトロン（simple
perceptron）&lt;/strong&gt;を提案した. ここで,
S層とA層の間の重みはランダムに固定し,
A層とR層の間の重みは&lt;strong&gt;学習&lt;/strong&gt;によって決めるようになっている.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="単純パーセプトロン" id="fig-simple-perceptron" src="./images/simple_perceptron.eps" /&gt;
&lt;p class="caption"&gt;単純パーセプトロン&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;単純パーセプトロンの学習は,
微積分といった解析的な知見ではなく&lt;strong&gt;ヘブ則（Hebbian
rule）&lt;/strong&gt;と呼ばれる生理学の法則を用いている.
即ちそれは&lt;strong&gt;「同時に発火したニューロン間のシナプス結合は強められる」&lt;/strong&gt;という法則であり,
多くの神経学者及び心理学者が受け入れている事実である. 後に述べるが,
ヘブ則による学習は解が存在すれば有限回数の学習で正しい解に収束することが示されており,
次節に述べるデルタ則（これは数値解析的に学習する）と併せて有用な学習法と言える.
単純パーセプトロンはNNの学習可能性を初めて示し,
史上初のNN研究ブームを引き起こすきっかけとなった.&lt;/p&gt;
&lt;p&gt;ところで, 単純パーセプトロンは3層の階層構造をなしているが,
重みの学習の際に本質的に関与するのは中間層と出力層の間だけである.
この学習する部分のみを抜き出すと,
図&lt;a class="reference external" href="#fig:single_layer_perceptron"&gt;2&lt;/a&gt;の様に,
学習するニューロンの単純な入出力関係が得られる.
これを&lt;strong&gt;単層パーセプトロン（single-layer
perceptron）&lt;/strong&gt;あるいは単に&lt;strong&gt;パーセプトロン（perceptron）&lt;/strong&gt;と呼ぶ.
そして単純パーセプトロンの学習の際には,
S層とA層間の重みをランダムに決定した後は単層パーセプトロンの学習だけを考えば良い事になる.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="単層パーセプトロン（パーセプトロン）" id="fig-single-layer-perceptron" src="./images/single_layer_perceptron.eps" /&gt;
&lt;p class="caption"&gt;単層パーセプトロン（パーセプトロン）&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id11"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id42"&gt;単層パーセプトロンの学習則 - ヘブ則とデルタ則&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;単層パーセプトロンの学習にはサンプルが必要となるため,
まずはサンプルの表記から行う. 学習の中でも特に教師あり学習（supervised
learning）はサンプルのデータにラベルが付いている.
ラベルは一般的にはなんでも良いが,
基本的にはデータがある性質を満たす場合（正例）はラベルを&lt;span class="math"&gt;\(1\)&lt;/span&gt;に,
満たさない場合（負例）はラベルを&lt;span class="math"&gt;\(-1\)&lt;/span&gt;とする &lt;a class="footnote-reference" href="#id29" id="id12"&gt;[5]&lt;/a&gt; .
そして&lt;span class="math"&gt;\(N\)&lt;/span&gt;個のデータからなるサンプルの集合&lt;span class="math"&gt;\(Z\)&lt;/span&gt;は,
データ&lt;span class="math"&gt;\(\ve{x}\)&lt;/span&gt;とその（教師）ラベル&lt;span class="math"&gt;\(t\)&lt;/span&gt;の組の集合で表される:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  Z = \{ (\ve{x}_{1}, t_{1}), (\ve{x}_{2}, t_{2}), \dots, (\ve{x}_{N}, t_{N}) \}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;以下,
出力層が1つのユニットだけからなる単層パーセプトロン（図式的には図と等価）の学習を考える.
ユニットが複数存在する場合でも出力層の内部でユニットは互いに独立に動作する（&lt;span class="math"&gt;\(\because\)&lt;/span&gt;結合が無いため）ので拡張は容易である.
また, 表記を簡単にするため,
ユニットへの入力&lt;span class="math"&gt;\(u\)&lt;/span&gt;はしきい値&lt;span class="math"&gt;\(b\)&lt;/span&gt;を省き,
重みと入力の内積&lt;span class="math"&gt;\(\ve{w}^{\mathsf{T}}\ve{x}\)&lt;/span&gt;のみで表現する:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  u &amp;amp;= \sum_{i=1}^{n} w_{i} x_{i} + b = \sum_{i=1}^{n+1} w_{i} x_{i} \quad (w_{n+1} = b,\ x_{n+1} = 1) \\
  &amp;amp;\equiv \ve{w}^{\mathsf{T}}\ve{x}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;これは常に&lt;span class="math"&gt;\(1\)&lt;/span&gt;を入力するユニットを仮定し,
その結合重みを&lt;span class="math"&gt;\(b\)&lt;/span&gt;とすることで説明できる.&lt;/p&gt;
&lt;div class="section" id="id13"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id43"&gt;ヘブ則&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;前節で述べたとおり,
ヘブ則は「同時に発火したニューロン間のシナプス結合は強められる」というものであった.
これはラベルを&lt;span class="math"&gt;\(t_{l} \in \{ 1, 0 \}\ (l=1,\dots,N)\)&lt;/span&gt;（正例を1,
負例を0）,
サンプルデータ&lt;span class="math"&gt;\(\ve{x}_{l}\)&lt;/span&gt;を入力した時の出力を&lt;span class="math"&gt;\(y_{l} = U(u_{l}) = U\left( \ve{w}^{\mathsf{T}} \ve{x}_{l}\right)\)&lt;/span&gt;とすれば,
重み（シナプス結合）の更新量&lt;span class="math"&gt;\(\Delta w_{i}\)&lt;/span&gt;は次の様に表せる:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \Delta w_{i} &amp;amp;=
  \left\{ \begin{array}{ll}
    \eta (\ve{x}_{l})_{i} &amp;amp; \text{if}\ t_{l} = y_{l} = 1 \\
    0          &amp;amp; \text{otherwise}
  \end{array} \right. \\
  &amp;amp;= \eta t_{l}y_{l}(\ve{x}_{l})_{i}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで,
&lt;span class="math"&gt;\((\ve{x}_{l})_{i}\)&lt;/span&gt;はベクトル&lt;span class="math"&gt;\(\ve{x}_{l}\)&lt;/span&gt;の第&lt;span class="math"&gt;\(i\)&lt;/span&gt;要素,
&lt;span class="math"&gt;\(\eta &amp;gt; 0\)&lt;/span&gt;は学習の早さを決める係数であり, &lt;strong&gt;学習率（learning
rate）&lt;/strong&gt;と呼ばれる.
学習の際には&lt;span class="math"&gt;\(\ve{w} = \ve{0}\)&lt;/span&gt;で初期化してサンプルを順次入力し,
上の更新量に沿って重みを更新していけば良い.
第&lt;span class="math"&gt;\(s\)&lt;/span&gt;ステップの時の重みベクトルを&lt;span class="math"&gt;\(\ve{w}^{(s)}\)&lt;/span&gt;と表すと,
更新規則は,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \ve{w}^{(s+1)} = \ve{w}^{(s)} + \Delta \ve{w} = \ve{w}^{(s)} + \eta t_{l} y_{l} \ve{x}_{l}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表せる. ここで,
&lt;span class="math"&gt;\(\Delta \ve{w}\)&lt;/span&gt;更新量を並べたベクトル&lt;span class="math"&gt;\(\Delta \ve{w} = [\Delta w_{1},\dots,\Delta w_{n}]^{\mathsf{T}}\)&lt;/span&gt;である.&lt;/p&gt;
&lt;p&gt;素朴なヘブ則の実装では,
上の&lt;span class="math"&gt;\(\Delta w_{i}\)&lt;/span&gt;を観察すれば即座に分かるように,
重みが際限なく大きくなって発散してしまって学習が停止しない場合がある.
従って, 重みの発散を防ぐために重みは抑制する方向に更新するようにとる.
即ち, ラベルを&lt;span class="math"&gt;\(\{ 1, -1 \}\)&lt;/span&gt;,
活性化関数を符号関数&lt;span class="math"&gt;\(\sign\)&lt;/span&gt;とし,
出力&lt;span class="math"&gt;\(y_{l} = \sign(u_{l})\)&lt;/span&gt;とラベル&lt;span class="math"&gt;\(t_{l}\)&lt;/span&gt;が異なる（サンプルを誤識別した）場合にのみ重みを更新する:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \Delta w_{i} &amp;amp;=
  \left\{ \begin{array}{ll}
    -\eta (\ve{x}_{l})_{i} = \eta t_{l}y_{l}(\ve{x}_{l})_{i} &amp;amp; \text{if}\ t_{l} \neq y_{l} \\
    0           &amp;amp; \text{otherwise}
  \end{array} \right.\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;この更新規則もヘブ則と呼ばれる事がある.&lt;/p&gt;
&lt;p&gt;ヘブ則の重要な性質に,
最適な重みが存在するならば有限ステップで学習が停止（サンプルの誤識別がなくなる）する事が示されている.
ここでは,  &lt;a class="footnote-reference" href="#id30" id="id14"&gt;[6]&lt;/a&gt; に従ってその証明を行う. まず,
存在が仮定された最適な重みを&lt;span class="math"&gt;\(\ve{w}^{\ast}\)&lt;/span&gt;と表し,
&lt;span class="math"&gt;\(||\ve{w}^{\ast}||^{2} = \ve{w}^{\ast\mathsf{T}}\ve{w}^{\ast} = \sum_{i=1}^{n} w_{i}^{\ast 2} = 1\)&lt;/span&gt;となる様に正規化しておく &lt;a class="footnote-reference" href="#id31" id="id15"&gt;[7]&lt;/a&gt; .
ここで,
&lt;span class="math"&gt;\(||\ve{v}||\)&lt;/span&gt;はベクトル&lt;span class="math"&gt;\(\ve{v}\)&lt;/span&gt;の2乗ノルムである. また,
&lt;span class="math"&gt;\(\gamma = \displaystyle \min_{l} y_{l} u_{l} = \min_{l} y_{l} \ve{w}^{\ast\mathsf{T}} \ve{x}_{l}\)&lt;/span&gt;なる定数 &lt;a class="footnote-reference" href="#id32" id="id16"&gt;[8]&lt;/a&gt; をおき,
&lt;span class="math"&gt;\(\gamma &amp;gt; 0\)&lt;/span&gt;とする. この時, 更新式により,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  ||\ve{w}^{(s+1)}||^{2} &amp;amp;= \ve{w}^{(s+1)\mathsf{T}} \ve{w}^{(s+1)} \\
  &amp;amp;= (\ve{w}^{(s)} + \Delta \ve{w})^{\mathsf{T}}(\ve{w}^{(s)} + \Delta \ve{w}) \\
  &amp;amp;= (\ve{w}^{(s)} + \eta t_{l} y_{l} \ve{x}_{l})^{\mathsf{T}}(\ve{w}^{(s)} + \eta t_{l} y_{l} \ve{x}_{l}) \\
  &amp;amp;= \ve{w}^{(s)\mathsf{T}} \ve{w}^{(s)} + 2\eta t_{l} y_{l} \ve{w}^{(s)\mathsf{T}} \ve{x}_{l} + \eta^{2} \ve{x}_{l}^{\mathsf{T}}\ve{x}_{l} \quad (\because t_{l}^{2} = y_{l}^{2} = 1) \\
  &amp;amp;\leq ||\ve{w}^{(s)}||^{2} + \eta^{2} ||\ve{x}_{l}||^{2} \quad (\because \eta t_{l} y_{l} (\ve{x}_{l})_{i} = \Delta w_{i} \leq 0)\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が任意の&lt;span class="math"&gt;\(l \in \{ 1,\dots,N \}\)&lt;/span&gt;で成り立つ.
この関係式をステップ毎に繰り返し適用すれば,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  ||\ve{w}^{(s)}||^{2} &amp;amp;\leq ||\ve{w}^{(s-1)}||^{2} + \eta^{2}||\ve{x}_{l^{(s-1)}}||^{2} \\
  &amp;amp;\leq ||\ve{w}^{(s-2)}||^{2} + \eta^{2}(||\ve{x}_{l^{(s-1)}}||^{2} + ||\ve{x}_{l^{(s-2)}}||^{2}) \\
  &amp;amp;\dots \\
  &amp;amp;\leq ||\ve{w}^{(0)}||^{2} + \eta^{2} \sum_{k=0}^{s-1} ||\ve{x}_{l^{(k)}}||^{2} \\
  &amp;amp;\leq s\eta^{2} \max_{l} ||\ve{x}_{l}||^{2} \quad (\because \ve{w}^{(0)} = \ve{0})\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を得る. ここで,
&lt;span class="math"&gt;\(l^{(s)}\)&lt;/span&gt;はステップ&lt;span class="math"&gt;\(s\)&lt;/span&gt;の更新の時に選ばれたサンプルの番号（インデックス）を表している.
また,
全ての&lt;span class="math"&gt;\(\ve{x}_{l}\ (l=1,\dots,N)\)&lt;/span&gt;は現実的に有界（いずれの要素も&lt;span class="math"&gt;\((-\infty, \infty)\)&lt;/span&gt;にある）と考えられるので,
全てのデータを包む事ができる球（超球）の最小の半径を&lt;span class="math"&gt;\(R\)&lt;/span&gt;とおけば,
&lt;span class="math"&gt;\(\displaystyle \max_{l} ||\ve{x}_{l}||^{2} \leq R^{2}\)&lt;/span&gt;が成り立つので,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  ||\ve{w}^{(s)}||^{2} \leq s\eta^{2} \max_{l} ||\ve{x}_{l}||^{2} \leq s \eta^{2} R^{2}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となる. 一方,
&lt;span class="math"&gt;\(\ve{w}^{\ast}\)&lt;/span&gt;と&lt;span class="math"&gt;\(\ve{w}^{(s+1)}\)&lt;/span&gt;の内積をとると,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \ve{w}^{\ast \mathsf{T}} \ve{w}^{(s+1)} &amp;amp;= \ve{w}^{\ast \mathsf{T}} ( \ve{w}^{(s)} + \eta t_{l} y_{l} \ve{x}_{l}) \\
  &amp;amp;= \ve{w}^{\ast \mathsf{T}} \ve{w}^{(s)} + \eta t_{l} y_{l} \ve{w}^{\ast \mathsf{T}} \ve{x}_{l} \\
  &amp;amp;\geq \ve{w}^{\ast \mathsf{T}} \ve{w}^{(s)} + \eta \gamma\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成立し, この関係式もステップ毎に繰り返し適用すると,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \ve{w}^{\ast \mathsf{T}} \ve{w}^{(s)} &amp;amp;\geq \ve{w}^{\ast \mathsf{T}} \ve{w}^{(s-1)} + \eta \gamma \\
  &amp;amp;\geq \ve{w}^{\ast \mathsf{T}} \ve{w}^{(s-2)} + 2\eta \gamma \\
  &amp;amp;\dots \\
  &amp;amp;\geq \ve{w}^{\ast \mathsf{T}} \ve{w}^{(0)} + s\eta \gamma = s\eta \gamma\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を得て, この式の両辺を二乗すると次の結果を得る:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  s^{2} \eta^{2} \gamma^{2} &amp;amp;\leq (\ve{w}^{\ast \mathsf{T}}\ve{w}^{(s)})^{2} \\
  &amp;amp;\leq (\ve{w}^{\ast \mathsf{T}} \ve{w}^{\ast}) (\ve{w}^{(s) \mathsf{T}} \ve{w}^{(s)}) \quad (\because シュワルツの不等式) \\
  &amp;amp;= ||\ve{w}^{\ast}||^{2} ||\ve{w}^{(s)}||^{2} = ||\ve{w}^{(s)}||^{2} \\
  &amp;amp;\leq s\eta^{2}R^{2}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで,
不等式中央の内積&lt;span class="math"&gt;\(\ve{w}^{\ast \mathsf{T}}\ve{w}^{(s)}\)&lt;/span&gt;は最適解&lt;span class="math"&gt;\(\ve{w}^{\ast}\)&lt;/span&gt;と現在の重み&lt;span class="math"&gt;\(\ve{w}^{(s)}\)&lt;/span&gt;との類似度とも捉えられる &lt;a class="footnote-reference" href="#id33" id="id17"&gt;[9]&lt;/a&gt; ので,
この不等式によりステップ数&lt;span class="math"&gt;\(s\)&lt;/span&gt;増加の度に類似度の下限&lt;span class="math"&gt;\(s^{2}\eta^{2}\gamma^{2}\)&lt;/span&gt;が上限&lt;span class="math"&gt;\(s\eta^{2}R^{2}\)&lt;/span&gt;よりも早く増加する事が観察できる.
即ち類似度は単調増加し, 重みは最適解に近づいて行くことが分かる.
またステップ数&lt;span class="math"&gt;\(s\)&lt;/span&gt;について解くと&lt;span class="math"&gt;\(\displaystyle s \leq \frac{R^{2}}{\gamma^{2}}\)&lt;/span&gt;が成立し,
&lt;span class="math"&gt;\(\gamma, R\)&lt;/span&gt;は有限のために&lt;span class="math"&gt;\(s\)&lt;/span&gt;もまた有限となる.
これらの結果により, 有限ステップで&lt;span class="math"&gt;\(\ve{w}^{\ast}\)&lt;/span&gt;が得られ,
学習が停止することが示された.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id18"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id44"&gt;デルタ則&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;デルタ則（デルタルール）は現在の重み&lt;span class="math"&gt;\(\ve{w}\)&lt;/span&gt;でのサンプルによる出力とラベルの誤差（経験誤差）&lt;span class="math"&gt;\(E(\ve{w})\)&lt;/span&gt;を定義し,
&lt;span class="math"&gt;\(E(\ve{w})\)&lt;/span&gt;を極小にする様に重みを更新していく学習則である.
誤差&lt;span class="math"&gt;\(E(\ve{w})\)&lt;/span&gt;の&lt;span class="math"&gt;\(\ve{w}\)&lt;/span&gt;による偏微分&lt;span class="math"&gt;\(\displaystyle\parfrac{E(\ve{w})}{\ve{w}}\)&lt;/span&gt;は勾配,
即ち最も&lt;span class="math"&gt;\(E(\ve{w})\)&lt;/span&gt;の変化する方向（最急勾配）を表すので,
重みの更新量&lt;span class="math"&gt;\(\Delta \ve{w}\)&lt;/span&gt;は学習率&lt;span class="math"&gt;\(\eta &amp;gt; 0\)&lt;/span&gt;を用いて&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \Delta \ve{w} = - \eta \parfrac{E(\ve{w})}{\ve{w}}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とすれば,
更新の度に誤差を最小にする様に重み&lt;span class="math"&gt;\(\ve{w}\)&lt;/span&gt;を更新することができる.
学習の収束は,
&lt;span class="math"&gt;\(\Delta \ve{w}\)&lt;/span&gt;の大きさ（&lt;span class="math"&gt;\(||\Delta \ve{w}||^{2}\)&lt;/span&gt;等）が十分に小さくなった時とすれば良く,
そのときは極小解 &lt;a class="footnote-reference" href="#id34" id="id19"&gt;[10]&lt;/a&gt; が得られている. この手法は&lt;strong&gt;最急勾配法（steepest
gradient method）&lt;/strong&gt;と呼ばれる基本的な数値最適化の手法の一種である.
ここでは, ユニットの活性化関数を単位ステップ関数&lt;span class="math"&gt;\(U(u)\)&lt;/span&gt;,
ラベルを&lt;span class="math"&gt;\(\{ 1, 0 \}\)&lt;/span&gt;として考える.&lt;/p&gt;
&lt;p&gt;さて, 誤差は様々なものが考えられるが, 単純に二乗誤差&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  E(\ve{w}) = \frac{1}{2} \sum_{l=1}^{N} (t_{l} - y_{l})^{2} = \frac{1}{2} \sum_{l=1}^{N} \left\{ t_{l} - U(\ve{w}^{\mathsf{T}}\ve{x}_{l}) \right\}^{2}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とする &lt;a class="footnote-reference" href="#id35" id="id20"&gt;[11]&lt;/a&gt; と, 後に示す様に局所最適解に嵌ってしまう可能性がある. 第一,
単位ステップ関数&lt;span class="math"&gt;\(U(u)\)&lt;/span&gt;はもとより微分可能では無く,
このままでは学習則を導出できない. そこで, まず,
ユニットの活性化関数を一旦微分可能なシグモイド関数&lt;span class="math"&gt;\(\varphi\)&lt;/span&gt;とし,
その出力を&lt;span class="math"&gt;\(y_{l}=1\)&lt;/span&gt;となる確率&lt;span class="math"&gt;\(p(y_{l}=1)\)&lt;/span&gt;として定義する:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  p(y_{l} = 1) = \varphi(u_{l}/T) = \frac{1}{1+\exp(-u_{l}/T)}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで, &lt;span class="math"&gt;\(T \geq 0\)&lt;/span&gt;は温度パラメタと呼ばれ,
図のグラフで見れるように&lt;span class="math"&gt;\(T \to 0\)&lt;/span&gt;とすると単位ステップ関数に漸近することが分かる.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="様々な温度パラメタ\ :math:`T`\ におけるシグモイド関数\ :math:`\varphi(u/T)`\ のグラフ" src="./images/sigmoids.eps" /&gt;
&lt;p class="caption"&gt;様々な温度パラメタ&lt;span class="math"&gt;\(T\)&lt;/span&gt;におけるシグモイド関数&lt;span class="math"&gt;\(\varphi(u/T)\)&lt;/span&gt;のグラフ&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;同時にラベル&lt;span class="math"&gt;\(t_{l}\)&lt;/span&gt;もある確率分布&lt;span class="math"&gt;\(q\)&lt;/span&gt;に従って生成される確率変数と考える事ができ,
&lt;span class="math"&gt;\(t_{l}\)&lt;/span&gt;が&lt;span class="math"&gt;\(1\)&lt;/span&gt;を取る確率は&lt;span class="math"&gt;\(q(t_{l}=1) = t_{l}\)&lt;/span&gt;で定義することができる.
この様に定義した出力とラベルの確率分布&lt;span class="math"&gt;\(q,p\)&lt;/span&gt;間の“違い”を誤差&lt;span class="math"&gt;\(E(\ve{w})\)&lt;/span&gt;とする.
特に機械学習では,
確率分布間の違いを測る尺度として非常に重要な&lt;strong&gt;KLダイバージェンス（Kullback-Leibler
divergence）&lt;/strong&gt;&lt;span class="math"&gt;\(KL(q||p)\)&lt;/span&gt;がある:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  KL(q||p) = \sum_{l=1}^{N} q(t_{l}) \log\left[ \frac{q(t_{l})}{p(t_{l})} \right]\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;すぐに分かるように&lt;span class="math"&gt;\(KL(q||p) = 0\)&lt;/span&gt;となるのは&lt;span class="math"&gt;\(q\)&lt;/span&gt;と&lt;span class="math"&gt;\(p\)&lt;/span&gt;が完全に一致する時（&lt;span class="math"&gt;\(q(t_{l}) = p(t_{l})\ (l=1,\dots,N)\)&lt;/span&gt;）のみである.&lt;/p&gt;
&lt;p&gt;それでは誤差&lt;span class="math"&gt;\(E(\ve{w})\)&lt;/span&gt;をKLダイバージェンスとして,
その&lt;span class="math"&gt;\(\ve{w}\)&lt;/span&gt;による偏微分を計算する事を考える. まず,
&lt;span class="math"&gt;\(KL(q||p)\)&lt;/span&gt;は定義式から次の様に展開できる:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  E(\ve{w}) &amp;amp;= KL(q||p) = \sum_{l=1}^{N} q(t_{l}) \log\left[ \frac{q(t_{l})}{p(t_{l})} \right] \\
  &amp;amp;= \sum_{l=1}^{N} \left\{ q(t_{l}=0) \log\left[ \frac{q(t_{l}=0)}{p(t_{l}=0)} \right] + q(t_{l}=1) \log\left[ \frac{q(t_{l}=1)}{p(t_{l}=1)} \right] \right\} \\
  &amp;amp;= \sum_{l=1}^{N} \left\{ (1-t_{l}) \log\left( \frac{1-t_{l}}{1-\varphi(u_{l}/T)} \right) + t_{l} \log \left( \frac{t_{l}}{\varphi(u_{l}/T)} \right) \right\}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;見通しを良くする為に和の内部を&lt;span class="math"&gt;\(e_{l}(\ve{w})\)&lt;/span&gt;とおき,
&lt;span class="math"&gt;\(e_{l}(\ve{w})\)&lt;/span&gt;を&lt;span class="math"&gt;\(w_{i}\)&lt;/span&gt;で偏微分すると,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \parfrac{}{w_{i}} e_{l}(\ve{w}) &amp;amp;= \parfrac{e_{l}(\ve{w})}{\varphi(u_{l}/T)} \parfrac{\varphi(u_{l}/T)}{w_{i}} \quad (\because 合成関数の微分) \\
  &amp;amp;= \left\{ (1-t_{l})\frac{1}{1-\varphi(u_{l}/T)} - \frac{t_{l}}{\varphi(u_{l}/T)} \right\} \parfrac{\varphi(u_{l}/T)}{u_{l}} \parfrac{u_{l}}{w_{i}} \quad (\because 合成関数の微分) \\
  &amp;amp;= \frac{\varphi(u_{l}/T)(1 - t_{l}) - t_{l} \left\{ 1 - \varphi(u_{l}/T) \right\}}{\varphi(u_{l}/T) \left\{ 1 - \varphi(u_{l}/T) \right\}} \frac{1}{T} \varphi(u_{l}/T) \left\{ 1 - \varphi(u_{l}/T) \right\} (\ve{x}_{l})_{i} \\
  &amp;amp;= \frac{1}{T} \left\{ \varphi(u_{l}/T) - t_{l} \right\} (\ve{x}_{l})_{i}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が得られ, 更新量&lt;span class="math"&gt;\(\Delta \ve{w}\)&lt;/span&gt;は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \Delta \ve{w} &amp;amp;= - \eta \parfrac{E(\ve{w})}{\ve{w}} = - \eta \frac{1}{T} \sum_{l=1}^{N} \parfrac{}{\ve{w}} e_{l}(\ve{w}) \\
  &amp;amp;= - \frac{\eta}{T} \sum_{l=1}^{N}(\varphi(u_{l}/T) - t_{l}) \ve{x}_{l} = - \frac{\eta}{T} \sum_{l=1}^{N} \delta_{l} \ve{x}_{l}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とまとめられる. ここで,
&lt;span class="math"&gt;\(\delta_{l} = \varphi(u_{l}/T) - t_{l}\)&lt;/span&gt;は誤差信号と呼ばれる.
シグモイド関数から単位ステップ関数に戻すために&lt;span class="math"&gt;\(T \to 0\)&lt;/span&gt;とするが,
同時に&lt;span class="math"&gt;\(\eta \to 0\)&lt;/span&gt;として&lt;span class="math"&gt;\((\eta / T) \to \epsilon\)&lt;/span&gt;となる様な&lt;span class="math"&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt;をとって&lt;span class="math"&gt;\(\Delta \ve{w}\)&lt;/span&gt;が発散しないようにすれば,
デルタ則による重みの更新量&lt;span class="math"&gt;\(\Delta \ve{w}\)&lt;/span&gt;は,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \Delta \ve{w} = -\epsilon \sum_{l=1}^{N} \delta_{l} \ve{x}_{l} = \epsilon \sum_{l=1}^{N} \left\{ t_{l} - U(u_{l}) \right\} \ve{x}_{l}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となる. この&lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;も学習率と呼ばれ,
実践においては&lt;span class="math"&gt;\(0.1\)&lt;/span&gt;から&lt;span class="math"&gt;\(0.5\)&lt;/span&gt;あたりに設定される.
この学習則は&lt;span class="math"&gt;\(\sum_{l=1}^{N}\)&lt;/span&gt;の存在により,
全てのサンプルを提示して更新するのでこれを特に一括（斉時）学習（batch
learning）と呼ぶが, 1つのサンプル毎に重みを更新するやり方もある:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \Delta \ve{w} = \epsilon \left\{ t_{l} - U(u_{l}) \right\} \ve{x}_{l}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;これは逐次学習（on-line learning）と呼ばれる.
一般に逐次学習の方が収束が早い事が知られている &lt;a class="footnote-reference" href="#id36" id="id21"&gt;[12]&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;この更新則による学習が局所最適に陥らないことを示す.
&lt;span class="math"&gt;\(\displaystyle\parfrac{e_{l}(\ve{w})}{w_{i}}\)&lt;/span&gt;を更に&lt;span class="math"&gt;\(w_{j}\)&lt;/span&gt;で偏微分し2階の偏導関数を求めると,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \parfrac{ }{w_{j}}\parfrac{e_{l}(\ve{w})}{w_{i}} &amp;amp;= \parfrac{{}^{2} e_{l}(\ve{w})}{w_{i} \partial w_{j}} \\
  &amp;amp;= \frac{1}{T} \parfrac{\varphi(u_{l}/T)}{w_{j}} x_{i} = \frac{1}{T^{2}} \varphi(u_{l}/T) \left\{ 1 - \varphi(u_{l}/T) \right\} (\ve{x}_{l})_{i}(\ve{x}_{l})_{j}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となり,
&lt;span class="math"&gt;\((H)_{ij} = \displaystyle \parfrac{{}^{2} e_{l}(\ve{w})}{w_{i} \partial w_{j}}\)&lt;/span&gt;なる&lt;span class="math"&gt;\(e_{l}(\ve{w})\)&lt;/span&gt;のヘッセ行列（Hessian
matrix）&lt;span class="math"&gt;\(H\)&lt;/span&gt;は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  H = \frac{1}{T^{2}} \varphi(u_{l}/T) \left\{ 1 - \varphi(u_{l}/T) \right\} \ve{x}_{l} \ve{x}_{l}^{\mathsf{T}}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;で計算できる.
明らかに&lt;span class="math"&gt;\(\displaystyle\frac{1}{T^{2}}\varphi(u_{l}/T) \left\{ 1 - \varphi(u_{l}/T) \right\} &amp;gt; 0\)&lt;/span&gt;であり,
行列&lt;span class="math"&gt;\(\ve{x}_{l}\ve{x}_{l}^{\mathsf{T}}\)&lt;/span&gt;は任意のベクトル&lt;span class="math"&gt;\(\ve{v}\)&lt;/span&gt;に対して二次形式&lt;span class="math"&gt;\(\ve{v}^{\mathsf{T}} (\ve{x}_{l}\ve{x}_{l}^{\mathsf{T}}) \ve{v}\)&lt;/span&gt;が,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \ve{v}^{\mathsf{T}} (\ve{x}_{l}\ve{x}_{l}^{\mathsf{T}} ) \ve{v} &amp;amp;= (\ve{x}_{l}^{\mathsf{T}} \ve{v})^{\mathsf{T}} (\ve{x}_{l}^{\mathsf{T}} \ve{v}) = (\ve{x}_{l}^{\mathsf{T}} \ve{v})^{2} \geq 0\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となるので半正定値行列である. 従って,
ヘッセ行列&lt;span class="math"&gt;\(H\)&lt;/span&gt;も半正定値となり,
&lt;span class="math"&gt;\(e_{l}(\ve{w})\)&lt;/span&gt;は凸関数であることが分かり,
極小値が大域的な最小値に一致する（局所最小値が存在しない）ことが確かめられた.&lt;/p&gt;
&lt;p&gt;最後に誤差&lt;span class="math"&gt;\(E(\ve{w})\)&lt;/span&gt;として二乗誤差を用いた場合の更新量&lt;span class="math"&gt;\(\Delta \ve{w}\)&lt;/span&gt;を求めておく.
今度は&lt;span class="math"&gt;\(e_{l}(\ve{w}) = \displaystyle \frac{1}{2} (t_{l} - y_{l})^{2}\)&lt;/span&gt;とおき,
ユニットの活性化関数を一般に微分可能な関数&lt;span class="math"&gt;\(f\)&lt;/span&gt;とすると,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \parfrac{ }{w_{i}} e_{l}(\ve{w}) &amp;amp;= \parfrac{e_{l}(\ve{w})}{y_{l}} \parfrac{y_{l}}{u_{l}}\parfrac{u_{l}}{w_{i}} \quad (\because 合成関数の微分) \\
  &amp;amp;= -(t_{l} - y_{l}) f^{\prime} (u_{l}) x_{i} \quad (f^{\prime} (u_{l}) \equiv \parfrac{y_{l}}{u_{l}} = \parfrac{ }{u_{l}} f(u_{l})) \\
  &amp;amp;= \delta_{l} f^{\prime}(u_{l}) x_{i}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となる. 従って更新量&lt;span class="math"&gt;\(\Delta \ve{w}\)&lt;/span&gt;は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \Delta \ve{w} = - \eta \sum_{l=1}^{N} \delta_{l} f^{\prime}(u_{l}) \ve{x}_{l}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となる. さて,
この学習則は局所最小値におちいる場合がある事に上で言及したが,
これは&lt;span class="math"&gt;\(e_{l}(\ve{w})\)&lt;/span&gt;の2階の偏導関数が&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \parfrac{{}^{2} e_{l}(\ve{w})}{w_{i} \partial w_{j}} &amp;amp;= \parfrac{ }{w_{j}} y_{l} f^{\prime}(u_{l}) x_{i} - (t_{l} - y_{l}) \parfrac{ }{w_{j}} f^{\prime}(u_{l}) x_{i} \\
  &amp;amp;= \left\{ (f^{\prime}(u_{l}))^{2} - (t_{l} - y_{l}) f^{\prime\prime} (u_{l}) \right\} x_{i} x_{j}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となるが,
&lt;span class="math"&gt;\((f^{\prime}(u_{l}))^{2} - (t_{l} - y_{l}) f^{\prime\prime} (u_{l})\)&lt;/span&gt;が常に非負になるとは限らないからである.
実際, &lt;span class="math"&gt;\(f\)&lt;/span&gt;をシグモイド関数とすると2階微分は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  f^{\prime\prime}(u_{l}) &amp;amp;= f^{\prime}(u_{l}) (1-f(u_{l})) - f(u_{l}) f^{\prime}(u_{l}) = f^{\prime}(u_{l}) (1 - 2 f(u_{l}))
  \\
  &amp;amp;= f(u_{l}) (1 - f(u_{l}))(1-2f(u_{l}))\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;であり, &lt;span class="math"&gt;\(t_{l} = 1\)&lt;/span&gt;とすると,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  (f^{\prime}(u_{l}))^{2} - (1 - y_{l}) f^{\prime\prime} (u_{l}) &amp;amp;= (f^{\prime}(u_{l}))^{2} + f^{\prime}(u_{l})(1-2f(u_{l})) - 1 \\
  &amp;amp;= f^{\prime}(u_{l}) (f^{\prime}(u_{l}) + 1 - 2f(u_{l}) ) - 1 \\
  &amp;amp;= f(u_{l}) (1 - f(u_{l})) (-(f(u_{l}))^{2} + 1 - f(u_{l})) - 1 &amp;lt; 0\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となってしまう.
従って二乗誤差を用いる場合はヘッセ行列が半正定値行列とならず,
誤差が局所最小値におちいる場合がある.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id22"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id45"&gt;多層パーセプトロン&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;単層パーセプトロンはサンプルが直線（平面）で分離できる（線形分離可能な）問題にしか適用できない事 &lt;a class="footnote-reference" href="#id37" id="id23"&gt;[13]&lt;/a&gt; が1969年にMinskey-Papertに指摘された.
線形分離不可能な例としてよく例に引き出されるのが図&lt;a class="reference external" href="#fig:XOR_problem"&gt;3&lt;/a&gt;の&lt;strong&gt;XOR問題&lt;/strong&gt;である.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="XOR問題" id="fig-xor-problem" src="./images/XOR_problem.eps" /&gt;
&lt;p class="caption"&gt;XOR問題&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;この問題は1本の直線では分離できず,
従って単層パーセプトロンでは正しく学習することができない.
この線形分離不可能な問題のために,
NN研究の第一次ブームは終焉を迎え最初の冬の時代が訪れた.&lt;/p&gt;
&lt;p&gt;この問題は1986年,
Rumelhart-McClelland（デビット・ラメルハート-ジェームス・マクレランド）によって提案された&lt;strong&gt;多層パーセプトロン（multi-layer
perceptron, MLP）&lt;/strong&gt;によって解決を見た.
多層パーセプトロンは図&lt;a class="reference external" href="#fig:MLP"&gt;4&lt;/a&gt;に表される様に, 入力層（input
layer）, 任意個数の中間（隠れ）層（middle(hidden) layer）,
出力層（output layer）からなる多層構造を持ち,
全てのユニット出力の活性化関数は非線形関数（大体はシグモイド関数）となっている.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="多層パーセプトロン" id="fig-mlp" src="./images/multi_layer_perceptron.eps" /&gt;
&lt;p class="caption"&gt;多層パーセプトロン&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;多層パーセプトロンが線形分離不可能な問題にも適用できるのは,
主に次の2つの理由による:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;階層構造を用いている事:
これは形式ニューロンのXOR素子で既に示唆されていたが,
ニューロンを階層的に繋いで全ての重みを可変にすれば,
1つのユニットが1つの分離結果を持つため複数の分離結果を合成することができる.&lt;/li&gt;
&lt;li&gt;ユニットの出力が非線形であること: ユニットの出力を非線形にすることで,
線形分離不可能な入力をニューロン内部で非線形変換し,
線形分離可能な問題に還元できる場合がある.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;多層パーセプトロンは様々な現実的な問題に適用できる為に,
NNの第二次研究ブームを引き起こした. 現在においても,
一口にNNと言うと3層（1つの中間層）からなる多層パーセプトロン（3層NN）の事を指すことが多い.&lt;/p&gt;
&lt;div class="section" id="id24"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id46"&gt;多層パーセプトロンの学習則 - 逆誤差伝搬法&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;全ての重みが可変となった多層パーセプトロンでは,
単層パーセプトロンにおける学習則の様に出力層の重みを更新するだけではなく,
全ての重みを逐次更新していく必要がある.
多層パーセプトロンの学習として標準的に用いられる&lt;strong&gt;逆誤差伝搬法（(error)
back-propagation method）&lt;/strong&gt;は,
出力層での誤差を順次後ろ向きに（出力&lt;span class="math"&gt;\(\to\)&lt;/span&gt;中間&lt;span class="math"&gt;\(\to\)&lt;/span&gt;入力層の順に）伝播させて重みを更新していく手法である.&lt;/p&gt;
&lt;p&gt;それでは学習則を導出していくが,
多層構造を表現する為に次の定義を導入する. まず,
入力層を第&lt;span class="math"&gt;\(1\)&lt;/span&gt;層, 入力層と繋がった中間層を第&lt;span class="math"&gt;\(2\)&lt;/span&gt;層,
第&lt;span class="math"&gt;\(2\)&lt;/span&gt;層と繋がった層を第&lt;span class="math"&gt;\(3\)&lt;/span&gt;層, &lt;span class="math"&gt;\(\dots\)&lt;/span&gt;と呼び,
出力層は第&lt;span class="math"&gt;\(n\)&lt;/span&gt;層とする.
即ち&lt;span class="math"&gt;\(n\)&lt;/span&gt;層構造の多層パーセプトロンを考える. また,
各層のユニット個数は一般に異なっても良いことにし,
第&lt;span class="math"&gt;\(k\)&lt;/span&gt;層におけるユニットの数を&lt;span class="math"&gt;\(L_{k}\)&lt;/span&gt;と表す.
第&lt;span class="math"&gt;\(k-1\)&lt;/span&gt;層における第&lt;span class="math"&gt;\(i\)&lt;/span&gt;ユニットと第&lt;span class="math"&gt;\(k\)&lt;/span&gt;層における第&lt;span class="math"&gt;\(j\)&lt;/span&gt;ユニットを繋ぐ重みを&lt;span class="math"&gt;\(w_{ij}^{k-1,k}\)&lt;/span&gt;と表し,
第&lt;span class="math"&gt;\(k\)&lt;/span&gt;層の第&lt;span class="math"&gt;\(i\)&lt;/span&gt;ユニットへの入力総量を&lt;span class="math"&gt;\(u_{i}^{k}\)&lt;/span&gt;と,
またその出力を&lt;span class="math"&gt;\(y_{i}^{k} = f(u_{i}^{k})\)&lt;/span&gt;と表す.
&lt;span class="math"&gt;\(f\)&lt;/span&gt;は微分可能な活性化関数ならば何でも良いが,
ここではシグモイド関数とする. また,
出力層に複数ユニットが存在するのでサンプルラベルも各出力ユニットに対応して用意し,
&lt;span class="math"&gt;\(i\)&lt;/span&gt;番目の出力ユニットに与えるラベルを&lt;span class="math"&gt;\(t^{l}_{i}\ (i=1,\dots,N)\)&lt;/span&gt;と表す.&lt;/p&gt;
&lt;p&gt;デルタ則の導出と同様に誤差の勾配を取ることを考える. 無論,
局所最小を回避する為に誤差関数&lt;span class="math"&gt;\(E\)&lt;/span&gt;としてKLダイバージェンスを導入する.
&lt;span class="math"&gt;\(E\)&lt;/span&gt;を&lt;span class="math"&gt;\(w_{ij}^{k-1,k}\)&lt;/span&gt;によって偏微分すると,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \parfrac{E}{w_{ij}^{k-1, k}} &amp;amp;= \parfrac{E}{u_{j}^{k}} \parfrac{u_{j}^{k}}{w_{ij}^{k-1,k}} \quad (\because 偏微分の連鎖律。 u_{j}^{k} を挟み込んでいるのが逆誤差伝播のキモ。) \\
  &amp;amp;= \parfrac{E}{u_{j}^{k}} \parfrac{ }{w_{ij}^{k-1,k}} \left( \sum_{s=1}^{L_{k-1}} w_{sj}^{k-1,k} y_{s}^{k-1} \right) = \parfrac{E}{u_{j}^{k}} y_{i}^{k-1}  \\
  &amp;amp;= \parfrac{E}{y_{j}^{k}} \parfrac{y_{j}^{k}}{u_{j}^{k}} y_{i}^{k-1} \quad (\because 偏微分の連鎖律) \\
  &amp;amp;= \parfrac{E}{y_{j}^{k}} f^{\prime}(u_{j}^{k}) y_{i}^{k-1} \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで&lt;span class="math"&gt;\(\displaystyle\parfrac{E}{y_{j}^{k}}\)&lt;/span&gt;は出力層の場合（&lt;span class="math"&gt;\(k=n\)&lt;/span&gt;）と中間層の場合（&lt;span class="math"&gt;\(k&amp;lt;n\)&lt;/span&gt;）で結果が異なる.
出力層の場合は, デルタ則の結果から,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \parfrac{E}{y_{j}^{n}} &amp;amp;= \frac{1-t_{j}^{l}}{1-y_{j}^{n}} - \frac{t_{j}^{l}}{y_{j}^{n}} = \frac{y_{j}^{n}(1-t_{j}^{l}) - t_{j}^{l}(1 - y_{j}^{n})}{y_{j}^{n}(1-y_{j}^{n})} = \frac{y_{j}^{n} - t_{j}^{l}}{f^{\prime}(u_{j}^{n})} \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となり, 一方中間層の場合は, 偏微分の連鎖律（chain rule）によって,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \parfrac{E}{y_{j}^{k}} &amp;amp;= \sum_{s=1}^{L_{k+1}} \parfrac{E}{u_{s}^{k+1}} \parfrac{u_{s}^{k+1}}{y_{j}^{k}} \\
  &amp;amp;= \sum_{s=1}^{L_{k+1}} \parfrac{E}{u_{s}^{k+1}} \parfrac{}{y_{j}^{k}} \left( \sum_{t=1}^{L_{k}} w_{ts}^{k, k+1} y_{t}^{k} \right) = \sum_{s=1}^{L_{k+1}} \parfrac{E}{u_{s}^{k+1}} w_{js}^{k,k+1} \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と展開できる. これらの結果をまとめると,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \parfrac{E}{w_{ij}^{k-1, k}} =
  \left\{ \begin{array}{ll}
    \displaystyle \frac{y_{j}^{n} - t_{j}^{l}}{f^{\prime}(u_{j}^{n})} f^{\prime}(u_{j}^{n}) y_{j}^{n-1} = (y_{j}^{n} - t_{l}) y_{i}^{n-1} &amp;amp; (k = n) \\
    \displaystyle \sum_{s=1}^{L_{k+1}} \parfrac{E}{u_{s}^{k+1}} w_{js}^{k,k+1} f^{\prime}(u_{j}^{k}) y_{i}^{k-1} &amp;amp; (k &amp;lt; n)
  \end{array} \right.\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となるが,
次の第&lt;span class="math"&gt;\(k\)&lt;/span&gt;層の&lt;span class="math"&gt;\(i\)&lt;/span&gt;番目のユニットの&lt;strong&gt;誤差信号&lt;/strong&gt;&lt;span class="math"&gt;\(\delta_{i}^{k}\)&lt;/span&gt;&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\begin{aligned}
  \delta_{i}^{k} &amp;amp;= \parfrac{E}{u_{i}^{k}} = \parfrac{E}{y_{i}^{k}} \parfrac{y_{i}^{k}}{u_{i}^{k}} \\
  &amp;amp;=
  \left\{ \begin{array}{ll}
    y_{i}^{n} - t_{i}^{l} &amp;amp; (k = n) \\
    \displaystyle \sum_{s=1}^{L_{k+1}} \parfrac{E}{u_{s}^{k+1}}w_{js}^{k,k+1} f^{\prime}(u_{i}^{k}) = \sum_{s=1}^{L_{k+1}} \delta_{s}^{k+1} w_{js}^{k,k+1}  f^{\prime}(u_{i}^{k}) &amp;amp; (k &amp;lt; n)
  \end{array} \right.\end{aligned}
\end{align*}
&lt;/div&gt;
&lt;p&gt;を用いれば, より簡潔に勾配を表現できる:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \parfrac{E}{w_{ij}^{k-1, k}} = y_{i}^{k-1} \delta_{j}^{k}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;以上により,
逆誤差伝搬法は次の手順に従って重みを更新すれば良い事が分かる:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(k \leftarrow n\)&lt;/span&gt;とする.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;誤差信号&lt;span class="math"&gt;\(\delta_{i}^{k}\ (i = 1,\dots,L_{k})\)&lt;/span&gt;の計算を行う:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
      \delta_{i}^{k} =
      \left\{ \begin{array}{ll}
        y_{i}^{n} - t_{i}^{l} &amp;amp; (k = n) \\
        \displaystyle \sum_{s=1}^{L_{k+1}} \delta_{s}^{k+1} w_{js}^{k,k+1}  f^{\prime}(u_{i}^{k}) &amp;amp; (k &amp;lt; n)
      \end{array} \right.
    \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(k \leftarrow k-1\)&lt;/span&gt;とする.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(k = 1\)&lt;/span&gt;ならば次へ, そうでなければ2. に戻る.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;重みを更新する:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
      w_{ij}^{k-1,k} \leftarrow w_{ij}^{k-1,k} - \eta y_{i}^{k-1} \delta_{j}^{k} \quad (k=2,\dots,n,\ i = 1,\dots, L_{k-1},\ j = 1,\dots,L_{k})
    \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;これは基本となる逐次学習法であるが,
一括学習の時は&lt;span class="math"&gt;\(\delta_{i}^{n}\)&lt;/span&gt;の所でサンプルについての和を取って次のようにすれば良い:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \delta_{i}^{n} = \sum_{l=1}^{N} (y_{i}^{n} - t_{i}^{l})\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;table class="docutils footnote" frame="void" id="id25" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;ノーバート・ウィーナー, 池原止戈夫, 彌永昌吉, 室賀三郎, 戸田巌,
“ウィーナー サイバネティックス ―動物と機械における制御と通信”
岩波書店, 2011&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id26" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id3"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;庄野逸, &lt;a class="reference external" href="http://www.slideshare.net/HAL9801/20140705"&gt;Deep Learning
勉強会(1)&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id27" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id4"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;高橋治久, 堀田一弘, “学習理論” コロナ社, 2009&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id28" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id7"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;これは非常に単純なモデルであり,
理解や応用が簡単な為に様々な場面で用いられる.
特に機械学習では無批判にこのユニットを用いる向きがある. しかし,
このモデルは厳密にニューロンの動作を表現できてはいないことに注意が必要である.
例えば,
このモデルでは入力&lt;span class="math"&gt;\(u\)&lt;/span&gt;が強ければ常に高電位を放出する事になるが,
実際にはニューロンはパルスを放出した後は一時的に放出電位が下がる事が実験により知られている.
よりニューロンの動作を精密に表したモデルにホジキン-ハックスレー型のニューロンモデルがある[^13].&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id29" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id12"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;正例のラベルを&lt;span class="math"&gt;\(1\)&lt;/span&gt;,
負例のラベルを&lt;span class="math"&gt;\(0\)&lt;/span&gt;としたり問題に応じて都合良く決められるが,
識別できる二値なら何でもよく, 本質的な違いは存在しない.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id30" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id14"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;高橋治久, 堀田一弘, “学習理論” コロナ社, 2009&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id31" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id15"&gt;[7]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;この正規化によっても一般性は全く失われない.
&lt;span class="math"&gt;\(\ve{w}\)&lt;/span&gt;は入力の重みの比率を定めているに過ぎず,
実際&lt;span class="math"&gt;\(u = \ve{w}^{\mathsf{T}}\ve{x} + b\)&lt;/span&gt;から見れるように,
&lt;span class="math"&gt;\(\ve{w}\)&lt;/span&gt;は面（識別面という）の法ベクトルとなっている.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id32" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id16"&gt;[8]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;最も面&lt;span class="math"&gt;\(\ve{w}^{\ast}\)&lt;/span&gt;に近いベクトルの距離を表しており,
&lt;strong&gt;マージン&lt;/strong&gt;と呼ばれる. かの有名なSVMのマージンそのものである&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id33" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id17"&gt;[9]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;2つのベクトル&lt;span class="math"&gt;\(\ve{v}_{1}, \ve{v}_{2}\)&lt;/span&gt;がなす角度&lt;span class="math"&gt;\(\theta\)&lt;/span&gt;は&lt;span class="math"&gt;\(\cos\theta = \ve{v}_{1}^{\mathsf{T}}\ve{v}_{2}/(||\ve{v}_{1}||||\ve{v}_{2}||)\)&lt;/span&gt;により求められるので,
&lt;span class="math"&gt;\(\theta=0\)&lt;/span&gt;ならば2つのベクトルは一致している（類似度が最大）と見ることができる.
角度&lt;span class="math"&gt;\(\theta\)&lt;/span&gt;が&lt;span class="math"&gt;\(0\)&lt;/span&gt;に近い（類似度が高い）時は内積&lt;span class="math"&gt;\(\ve{v}_{1}^{\mathsf{T}}\ve{v}_{2}\)&lt;/span&gt;が高い値を取ることが分かる&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id34" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id19"&gt;[10]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;大域的な最小解とは限らない事に注意&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id35" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id20"&gt;[11]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;係数の&lt;span class="math"&gt;\(1/2\)&lt;/span&gt;に本質的な意味は無いが,
微分の際に計算を簡単にする狙いがある.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id36" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id21"&gt;[12]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;しかし, 局所最適に嵌ってしまうリスクが潜んでいる&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id37" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id23"&gt;[13]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;span class="math"&gt;\(\ve{w}\)&lt;/span&gt;は識別面の法ベクトルを表すが,
出力を単位ステップ（もしくは符号）関数とすると入力ベクトルが面の上半領域にある場合は&lt;span class="math"&gt;\(1\)&lt;/span&gt;を,
下半領域にある場合は&lt;span class="math"&gt;\(0(-1)\)&lt;/span&gt;を出力する.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="記事"></category><category term="古事記"></category><category term="機械学習"></category></entry><entry><title>最大エントロピーモデル</title><link href="/zui-da-entoropimoderu.html" rel="alternate"></link><published>2020-04-23T12:40:00+09:00</published><updated>2020-04-23T12:40:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-23:/zui-da-entoropimoderu.html</id><summary type="html">&lt;p class="first last"&gt;最大エントロピーモデルについての理論的概要。MRFよりも更に前の話！古い！&lt;/p&gt;
</summary><content type="html">&lt;p&gt;最大エントロピーモデルの導出過程、学習の更新則、素性選択についての理論的側面を述べる。記述の大部分は &lt;a class="footnote-reference" href="#id27" id="id2"&gt;[1]&lt;/a&gt; を参照し、一部 &lt;a class="footnote-reference" href="#id28" id="id3"&gt;[2]&lt;/a&gt;, &lt;a class="footnote-reference" href="#id29" id="id4"&gt;[3]&lt;/a&gt; も参照している。&lt;/p&gt;
&lt;p&gt;最大エントロピーモデルは、データの特徴を &lt;strong&gt;素性関数 (feature function)&lt;/strong&gt;
によって記述し、素性関数がある &lt;strong&gt;制約 (constraint)&lt;/strong&gt;
を満たし、かつ、モデルを表現する確率分布のエントロピーが最大となる（最大エントロピー原理を満たす）モデルである。&lt;/p&gt;
&lt;p&gt;エントロピーを最大にする事により、制約を満たしながら最大エントロピーモデルの確率分布が最も一様に分布する様になり、未知データに対する確率を無下に&lt;span class="math"&gt;\(0\)&lt;/span&gt;にすることが無くなるため、高い汎用性（汎化性能）が期待できる。&lt;/p&gt;
&lt;div class="contents local topic" id="id5"&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id43"&gt;モデルを表現する確率分布の導出&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id44"&gt;最大のエントロピー原理の性質と最尤推定&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id45"&gt;最大エントロピーモデルの唯一存在性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id46"&gt;最大尤度を持つ最大エントロピーモデル&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id47"&gt;最大のエントロピーモデルの学習 - 反復スケーリング法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id12" id="id48"&gt;条件付き最大エントロピーモデル&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id15" id="id49"&gt;素性の自動選択&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id26" id="id50"&gt;脚注・参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id43"&gt;モデルを表現する確率分布の導出&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;まず、サンプル（事例）データのドメイン（定義域）を&lt;span class="math"&gt;\(X\)&lt;/span&gt;、データに付与されたラベルのドメインを&lt;span class="math"&gt;\(Y\)&lt;/span&gt;と書く。例えば、次に来る単語を予測させたい場合には、サンプル&lt;span class="math"&gt;\(X\)&lt;/span&gt;は 1 つ前までの単語の並び、ラベル&lt;span class="math"&gt;\(Y\)&lt;/span&gt;は今の単語となる。
データとラベルを組にすることで 1 つの学習サンプルが構成され、また、モデルに与える&lt;span class="math"&gt;\(m\)&lt;/span&gt;個の学習サンプルの集合&lt;span class="math"&gt;\(Z_{m} \subset 2^{X\times Y}\)&lt;/span&gt;を次で表す :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
Z_{m} = \{ (x_{1}, y_{1}), (x_{2}, y_{2}), \dots, (x_{m}, y_{m}) \}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;このようなサンプルに対し、&lt;strong&gt;素性関数（素性）&lt;/strong&gt;の集合&lt;span class="math"&gt;\({\cal F}\)&lt;/span&gt;は次で定義される :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
{\cal F} = \{ f_{i} : X \times Y \to \{0,1\}, i \in \{1,2,\dots,n\} \}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;即ち&lt;span class="math"&gt;\({\cal F}\)&lt;/span&gt;は、データとラベルの組&lt;span class="math"&gt;\((x,y) \in X \times Y\)&lt;/span&gt;を受け取って&lt;span class="math"&gt;\(\{0,1\}\)&lt;/span&gt;いずれかを返す関数の集合である。ここでは&lt;span class="math"&gt;\(f\)&lt;/span&gt;の値域は議論の簡略化のため&lt;span class="math"&gt;\(\{0,1\}\)&lt;/span&gt;としたが、値域は&lt;span class="math"&gt;\(\{0,\alpha\} (\alpha &amp;gt; 0)\)&lt;/span&gt;、即ち&lt;span class="math"&gt;\(0\)&lt;/span&gt;と&lt;span class="math"&gt;\(0\)&lt;/span&gt;以外の正数実数を取るようにもできる。また、素性が条件を満たし正の値を取る時は、素性が活性化しているという。&lt;/p&gt;
&lt;p&gt;素性の例を挙げると、&lt;span class="math"&gt;\(n\)&lt;/span&gt;個の単語列&lt;span class="math"&gt;\(w_{1},\dots,w_{n}\)&lt;/span&gt;から、直前の&lt;span class="math"&gt;\(N-1\)&lt;/span&gt;個の単語列&lt;span class="math"&gt;\(w_{n-N+1},\dots,w_{n-1}\)&lt;/span&gt;のみを用いて今の単語&lt;span class="math"&gt;\(w_{n}\)&lt;/span&gt;を予測する（&lt;span class="math"&gt;\(N\)&lt;/span&gt;- グラムの）場合は、素性は次の様に表現出来る。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f_{x_{1}x_{2}\dots x_{N}}(w_{1},\dots,w_{n-1},w_{n}) =
\left\{
  \begin{array}{ll}
    1 &amp;amp; w_{n-N+1} = x_{1}, w_{n-N+2} = x_{2}, \dots, w_{n-1} = x_{N-1}, w_{n} = x_{N} \\
    0 &amp;amp; {\rm otherwise}
  \end{array} \right.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで&lt;span class="math"&gt;\(f\)&lt;/span&gt;のインデックス&lt;span class="math"&gt;\(x_{1}\dots x_{N}\)&lt;/span&gt;は整数との対応を適当に取ることで、容易に実現できる。&lt;/p&gt;
&lt;p&gt;最大エントロピーモデルの制約として与えられる条件は、素性の平均（期待値）が、モデルと経験確率で一致することである。この条件を数式で表現する事を考える。&lt;/p&gt;
&lt;p&gt;定義域&lt;span class="math"&gt;\(X\times Y\)&lt;/span&gt;上に定義されるモデルの確率分布を&lt;span class="math"&gt;\(P(x,y)\)&lt;/span&gt;と書き、経験確率分布を&lt;span class="math"&gt;\(\tilde{P}(x,y)\)&lt;/span&gt;と書く。ここで経験確率分布&lt;span class="math"&gt;\(\tilde{P}\)&lt;/span&gt;は、頻度確率で与える。即ち、学習サンプルに現れた&lt;span class="math"&gt;\((x,y)\)&lt;/span&gt;の組の回数を&lt;span class="math"&gt;\(C(x,y)\)&lt;/span&gt;と書くと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\tilde{P}(x,y) = \frac{C(x,y)}{m}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表せる。モデルの確率分布は後で導出する。
ある素性&lt;span class="math"&gt;\(f_{i}\)&lt;/span&gt;の分布&lt;span class="math"&gt;\(p\)&lt;/span&gt;による平均を&lt;span class="math"&gt;\(E_{p}[f_{i}]\)&lt;/span&gt;と書くと、経験分布とモデルの確率分布のそれぞれの平均は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
E_{\tilde{P}}[f_{i}] &amp;amp;= \sum_{x,y} \tilde{P}(x,y) f_{i}(x,y) \\
E_{P}[f_{i}] &amp;amp;= \sum_{x,y} P(x,y) f_{i}(x,y)
\end{align*}
&lt;/div&gt;
&lt;p&gt;と表せられ、従って制約を数式で表現すると ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
E_{\tilde{P}}[f_{i}] &amp;amp;= E_{P}[f_{i}] \ \ (i=1,\dots,n) \\
\iff \sum_{x,y} \tilde{P}(x,y) f_{i}(x,y) &amp;amp;= \sum_{x,y} P(x,y) f_{i}(x,y) \ \ (i=1,\dots,n)
\end{align*}
&lt;/div&gt;
&lt;p&gt;となる。最大エントロピーモデルの候補となる集合&lt;span class="math"&gt;\({\cal P}\)&lt;/span&gt;は、全ての素性に関する制約を満たすモデルの集合となる :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
{\cal P} = \{ P | E_{P}[f_{i}] = E_{\tilde{P}}[f_{i}], i = \{1,\dots,n\} \}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;明らかに、2 つのモデル&lt;span class="math"&gt;\(P,P^{\prime} \in {\cal P}\)&lt;/span&gt;に対して、&lt;span class="math"&gt;\(E_{P}[f_{i}] = E_{\tilde{P}}[f_{i}] = E_{P^{\prime}}[f_{i}]\ \ (i=1,\dots,n)\)&lt;/span&gt;（候補となるモデルの素性の平均は同一）となる。&lt;/p&gt;
&lt;p&gt;更に考慮すべき点は、最大エントロピーモデルの名の通り、モデル（確率分布&lt;span class="math"&gt;\(P\)&lt;/span&gt;）のエントロピーを最大にする必要がある。モデルのエントロピーを&lt;span class="math"&gt;\(H(P)\)&lt;/span&gt;と書くと、確率分布のエントロピーの式から ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
H(P) = -\sum_{x,y}P(x,y) \log P(x,y)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表現できる。集合&lt;span class="math"&gt;\({\cal P}\)&lt;/span&gt;の中で最もエントロピーが高いものが得るべきモデル&lt;span class="math"&gt;\(P^{\ast}\)&lt;/span&gt;である :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
P^{\ast} = \underset{P \in {\cal P}}{\rm argmax}\ H(P)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;この式を &lt;strong&gt;最大エントロピー原理 (maximum entropy principle)&lt;/strong&gt;
と呼ぶ。集合&lt;span class="math"&gt;\({\cal P}\)&lt;/span&gt;は無限集合だが最大エントロピー原理を満たすモデルは解析的に求められ、かつ一意に存在する（後術）。&lt;/p&gt;
&lt;p&gt;最大エントロピー原理を満たすモデルの確率分布&lt;span class="math"&gt;\(P\)&lt;/span&gt;を求める事を考える。これは制約付き非線形最適化問題であることから、ラグランジェの未定定数法が適用できる。&lt;span class="math"&gt;\(P\)&lt;/span&gt;が満たすべき制約を列挙すると&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
1:&amp;amp; \quad E_{P}[f_{i}] = E_{\tilde{P}}[f_{i}] \ \ (i=1,\dots,n) \\
2:&amp;amp; \quad P(x,y) \geq 0 \\
3:&amp;amp; \quad \sum_{x,y}P(x,y) = 1
\end{align*}
&lt;/div&gt;
&lt;p&gt;であり（2,3 は&lt;span class="math"&gt;\(P\)&lt;/span&gt;が確率分布となる為の条件）、&lt;span class="math"&gt;\(n\)&lt;/span&gt;個の制約に対応する未定定数を&lt;span class="math"&gt;\(\Lambda = \{\lambda_{1},\dots,\lambda_{n}\}\)&lt;/span&gt;と書くと、ラグランジアン（ラグランジュ関数）&lt;span class="math"&gt;\({\cal L}(P,\Lambda)\)&lt;/span&gt;は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
{\cal L}(P, \Lambda) &amp;amp;= H(P) + \sum_{i=1}^{n} \lambda_{i} (E_{P}[f_{i}] - E_{\tilde{P}}[f_{i}]) \\
&amp;amp;= -\sum_{x,y}P(x,y)\log P(x,y) + \sum_{i=1}^{n} \lambda_{i} \left\{ \sum_{x,y} P(x,y) f_{i}(x,y) - \sum_{x,y} \tilde{P}(x,y) f_{i}(x,y) \right\}
\end{align*}
&lt;/div&gt;
&lt;p&gt;と書ける。最大値を得るため、&lt;span class="math"&gt;\(P(x,y)\)&lt;/span&gt;によって偏微分すると ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\frac{\partial {\cal L}(P,\Lambda)}{\partial P(x,y)} = -\log P(x,y) - 1 + \sum_{i=1}^{n} \lambda_{i} f_{i}(x,y)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;この式を&lt;span class="math"&gt;\(0\)&lt;/span&gt;とおいて&lt;span class="math"&gt;\(P(x,y)\)&lt;/span&gt;について解くと&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
P(x,y) = \exp \left[ -1 + \sum_{i=1}^{n} \lambda_{i} f_{i}(x,y) \right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を得る。確率分布が指数関数で表現される為条件 2 の非負条件は満たされるが、条件 3 の全確率が 1 になることが保証されていない。そこで
&lt;span class="math"&gt;\(\sum_{x,y}P(x,y) = Z_{\Lambda}\)&lt;/span&gt;なる正規化項 (normalization
factor) を導入し&lt;span class="math"&gt;\(P(x,y)\)&lt;/span&gt;の&lt;span class="math"&gt;\(x,y\)&lt;/span&gt;についての総和が 1 になるようにする。従ってモデルの確率分布は次で表される :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
P(x,y) &amp;amp;= \frac{ \exp \left[ -1 + \sum_{i=1}^{n} \lambda_{i} f_{i}(x,y) \right] }{ \sum_{x,y} \exp \left[ -1 + \sum_{i=1}^{n} \lambda_{i} f_{i}(x,y) \right] } \\
&amp;amp;= \frac{1}{Z_{\Lambda}} \exp \left[ \sum_{i} \lambda_{i} f_{i}(x,y) \right] \\
Z_{\Lambda} &amp;amp;= \sum_{x,y} \exp \left[ \sum_{i} \lambda_{i} f_{i}(x,y) \right]
\end{align*}
&lt;/div&gt;
&lt;p&gt;（以下、&lt;span class="math"&gt;\(\sum_{i=1}^{n} \equiv \sum_{i}\)&lt;/span&gt;とする）得られた確率分布は MRF(Markov
Random
Fields、マルコフ確率場 ) のクリークサイズを 1 とした時、即ち節点ポテンシャル（連想ポテンシャル）のみを考えた結合確率に一致する。従って最大エントロピーモデルは MRF のサブクラスとして捉えられる。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id44"&gt;最大のエントロピー原理の性質と最尤推定&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;最大エントロピー原理を満たすモデルは上述の議論で求められたが、このモデルが唯一に定まる事を示す。まず、上述の議論で得られた確率分布を持つモデルの集合を&lt;span class="math"&gt;\({\cal Q}\)&lt;/span&gt;と書く :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
{\cal Q} = \left\{ P \left| P(x,y) = \frac{1}{Z_{\Lambda}} \exp\left[ \sum_{i} \lambda_{i}f_{i}(x,y) \right] \right. \right\}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;集合&lt;span class="math"&gt;\({\cal Q}\)&lt;/span&gt;の要素に制約は陽に表れていない。そして、&lt;span class="math"&gt;\({\cal P,Q}\)&lt;/span&gt;と最大エントロピー原理について次の定理が成り立つ :&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;div class="section" id="id8"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id45"&gt;最大エントロピーモデルの唯一存在性&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span class="math"&gt;\(P^{\ast} \in {\cal P} \cap {\cal Q}\)&lt;/span&gt;ならば ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
P^{\ast} = \underset{P \in {\cal P}}{\rm argmax} \ H(P)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成り立ち、かつ&lt;span class="math"&gt;\(P^{\ast}\)&lt;/span&gt;は唯一に定まる。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;（証明）まず補助定理として、&lt;span class="math"&gt;\(R, S \in {\cal P}, T \in {\cal Q}\)&lt;/span&gt;ならば ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\sum_{x,y} R(x,y) \log T(x,y) = \sum_{x,y} S(x,y) \log T(x,y)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を示す。&lt;span class="math"&gt;\(T \in {\cal Q}\)&lt;/span&gt;より&lt;span class="math"&gt;\(T(x,y) = \displaystyle\frac{1}{Z_{\Lambda}} \exp\left[ \sum_{i} \lambda_{i} f_{i}(x,y) \right]\)&lt;/span&gt;と表せるので、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
（左辺） &amp;amp;= \sum_{x,y} R(x,y) \left[ \sum_{i} \lambda_{i} f_{i}(x,y) - \log Z_{\Lambda} \right] = \sum_{i} \lambda_{i} \sum_{x,y} R(x,y) f_{i}(x,y) - \log Z_{\Lambda} \sum_{x,y}R(x,y) \\
&amp;amp;= \sum_{i} \lambda_{i} E_{R}[f_{i}] - \log Z_{\Lambda} \\
&amp;amp;= \sum_{i} \lambda_{i} E_{S}[f_{i}] - \log Z_{\Lambda} \ \ (\because E_{R}[f_{i}] = E_{\tilde{P}}[f_{i}] = E_{S}[f_{i}]） \\
&amp;amp;= \sum_{x,y} S(x,y) \left[\sum_{i} \lambda_{i} f_{i}(x,y) \right] - \sum_{x,y} S(x,y) \log Z_{\Lambda} \\
&amp;amp;= \sum_{x,y} S(x,y) \log T(x,y) = （右辺）
\end{align*}
&lt;/div&gt;
&lt;p&gt;補助定理を用いて、定理の証明を行う。&lt;span class="math"&gt;\(P \in {\cal P}, P^{\ast} \in {\cal P} \cap {\cal Q}\)&lt;/span&gt;とすると ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
H(P^{\ast}) - H(P) &amp;amp;= -\sum_{x,y} P^{\ast}(x,y) \log P^{\ast}(x,y) + \sum_{x,y} P(x,y) \log P(x,y) \\
&amp;amp;= -\sum_{x,y} P(x,y) \log P^{\ast}(x,y) + \sum_{x,y} P(x,y) \log P(x,y) \ \ （\because 補助定理） \\
&amp;amp;= \sum_{x,y} P(x,y) \log \left[ \frac{P(x,y)}{P^{\ast}(x,y)} \right] \\
&amp;amp;= {\rm KL}(P || P^{\ast}) \geq 0\ \ （{\rm KL}:KL ダイバージェンス）
\end{align*}
&lt;/div&gt;
&lt;p&gt;よって&lt;span class="math"&gt;\(H(P^{\ast}) \geq H(P)\)&lt;/span&gt;が成立する。また&lt;span class="math"&gt;\(H(P^{\ast}) = H(P)\)&lt;/span&gt;ならば KL ダイバージェンスの性質により&lt;span class="math"&gt;\(P^{\ast} = P\)&lt;/span&gt;となる。以上により、定理の成立が示された。&lt;/p&gt;
&lt;p&gt;生成モデルの学習に関連して、最大エントロピー原理を満たすモデル&lt;span class="math"&gt;\(P^{\ast}\)&lt;/span&gt;は、経験確率分布&lt;span class="math"&gt;\(\tilde{P}\)&lt;/span&gt;が与えられた時に最大尤度を持つ事も示されている。モデルの尤度の式を導く事を考えると、まず経験確率分布&lt;span class="math"&gt;\(\tilde{P}\)&lt;/span&gt;に対するモデル&lt;span class="math"&gt;\(P\)&lt;/span&gt;の経験誤差は KL ダイバージェンス&lt;span class="math"&gt;\({\rm KL}(\tilde{P} || P)\)&lt;/span&gt;で与えられる &lt;a class="footnote-reference" href="#id30" id="id9"&gt;[4]&lt;/a&gt; ので ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
{\rm KL}(\tilde{P} || P) &amp;amp;= \sum_{x,y} \tilde{P}(x,y) \log \left[ \frac{\tilde{P}(x,y)}{P(x,y)} \right] \\
&amp;amp;= \sum_{x,y} \tilde{P}(x,y) \log \tilde{P}(x,y) - \sum_{x,y} \tilde{P}(x,y) \log P(x,y)
\end{align*}
&lt;/div&gt;
&lt;p&gt;なる。大数の弱法則より、サンプル数の極限&lt;span class="math"&gt;\(m\to \infty\)&lt;/span&gt;を取ることにより経験確率分布は標的概念の確率分布に一致し、また経験誤差は汎化誤差に一致する。今&lt;span class="math"&gt;\({\rm KL}(\tilde{P} || P) \geq 0\)&lt;/span&gt;であり、かつ、&lt;span class="math"&gt;\(\tilde{P}\)&lt;/span&gt;は観測により固定されるので、経験誤差を最小にするには下段の式の第 2 項を最大化すれば良いことになる。そして、下段式の第 2 項は対数尤度（経験対数尤度）と呼ばれる。モデル&lt;span class="math"&gt;\(P\)&lt;/span&gt;の対数尤度を&lt;span class="math"&gt;\(L(P)\)&lt;/span&gt;と書くと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
L(P) = \sum_{x,y} \tilde{P}(x,y) \log P(x,y)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表すことができる。尤度との関連として、最大エントロピー原理を満たすモデル&lt;span class="math"&gt;\(P^{\ast}\)&lt;/span&gt;は次を満たす :&lt;/p&gt;
&lt;/div&gt;
&lt;hr class="docutils" /&gt;
&lt;div class="section" id="id10"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id46"&gt;最大尤度を持つ最大エントロピーモデル&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span class="math"&gt;\(P^{\ast} \in {\cal P} \cap {\cal Q}\)&lt;/span&gt;ならば、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
P^{\ast} = \underset{Q \in {\cal Q}}{\rm argmax} \ L(Q)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成り立ち、かつ&lt;span class="math"&gt;\(P^{\ast}\)&lt;/span&gt;は唯一に定まる。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;（証明）前の定理と同様の方針と、補助定理により ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
L(P^{\ast}) - L(P) &amp;amp;= \sum_{x,y} \tilde{P}(x,y) \log P^{\ast}(x,y) - \sum_{x,y} \tilde{P}(x,y) \log P(x,y) \\
&amp;amp;= \sum_{x,y} P^{\ast}(x,y) \log P^{\ast}(x,y) - \sum_{x,y} P^{\ast}(x,y) \log P(x,y) \ \ (\because 反射性 E_{\tilde{P}}[f_{i}] = E_{\tilde{P}}[f_{i}] により、\tilde{P} \in {\cal P}) \\
&amp;amp;= \sum_{x,y} P^{\ast}(x,y) \log \left[ \frac{P^{\ast}(x,y)}{P(x,y)} \right] \\
&amp;amp;= {\rm KL}(P^{\ast} || P) \geq 0
\end{align*}
&lt;/div&gt;
&lt;p&gt;よって&lt;span class="math"&gt;\(L(P^{\ast}) \geq L(P)\)&lt;/span&gt;であり、再び KL ダイバージェンスの性質により、&lt;span class="math"&gt;\(L(P^{\ast}) = L(P)\)&lt;/span&gt;ならば&lt;span class="math"&gt;\(P^{\ast} = P\)&lt;/span&gt;が成り立つので唯一性も示される。従って定理の成立が示された。&lt;/p&gt;
&lt;p&gt;定理 1 と 2 により、次の性質が成り立つ :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
P^{\ast} = \underset{P \in {\cal P}}{\rm argmax} \ H(P) = \underset{Q \in {\cal Q}}{\rm argmax} \ L(Q)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;即ち、モデルの最大エントロピー原理は最尤推定の枠組みで捉える事もでき、尤度を最大化したモデルが最大のエントロピーを持つ。よって、モデルの学習には通常の生成モデルの学習と同じ様に、&lt;span class="math"&gt;\({\cal Q}\)&lt;/span&gt;の要素で表現されるモデルの尤度最大化を考えれば良いことになる。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id11"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id47"&gt;最大のエントロピーモデルの学習 - 反復スケーリング法&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;最尤推定法に基づく最大エントロピーモデルの学習は、モデルの尤度が最大になるようにモデル&lt;span class="math"&gt;\(P\)&lt;/span&gt;のパラメタ&lt;span class="math"&gt;\(\Lambda\)&lt;/span&gt;を調節してやれば良い。単純なアプローチとしては、対数尤度&lt;span class="math"&gt;\(L(P)\)&lt;/span&gt;をパラメタ&lt;span class="math"&gt;\(\Lambda=\{\lambda_{1},\cdots,\lambda_{n}\}\)&lt;/span&gt;で偏微分し、最急上昇法によって最大値を得る方法がある。実際に計算してみると ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\frac{\partial L(P)}{\partial \lambda_{i}} &amp;amp;= \sum_{x,y} \tilde{P}(x,y) \frac{\partial}{\partial \lambda_{i}} \log P(x,y) \\
&amp;amp;= \sum_{x,y} \tilde{P}(x,y) \frac{\partial}{\partial \lambda_{i}} \left[ \sum_{j} \lambda_{j} f_{j}(x,y) - \log Z_{\Lambda} \right] \\
&amp;amp;= \sum_{x,y} \tilde{P}(x,y) \left[ f_{i}(x,y) - \frac{1}{Z_{\Lambda}} \sum_{x^{\prime},y^{\prime}} f_{i}(x^{\prime},y^{\prime}) \exp \left( \sum_{j} \lambda_{j} f_{j}(x^{\prime},y^{\prime}) \right) \right] \\
&amp;amp;= \sum_{x,y} \tilde{P}(x,y) \left( f_{i}(x,y) - E_{P}[f_{i}] \right) \\
&amp;amp;= E_{\tilde{P}}[f_{i}] - E_{P}[f_{i}]
\end{align*}
&lt;/div&gt;
&lt;p&gt;であり（最適時には制約が満たされることが分かる）、ステップ&lt;span class="math"&gt;\(t\)&lt;/span&gt;におけるパラメタ&lt;span class="math"&gt;\(\lambda_{i}^{t}\)&lt;/span&gt;の更新規則は次の様に得られる :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\lambda_{i}^{t+1} &amp;amp;= \lambda_{i}^{t} + \eta \frac{\partial L(P)}{\partial \lambda_{i}^{t}} \\
&amp;amp;= \lambda_{i}^{t} + \eta ( E_{\tilde{P}}[f_{i}] - E_{P}[f_{i}] )
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで&lt;span class="math"&gt;\(\eta\)&lt;/span&gt;は収束の早さを決める学習率 (learning
rate) であり、ヒューリスティックに決める必要がある。
この様に再急上昇法による学習は単純だが、学習（収束）が遅く、&lt;span class="math"&gt;\(\eta\)&lt;/span&gt;を決めなければならないという問題がある。&lt;span class="math"&gt;\(\eta\)&lt;/span&gt;を大きく設定し過ぎると勾配の谷を越えてしまい発散を招き、逆に小さく設定すると学習がいつまでたっても終わらない。現状、最大エントロピーモデルの学習では、反復スケーリング法 (iterative
scaling) という学習手法が伝統的に用いられている。&lt;/p&gt;
&lt;p&gt;反復スケーリング法の基本的な考え方は、まずパラメタ&lt;span class="math"&gt;\(\Lambda\)&lt;/span&gt;を&lt;span class="math"&gt;\(\Lambda+\Delta\)&lt;/span&gt;に変化させた時の対数尤度の変化量の下限&lt;span class="math"&gt;\(A(\Lambda,\Delta)\)&lt;/span&gt;を計算し、次にこの&lt;span class="math"&gt;\(A(\Lambda,\Delta)\)&lt;/span&gt;を最大にする&lt;span class="math"&gt;\(\Delta\)&lt;/span&gt;を求める事で、結果増加量を最大にするようにしている。この考え方には学習率の様なヒューリスティックは介在せず、かつ毎ステップの対数尤度の増加量を最大にするようにパラメタを更新できる。&lt;/p&gt;
&lt;p&gt;それでは反復スケーリング法の更新式を導くことを考える。各パラメタの更新量を&lt;span class="math"&gt;\(\Delta=\{\delta_{1},\cdots,\delta_{n}\}\)&lt;/span&gt;と表すものとし、まず、パラメタ更新時の対数尤度の変化量&lt;span class="math"&gt;\(L(P_{\Lambda+\Delta})-L(P_{\Lambda})\)&lt;/span&gt;は ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
L(P_{\Lambda+\Delta})-L(P_{\Lambda}) &amp;amp;= \sum_{x,y} \tilde{P}(x,y) \log P_{\Lambda+\Delta}(x,y) - \sum_{x,y} \tilde{P}(x,y) \log P_{\Lambda}(x,y) \\
&amp;amp;= \sum_{x,y} \tilde{P}(x,y) \log \left[ \frac{P_{\Lambda+\Delta}(x,y)}{P_{\Delta}(x,y)} \right] \\
&amp;amp;= \sum_{x,y} \tilde{P}(x,y) \log \left[ \frac{Z_{\Lambda}}{Z_{\Lambda+\Delta}} \frac{\exp\left[ \sum_{i}(\lambda_{i} + \delta_{i}) f_{i}(x,y) \right]}{\exp\left[ \sum_{i}\lambda_{i}f_{i}(x,y) \right] } \right] \\
&amp;amp;= \sum_{x,y} \tilde{P}(x,y) \left[ \sum_{i} \delta_{i} f_{i}(x,y) - \log\left(\frac{Z_{\Lambda+\Delta}}{Z_{\Lambda}} \right) \right] \\
&amp;amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i} \delta_{i} f_{i}(x,y) - \log \left(\frac{Z_{\Lambda+\Delta}}{Z_{\Lambda}} \right) \\
&amp;amp;\geq \sum_{x,y} \tilde{P}(x,y) \sum_{i} \delta_{i} f_{i}(x,y) + 1 - \frac{Z_{\Lambda+\Delta}}{Z_{\Lambda}} \ \ (\because -\log x \geq 1-x) \\
&amp;amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i} \delta_{i} f_{i}(x,y) + 1 - \frac{\sum_{x,y}\exp\left[ \sum_{i}(\lambda_{i} + \delta_{i})f_{i}(x,y) \right]}{\sum_{x,y}\exp\left[ \sum_{i}\lambda_{i}f_{i}(x,y) \right]} \\
&amp;amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i} \delta_{i} f_{i}(x,y) + 1 - \frac{Z_{\Lambda}\sum_{x,y}P_{\Lambda}(x,y)\exp\left[ \sum_{i}\delta_{i}f_{i}(x,y) \right]}{Z_{\Lambda} \sum_{x,y}P_{\Lambda}(x,y)} \\
&amp;amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i} \delta_{i} f_{i}(x,y) + 1 - \sum_{x,y}P_{\Lambda}(x,y)\exp\left[ \sum_{i}\delta_{i}f_{i}(x,y) \right]
\end{align*}
&lt;/div&gt;
&lt;p&gt;素性&lt;span class="math"&gt;\(f_{i}(x,y)\)&lt;/span&gt;の&lt;span class="math"&gt;\(i\)&lt;/span&gt;についての和&lt;span class="math"&gt;\(f^{\#}(x,y) = \sum_{i=1}^{n}f_{i}(x,y)\)&lt;/span&gt;を用いると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
L(P_{\Lambda+\Delta})-L(P_{\Lambda}) = \sum_{x,y} \tilde{P}(x,y) \sum_{i} \delta_{i} f_{i}(x,y) + 1 - \sum_{x,y}P_{\Lambda}(x,y)\exp\left[ \sum_{i}\frac{f_{i}(x,y)}{f^{\#}(x,y)}\delta_{i}f^{\#}(x,y) \right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と書ける。今&lt;span class="math"&gt;\(f_{i}(x,y)/f^{\#}(x,y)\)&lt;/span&gt;は確率分布となることから、&lt;span class="math"&gt;\(\sum_{i}\frac{f_{i}(x,y)}{f^{\#}(x,y)}\delta_{i}f^{\#}(x,y)\)&lt;/span&gt;は&lt;span class="math"&gt;\(\delta_{i}f^{\#}(x,y)\)&lt;/span&gt;についての平均と読み取れる。更に&lt;span class="math"&gt;\(\exp\)&lt;/span&gt;は明らかに凸関数であることから、イェンセンの不等式&lt;span class="math"&gt;\(\exp(E[X]) \leq E[\exp(X)]\)&lt;/span&gt;を用いて最終的な下限の式を得る。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
L(P_{\Lambda+\Delta})-L(P_{\Lambda}) &amp;amp;\geq \sum_{x,y} \tilde{P}(x,y) \sum_{i} \delta_{i} f_{i}(x,y) + 1 - \sum_{x,y}P_{\Lambda}(x,y)\sum_{i}\frac{f_{i}(x,y)}{f^{\#}(x,y)}\exp\left[ \delta_{i}f^{\#}(x,y) \right] \\
&amp;amp;= A(\Lambda, \Delta)
\end{align*}
&lt;/div&gt;
&lt;p&gt;次に&lt;span class="math"&gt;\(A(\Lambda, \Delta)\)&lt;/span&gt;を&lt;span class="math"&gt;\(\delta_{i}\)&lt;/span&gt;で偏微分することで下限の最大化を考える。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\frac{\partial A(\Lambda, \Delta)}{\partial \delta_{i}} &amp;amp;= \sum_{x,y} \tilde{P}(x,y) f_{i}(x,y) - \sum_{x,y} P_{\Lambda}(x,y) f_{i}(x,y) \exp \left[ \delta_{i}f^{\#}(x,y) \right] \\
&amp;amp;= E_{\tilde{P}}[f_{i}] - \sum_{x,y} P_{\Lambda}(x,y) f_{i}(x,y) \exp \left[ \delta_{i}f^{\#}(x,y) \right]
\end{align*}
&lt;/div&gt;
&lt;p&gt;この式を&lt;span class="math"&gt;\(0\)&lt;/span&gt;とおき&lt;span class="math"&gt;\(\delta_{i}\)&lt;/span&gt;について解くことで変化量を求める事ができる。この式は&lt;span class="math"&gt;\(\delta_{i}\)&lt;/span&gt;について閉じた形をしていないので、基本的には数値解析によって極値を求める。しかし、もしも任意の&lt;span class="math"&gt;\((x,y)\)&lt;/span&gt;に対し
&lt;span class="math"&gt;\(f^{\#}(x,y) = C\)&lt;/span&gt;（定数）となるならば、&lt;span class="math"&gt;\(\delta_{i}\)&lt;/span&gt;について解く事ができ、次の結果を得る。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
&amp;amp; E_{\tilde{P}}[f_{i}] - \sum_{x,y} P_{\Lambda}(x,y) f_{i}(x,y) \exp \left[ \delta_{i}f^{\#}(x,y) \right] = 0 \\
&amp;amp;\implies \exp \left[C \delta_{i} \right] \sum_{x,y} P_{\Lambda}(x,y) f_{i}(x,y) = E_{\tilde{P}}[f_{i}] \iff \exp \left[C \delta_{i} \right] = \frac{E_{\tilde{P}}[f_{i}]}{E_{P}[f_{i}]} \\
&amp;amp;\iff \delta_{i} = \frac{1}{C} \log \left( \frac{E_{\tilde{P}}[f_{i}]}{E_{P}[f_{i}]} \right)
\end{align*}
&lt;/div&gt;
&lt;p&gt;任意の&lt;span class="math"&gt;\((x,y)\)&lt;/span&gt;で&lt;span class="math"&gt;\(f^{\#}(x,y)\)&lt;/span&gt;が定数にならない場合でも、実は&lt;span class="math"&gt;\(C = \displaystyle\max_{x,y} f^{\#}(x,y)\)&lt;/span&gt;とし、新しい素性&lt;span class="math"&gt;\(f_{n+1}(x,y)\)&lt;/span&gt;を&lt;span class="math"&gt;\(f_{n+1}(x,y) = C - f^{\#}(x,y)\)&lt;/span&gt;とおけば、変更後の和&lt;span class="math"&gt;\(f^{\#\prime}(x,y)\)&lt;/span&gt;は&lt;span class="math"&gt;\(f^{\#\prime}(x,y)=C\)&lt;/span&gt;となる事が知られている。&lt;span class="math"&gt;\(f^{\#\prime}(x,y)\)&lt;/span&gt;について検算を行ってみると ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
f^{\#\prime}(x,y) &amp;amp;= \sum_{i=1}^{n+1} f_{i}(x,y) = \sum_{i=1}^{n} f_{i}(x,y) + f_{n+1}(x,y)  \\
&amp;amp;=  f^{\#}(x,y) + C - f^{\#}(x,y) = C
\end{align*}
&lt;/div&gt;
&lt;p&gt;となって、定数&lt;span class="math"&gt;\(C\)&lt;/span&gt;を取ることが確かめられた。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id12"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id48"&gt;条件付き最大エントロピーモデル&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;前節までのモデルはあるパターン&lt;span class="math"&gt;\((x,y)\)&lt;/span&gt;を生成する結合確率を表現しているが、応用上は何らかの入力&lt;span class="math"&gt;\(x\)&lt;/span&gt;に対して出力&lt;span class="math"&gt;\(y\)&lt;/span&gt;の結果を得たいというケースが多い。例えば、再び単語予測の例を挙げると、一つ前までの単語を&lt;span class="math"&gt;\(x\)&lt;/span&gt;として入力として、今の単語&lt;span class="math"&gt;\(y\)&lt;/span&gt;を予測するというタスクである。そのような場合はモデルの条件付き確率&lt;span class="math"&gt;\(P(y|x)\)&lt;/span&gt;が用いられる。このモデルは&lt;span class="math"&gt;\(y\)&lt;/span&gt;の識別を行うので生成識別モデルと呼ばれ、条件付き最大エントロピーモデルは CRF(Conditional
Random Fields、条件付き確率場 ) のサブクラスとして捉えられる。&lt;/p&gt;
&lt;p&gt;条件付き最大エントロピーモデルの確率分布&lt;span class="math"&gt;\(P_{\Lambda}(y|x)\)&lt;/span&gt;は、&lt;span class="math"&gt;\(P_{\Lambda}(x,y)\)&lt;/span&gt;とベイズの定理から得られる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
P_{\Lambda}(y|x) &amp;amp;= \frac{P_{\Lambda}(x,y)}{P_{\Lambda}(x)} \\
&amp;amp;= \frac{\exp\left[ \sum_{i}\lambda_{i}f_{i}(x,y) \right]}{Z_{\Lambda}} \left( \sum_{y} \frac{\exp\left[ \sum_{i}\lambda_{i}f_{i}(x,y) \right]}{Z_{\Lambda}} \right)^{-1} \\
&amp;amp;= \frac{1}{Z_{\Lambda}(x)} \exp\left[ \sum_{i}\lambda_{i}f_{i}(x,y) \right] \\
Z_{\Lambda}(x) &amp;amp;= \sum_{y}\exp\left[\sum_{i}\lambda_{i}f_{i}(x,y)\right]
\end{align*}
&lt;/div&gt;
&lt;p&gt;このモデルを用いた素性の平均&lt;span class="math"&gt;\(E_{P}[f_{i}]\)&lt;/span&gt;は次の様に計算できる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
E_{P}[f_{i}] &amp;amp;= \sum_{x,y} P(x,y) f_{i}(x,y) = \sum_{x,y} P(y|x)P(x)f_{i}(x,y) \\
&amp;amp;= \sum_{x} P(x) \sum_{y} P(y|x) f_{i}(x,y)
\end{align*}
&lt;/div&gt;
&lt;p&gt;外側の&lt;span class="math"&gt;\(P(x)\)&lt;/span&gt;の和は、考えうる全ての入力&lt;span class="math"&gt;\(x \in X\)&lt;/span&gt;についての和を取らねばならず、その計算は現実的に不可能である。従って経験確率による近似&lt;span class="math"&gt;\(P(x) \approx \tilde{P}(x)\)&lt;/span&gt;を用いて、平均は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
E_{P}[f_{i}] \approx \sum_{x}\tilde{P}(x) \sum_{y} P(y|x) f_{i}(x,y)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とする。この近似を用いることで、&lt;span class="math"&gt;\(x\)&lt;/span&gt;については学習データに現れるものだけの和を取ればよく、また&lt;span class="math"&gt;\(y\)&lt;/span&gt;についても素性関数が非零の時のみ和を取れば良ため、計算の効率化が望める。&lt;/p&gt;
&lt;p&gt;平均だけでなく、正規化項&lt;span class="math"&gt;\(Z_{\Lambda}(x)\)&lt;/span&gt;の計算もボトルネックな部分であり、効率化が望まれる。そこで、文献 &lt;a class="footnote-reference" href="#id31" id="id13"&gt;[5]&lt;/a&gt;  &lt;a class="footnote-reference" href="#id32" id="id14"&gt;[6]&lt;/a&gt; による効率的な正規化項の計算手法を見ていく。まず、素性関数の集合&lt;span class="math"&gt;\({\cal F}\)&lt;/span&gt;を次の 2 つに分割する :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
{\cal F}_{m} &amp;amp;= \{ f_{i} | \forall{w,x,y} \ f_{i}(x,y) = f_{i}(w,y) \} \ \ \text{（周辺素性 (marginalized feature) の集合）} \\
{\cal F}_{c} = {\cal F}_{m}^{c} &amp;amp;= \{ f_{i} | \exists{w,x,y} \ f_{i}(x,y) \neq f_{i}(w,y) \} \ \ \text{（条件付き素性 (conditional feature) の集合）}
\end{align*}
&lt;/div&gt;
&lt;p&gt;周辺素性は&lt;span class="math"&gt;\(y\)&lt;/span&gt;の値のみによって決まる素性であり、&lt;span class="math"&gt;\(y\)&lt;/span&gt;の関数として捉えられる。集合演算の性質により、&lt;span class="math"&gt;\({\cal F}\_{m} \cap {\cal F}_{c} = \emptyset\)&lt;/span&gt;は自明に成り立つ。次に、&lt;span class="math"&gt;\(y\)&lt;/span&gt;の値域&lt;span class="math"&gt;\(Y\)&lt;/span&gt;についても次の分割を行う :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
Y_{m} &amp;amp;= \{ y | \exists f_{i} \in {\cal F}_{m} \ f_{i}(y) \neq 0 \} \ \ \text{（周辺素性が活性化される $Y$ の要素）} \\
Y(x) &amp;amp;= \{ y | \exists f_{i} \in {\cal F}_{c} \ f_{i}(x,y) \neq 0 \} \ \ \text{（$x$ を固定した時に , 条件付き素性が活性化される $Y$ の要素）}
\end{align*}
&lt;/div&gt;
&lt;p&gt;定義より&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
Y_{m}^{c} = \{ y | \forall{f_{i}} \in {\cal F}_{m} \ f_{i}(y) = 0 \}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;（どの周辺素性に対しても活性化されない&lt;span class="math"&gt;\(Y\)&lt;/span&gt;の要素）は自明に成り立つ。また、一般には&lt;span class="math"&gt;\(Y_{m} \cap Y(x) \neq \emptyset\)&lt;/span&gt;である。即ち周辺素性と条件付き素性を同時に活性化させる&lt;span class="math"&gt;\(Y\)&lt;/span&gt;の要素は存在する。&lt;/p&gt;
&lt;p&gt;以上の集合分割を考慮しつつ、正規化項&lt;span class="math"&gt;\(Z_{\Lambda}(x) = \sum_{y}\exp\left[\sum_{i}\lambda_{i}f_{i}(x,y)\right]\)&lt;/span&gt;の計算を考えていくが、表記の簡略化の為、文献と同じように次の表記を用いる :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
z(y|x) = \exp\left[ \sum_{i}\lambda_{i} f_{i}(x,y) \right] \ ,\ z(y) = \exp\left[ \sum_{f_{i} \in {\cal F}_{m}} \lambda_{i} f_{i}(y) \right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;正規化項&lt;span class="math"&gt;\(Z_{\Lambda}(x)\)&lt;/span&gt;の計算式は次のように展開される。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
Z_{\Lambda}(x) &amp;amp;= \sum_{y \in Y}z(y|x) \\
&amp;amp;= \sum_{y \in Y_{m}^{c} \cap Y(x)^{c}} z(y|x) + \sum_{y \in Y_{m} \cap Y(x)^{c}} z(y|x) + \sum_{y \in Y(x)} z(y|x) \\
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
y \in Y(x)^{c} &amp;amp;\implies z(y|x) = z(y) \\
&amp;amp;\because z(y|x) = \exp\left[ \sum_{f_{i} \in {\cal F}_{m}} \lambda_{i} f_{i}(y) + \sum_{f_{i} \in {\cal F}_{c}} \lambda_{i} 0 \right] = \exp \left[ \sum_{f_{i} \in {\cal F}_{m}} \lambda_{i} f_{i}(y) \right] = z(y)
\end{align*}
&lt;/div&gt;
&lt;p&gt;が成立するので、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
Z_{\Lambda}(x) =  \sum_{y \in Y_{m}^{c} \cap Y(x)^{c}} z(y) + \sum_{y \in Y_{m} \cap Y(x)^{c}} z(y) +\sum_{y \in Y(x)} z(y|x)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となり、さらに集合の包含関係に注目すれば、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\sum_{y \in Y} z(y) &amp;amp;= \sum_{y \in Y_{m} \cap Y(x)^{c}} z(y) + \sum_{y \in Y_{m}^{c} \cap Y(x)^{c}} z(y) + \sum_{y \in Y(x)} z(y) \\
&amp;amp;= \sum_{y \in Y_{m}} z(y) + \sum_{y \in Y_{m}^{c}} z(y) \\
\therefore \sum_{y \in Y_{m} \cap Y(x)^{c}} z(y) + \sum_{y \in Y_{m}^{c} \cap Y(x)^{c}} z(y) &amp;amp;= \sum_{y \in Y_{m}} z(y) + \sum_{y \in Y_{m}^{c}} z(y) - \sum_{y \in Y(x)} z(y)
\end{align*}
&lt;/div&gt;
&lt;p&gt;が成立するので、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
Z_{\Lambda}(x) = \sum_{y \in Y_{m}^{c}} z(y) + \sum_{y \in Y_{m}} z(y) + \sum_{y \in Y(x)} \left\{ z(y|x) -z(y) \right\}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となり、更に&lt;span class="math"&gt;\(Y_{m}^{c}\)&lt;/span&gt;の要素の性質&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
y \in Y_{m}^{c} &amp;amp;\implies z(y) = 1 \\
&amp;amp;\because z(y) = \exp\left[ \sum_{f_{i} \in {\cal F}_{m}} \lambda 0 \right] = 1
\end{align*}
&lt;/div&gt;
&lt;p&gt;を用いて、次の最終結果を得る。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
Z_{\Lambda}(x) &amp;amp;= \sum_{y \in Y_{m}^{c}} 1 + \sum_{y \in Y_{m}} z(y) + \sum_{y \in Y(x)} \left\{ z(y|x) -z(y) \right\} \\
&amp;amp;= |Y-Y_{m}| + \sum_{y \in Y_{m}}z(y) + \sum_{y \in Y(x)} \left\{ z(y|x) -z(y) \right\}
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで&lt;span class="math"&gt;\(Y-Y_{m}=Y \cap Y_{m}^{c}\)&lt;/span&gt;は集合演算の意味での差である。この計算式は、第 1 項と第 2 項は予め計算しておくことができ、しかも第 3 項については&lt;span class="math"&gt;\(Y\)&lt;/span&gt;の部分集合&lt;span class="math"&gt;\(Y(x)\)&lt;/span&gt;の和を考えれば良い。結果、ナイーブな計算（計算量&lt;span class="math"&gt;\(O(|X||Y|)\)&lt;/span&gt;）を行うよりも効率的（計算量&lt;span class="math"&gt;\(O(|X||Y(x)|+|X|)\)&lt;/span&gt;）に計算を行うことができる。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id15"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id49"&gt;素性の自動選択&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;前節までは、最大エントロピーモデルの学習について考えてきたが、モデルの構成要素となる素性については触れてなかった。観測された経験確率分布&lt;span class="math"&gt;\(\tilde{P}(x,y)\)&lt;/span&gt;に対し、素性の組み合わせによって実現可能な最大尤度が異なり、従って尤度が最大になる素性集合&lt;span class="math"&gt;\({\cal F}\)&lt;/span&gt;を選び出さなければならない。&lt;/p&gt;
&lt;p&gt;しかし素性の候補となる集合&lt;span class="math"&gt;\({\cal F}_{0}\)&lt;/span&gt;は非常に大きくなる為に、網羅的に全ての素性の組み合わせを試していくのは現実的に不可能である。また、サンプルで出現頻度が高い素性を選択する手法も存在するが、これでは尤度を厳密に最大化できない。そこで、逐次的にモデルの尤度が増加する様に素性を追加する手法が基本的に用いられており、その手順の概要は以下の様になる。&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;モデルの素性集合&lt;span class="math"&gt;\({\cal F}\)&lt;/span&gt;を空集合とする :
&lt;span class="math"&gt;\({\cal F} \leftarrow \emptyset\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;（反復スケーリング法等の学習手法によって）素性集合&lt;span class="math"&gt;\({\cal F}\)&lt;/span&gt;における最大尤度モデル&lt;span class="math"&gt;\(P_{\cal F}\)&lt;/span&gt;を得る。&lt;/li&gt;
&lt;li&gt;素性集合の候補&lt;span class="math"&gt;\({\cal F}\_{0}\)&lt;/span&gt;の各要素&lt;span class="math"&gt;\(f_{0} \in {\cal F}_{0}\)&lt;/span&gt;について、以下を行う。
1.
素性を加えたモデルを学習し&lt;span class="math"&gt;\(P_{{\cal F} \cup f_{0}}\)&lt;/span&gt;を得る。
2. 対数尤度の増分&lt;span class="math"&gt;\(\Delta L({\cal F}, f_{0})\)&lt;/span&gt;を計算する :
&lt;span class="math"&gt;\(\Delta L({\cal F}, f_{0}) \leftarrow L(P_{{\cal F} \cup f_{0}}) - L(P_{\cal F})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;最大の増分&lt;span class="math"&gt;\(\Delta L({\cal F}, \hat{f})\)&lt;/span&gt;を与える&lt;span class="math"&gt;\(\hat{f} = \underset{f \in {\cal F}_{0}}{\rm argmax}\ \Delta L({\cal F}, f)\)&lt;/span&gt;を選び出し、素性集合に加える :
&lt;span class="math"&gt;\({\cal F} \leftarrow {\cal F} \cup \hat{f}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;最大増分がある閾値以下になったら終了し、それ以外は 2. に戻る。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;逐次的に計算が行える為に手続き的に実行しやすいものの、結局手順 3,4 において&lt;span class="math"&gt;\({\cal F}_{0}\)&lt;/span&gt;を走査しているので依然として膨大な計算量が必要になる。文献 &lt;a class="footnote-reference" href="#id33" id="id16"&gt;[7]&lt;/a&gt;  &lt;a class="footnote-reference" href="#id34" id="id17"&gt;[8]&lt;/a&gt; では対数尤度の増分を近似的に求める手法を述べているが、それでも本質的に計算量を削減できたとは言えず、効率的な素性選択の手法については研究の対象となっていた &lt;a class="footnote-reference" href="#id35" id="id18"&gt;[9]&lt;/a&gt;  &lt;a class="footnote-reference" href="#id36" id="id19"&gt;[10]&lt;/a&gt; 。&lt;/p&gt;
&lt;p&gt;ここでは元の文献 &lt;a class="footnote-reference" href="#id37" id="id20"&gt;[11]&lt;/a&gt;  &lt;a class="footnote-reference" href="#id38" id="id21"&gt;[12]&lt;/a&gt; に述べられていた、増分の近似による手法を見ていく。近似の仮定としては、元のモデル&lt;span class="math"&gt;\(P_{\cal F}\)&lt;/span&gt;とそのパラメタ集合&lt;span class="math"&gt;\(\Lambda\)&lt;/span&gt;に&lt;span class="math"&gt;\(f \in {\cal F}\)&lt;/span&gt;とそれに付随するパラメタ&lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;を加えたモデル&lt;span class="math"&gt;\(P_{{\cal F} \cup f}\)&lt;/span&gt;においても、最大尤度を与える元のパラメタ&lt;span class="math"&gt;\(\Lambda\)&lt;/span&gt;は変化しないというものである。実際には素性を加える事で最大尤度を与えるパラメタ&lt;span class="math"&gt;\(\Lambda\)&lt;/span&gt;は変化するが、この変化を無視することでモデル&lt;span class="math"&gt;\(P_{{\cal F} \cup f}\)&lt;/span&gt;の最大尤度&lt;span class="math"&gt;\(L(P_{{\cal F} \cup f})\)&lt;/span&gt;の計算を回避する。素性を追加することにより尤度は増えこそすれ減ることはないので（&lt;span class="math"&gt;\(\because\)&lt;/span&gt;経験分布に適合しない素性に対しては学習の結果&lt;span class="math"&gt;\(\alpha = 0\)&lt;/span&gt;となり、元のモデルと一致するので尤度増分は 0）
、近似的増分を最大にする&lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;を探索する問題に帰着される。&lt;/p&gt;
&lt;p&gt;仮定の下で、素性集合&lt;span class="math"&gt;\({\cal F} \cup f\)&lt;/span&gt;に対するモデル&lt;span class="math"&gt;\(P_{{\cal F} \cup f}^{\alpha}\)&lt;/span&gt;の確率分布は次の様に書ける。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
P_{ {\cal F} \cup f}^{\alpha}(y|x) &amp;amp;= \frac{1}{Z_{\alpha}(x)} P_{\cal F} (y|x) \exp \left[ \alpha f(x,y) \right] \\
Z_{\alpha}(x) &amp;amp;= \sum_{y} P_{\cal F}(y|x) \exp \left[ \alpha f(x,y) \right]
\end{align*}
&lt;/div&gt;
&lt;p&gt;対数尤度の近似的増分&lt;span class="math"&gt;\(G_{{\cal F} \cup f}(\alpha)\)&lt;/span&gt;は ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
G_{{\cal F} \cup f}(\alpha) &amp;amp;= L(P_{{\cal F}\cup f}^{\alpha}) - L(P_{\cal F}) \\
&amp;amp;= \sum_{x,y} \tilde{P}(x,y) \log P_{{\cal F} \cup f}^{\alpha}(x,y) - \sum_{x,y} \tilde{P}(x,y) \log P_{\cal F}(x,y) \\
&amp;amp;= \sum_{x,y} \tilde{P}(x,y) \left\{ \log P_{\cal F}(x,y) + \alpha f(x,y) - \log Z_{\alpha}(x) - \log P_{\cal F}(x,y) \right\} \\
&amp;amp;= \alpha \sum_{x,y} \tilde{P}(x,y) f(x,y) - \sum_{x} \log Z_{\alpha}(x) \sum_{y} \tilde{P}(x,y) \\
&amp;amp;= \alpha E_{\tilde{P}}[f] - \sum_{x} \tilde{P}(x) \log Z_{\alpha}(x)
\end{align*}
&lt;/div&gt;
&lt;p&gt;となる、&lt;span class="math"&gt;\(G_{{\cal F} \cup f}(0) = 0\)&lt;/span&gt;は&lt;span class="math"&gt;\(Z_{0}(x) = 1\)&lt;/span&gt;より容易に確かめられる。増分最大化の為、偏微分&lt;span class="math"&gt;\(\frac{\partial G_{{\cal F} \cup f}}{\partial \alpha} = G_{{\cal F} \cup f}^{\prime}(\alpha)\)&lt;/span&gt;を計算すると ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
G_{{\cal F} \cup f}^{\prime}(\alpha) &amp;amp;= E_{\tilde{P}}[f] - \sum_{x} P(x) \frac{\partial \log Z_{\alpha}(x)}{\partial \alpha} \\
&amp;amp;= E_{\tilde{P}}[f] - \sum_{x} \tilde{P}(x) \frac{1}{Z_{\alpha}(x)} \sum_{y} P_{\cal F}(y|x) \exp\left[ \alpha f(x,y) \right] f(x,y) \\
&amp;amp;= E_{\tilde{P}}[f] - \sum_{x} \tilde{P}(x) \sum_{y} P_{ {\cal F} \cup f}^{\alpha}(y|x) f(x,y)\ \  (= E_{\tilde{P}}[f] - E_{P_{ {\cal F} \cup f}}[f]) \\
&amp;amp;= E_{\tilde{P}}[f] - \sum_{x} \tilde{P}(x) Q_{ {\cal F} \cup f}^{\alpha} (f|x)
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで、文献にもあるように&lt;span class="math"&gt;\(Q_{ {\cal F} \cup f}^{\alpha} (h|x) = \sum_{y} P_{ {\cal F} \cup f}^{\alpha}(y|x) h(x,y)\)&lt;/span&gt;（分布&lt;span class="math"&gt;\(P_{ {\cal F} \cup f}\)&lt;/span&gt;による、&lt;span class="math"&gt;\(h\)&lt;/span&gt;の&lt;span class="math"&gt;\(y\)&lt;/span&gt;における平均）とおいている。&lt;span class="math"&gt;\(G_{{\cal F} \cup f}^{\prime}(0)\)&lt;/span&gt;の値は&lt;span class="math"&gt;\(P_{ {\cal F} \cup f}^{0}(y|x) = P_{\cal F}(y|x)\)&lt;/span&gt;により&lt;span class="math"&gt;\(G_{{\cal F}\cup f}^{\prime}(0) = E_{\tilde{P}}[f] - E_{P_{\cal F}}[f]\)&lt;/span&gt;となる。更に 2 階微分&lt;span class="math"&gt;\(G_{{\cal F} \cup f}^{\prime \prime}(\alpha)\)&lt;/span&gt;を計算すると ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
G_{{\cal F} \cup f}^{\prime \prime}(\alpha) &amp;amp;= - \sum_{x} P(x) \frac{1}{Z_{\alpha}^{2}(x)} \left[ \left\{ \sum_{y} P_{\cal F}(y|x) \exp\left[ \alpha f(x,y) \right] f^{2}(x,y) \right\} Z_{\alpha}(x) \right. \\
&amp;amp;  \left. - \left\{ \sum_{y} P_{\cal F}(y|x)\exp\left[ \alpha f(x,y) \right] f(x,y) \right\}^{2} \right] \\
&amp;amp;= - \sum_{x} \tilde{P}(x) \left[ Q_{ {\cal F} \cup f}^{\alpha} (f^{2}|x) - \left\{Q_{ {\cal F} \cup f}^{\alpha}(f|x) \right\}^{2} \right] \\
&amp;amp;= - \sum_{x} \tilde{P}(x) Q_{ {\cal F} \cup f}^{\alpha} \left( (f - Q_{ {\cal F} \cup f}^{\alpha}(f|x))^{2} | x \right)
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで最下段の式変形には、分散と平均の関係&lt;span class="math"&gt;\(E[(X-E[X])^{2}] = E[X^{2}] - \{E[X]\}^{2}\)&lt;/span&gt;を用いている。&lt;span class="math"&gt;\((f - Q_{ {\cal F} \cup f}^{\alpha}(f|x))^{2} \geq 0\)&lt;/span&gt;より、&lt;span class="math"&gt;\(G_{{\cal F} \cup f}^{\prime \prime}(\alpha) \leq 0\)&lt;/span&gt;が成立し、&lt;span class="math"&gt;\(G_{{\cal F} \cup f}(\alpha)\)&lt;/span&gt;は上に凸な関数であり、極大値がそのまま大域的な最大値となる事が分かる。&lt;/p&gt;
&lt;p&gt;上述の議論により、&lt;span class="math"&gt;\(G_{{\cal F} \cup f}^{\prime}(\alpha^{\ast}) = 0\)&lt;/span&gt;を満たす&lt;span class="math"&gt;\(\alpha^{\ast}\)&lt;/span&gt;を得れば良いことになるが、解くべき式が&lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;について閉じた形をしていない為、数値解析的な手法を用いることになる。文献 &lt;a class="footnote-reference" href="#id39" id="id22"&gt;[13]&lt;/a&gt;  &lt;a class="footnote-reference" href="#id40" id="id23"&gt;[14]&lt;/a&gt;  &lt;a class="footnote-reference" href="#id41" id="id24"&gt;[15]&lt;/a&gt; によると、&lt;span class="math"&gt;\(G_{{\cal F} \cup f}^{\prime}(\alpha)\)&lt;/span&gt;は&lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;に対して凸関数ではないが、&lt;span class="math"&gt;\(\exp(\alpha)\)&lt;/span&gt;に関しては下に凸の減少関数、かつ&lt;span class="math"&gt;\(\exp(-\alpha)\)&lt;/span&gt;に関しては上に凸の増加関数となる事が示されているので、&lt;span class="math"&gt;\(\exp(\alpha)、\exp(-\alpha)\)&lt;/span&gt;の数列に対してニュートン法を適用する事を考える。偏微分の連鎖律を用いることで ,&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\frac{\partial G_{{\cal F} \cup f}^{\prime}(\alpha)}{\partial \exp(\alpha)}  &amp;amp;= \frac{\partial G_{{\cal F} \cup f}^{\prime}(\alpha)}{\partial \alpha} \frac{\partial \alpha}{\partial \exp(\alpha)} \\
&amp;amp;= \frac{\log t}{t} G_{{\cal F} \cup f}^{\prime \prime}(\alpha) \ \ (t = \exp(\alpha)) \\
&amp;amp;= \frac{1}{t} G_{{\cal F} \cup f}^{\prime \prime}(\alpha) = \exp(-\alpha) G_{{\cal F} \cup f}^{\prime \prime}(\alpha)
\end{align*}
&lt;/div&gt;
&lt;p&gt;が成り立つので、ニュートン法の更新則は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\exp(\alpha_{n+1}) &amp;amp;= \exp(\alpha_{n}) - \frac{G_{{\cal F} \cup f}^{\prime}(\alpha_{n})}{\frac{\partial G_{{\cal F} \cup f}^{\prime}(\alpha_{n})}{\partial \exp(\alpha_{n})}} = \exp(\alpha_{n}) \left[ 1 - \frac{G_{{\cal F} \cup f}^{\prime}(\alpha_{n})}{G_{{\cal F} \cup f}^{\prime\prime}(\alpha_{n})} \right] \\
\iff \alpha_{n+1} &amp;amp;= \alpha_{n} + \log \left[ 1 - \frac{G_{{\cal F} \cup f}^{\prime}(\alpha_{n})}{G_{{\cal F} \cup f}^{\prime\prime}(\alpha_{n})} \right] \\
\exp(-\alpha_{n+1}) &amp;amp;= \exp(-\alpha_{n}) - \frac{G_{{\cal F} \cup f}^{\prime}(\alpha_{n})}{\frac{\partial G_{{\cal F} \cup f}^{\prime}(\alpha_{n})}{\partial \exp(-\alpha_{n})}} = \exp(-\alpha_{n}) \left[ 1 + \frac{G_{{\cal F} \cup f}^{\prime}(\alpha_{n})}{G_{{\cal F} \cup f}^{\prime\prime}(\alpha_{n})} \right] \\
\iff \alpha_{n+1} &amp;amp;= \alpha_{n} - \log \left[ 1 + \frac{G_{{\cal F} \cup f}^{\prime}(\alpha_{n})}{G_{{\cal F} \cup f}^{\prime\prime}(\alpha_{n})} \right]
\end{align*}
&lt;/div&gt;
&lt;p&gt;となる。最適値&lt;span class="math"&gt;\(\alpha^{\ast}\)&lt;/span&gt;が&lt;span class="math"&gt;\(\alpha^{\ast} &amp;gt; 0\)&lt;/span&gt;の場合（&lt;span class="math"&gt;\(E_{\tilde{P}}[f] &amp;gt; E_{P_{\cal F}}[f]\)&lt;/span&gt; &lt;a class="footnote-reference" href="#id42" id="id25"&gt;[16]&lt;/a&gt; ）には上の更新式を用いれば良く、&lt;span class="math"&gt;\(\alpha^{\ast} &amp;lt; 0\)&lt;/span&gt;の場合（&lt;span class="math"&gt;\(E_{\tilde{P}}[f] &amp;lt; E_{P_{\cal F}}[f]\)&lt;/span&gt;）には下の更新式を用いれば良い。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id26"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id50"&gt;脚注・参考文献&lt;/a&gt;&lt;/h2&gt;
&lt;table class="docutils footnote" frame="void" id="id27" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;北研二、辻井潤一、&amp;quot; 確率的言語モデル &amp;quot;、東京大学出版会、1999&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id28" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id3"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;高村大也、奥村学、&amp;quot; 言語処理のための機械学習入門 &amp;quot;、コロナ社、2010&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id29" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id4"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;高橋治久、堀田一弘、&amp;quot; 学習理論 &amp;quot; コロナ社、2009&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id30" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id9"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;高橋治久、堀田一弘、&amp;quot; 学習理論 &amp;quot; コロナ社、2009&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id31" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id13"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;北研二、辻井潤一、&amp;quot; 確率的言語モデル &amp;quot;、東京大学出版会、1999&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id32" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id14"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Wu, Jun, and Sanjeev Khudanpur, “Efficient training methods for
maximum entropy language modeling.” INTERSPEECH. 2000.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id33" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id16"&gt;[7]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;北研二、辻井潤一、&amp;quot; 確率的言語モデル &amp;quot;、東京大学出版会、1999&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id34" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id17"&gt;[8]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Berger, Adam L., Vincent J, Della Pietra, and Stephen A. Della
Pietra. “A maximum entropy approach to natural language processing.”
Computational linguistics 22.1 (1996): 39-71.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id35" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id18"&gt;[9]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Zhou, Yaqian, et al.&amp;nbsp;“A fast algorithm for feature selection in
conditional maximum entropy modeling.” Proceedings of the 2003
conference on Empirical methods in natural language processing.
Association for Computational Linguistics, 2003.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id36" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id19"&gt;[10]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;谷垣宏一 , 渡邉圭輔 , and 石川泰 ,
`` 最大エントロピー法による発話理解のための効率的モデル構築 (&amp;lt; 特集 &amp;gt;
音声言語情報処理とその応用 ).’’ 情報処理学会論文誌 43.7 (2002):
2138-2146.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id37" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id20"&gt;[11]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;北研二、辻井潤一、&amp;quot; 確率的言語モデル &amp;quot;、東京大学出版会、1999&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id38" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id21"&gt;[12]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Berger, Adam L., Vincent J, Della Pietra, and Stephen A. Della
Pietra. “A maximum entropy approach to natural language processing.”
Computational linguistics 22.1 (1996): 39-71.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id39" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id22"&gt;[13]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;北研二、辻井潤一、&amp;quot; 確率的言語モデル &amp;quot;、東京大学出版会、1999&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id40" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id23"&gt;[14]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Berger, Adam L., Vincent J, Della Pietra, and Stephen A. Della
Pietra. “A maximum entropy approach to natural language processing.”
Computational linguistics 22.1 (1996): 39-71.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id41" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id24"&gt;[15]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Pietra, Stephen Della, Vincent Della Pietra, and John Lafferty.
“Inducing features of random fields.” Pattern Analysis and Machine
Intelligence、IEEE Transactions on 19.4 (1997): 380-393.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id42" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id25"&gt;[16]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;span class="math"&gt;\(G_{{\cal F} \cup f}^{\prime}(\alpha)\)&lt;/span&gt;は&lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;に関して単調減少するので、&lt;span class="math"&gt;\(G_{{\cal F} \cup f}^{\prime}(0) = E_{\tilde{P}}[f] - E_{P_{\cal F}}[f]&amp;gt;0\)&lt;/span&gt;ならば、かつその時に限り最適値&lt;span class="math"&gt;\(\alpha^{\ast}\)&lt;/span&gt;は正の値をとる。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="記事"></category><category term="機械学習"></category></entry><entry><title>SVM（サポートベクトルマシン）</title><link href="/svmsapotobekutorumashin.html" rel="alternate"></link><published>2020-04-23T12:30:00+09:00</published><updated>2020-04-23T12:30:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-23:/svmsapotobekutorumashin.html</id><summary type="html">&lt;p class="first last"&gt;SVMの導入のところまで。SVRも一応。カーネル法に関しては触れるだけ。&lt;/p&gt;
</summary><content type="html">&lt;p&gt;&lt;strong&gt;SVM(Support Vector Machine,
サポートベクトルマシン )&lt;/strong&gt;は、深層学習の影に隠れがちではあるものの、現在使われている識別学習モデルの中でも比較的認識性能が優れ、実用に供される事はもちろん、様々な研究でも比較対象となる手法の一つである。&lt;/p&gt;
&lt;p&gt;SVM の大雑把な理論的概要を述べると、SVM は与えられた学習サンプルを最も適切に分離（識別）する境界面（&lt;strong&gt;識別面&lt;/strong&gt;）を発見する手法である。その識別面は凸計画問題に帰着して求める事ができるので、どの様なサンプルにおいても（存在するならば）最適な識別面を構成できる。&lt;/p&gt;
&lt;p&gt;本稿では、最初に基本となる線形 SVM の定式化を行い、次に汎用性をより高めた非線形 SVM とソフトマージン SVM を説明し、最後に SVM を回帰問題に適用した SVR(Support
Vector Regression,
サポートベクトル回帰 ) を説明する。最後に C 言語による実装例を挙げる。&lt;/p&gt;
&lt;p&gt;SVM も知り尽くされており、文献・資料は大量に存在する。ここでは、参考書籍 &lt;a class="footnote-reference" href="#id34" id="id1"&gt;[1]&lt;/a&gt;, &lt;a class="footnote-reference" href="#id35" id="id2"&gt;[2]&lt;/a&gt; を挙げる。&lt;/p&gt;
&lt;div class="contents local topic" id="id3"&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id47"&gt;線形 SVM&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id48"&gt;マージンの定式化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id49"&gt;マージン最大化&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#kkt" id="id50"&gt;KKT 条件&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id51"&gt;非線形 SVM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id13" id="id52"&gt;ソフトマージン SVM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#svr-support-vector-regression" id="id53"&gt;SVR（Support Vector Regression, サポートベクトル回帰）&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#svr" id="id54"&gt;1 ノルム SVR ・双対問題の導出&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id20" id="id55"&gt;2 ノルム SVR ・双対問題の導出&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id22" id="id56"&gt;実装の例&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id23" id="id57"&gt;学習&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id24" id="id58"&gt;学習則の導出&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id27" id="id59"&gt;実装&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id28" id="id60"&gt;制約条件の考慮&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id29" id="id61"&gt;正例と負例の双対係数の和を等しくする&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id30" id="id62"&gt;双対係数は非負&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id31" id="id63"&gt;識別&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id33" id="id64"&gt;脚注&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id47"&gt;線形 SVM&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id48"&gt;マージンの定式化&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;識別の例として、まずは図にあるような、2 次元空間&lt;span class="math"&gt;\(X\times Z\)&lt;/span&gt;に存在する 2 クラスのサンプルデータ（以下サンプル）を仮定する。各クラスは二値のラベル付け&lt;span class="math"&gt;\(y=\{-1, 1\}\)&lt;/span&gt;がなされており、識別面（2 次元空間では直線）&lt;span class="math"&gt;\(ax+bz+c=0\)&lt;/span&gt;の上半領域（&lt;span class="math"&gt;\(ax+bz+c&amp;gt;0\)&lt;/span&gt;）にラベル&lt;span class="math"&gt;\(y=1\)&lt;/span&gt;のサンプルが、下半領域（&lt;span class="math"&gt;\(ax+bz+c&amp;lt;0\)&lt;/span&gt;）にラベル&lt;span class="math"&gt;\(y=-1\)&lt;/span&gt;のサンプルが分布するようにする。&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="2 クラス分離の例 " src="./images/2class_separation.png" /&gt;
&lt;p class="caption"&gt;2 クラス分離の例&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;更に、&lt;span class="math"&gt;\(n\)&lt;/span&gt;次元空間の元（ベクトル）&lt;span class="math"&gt;\(\boldsymbol{x} \in \mathbb{R}^{n}\)&lt;/span&gt;で表されるサンプルに対しても一般化でき、&lt;span class="math"&gt;\(n\)&lt;/span&gt;次元の係数ベクトル&lt;span class="math"&gt;\(\boldsymbol{w} \in \mathbb{R}^{n}\)&lt;/span&gt;を用いることで、
識別面は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \boldsymbol{w}^{\mathsf{T}}\boldsymbol{x} + b = 0
 \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表現できる。ここで&lt;span class="math"&gt;\(b \in \mathbb{R}\)&lt;/span&gt;は切片（しきい値、
バイアス）である。&lt;/p&gt;
&lt;p&gt;概要でも述べたとおり、識別面は異なるラベルが付いたサンプルを互いに分離さえできていれば良いので、識別面の候補は無限に存在してしまう（上の 2 次元の例でも明らかである）。しかし、
その全てが適切な識別面とは限らない。
SVM では、次の 2 点を最適な識別面の条件とする。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;各クラスの、最も識別面に近いサンプル（&lt;strong&gt;サポートベクトル&lt;/strong&gt;）までの距離を最大にする。&lt;/li&gt;
&lt;li&gt;また、 その距離を各クラスで同一にする。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;この 2 点を満たす識別面ならば、
丁度クラス間の中心を区切ることが出来、適切な識別面といえる。
また、図に示す様に、サポートベクトル間の距離を&lt;strong&gt;マージン&lt;/strong&gt;（余白）という。
SVM は、このマージンを最大化することが目的となる。&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt=" マージン " src="./images/margin.png" /&gt;
&lt;p class="caption"&gt;マージン&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;それでは、
マージンの定式化を考える。&lt;span class="math"&gt;\(n\)&lt;/span&gt;次元空間上に&lt;span class="math"&gt;\(N\)&lt;/span&gt;個存在するサンプルを&lt;span class="math"&gt;\(\boldsymbol{x}\_{i} \in \mathbb{R}^{n} \ (i=1, \dots, N)\)&lt;/span&gt;と書き、またそのデータに対応する二値ラベルを&lt;span class="math"&gt;\(y_{i} \in \{-1, 1\}\ (i=1, \dots, N)\)&lt;/span&gt;とかく。全てのサンプルが正しく識別されている時には、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  y_{i}(\boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}_{i} + b) \geq 0 \quad (i = 1, \dots, N)
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が明らかに成立する。
そして、異なる 2 クラスのサポートベクトル&lt;span class="math"&gt;\(\boldsymbol{x}\_{s}, \boldsymbol{x}\_{t}\)&lt;/span&gt;が&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}_{s} + b = l , \quad \boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}_{t} + b = -l\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成立すると仮定する &lt;a class="footnote-reference" href="#id36" id="id6"&gt;[3]&lt;/a&gt; と（&lt;span class="math"&gt;\(l&amp;gt;0\)&lt;/span&gt;）、
&lt;span class="math"&gt;\(\boldsymbol{x}\_{s}\)&lt;/span&gt;と&lt;span class="math"&gt;\(\boldsymbol{x}\_{t}\)&lt;/span&gt;の、識別面に対して平行な距離がマージンとして計算できる。マージンを&lt;span class="math"&gt;\(\gamma\)&lt;/span&gt;と書くと、
平面の単位法ベクトルは&lt;span class="math"&gt;\(\boldsymbol{w}/||\boldsymbol{w}||\)&lt;/span&gt;（&lt;span class="math"&gt;\(||\boldsymbol{w}|| = \sqrt{\boldsymbol{w}^{\mathsf{T}}\boldsymbol{w}}\)&lt;/span&gt;）で与えられるので、マージンは&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  &amp;amp;  \boldsymbol{w}^{\mathsf{T}}(\boldsymbol{x}_{t} + \gamma \frac{\boldsymbol{w}}{||\boldsymbol{w}||}) + b = \boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}_{s} + b \nonumber \\
  &amp;amp;\iff \gamma \frac{\boldsymbol{w}^{\mathsf{T}}\boldsymbol{w}}{||\boldsymbol{w}||} = \gamma ||\boldsymbol{w}|| = (\boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}_{s}+b) - (\boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}_{t}+b) = 2l \nonumber \\
  &amp;amp;\therefore \gamma = \frac{2l}{||\boldsymbol{w}||}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;で求められる。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id49"&gt;マージン最大化&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;前節でも既に述べたが、
SVM の目的はマージン&lt;span class="math"&gt;\(\gamma\)&lt;/span&gt;を最大化することである。単純には&lt;span class="math"&gt;\(\max \gamma\)&lt;/span&gt;と書けるが、
最適化を行いやすくするため、&lt;span class="math"&gt;\(1/\gamma\)&lt;/span&gt;の最小化に置き換え、
&lt;span class="math"&gt;\(l\)&lt;/span&gt;は最適化に関与しないので&lt;span class="math"&gt;\(l=1\)&lt;/span&gt;とし、更に&lt;span class="math"&gt;\(||\boldsymbol{w}||\)&lt;/span&gt;が最小化された時は&lt;span class="math"&gt;\(\boldsymbol{w}^{\mathsf{T}}\boldsymbol{w}\)&lt;/span&gt;も最小化されるので、考えるべき最適化問題は次のように書ける :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  &amp;amp; \max_{\scriptsize \boldsymbol{w}} \gamma = \frac{2l}{||\boldsymbol{w}||} \quad \text{subject to : } y_{i}(\boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}_{i} + b) \geq l \nonumber \\
  &amp;amp;\implies \min_{\scriptsize \boldsymbol{w}} \frac{1}{2} \boldsymbol{w}^{\mathsf{T}}\boldsymbol{w} \quad \text{subject to : } y_{i}(\boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}_{i} + b) \geq 1 \quad (i=1, \dots, N)\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;この最適化問題は、 凸計画問題 &lt;a class="footnote-reference" href="#id37" id="id8"&gt;[4]&lt;/a&gt; であり、不等式制約付き非線形計画問題なので、 KKT 条件 (Karush-Kuhn-Tucker
condition) を用いる。KKT 条件はラグランジェの未定乗数法（等式制約）の一般化であり、次の定理で表される :&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;div class="section" id="kkt"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id50"&gt;KKT 条件&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\boldsymbol{v}^{\star}\)&lt;/span&gt;を&lt;span class="math"&gt;\(f(\boldsymbol{v})\)&lt;/span&gt;に関しての最適化問題の最適解とするならば、次の条件を満たす最適重みベクトル&lt;span class="math"&gt;\(\boldsymbol{\alpha}^{\star}=[\alpha_{1}^{\star}, \cdots, \alpha_{N}^{\star}]^{\mathsf{T}}\ (\alpha_{i} \geq 0)\)&lt;/span&gt;が存在する。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
      \left\{
        \begin{array}{ll}
          \displaystyle\frac{\partial{\cal L}(\boldsymbol{v}^{\star}, \boldsymbol{\alpha}^{\star})}{\partial \boldsymbol{v}} &amp;amp;=  0 \\
          \boldsymbol{\alpha}^{\star\mathsf{T}}\boldsymbol{g}(\boldsymbol{v}^{\star}) &amp;amp;= 0
        \end{array}
        \right.
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで&lt;span class="math"&gt;\(\boldsymbol{g}(\boldsymbol{v})\)&lt;/span&gt;は制約条件式&lt;span class="math"&gt;\(\boldsymbol{g}(\boldsymbol{v}) = [g_{1}(\boldsymbol{v}), \cdots, g_{N}(\boldsymbol{v})]^{\mathsf{T}}\)&lt;/span&gt;,
&lt;span class="math"&gt;\({\cal L}\)&lt;/span&gt;はラグランジアン（ラグランジェ関数）であり以下の様に表される。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
        g_{i}(\boldsymbol{v}) &amp;amp;\geq 0\ \ (i = 1, \dots, N) \\
        {\cal L}(\boldsymbol{v}, \boldsymbol{\alpha}) &amp;amp;= f(\boldsymbol{v}) + \boldsymbol{\alpha}^{\mathsf{T}}\boldsymbol{g}(\boldsymbol{v})
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\({\cal L}\)&lt;/span&gt;が凸関数ならば、最適点&lt;span class="math"&gt;\((\boldsymbol{v}^{\star}, \boldsymbol{\alpha}^{\star})\)&lt;/span&gt;は鞍点にあり、&lt;span class="math"&gt;\(\displaystyle\max_{\scriptsize \boldsymbol{v}} {\cal L}(\boldsymbol{v}, \boldsymbol{\alpha}^{\star})\)&lt;/span&gt;を主問題とする時、&lt;span class="math"&gt;\(\displaystyle\min_{\scriptsize \boldsymbol{\alpha}}{\cal L}(\boldsymbol{v}^{\star}, \boldsymbol{\alpha})\)&lt;/span&gt;を主問題に対する双対問題という。 &lt;a class="footnote-reference" href="#id38" id="id9"&gt;[5]&lt;/a&gt;&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;それでは実際に KKT 条件を適用し、最適化問題を主問題 ( 式 ) から双対問題へ変換する事を考える。
まず制約条件から&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  g_{i}(\boldsymbol{w}) = 1 - y_{i} (\boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}_{i} + b) \leq 0\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;（最小化を考えているので、
符号が逆転している事に注意）より、ラグランジアンは、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  {\cal L}(\boldsymbol{w}, \boldsymbol{\alpha}) &amp;amp;=  \frac{1}{2} \boldsymbol{w}^{\mathsf{T}}\boldsymbol{w} + \boldsymbol{\alpha}^{\mathsf{T}}\boldsymbol{g}(\boldsymbol{w})  \\
  &amp;amp;= \frac{1}{2} \boldsymbol{w}^{\mathsf{T}}\boldsymbol{w} + \sum_{i=1}^{N}\alpha_{i} \{ 1 - y_{i}(\boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}_{i} + b) \}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表現でき、
&lt;span class="math"&gt;\({\cal L}(\boldsymbol{w}, \boldsymbol{\alpha})\)&lt;/span&gt;の&lt;span class="math"&gt;\(\boldsymbol{w}, b\)&lt;/span&gt;による偏微分は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \frac{\partial {\cal L}(\boldsymbol{w}, \boldsymbol{\alpha})}{\partial \boldsymbol{w}} = \boldsymbol{w} - \sum_{i=1}^{N} \alpha_{i}y_{i}\boldsymbol{x}_{i}, \quad \frac{\partial {\cal L}(\boldsymbol{w}, \boldsymbol{\alpha})}{\partial b} = \sum_{i=1}^{N}\alpha_{i}y_{i}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となる。&lt;span class="math"&gt;\(\displaystyle\frac{\partial {\cal L}(\boldsymbol{w}^{\star}, \boldsymbol{\alpha})}{\partial \boldsymbol{w}} = \boldsymbol{0}\)&lt;/span&gt;とおくことで最適時の係数&lt;span class="math"&gt;\(\boldsymbol{w}^{\star}\)&lt;/span&gt;が求まる :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \boldsymbol{w}^{\star} = \sum_{i=1}^{N} \alpha_{i}y_{i}\boldsymbol{x}_{i}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;また、&lt;span class="math"&gt;\(\displaystyle\frac{\partial {\cal L}(\boldsymbol{w}^{\star}, \boldsymbol{\alpha})}{\partial b} = 0\)&lt;/span&gt;により双対変数&lt;span class="math"&gt;\(\boldsymbol{\alpha}\)&lt;/span&gt;の制約条件が得られる :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \sum_{i=1}^{N} \alpha_{i}y_{i} = 0\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;これらの関係式をラグランジアンに代入することで、 双対問題式を得る :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  {\cal L}(\boldsymbol{w}^{\star}、 \boldsymbol{\alpha}) &amp;amp;= \frac{1}{2} \boldsymbol{w}^{\star\mathsf{T}}\boldsymbol{w}^{\star} + \boldsymbol{\alpha}^{\mathsf{T}} \boldsymbol{g}(\boldsymbol{w}^{\star}) \\
  &amp;amp;= \frac{1}{2} \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}\boldsymbol{x}_{j}^{\mathsf{T}}\boldsymbol{x}_{i} + \sum_{i=1}^{N} \alpha_{i} \left\{ 1 - y_{i} \left( \sum_{j=1}^{N}\alpha_{j}y_{j}\boldsymbol{x}_{j}^{\mathsf{T}} \boldsymbol{x}_{i} + b \right) \right\} \\
  &amp;amp;= \frac{1}{2} \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}\boldsymbol{x}_{i}^{\mathsf{T}}\boldsymbol{x}_{j} + \sum_{i=1}^{N} \alpha_{i} - b\sum_{i=1}^{N} \alpha_{i} y_{i} - \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}\boldsymbol{x}_{i}^{\mathsf{T}} \boldsymbol{x}_{j} \\
  &amp;amp;= \sum_{i=1}^{N} \alpha_{i} - \frac{1}{2} \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}\boldsymbol{x}_{i}^{\mathsf{T}}\boldsymbol{x}_{j}\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;（途中の式変形において、内積の対称性（&lt;span class="math"&gt;\(\boldsymbol{x}^{\mathsf{T}}\_{j}\boldsymbol{x}\_{i} = \boldsymbol{x}^{\mathsf{T}}\_{i}\boldsymbol{x}\_{j}\)&lt;/span&gt;）を用いている。）よって、
双対問題は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  &amp;amp; \max_{\scriptsize \boldsymbol{\alpha}} \left[ \sum_{i=1}^{N} \alpha_{i} - \frac{1}{2} \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}\boldsymbol{x}_{i}^{\mathsf{T}}\boldsymbol{x}_{j} \right] \\
  &amp;amp; \text{subject to : } \alpha_{i} \geq 0, \ \sum_{i=1}^{N} \alpha_{i}y_{i} = 0 \quad (i = 1, \dots, N) \nonumber\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表現できる。双対問題は非負制約&lt;span class="math"&gt;\(\alpha_{i} \geq 0\)&lt;/span&gt;の中で&lt;span class="math"&gt;\(\boldsymbol{\alpha}\)&lt;/span&gt;を動かし、その最大値を得れば良いので、
主問題を直接解くよりも容易に、数値最適化によって解を求める（学習する）ことができる。実際の実装については後に述べる。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id51"&gt;非線形 SVM&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;前節までの議論は、入力データと同じ空間（次元）で適切な識別面を発見する SVM であり、これを特に&lt;strong&gt;線形 SVM&lt;/strong&gt;という。
線形 SVM の場合、識別面は入力データ空間の次元&lt;span class="math"&gt;\(n\)&lt;/span&gt;に対し&lt;span class="math"&gt;\(n-1\)&lt;/span&gt;次元の平面（&lt;strong&gt;超平面&lt;/strong&gt;）であり（例 :2 次元空間では直線、3 次元空間では平面）、図の様に、異なるクラスのサンプルが入り組んだ状態では識別面を構成できない（&lt;strong&gt;線形分離不可能&lt;/strong&gt;）。&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt=" 線形分離不可能な例 " src="./images/linearly_unseparatable.png" /&gt;
&lt;p class="caption"&gt;線形分離不可能な例&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;この場合、入力データの空間&lt;span class="math"&gt;\(\mathbb{R}^{n}\)&lt;/span&gt;から高次元空間&lt;span class="math"&gt;\(\mathbb{R}^{h}\)&lt;/span&gt;(&lt;span class="math"&gt;\(h \gg n\)&lt;/span&gt;) への高次元な非線形写像（&lt;strong&gt;特徴写像&lt;/strong&gt;）&lt;span class="math"&gt;\(\boldsymbol{\phi} : \mathbb{R}^{n} \to \mathbb{R}^{h}\)&lt;/span&gt;を用いて高次元空間（特徴空間）へ写像すれば、線形分離不可能だったサンプルを一般位置 &lt;a class="footnote-reference" href="#id39" id="id11"&gt;[6]&lt;/a&gt; に写し、識別面を構成できる（線形分離可能）ようになる（図参照）。&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt=" 特徴空間で線形分離可能になる例 " src="./images/linearly_separatable_in_high_dimension.png" /&gt;
&lt;p class="caption"&gt;特徴空間で線形分離可能になる例&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;図では、入力空間は 1 次元（数直線）、
特徴空間は 2 次元（平面）である。入力空間で線形分離不可能なサンプルが、
特徴写像によって一般位置に写され、線形分離可能になっている。&lt;/p&gt;
&lt;p&gt;この様に、
入力データ次元で線形分離不可能なサンプルを、特徴写像によって写して識別面を構成し、元の次元に戻す SVM を&lt;strong&gt;非線形 SVM&lt;/strong&gt;という。
この場合、識別面は曲がった形状を持つ（超曲面）。&lt;/p&gt;
&lt;p&gt;それでは非線形 SVM の定式化を見ていく。特徴写像を用いてサンプルを写像することで、高次元空間内のサンプル（特徴サンプル）&lt;span class="math"&gt;\(\boldsymbol{\phi}(\boldsymbol{x}_{i})\ (i =1, \dots, N)\)&lt;/span&gt;が得られる。後は線形 SVM の時と全く同様の議論を適用し、
双対問題は次の様に表現される :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  &amp;amp;\max_{\scriptsize \boldsymbol{\alpha}} \left[ \sum_{i=1}^{N} \alpha_{i} - \frac{1}{2} \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}\boldsymbol{\phi}(\boldsymbol{x}_{i})^{\mathsf{T}}\boldsymbol{\phi}(\boldsymbol{x}_{j}) \right] \\
  &amp;amp;\text{subject to : } \alpha_{i} \geq 0,\ \sum_{i=1}^{N} \alpha_{i}y_{i} = 0 \quad (i = 1, \dots, N) \nonumber\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;さて、 この様にして非線形 SVM が実現できるが、
一般に、入力次元&lt;span class="math"&gt;\(n\)&lt;/span&gt;はもとより特徴空間の次元&lt;span class="math"&gt;\(h\)&lt;/span&gt;は非常に大きくなる（&lt;span class="math"&gt;\(\infty\)&lt;/span&gt;次元にすらなりうる）。特徴写像&lt;span class="math"&gt;\(\boldsymbol{\phi}\)&lt;/span&gt;を構成する&lt;span class="math"&gt;\(h\)&lt;/span&gt;個の非線形な基底を用意するのは、非常に困難であり、
実用上大変な不便が生じる。
そこで、特徴写像同士の内積&lt;span class="math"&gt;\(\boldsymbol{\phi}(\boldsymbol{x}\_{i})^{\mathsf{T}}\boldsymbol{\phi}(\boldsymbol{x}\_{j})\)&lt;/span&gt;の計算結果はノルムなので、その内積を計算するのではなく、
天下り的に、最初から内積値を与えてしまうやり方がある。 即ち、
特徴写像同士の内積値を、 &lt;strong&gt;カーネル関数&lt;/strong&gt;
&lt;span class="math"&gt;\(K : \mathbb{R}^{n} \times \mathbb{R}^{n} \to \mathbb{R}\)&lt;/span&gt;で定める :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) = \langle \boldsymbol{\phi}(\boldsymbol{x}_{i}), \boldsymbol{\phi}(\boldsymbol{x}_{j}) \rangle = \boldsymbol{\phi}(\boldsymbol{x}_{i})^{\mathsf{T}}\boldsymbol{\phi}(\boldsymbol{x}_{j})\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで&lt;span class="math"&gt;\(K\)&lt;/span&gt;は入力データのみで記述されるので、特徴写像はカーネル関数の中に閉じ込められてしまい、
陽に現れない。
即ち、特徴写像を構成する必要がないというのが大きなメリットである。任意の関数がカーネルになるとは限らず、
マーサーの定理 &lt;a class="footnote-reference" href="#id40" id="id12"&gt;[7]&lt;/a&gt; という条件をカーネル関数は満たす必要がある。代表的なカーネル関数を以下に挙げる :&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;線形カーネル :&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) = \langle \boldsymbol{x}_{i}, \boldsymbol{x}_{j} \rangle
        \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;入力次元における標準内積もカーネルとなり、 線形カーネルと呼ばれる。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;ガウシアン（Radial Basis Function、 RBF: 放射基底関数）カーネル :&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) = \exp\left(-\frac{||\boldsymbol{x}_{i}-\boldsymbol{x}_{j}||^{2}}{2\sigma^{2}}\right)
        \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;分散パラメタ&lt;span class="math"&gt;\(\sigma\)&lt;/span&gt;を伴ってガウス関数に従った分布を示す。実用上よく用いられる。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;多項式カーネル :&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) = (\langle \boldsymbol{x}_{i}, \boldsymbol{x}_{j} \rangle + c)^{k}
        \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;正定数&lt;span class="math"&gt;\(c\)&lt;/span&gt;と多項式の次数&lt;span class="math"&gt;\(k\)&lt;/span&gt;によって構成されるカーネルである。ガウシアンカーネルよりも性能がパラメタに依存しない特徴を持つ。&lt;/p&gt;
&lt;p&gt;カーネル関数&lt;span class="math"&gt;\(K\)&lt;/span&gt;を用いる事で、
非線形 SVM の双対問題は次で表される :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  &amp;amp;\max_{\scriptsize \boldsymbol{\alpha}} \left[ \sum_{i=1}^{N} \alpha_{i} - \frac{1}{2} \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}K(\boldsymbol{x}_{i}、 \boldsymbol{x}_{j}) \right] \\
  &amp;amp;\text{subject to : } \alpha_{i} \geq 0、\ \sum_{i=1}^{N} \alpha_{i}y_{i} = 0 \quad (i = 1, \dots, N) \nonumber\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id13"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id52"&gt;ソフトマージン SVM&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;前節までの SVM は、
マージンの内部にサンプルが入る事を一切許さないので、これを特に&lt;strong&gt;ハードマージン SVM&lt;/strong&gt;ということがある。カーネルを用いた非線形ハードマージン SVM は、線形分離不可能なサンプルにでも強引に曲がりくねった識別面を構成する。これは実用に供する場合に問題になることがある。
例えば、データに雑音が乗っていたり、
一部のラベルを付け間違えたりする場合であり、これらは実データを扱う場合、
往々にして起こりうる事である。この様な雑音を拾いすぎてしまうと SVM の汎化性能 &lt;a class="footnote-reference" href="#id41" id="id14"&gt;[8]&lt;/a&gt; が悪化してしまうので、マージンの制約を緩め、一部のサンプルはマージンの内部に入っても良いように SVM を改善する事を考える。マージンの内部にサンプルが入ることを許す SVM を&lt;strong&gt;ソフトマージン SVM&lt;/strong&gt;と呼ぶことがある。&lt;/p&gt;
&lt;p&gt;ハードマージン SVM の制約を緩める事を考える。サンプル&lt;span class="math"&gt;\(\boldsymbol{x}\_{i}\)&lt;/span&gt;に対応するスラック（緩衝）変数&lt;span class="math"&gt;\(\eta_{i} \geq 0\ (i=1, \dots, N)\)&lt;/span&gt;を用意して、
SVM の制約を&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  y_{i}(\boldsymbol{w}^{\mathsf{T}}\boldsymbol{\phi}(\boldsymbol{x}\_{i}) + b) \geq 1 - \eta_{i} \quad (i = 1, \dots, N)\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とする（最初から、サンプルは特徴写像&lt;span class="math"&gt;\(\boldsymbol{\phi}\)&lt;/span&gt;によって写像されている場合を考える）。スラック変数はサンプルがマージンに食い込んでいる距離を表しており、もちろん、
&lt;span class="math"&gt;\(\eta_{i}\)&lt;/span&gt;は小さい方が良く、&lt;span class="math"&gt;\(\eta_{i} = 0\)&lt;/span&gt;の時はハードマージンに一致する。
そして、&lt;span class="math"&gt;\(\eta_{i}\)&lt;/span&gt;も同時に最適化に組み込んでしまう事で、ソフトマージン SVM が実現できる。
多くの文献では、スラック変数のノルムの取り方で異なる 2 種類のソフトマージン SVM の式を提示している :&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;1 ノルムソフトマージン SVM ・主問題&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          &amp;amp; \min_{\scriptsize \boldsymbol{w}} \frac{1}{2} \boldsymbol{w}^{\mathsf{T}}\boldsymbol{w} + C_{1}\sum_{i=1}^{N} \eta_{i} \\ &amp;amp; \text{subject to : } y_{i}(\boldsymbol{w}^{\mathsf{T}}\boldsymbol{\phi}(\boldsymbol{x}_{i}) + b) \geq 1 - \eta_{i}, \ \eta_{i} \geq 0 \quad (i=1, \dots, N)
        \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;ul class="simple" id="svm-1"&gt;
&lt;li&gt;2 ノルムソフトマージン SVM ・主問題&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          &amp;amp;\min_{\scriptsize \boldsymbol{w}} \frac{1}{2} \boldsymbol{w}^{\mathsf{T}}\boldsymbol{w} + \frac{C_{2}}{2}\sum_{i=1}^{N} \eta_{i}^{2} \quad \\ &amp;amp;\text{subject to : } y_{i}(\boldsymbol{w}^{\mathsf{T}}\boldsymbol{\phi}(\boldsymbol{x}_{i}) + b) \geq 1 - \eta_{i} \quad (i=1, \dots, N)
        \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで、
&lt;span class="math"&gt;\(C_{1}, C_{2}\)&lt;/span&gt;はハードマージンとソフトマージンのトレードオフを与える定数 &lt;a class="footnote-reference" href="#id42" id="id15"&gt;[9]&lt;/a&gt; で、最適な値は実験等によって求める必要がある。
双対問題の導出は、前節までの議論と同様に、
KKT 条件に当てはめる事により得られる :&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;1 ノルムソフトマージン SVM ・双対問題の導出&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ラグランジアンは、
&lt;span class="math"&gt;\(\beta_{i} \geq 0\)&lt;/span&gt;なる双対変数を導入して、&lt;span class="math"&gt;\(-\beta_{i}\eta_{i} \leq 0\)&lt;/span&gt;より、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
      {\cal L}(\boldsymbol{w}, \boldsymbol{\eta}, \boldsymbol{\alpha}, \boldsymbol{\beta}) = \frac{1}{2} \boldsymbol{w}^{\mathsf{T}} \boldsymbol{w} + C_{1} \sum_{i=1}^{N}\eta_{i} + \sum_{i=1}^{N} \alpha_{i} \left\{ 1 - \eta_{i} - y_{i}(\boldsymbol{w}^{\mathsf{T}} \boldsymbol{\phi}(\boldsymbol{x}_{i}) + b) \right\} + \sum_{i=1}^{N}(-\beta_{i}\eta_{i})
    \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;より、&lt;span class="math"&gt;\({\cal L}(\boldsymbol{w}, \boldsymbol{\eta}, \boldsymbol{\alpha}, \boldsymbol{\beta})\)&lt;/span&gt;の&lt;span class="math"&gt;\(\boldsymbol{w}, b, \eta_{i},\)&lt;/span&gt;による偏微分&lt;span class="math"&gt;\(\displaystyle\frac{\partial \cal L}{\partial \boldsymbol{w}}, \frac{\partial \cal L}{\partial b}, \frac{\partial \cal L}{\partial \eta_{i}}\)&lt;/span&gt;は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
      \frac{\partial \cal L}{\partial \boldsymbol{w}} = \boldsymbol{w} - \sum_{i=1}^{N} y_{i} \alpha_{i} \boldsymbol{\phi}(\boldsymbol{x}_{i}), \quad \frac{\partial \cal L}{\partial b} = \sum_{i=1}^{N}\alpha_{i}y_{i}, \quad \frac{\partial \cal L}{\partial \eta_{i}} = C_{1} - \alpha_{i} - \beta_{i}
    \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\displaystyle\frac{\partial \cal L}{\partial \boldsymbol{w}} = \boldsymbol{0}, \frac{\partial \cal L}{\partial \eta_{i}} = 0\)&lt;/span&gt;とおくことで、最適時パラメタは、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          \boldsymbol{w}^{\star} = \sum_{i=1}^{N} y_{i} \alpha_{i} \boldsymbol{\phi}(\boldsymbol{x}_{i}), \quad C_{1} = \alpha_{i} + \beta_{i}
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\boldsymbol{w}^{\star}\)&lt;/span&gt;をラグランジアンに代入すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          {\cal L}(\boldsymbol{w}^{\star}, \boldsymbol{\eta}^{\star}、 \boldsymbol{\alpha}、 \boldsymbol{\beta}) &amp;amp;= \sum_{i=1}^{N} \alpha_{i} - \frac{1}{2} \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) + \sum_{i=1}^{N} (C_{1} - \alpha_{i} - \beta_{i}) \eta_{i} \\
          &amp;amp;= \sum_{i=1}^{N} \alpha_{i} - \frac{1}{2} \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j})
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;制約条件&lt;span class="math"&gt;\(\alpha_{i}, \beta_{i} \geq 0\)&lt;/span&gt;を含めて考えると、&lt;span class="math"&gt;\(\beta_{i} = C_{1} - \alpha_{i} \geq 0\)&lt;/span&gt;より、&lt;span class="math"&gt;\(\alpha_{i}\)&lt;/span&gt;についての制約&lt;span class="math"&gt;\(0 \leq \alpha_{i} \leq C_{1}\)&lt;/span&gt;が得られ、結局、普通の SVM の双対問題に&lt;span class="math"&gt;\(\alpha_{i}\)&lt;/span&gt;についての制約を加えるだけで、1 ノルムソフトマージン SVM が実現できる。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;1 ノルムソフトマージン SVM ・双対問題&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
      &amp;amp;\max_{\scriptsize \boldsymbol{\alpha}} \left[ \sum_{i=1}^{N} \alpha_{i} - \frac{1}{2} \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) \right] \\
      &amp;amp;\text{subject to : } 0 \leq \alpha_{i} \leq C_{1}, \ \sum_{i=1}^{N} \alpha_{i}y_{i} = 0 \quad (i = 1, \dots, N) \nonumber\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;ul class="simple" id="id16"&gt;
&lt;li&gt;2 ノルムソフトマージン SVM ・双対問題の導出&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ラグランジアンは、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          {\cal L}(\boldsymbol{w}, \boldsymbol{\eta}, \boldsymbol{\alpha}) = \frac{1}{2} \boldsymbol{w}^{\mathsf{T}} \boldsymbol{w} + \frac{C_{2}}{2} \sum_{i=1}^{N}\eta_{i}^{2} + \sum_{i=1}^{N} \alpha_{i} \left\{ 1 - \eta_{i} - y_{i}(\boldsymbol{w}^{\mathsf{T}} \boldsymbol{\phi}(\boldsymbol{x}_{i}) + b) \right\}
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;より、&lt;span class="math"&gt;\({\cal L}(\boldsymbol{w}, \boldsymbol{\eta}, \boldsymbol{\alpha})\)&lt;/span&gt;の&lt;span class="math"&gt;\(\boldsymbol{w}, b, \eta_{i}\)&lt;/span&gt;による偏微分&lt;span class="math"&gt;\(\displaystyle\frac{\partial \cal L}{\partial \boldsymbol{w}}, \frac{\partial \cal L}{\partial b}, \frac{\partial \cal L}{\partial \eta_{i}}\)&lt;/span&gt;は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          \frac{\partial \cal L}{\partial \boldsymbol{w}} = \boldsymbol{w} - \sum_{i=1}^{N} y_{i} \alpha_{i} \boldsymbol{\phi}(\boldsymbol{x}_{i}), \quad \frac{\partial \cal L}{\partial b} = \sum_{i=1}^{N}\alpha_{i}y_{i}, \quad \frac{\partial \cal L}{\partial \eta_{i}} = C_{2}\eta_{i} - \alpha_{i}
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\displaystyle\frac{\partial \cal L}{\partial \boldsymbol{w}} = \boldsymbol{0}, \frac{\partial \cal L}{\partial \eta_{i}} = 0\)&lt;/span&gt;とおくことで、最適時パラメタは、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          \boldsymbol{w}^{\star} = \sum_{i=1}^{N} y_{i} \alpha_{i} \boldsymbol{\phi}(\boldsymbol{x}_{i}), \quad \eta_{i}^{\star} = \frac{\alpha_{i}}{C_{2}}
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;これをラグランジアンに代入すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          {\cal L}(\boldsymbol{w}^{\star}, \boldsymbol{\eta}^{\star}, \boldsymbol{\alpha}) &amp;amp;= \sum_{i=1}^{N} \alpha_{i} + \frac{1}{2C_{2}} \sum_{i=1}^{N} \alpha_{i}^{2} + \sum_{i=1}^{N} \alpha_{i} \left[ - \frac{\alpha_{i}}{C_{2}} - y_{i} \sum_{j=1}^{N} y_{j}\alpha_{j} K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) \right] + \frac{1}{2} \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) \\
          &amp;amp;= \sum_{i=1}^{N} \alpha_{i} - \frac{1}{2C_{2}} \sum_{i=1}^{N} \alpha_{i}^{2} - \frac{1}{2} \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j})
        \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで&lt;span class="math"&gt;\(y_{i}y_{j} \in \{-1, 1\}\)&lt;/span&gt;に注目すれば、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          {\cal L}(\boldsymbol{w}^{\star}, \boldsymbol{\eta}^{\star}, \boldsymbol{\alpha}) = \sum_{i=1}^{N} \alpha_{i} - \frac{1}{2} \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}\left( K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) + \frac{1}{C_{2}}\delta_{ij} \right)
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と整理できる。ここで&lt;span class="math"&gt;\(\delta_{ij}\)&lt;/span&gt;はディラックのデルタであり、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          \delta_{ij} =
          \left\{
            \begin{array}{ll}
              1 &amp;amp; i = j \\
              0 &amp;amp; otherwise
            \end{array}
            \right.
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たす。 2 ノルムソフトマージン SVM も、
結局、カーネル関数を簡単に書き換える事で実現できる。&lt;/p&gt;
&lt;ul class="simple" id="id17"&gt;
&lt;li&gt;2 ノルムソフトマージン SVM ・双対問題&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
            &amp;amp;\max_{\scriptsize \boldsymbol{\alpha}} \left[ \sum_{i=1}^{N} \alpha_{i} - \frac{1}{2} \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}\left(K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) + \frac{1}{C_{2}}\delta_{ij} \right) \right] \\
            &amp;amp;\text{subject to : } \alpha_{i} \geq 0, \ \sum_{i=1}^{N} \alpha_{i}y_{i} = 0 \quad (i = 1,\dots,N) \nonumber
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="svr-support-vector-regression"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id53"&gt;SVR（Support Vector Regression, サポートベクトル回帰）&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;一般に SVM は識別器として用いられる事がほとんどだが、ラベルを実数とした回帰問題 &lt;a class="footnote-reference" href="#id43" id="id18"&gt;[10]&lt;/a&gt; にも適用することができる。SVM による回帰モデルのことを、
&lt;strong&gt;SVR&lt;/strong&gt;（Support Vector Regression, サポートベクトル回帰）という。
基本的な考え方としては、図の様に、識別面（回帰面）を中心に幅&lt;span class="math"&gt;\(2\varepsilon\)&lt;/span&gt;の “ 帯 ” に多くのサンプルが入るようにすれば良い。&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="SVR" src="./images/svr.png" /&gt;
&lt;p class="caption"&gt;SVR&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;帯を考慮して制約を表現すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  | y_{i} - (\boldsymbol{w}^{\mathsf{T}}\boldsymbol{\phi}(\boldsymbol{x}_{i})+b) | \leq \varepsilon \quad (i = 1, \dots, N)
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となる。
これはハードマージン的な制約であり、幅&lt;span class="math"&gt;\(2\varepsilon\)&lt;/span&gt;の帯に全てのサンプルが入る事を要求している。もちろん&lt;span class="math"&gt;\(\varepsilon\)&lt;/span&gt;を十分に大きくとれば全てのサンプルは帯に入るが、帯が広すぎるために自由度が大きく、
結果汎化性能の悪化に繋がってしまう。ラベルが実数となり、
雑音の影響をより受けやすくなることから、SVR においては、
最初からスラック変数を用いて、ソフトマージン的に定式化することが多い。&lt;/p&gt;
&lt;p&gt;スラック変数を用いて、帯から飛び出た距離&lt;span class="math"&gt;\(\eta_{i}^{+}, \eta_{i}^{-} \geq 0\)&lt;/span&gt;を次で定義する（図参照）:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\begin{aligned}
  \eta_{i}^{+} =
  \left\{ \begin{array}{ll}
    y_{i} - \varepsilon - (\boldsymbol{w}^{\mathsf{T}}\boldsymbol{\phi}(\boldsymbol{x}_{i})+b) &amp;amp; y_{i} \geq (\boldsymbol{w}^{\mathsf{T}}\boldsymbol{\phi}(\boldsymbol{x}_{i})+b) + \varepsilon \\
    0 &amp;amp; otherwise
    \end{array} \right.
  \\
  \eta_{i}^{-} =
  \left\{ \begin{array}{ll}
    (\boldsymbol{w}^{\mathsf{T}}\boldsymbol{\phi}(\boldsymbol{x}_{i})+b) - y_{i} - \varepsilon &amp;amp; y_{i} \leq (\boldsymbol{w}^{\mathsf{T}}\boldsymbol{\phi}(\boldsymbol{x}_{i})+b) - \varepsilon \\
    0 &amp;amp; otherwise
    \end{array} \right.
\end{aligned}
\end{align*}
&lt;/div&gt;
&lt;p&gt;なお、サンプルは帯からどちらか一方にしか飛び出ないので、&lt;span class="math"&gt;\(\eta_{i}^{+}, \eta_{i}^{-}\)&lt;/span&gt;のいずれか一方は必ず&lt;span class="math"&gt;\(0\)&lt;/span&gt;となり、サンプルが帯に収まっている時は両方共&lt;span class="math"&gt;\(0\)&lt;/span&gt;となる。スラック変数を用いる事で、
制約は次のように表現できる :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \left\{ \begin{array}{l}
    (\boldsymbol{w}^{\mathsf{T}}\boldsymbol{\phi}(\boldsymbol{x}_{i})+b) - y_{i} \leq \varepsilon + \eta_{i}^{-} \\
    y_{i} - (\boldsymbol{w}^{\mathsf{T}}\boldsymbol{\phi}(\boldsymbol{x}_{i})+b) \leq \varepsilon + \eta_{i}^{+}
  \end{array} \right.
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ソフトマージンの時と同様に考える事で、 最適化問題が定式化できる :&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;1 ノルム SVR ・主問題&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          &amp;amp;\min_{\scriptsize \boldsymbol{w}} \frac{1}{2} \boldsymbol{w}^{\mathsf{T}}\boldsymbol{w} + C_{1}\sum_{i=1}^{N} (\eta_{i}^{+} + \eta_{i}^{-}) \\
          &amp;amp;\text{subject to : } (\boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}_{i} + b) - y_{i} \leq \varepsilon + \eta_{i}^{-}, \ y_{i} - (\boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}_{i} + b) \leq \varepsilon + \eta_{i}^{+} \quad (i=1,\dots,N)
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;ul class="simple" id="svr-1"&gt;
&lt;li&gt;2 ノルム SVR ・主問題&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          &amp;amp;\min_{\scriptsize \boldsymbol{w}} \frac{1}{2} \boldsymbol{w}^{\mathsf{T}}\boldsymbol{w} + \frac{C_{2}}{2}\sum_{i=1}^{N} \left\{ (\eta_{i}^{+})^{2} + (\eta_{i}^{-})^{2} \right\} \\
          &amp;amp;\text{subject to : } (\boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}_{i} + b) - y_{i} \leq \varepsilon + \eta_{i}^{-}, \ y_{i} - (\boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}_{i} + b) \leq \varepsilon + \eta_{i}^{+} \quad (i=1, \dots, N)
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;後は KKT 条件にぶち込むだけの流れ作業である。よし、じゃあぶち込んでやるぜ！&lt;/p&gt;
&lt;div class="section" id="svr"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id54"&gt;1 ノルム SVR ・双対問題の導出&lt;/a&gt;&lt;/h3&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          \begin{split}
            &amp;amp;{\cal L}(\boldsymbol{w}, \boldsymbol{\eta}^{+}, \boldsymbol{\eta}^{-}, \boldsymbol{\alpha}^{+}, \boldsymbol{\alpha}^{-}, \boldsymbol{\beta}^{+}, \boldsymbol{\beta}^{-}) = \\
          &amp;amp;\frac{1}{2} \boldsymbol{w}^{\mathsf{T}} \boldsymbol{w} + C_{1} \sum_{i=1}^{N}(\eta_{i}^{+}+\eta_{i}^{-}) + \sum_{i=1}^{N}(-\beta_{i}^{+}\eta_{i}^{+} -\beta_{i}^{-}\eta_{i}^{-} ) \\
          &amp;amp;+ \sum_{i=1}^{N} \left[ \alpha_{i}^{-} \left\{ (\boldsymbol{w}^{\mathsf{T}} \boldsymbol{\phi}(\boldsymbol{x}_{i}) + b) - y_{i} - \varepsilon - \eta_{i}^{-} \right\} + \alpha_{i}^{+} \left\{ y_{i} - (\boldsymbol{w}^{\mathsf{T}} \boldsymbol{\phi}(\boldsymbol{x}_{i}) + b) - \varepsilon - \eta_{i}^{+} \right\} \right]
          \end{split}
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;より、&lt;span class="math"&gt;\({\cal L}(\boldsymbol{w}, \boldsymbol{\eta}^{+}, \boldsymbol{\eta}^{-}, \boldsymbol{\alpha}^{+}, \boldsymbol{\alpha}^{-}, \boldsymbol{\beta}^{+}, \boldsymbol{\beta}^{-})\)&lt;/span&gt;の&lt;span class="math"&gt;\(\boldsymbol{w}, b, \eta_{i}^{+}, \eta_{i}^{-}\)&lt;/span&gt;による偏微分&lt;span class="math"&gt;\(\displaystyle\frac{\partial \cal L}{\partial \boldsymbol{w}}, \frac{\partial \cal L}{\partial b}, \frac{\partial \cal L}{\partial \eta_{i}^{+}}, \frac{\partial \cal L}{\partial \eta_{i}^{-}}\)&lt;/span&gt;は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          \frac{\partial \cal L}{\partial \boldsymbol{w}} = \boldsymbol{w} + \sum_{i=1}^{N}(\alpha_{i}^{-} - \alpha_{i}^{+}) \boldsymbol{\phi}(\boldsymbol{x}_{i}), \quad \frac{\partial \cal L}{\partial b} = \sum_{i=1}^{N}(\alpha_{i}^{-} - \alpha_{i}^{+}) \\
          \frac{\partial \cal L}{\partial \eta_{i}^{+}} = C_{1} - \alpha_{i}^{+} - \beta_{i}^{+}, \quad \frac{\partial \cal L}{\partial \eta_{i}^{-}} = C_{1} - \alpha_{i}^{-} - \beta_{i}^{-}
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;それぞれ&lt;span class="math"&gt;\(0\)&lt;/span&gt;とおくと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          \boldsymbol{w}^{\star} = \sum_{i=1}^{N} (\alpha_{i}^{+} - \alpha_{i}^{-}) \boldsymbol{\phi}(\boldsymbol{x}_{i}), \quad \sum_{i=1}^{N}(\alpha_{i}^{-} - \alpha_{i}^{+}) = 0, \quad C_{1} = \alpha_{i}^{+} + \beta_{i}^{+} = \alpha_{i}^{-} + \beta_{i}^{-}
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;これをラグランジアンに代入すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          \begin{split}
            &amp;amp;{\cal L}(\boldsymbol{w}^{\star}, \boldsymbol{\eta}^{+\star}, \boldsymbol{\eta}^{-\star}, \boldsymbol{\alpha}^{+}, \boldsymbol{\alpha}^{-}, \boldsymbol{\beta}^{+}, \boldsymbol{\beta}^{-}) = \\
            &amp;amp;\frac{1}{2} \sum_{i、j=1}^{N} (\alpha_{i}^{+} - \alpha_{i}^{-})(\alpha_{j}^{+} - \alpha_{j}^{-})K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) + C_{1} \sum_{i=1}^{N}(\eta_{i}^{+}+\eta_{i}^{-}) - \sum_{i=1}^{N}(\beta_{i}^{+}\eta_{i}^{+} + \beta_{i}^{-}\eta_{i}^{-}) \\
            &amp;amp;+\sum_{i=1}^{N} \left[ \alpha_{i}^{-}\sum_{j=1}^{N}(\alpha_{j}^{+}-\alpha_{j}^{-})K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) - \alpha_{i}^{+}\sum_{j=1}^{N}(\alpha_{j}^{+}-\alpha_{j}^{-})K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) \right] \\
            &amp;amp;+\sum_{i=1}^{N}\left[ \alpha_{i}^{-} (-\varepsilon-\eta_{i}^{-}-y_{i}) + \alpha_{i}^{+} (-\varepsilon-\eta_{i}^{+}+y_{i}) \right]
          \end{split}
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(C_{1} = \alpha_{i}^{+} + \beta_{i}^{+} = \alpha_{i}^{-} + \beta_{i}^{-}\)&lt;/span&gt;を用いて整理すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          \begin{split}
            &amp;amp;{\cal L}(\boldsymbol{w}^{\star}, \boldsymbol{\eta}^{+\star}, \boldsymbol{\eta}^{-\star}, \boldsymbol{\alpha}^{+}, \boldsymbol{\alpha}^{-}, \boldsymbol{\beta}^{+}, \boldsymbol{\beta}^{-}) = \\
            &amp;amp;\sum_{i=1}^{N}(\alpha_{i}^{+}-\alpha_{i}^{-}) - \varepsilon\sum_{i=1}^{N}(\alpha_{i}^{-}+\alpha_{i}^{+}) - \frac{1}{2} \sum_{i、j=1}^{N} (\alpha_{i}^{+} - \alpha_{i}^{-})(\alpha_{j}^{+} - \alpha_{j}^{-})K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j})
          \end{split}
        \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ところで、上でも既に述べたが&lt;span class="math"&gt;\(\eta_{i}^{+}, \eta_{i}^{-}\)&lt;/span&gt;のどちらか一方は必ず&lt;span class="math"&gt;\(0\)&lt;/span&gt;となるので、その場合は対応する&lt;span class="math"&gt;\(\alpha_{i}^{+}, \alpha_{i}^{-}\)&lt;/span&gt;の制約条件はなくなり、従って、
&lt;span class="math"&gt;\(\alpha_{i}^{+}, \alpha_{i}^{-}\)&lt;/span&gt;のどちらか一方も&lt;span class="math"&gt;\(0\)&lt;/span&gt;となる。この事から&lt;span class="math"&gt;\(\alpha_{i} = \alpha_{i}^{+} - \alpha_{i}^{-}\)&lt;/span&gt;とおけば、&lt;span class="math"&gt;\(\alpha_{i}^{-} + \alpha_{i}^{+} = |\alpha_{i}|\)&lt;/span&gt;と表現できるので、双対問題は以下の様に表現できる。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;1 ノルム SVR ・双対問題&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          &amp;amp;\max_{\scriptsize \boldsymbol{\alpha}} \left[ \sum_{i=1}^{N}y_{i}\alpha_{i} - \varepsilon\sum_{i=1}^{N}|\alpha_{i}| - \frac{1}{2} \sum_{i、j=1}^{N}\alpha_{i}\alpha_{j}K(\boldsymbol{x}_{i}、 \boldsymbol{x}_{j}) \right] \\
          &amp;amp;\text{subject to : } \sum_{i=1}^{N}\alpha_{i} = 0, \ -C_{1} \leq \alpha_{i} \leq C_{1} \quad (i = 1、\dots、N) \nonumber
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id20"&gt;
&lt;span id="id19"&gt;&lt;/span&gt;&lt;h3&gt;&lt;a class="toc-backref" href="#id55"&gt;2 ノルム SVR ・双対問題の導出&lt;/a&gt;&lt;/h3&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
            &amp;amp;{\cal L}(\boldsymbol{w}, \boldsymbol{\eta}^{+}, \boldsymbol{\eta}^{-}, \boldsymbol{\alpha}^{+}, \boldsymbol{\alpha}^{-}) = \\
            &amp;amp;\frac{1}{2} \boldsymbol{w}^{\mathsf{T}} \boldsymbol{w} + \frac{C_{2}}{2} \sum_{i=1}^{N} \{ (\eta_{i}^{+})^{2} + (\eta_{i}^{-})^{2} \} \\
            &amp;amp;+\sum_{i=1}^{N} \left[ \alpha_{i}^{-} \left\{ (\boldsymbol{w}^{\mathsf{T}} \boldsymbol{\phi}(\boldsymbol{x}_{i}) + b) - y_{i} - \varepsilon - \eta_{i}^{-} \right\} + \alpha_{i}^{+} \left\{ y_{i} - (\boldsymbol{w}^{\mathsf{T}} \boldsymbol{\phi}(\boldsymbol{x}_{i}) + b) - \varepsilon - \eta_{i}^{+} \right\} \right]
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;より、&lt;span class="math"&gt;\({\cal L}(\boldsymbol{w}, \boldsymbol{\eta}^{+}, \boldsymbol{\eta}^{-}, \boldsymbol{\alpha}^{+}, \boldsymbol{\alpha}^{-})\)&lt;/span&gt;の&lt;span class="math"&gt;\(\boldsymbol{w}, b, \eta_{i}^{+}, \eta_{i}^{-}\)&lt;/span&gt;による偏微分&lt;span class="math"&gt;\(\displaystyle\frac{\partial \cal L}{\partial \boldsymbol{w}}, \frac{\partial \cal L}{\partial b}, \frac{\partial \cal L}{\partial \eta_{i}^{+}}, \frac{\partial \cal L}{\partial \eta_{i}^{-}}\)&lt;/span&gt;は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          \frac{\partial \cal L}{\partial \boldsymbol{w}} = \boldsymbol{w} + \sum_{i=1}^{N}(\alpha_{i}^{-} - \alpha_{i}^{+}) \boldsymbol{\phi}(\boldsymbol{x}_{i}), \quad \frac{\partial \cal L}{\partial b} = \sum_{i=1}^{N}(\alpha_{i}^{-} - \alpha_{i}^{+}) \\
          \frac{\partial \cal L}{\partial \eta_{i}^{+}} = C_{2}\eta_{i}^{+} - \alpha_{i}^{+}, \quad \frac{\partial \cal L}{\partial \eta_{i}^{-}} = C_{2}\eta_{i}^{-} - \alpha_{i}^{-}
        \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;それぞれ&lt;span class="math"&gt;\(0\)&lt;/span&gt;とおくと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          \boldsymbol{w}^{\star} = \sum_{i=1}^{N} (\alpha_{i}^{+} - \alpha_{i}^{-}) \boldsymbol{\phi}(\boldsymbol{x}_{i}), \quad \sum_{i=1}^{N}(\alpha_{i}^{-} - \alpha_{i}^{+}) = 0, \quad \eta_{i}^{+\star} = \frac{\alpha_{i}^{+}}{C_{2}}, \quad \eta_{i}^{-\star} = \frac{\alpha_{i}^{-}}{C_{2}}
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\boldsymbol{w}^{\star}\)&lt;/span&gt;をラグランジアンに代入すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          \begin{split}
            &amp;amp;{\cal L}(\boldsymbol{w}^{\star}, \boldsymbol{\eta}^{+\star}, \boldsymbol{\eta}^{-\star}, \boldsymbol{\alpha}^{+},\boldsymbol{\alpha}^{-}) = \\
            &amp;amp;\frac{1}{2} \sum_{i、j=1}^{N} (\alpha_{i}^{+} - \alpha_{i}^{-})(\alpha_{j}^{+} - \alpha_{j}^{-})K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) + \frac{1}{C_{2}} \sum_{i=1}^{N}\left\{ (\alpha_{i}^{+})^{2}+(\alpha_{i}^{-})^{2} \right\} \\
            &amp;amp;+\sum_{i=1}^{N} \left[ \alpha_{i}^{-}\sum_{j=1}^{N}(\alpha_{j}^{+}-\alpha_{j}^{-})K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) - \alpha_{i}^{+}\sum_{j=1}^{N}(\alpha_{j}^{+}-\alpha_{j}^{-})K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) \right] \\
            &amp;amp;+\sum_{i=1}^{N}\left[ \alpha_{i}^{-} (-\varepsilon - \frac{\alpha_{i}^{-}}{C_{2}} - y_{i}) + \alpha_{i}^{+} (- \varepsilon - \frac{\alpha_{i}^{+}}{C_{2}} +y_{i}) \right] \\
            &amp;amp;=\sum_{i=1}^{N} (\alpha_{i}^{+} - \alpha_{i}^{-})y_{i} - \frac{1}{2} \sum_{i、j=1}^{N}(\alpha_{i}^{+}-\alpha_{i}^{-})(\alpha_{j}^{+}-\alpha_{j}^{-})K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) \\
            &amp;amp;-\varepsilon\sum_{i=1}^{N}(\alpha_{i}^{-} + \alpha_{i}^{+}) - \frac{1}{2C_{2}}\sum_{i=1}^{N}\left\{ (\alpha_{i}^{-})^{2} + (\alpha_{i}^{+})^{2} \right\}
          \end{split}
        \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;1 ノルム SVR の時と同様に、&lt;span class="math"&gt;\(\alpha_{i} = \alpha_{i}^{+} - \alpha_{i}^{-}\)&lt;/span&gt;とおくと、&lt;span class="math"&gt;\((\alpha_{i}^{+})^{2} + (\alpha_{i}^{-})^{2} = \alpha_{i}^{2}\)&lt;/span&gt;が成り立つので、双対問題は以下の様に表現できる。&lt;/p&gt;
&lt;ul class="simple" id="id21"&gt;
&lt;li&gt;2 ノルム SVR ・双対問題&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
          &amp;amp; \max_{\scriptsize \boldsymbol{\alpha}} \left[ \sum_{i=1}^{N}y_{i}\alpha_{i} - \varepsilon\sum_{i=1}^{N}|\alpha_{i}| - \frac{1}{2} \sum_{i, j=1}^{N}\alpha_{i}\alpha_{j}\left( K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) + \frac{1}{C_{2}} \right) \right] \\
          &amp;amp; \text{subject to : } \sum_{i=1}^{N}\alpha_{i} = 0 \quad (i = 1, \dots, N) \nonumber
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id22"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id56"&gt;実装の例&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;実装例は &lt;a class="reference external" href="https://github.com/MrAiki/SimpleSVM"&gt;ここ&lt;/a&gt;
にある。本稿では要点を絞って見ていく。&lt;/p&gt;
&lt;div class="section" id="id23"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id57"&gt;学習&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="id24"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id58"&gt;学習則の導出&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;SVM の学習は、双対問題&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  &amp;amp;\max_{\scriptsize \boldsymbol{\alpha}} \left[ \sum_{i=1}^{N} \alpha_{i} - \frac{1}{2} \sum_{i、j=1}^{N} \alpha_{i}\alpha_{j}y_{i}y_{j}\boldsymbol{\phi}(\boldsymbol{x}_{i})^{\mathsf{T}}\boldsymbol{\phi}(\boldsymbol{x}_{j}) \right] = \max_{\scriptsize \boldsymbol{\alpha}} {\cal L}(\boldsymbol{w}^{\star}, \boldsymbol{\alpha}) \\
  &amp;amp;\text{subject to : } \alpha_{i} \geq 0,\ \sum_{i=1}^{N} \alpha_{i}y_{i} = 0 \quad (i = 1, \dots, N)
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を解けば良いことになる。
脚注 &lt;a class="footnote-reference" href="#id44" id="id25"&gt;[11]&lt;/a&gt; で既に触れたが、SVM のマージン最大化は凸計画問題である。従って局所最適解が存在せず、極大値が大域的な最大値に一致する。
ソフトマージンに対応する時は、1 ノルムソフトマージンの際には係数に値域&lt;span class="math"&gt;\(0 \geq \alpha_{i} \geq C_{1}\ (i=1,...,N)\)&lt;/span&gt;を設け、2 ノルムの際にはカーネル関数&lt;span class="math"&gt;\(K\)&lt;/span&gt;を次のように書き換えれば良い：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
K'(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) = K(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) + \frac{\delta_{ij}}{C_{2}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここでは簡単な&lt;strong&gt;最急勾配法&lt;/strong&gt;によって解を求めることを考える。
最急勾配法の原理は単純である。&lt;span class="math"&gt;\(F(\boldsymbol{\alpha}) = {\cal L}(\boldsymbol{w}^{\star}, \boldsymbol{\alpha})\)&lt;/span&gt;
とおくと、その&lt;span class="math"&gt;\(\boldsymbol{\alpha}\)&lt;/span&gt;による偏微分&lt;span class="math"&gt;\(\frac{\partial F(\boldsymbol{\alpha})}{\partial \boldsymbol{\alpha}}\)&lt;/span&gt;は&lt;strong&gt;勾配&lt;/strong&gt;、即ち&lt;span class="math"&gt;\(F(\boldsymbol{\alpha})\)&lt;/span&gt;の最も上昇する方向を指すベクトルとなるので、係数の更新量&lt;span class="math"&gt;\(\Delta\boldsymbol{\alpha}\)&lt;/span&gt;は学習率&lt;span class="math"&gt;\(\eta &amp;gt; 0\)&lt;/span&gt;を用いて&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\Delta \boldsymbol{\alpha} = \eta \frac{\partial F(\boldsymbol{\alpha})}{\partial \boldsymbol{\alpha}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とすれば良い &lt;a class="footnote-reference" href="#id45" id="id26"&gt;[12]&lt;/a&gt; 。学習の収束判定は、例えば&lt;span class="math"&gt;\(||\Delta \boldsymbol{\alpha}||\)&lt;/span&gt;が十分小さくなった時とすれば良く、その時は極大値が得られている。
実際に&lt;span class="math"&gt;\(\frac{\partial F(\boldsymbol{\alpha})}{\partial \boldsymbol{\alpha}}\)&lt;/span&gt;を計算することを考える。&lt;span class="math"&gt;\(\frac{\partial F(\boldsymbol{\alpha})}{\partial \alpha_{i}}\ (i=1,...,N)\)&lt;/span&gt;は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
\frac{\partial F(\boldsymbol{\alpha})}{\partial \alpha_{i}} &amp;amp;= 1 - \frac{1}{2} \frac{\partial}{\partial \alpha_{i}} \left( \alpha_{1} \alpha_{1} y_{1} y_{1} \boldsymbol{x}_{1}^{\mathsf{T}} \boldsymbol{x}_{1} + ... + \alpha_{i} \alpha_{1} y_{i} y_{1} \boldsymbol{x}_{i}^{\mathsf{T}} \boldsymbol{x}_{1} + ... + \alpha_{i} \alpha_{N} y_{i} y_{N} \boldsymbol{x}_{i}^{\mathsf{T}} \boldsymbol{x}_{N} + ... + \alpha_{1} \alpha_{i} y_{1} y_{i} \boldsymbol{x}_{1}^{\mathsf{T}} \boldsymbol{x}_{i} + ... + \alpha_{N} \alpha_{i} y_{N} y_{i} \boldsymbol{x}_{N}^{\mathsf{T}} \boldsymbol{x}_{i} + ... + \alpha_{N} \alpha_{N} y_{N} y_{N} \boldsymbol{x}_{N}^{\mathsf{T}} \boldsymbol{x}_{N} \right) \\
    &amp;amp;= 1 - \sum_{j=1}^{N} \alpha_{j} y_{i} y_{j} \boldsymbol{x}_{i}^{\mathsf{T}} \boldsymbol{x}_{j}
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;よって、ステップ&lt;span class="math"&gt;\(t\)&lt;/span&gt;時の係数&lt;span class="math"&gt;\(\alpha_{i}(t)\ (i=1,...,N)\)&lt;/span&gt;について以下の更新規則に従って学習を行えば良い：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\alpha_{i}(t+1) = \alpha_{i}(t) + \eta \left( 1 - \sum_{j=1}^{N} \alpha_{j} y_{i} y_{j} \boldsymbol{x}_{i}^{\mathsf{T}} \boldsymbol{x}_{j} \right)
\end{equation*}
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id27"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id59"&gt;実装&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;学習を行っている箇所を抜粋すると次の様になる：&lt;/p&gt;
&lt;pre class="code c literal-block"&gt;
&lt;span class="cm"&gt;/* 勾配値の計算 */&lt;/span&gt;
&lt;span class="n"&gt;diff_dist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_num&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;i_x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;diff_sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_y&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_num&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;i_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="cm"&gt;/* C2 を踏まえたカーネル関数値を計算 */&lt;/span&gt;
    &lt;span class="n"&gt;kernel_val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GRAM_MATRIX_AT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;gram_matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_num&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i_y&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_x&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;i_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;kernel_val&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0f&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;soft_margin_C2&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;diff_sum&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_y&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_label&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_y&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;kernel_val&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;diff_sum&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_label&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_x&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
  &lt;span class="n"&gt;diff_dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0f&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;diff_sum&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;diff_dist&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0f&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;diff_sum&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0f&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;diff_sum&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="cm"&gt;/* 双対係数の更新 */&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_num&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_label&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;continue&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="cm"&gt;/* printf(&amp;quot;dual_coef[%d]:%f -&amp;gt; &amp;quot;, i_sample, handle-&amp;gt;dual_coef[i_sample]); */&lt;/span&gt;
  &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;diff_dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;SMPSVM_MOMENT_RATE&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;pre_diff_dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
  &lt;span class="cm"&gt;/* printf(&amp;quot;%f \n&amp;quot;, handle-&amp;gt;dual_coef[i_sample]); */&lt;/span&gt;

  &lt;span class="cm"&gt;/* 非数 , 無限チェック */&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;isnan&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;isinf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;fprintf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Detected NaN or Inf Dual-Coffience. &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;既にコメントが付いているが、特筆すべき点について補足する。&lt;/p&gt;
&lt;pre class="code c literal-block"&gt;
&lt;span class="cm"&gt;/* C2 を踏まえたカーネル関数値を計算 */&lt;/span&gt;
&lt;span class="n"&gt;kernel_val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GRAM_MATRIX_AT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;gram_matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_num&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i_y&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;予め計算しておいたカーネル関数値をグラム行列から取り出している。学習中は何度もカーネル関数値を計算するため、グラム行列を用意しておくことで若干高速化できる。&lt;/p&gt;
&lt;pre class="code c literal-block"&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_x&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;i_y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;kernel_val&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0f&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;soft_margin_C2&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;2 ノルムソフトマージンのカーネル関数値を加味している。2 ノルムソフトマージンを使用しない場合は&lt;tt class="docutils literal"&gt;soft_margin_C2 == FLT_MAX&lt;/tt&gt;となっているため、無視できる。&lt;/p&gt;
&lt;pre class="code c literal-block"&gt;
&lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;diff_dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;SMPSVM_MOMENT_RATE&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;pre_diff_dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;係数更新を行っている。ここでは、単純な最急勾配分のみだけではなく、前回の勾配値に定数を乗じて加えた&lt;strong&gt;モーメント法&lt;/strong&gt;を使用している。一般にモーメント法を使用したほうが学習が早くなることが知られている。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id28"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id60"&gt;制約条件の考慮&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;学習則は単純に見えても実装時に落とし穴になるのが制約条件である。&lt;/p&gt;
&lt;div class="section" id="id29"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id61"&gt;正例と負例の双対係数の和を等しくする&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;KKT 条件から導かれる&lt;span class="math"&gt;\(\boldsymbol{\alpha}\)&lt;/span&gt;についての制約&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\sum_{i=1}^{N} \alpha_{i}y_{i} = 0
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を実現するのが案外難しい。上の制約から、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  &amp;amp;\sum_{y_{i}=1} \alpha_{i} - \sum_{y_{i}=-1} \alpha_{i} = 0  \\
  &amp;amp;\iff \sum_{y_{i}=1} \alpha_{i} = \sum_{y_{i}=-1} \alpha_{i}
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が導かれるため、正例と負例の双対係数の和は等しくなる事が分かる。
本実装では、&lt;span class="math"&gt;\(\alpha_{i}y_{i}\)&lt;/span&gt;の平均を取り、全係数&lt;span class="math"&gt;\(\alpha_{i}\ (i=1,...,N)\)&lt;/span&gt;をその平均に寄せることで上記の制約を満たすように係数を修正している。&lt;/p&gt;
&lt;pre class="code c literal-block"&gt;
&lt;span class="cm"&gt;/* 制約 1: 正例と負例の双対係数和を等しくする . */&lt;/span&gt;
&lt;span class="n"&gt;dual_coef_average&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_num&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;dual_coef_average&lt;/span&gt;
    &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_label&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;dual_coef_average&lt;/span&gt; &lt;span class="o"&gt;/=&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_num&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_num&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_label&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;continue&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dual_coef_average&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_label&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;この制約を満たすための実装はこの限りではない。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id30"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id62"&gt;双対係数は非負&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;双対係数は非負でなければならないため、負になった係数は全て 0 に修正してしまう。
学習が進むに連れて 0 の係数が増えていくが、それは SVM の持つスパース学習の効果が現れている状態である。学習が収束した時、0 に潰れず非負値となった係数に対応するサンプルが&lt;strong&gt;サポートベクトル&lt;/strong&gt;である。&lt;/p&gt;
&lt;pre class="code c literal-block"&gt;
&lt;span class="cm"&gt;/* 制約 2: 双対係数は非負 */&lt;/span&gt;
&lt;span class="n"&gt;coef_dist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_num&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;soft_margin_C1&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="cm"&gt;/* C1 ノルムの制約を適用 */&lt;/span&gt;
    &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soft_margin_C1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="cm"&gt;/* ここで最終結果が出る . 前回との変化を計算 */&lt;/span&gt;
  &lt;span class="n"&gt;coef_diff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pre_dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
  &lt;span class="n"&gt;coef_dist&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coef_diff&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;coef_diff&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;本実装では、非負条件に咥えて 1 ノルムソフトマージンの制約も追加で判定している。1 ノルムソフトマージンを使用しない時は&lt;tt class="docutils literal"&gt;soft_margin_C1 == FLT_MAX&lt;/tt&gt;となっているため、無視できる。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id31"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id63"&gt;識別&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="# マージンの定式化 "&gt;マージンの定式化&lt;/a&gt;で述べたが、SVM のクラス識別は出力値&lt;span class="math"&gt;\(y\)&lt;/span&gt;の正負によって判断する &lt;a class="footnote-reference" href="#id46" id="id32"&gt;[13]&lt;/a&gt; 。SVM の出力式&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
g(\boldsymbol{x}, \boldsymbol{w}) = \boldsymbol{w}^{\mathsf{T}} \boldsymbol{x} + b
\end{equation*}
&lt;/div&gt;
&lt;p&gt;に、KKT 条件における最適条件&lt;span class="math"&gt;\(\boldsymbol{w}^{\star} = \sum_{i=1}^{N} \alpha_{i}y_{i}\boldsymbol{x}_{i}\)&lt;/span&gt;を代入すれば、次の&lt;strong&gt;双対表現&lt;/strong&gt;が得られる：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
g(\boldsymbol{x}, \boldsymbol{w}^{\star}) = \sum_{i=1}^{N} \alpha_{i} y_{i} K(\boldsymbol{x}_{i}, \boldsymbol{x}) + b
\end{equation*}
&lt;/div&gt;
&lt;p&gt;識別の際には、学習済みの係数&lt;span class="math"&gt;\(\boldsymbol{\alpha}\)&lt;/span&gt;を使用して上式を計算し、その正負を判定すれば良い。実装としては次の様になる：&lt;/p&gt;
&lt;pre class="code c literal-block"&gt;
&lt;span class="cm"&gt;/* ネットワーク出力計算 */&lt;/span&gt;
&lt;span class="n"&gt;network_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_num&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="cm"&gt;/* 係数が正に相当するサンプル（サポートベクトル）
   * のみを計算する */&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;network_output&lt;/span&gt;
      &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_label&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;dual_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
      &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;kernel_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;sample_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;normalized_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data_dim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;kernel_parameter&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="cm"&gt;/* 識別 */&lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;network_output&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="id33"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id64"&gt;脚注&lt;/a&gt;&lt;/h2&gt;
&lt;table class="docutils footnote" frame="void" id="id34" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;高村大也、 奥村学、 “ 言語処理のための機械学習入門 ”、 コロナ社、 2010&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id35" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;高橋治久、 堀田一弘、 “ 学習理論 ” コロナ社、 2009&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id36" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id6"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;くどいかもしれないが、
サポートベクトルは最も識別面に近いサンプルなので、この仮定により&lt;span class="math"&gt;\(y_{i}(\boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}+b) \geq l \quad (i=1, \dots, N)\)&lt;/span&gt;が成り立つ。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id37" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id8"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;（証明） -
最適化対象について、&lt;span class="math"&gt;\(\displaystyle \frac{1}{2}\boldsymbol{w}^{\mathsf{T}}\boldsymbol{w} = \frac{1}{2} \sum_{i=1}^{n} w_{i}^{2}\)&lt;/span&gt;より（&lt;span class="math"&gt;\(\boldsymbol{w}=[w_{1}\dots w_{n}]^\mathsf{T}\)&lt;/span&gt;）、
明らかに下に凸である。 -
制約条件について、&lt;span class="math"&gt;\(W_{i} = \{ \boldsymbol{w} | y_{i}(\boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}\_{i}+b) \geq 1 \}\)&lt;/span&gt;とおくと、&lt;span class="math"&gt;\(\forall \boldsymbol{w}^{\prime}, \boldsymbol{w}^{\prime\prime} \in W_{i}, \forall t \in [0, 1]\)&lt;/span&gt;に対して、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned} y_{i} \left[ \left( t\boldsymbol{w}^{\prime\mathsf{T}} + (1-t) \boldsymbol{w}^{\prime\prime\mathsf{T}} \right) \boldsymbol{x}\_{i} + b \right] = y_{i} \left[ t(\boldsymbol{w}^{\prime\mathsf{T}}\boldsymbol{x}\_{i} - \boldsymbol{w}^{\prime\prime\mathsf{T}}\boldsymbol{x}\_{i}) + \boldsymbol{w}^{\prime\prime\mathsf{T}}\boldsymbol{x}\_{i} + b \right] \\
            = y_{i} \left[ t\left( (\boldsymbol{w}^{\prime\mathsf{T}}\boldsymbol{x}\_{i} + b) - (\boldsymbol{w}^{\prime\prime\mathsf{T}}\boldsymbol{x}\_{i} + b) \right) + \boldsymbol{w}^{\prime\prime\mathsf{T}}\boldsymbol{x}\_{i} + b \right] \\
            = t y_{i} (\boldsymbol{w}^{\prime\mathsf{T}}\boldsymbol{x}\_{i} + b) + (1-t) y_{i}(\boldsymbol{w}^{\prime\prime\mathsf{T}}\boldsymbol{x}\_{i} + b) \\
            \geq t + (1-t) = 1\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;よって、&lt;span class="math"&gt;\(t\boldsymbol{w}^{\prime} + (1-t) \boldsymbol{w}^{\prime\prime} \in W_{i}\)&lt;/span&gt;より&lt;span class="math"&gt;\(W_{i}\)&lt;/span&gt;は凸集合。
最適化問題においては、
&lt;span class="math"&gt;\(W_{i}\)&lt;/span&gt;の共通部分&lt;span class="math"&gt;\(\bigcap_{i=1}^{N} W_{i}\)&lt;/span&gt;を考えれば良く、
&lt;strong&gt;凸集合の積集合もまた凸集合&lt;/strong&gt; なので、
制約条件も凸集合となる。以上の 2 点より、 マージン最大化は凸計画問題。
（凸集合の積集合もまた凸集合であることの証明）2 つの凸集合を&lt;span class="math"&gt;\(A_{1},A_{2}\)&lt;/span&gt;とする。
両者の集合の積&lt;span class="math"&gt;\(A_{1}\cap A_{2}\)&lt;/span&gt;が空集合ならば、
空集合は凸集合と定義されるので命題は成立する。
一般に&lt;span class="math"&gt;\(A_{1}\cap A_{2}\)&lt;/span&gt;から 2 点&lt;span class="math"&gt;\(x,y\)&lt;/span&gt;をとると ,
&lt;span class="math"&gt;\(x, y\)&lt;/span&gt;を結ぶ線分は、
&lt;span class="math"&gt;\(A_{1}, A_{2}\)&lt;/span&gt;は共に凸集合なので、
&lt;span class="math"&gt;\(A_{1}\)&lt;/span&gt;にも&lt;span class="math"&gt;\(A_{2}\)&lt;/span&gt;にも属していて飛び出ることはない。
これは集合の積&lt;span class="math"&gt;\(A_{1}\cap A_{2}\)&lt;/span&gt;が凸集合であることを示している。&lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id38" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id9"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;（鞍点&lt;span class="math"&gt;\((\boldsymbol{v}^{\star}, \boldsymbol{\alpha}^{\star})\)&lt;/span&gt;が最適点となる事の証明）
&lt;span class="math"&gt;\((\boldsymbol{v}^{\star}, \boldsymbol{\alpha}^{\star})\)&lt;/span&gt;は鞍点なので、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned} {\cal L}(\boldsymbol{v}, \boldsymbol{\alpha}^{\star}) \leq {\cal L}(\boldsymbol{v}^{\star}, \boldsymbol{\alpha}^{\star}) \leq {\cal L}(\boldsymbol{v}^{\star}, \boldsymbol{\alpha}) \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たす。
従って右側の不等式から&lt;span class="math"&gt;\(\boldsymbol{\alpha}^{\star\mathsf{T}}\boldsymbol{g}(\boldsymbol{v}^{\star}) \leq \boldsymbol{\alpha}^{\mathsf{T}}\boldsymbol{g}(\boldsymbol{v}^{\star})\)&lt;/span&gt;が任意の&lt;span class="math"&gt;\(\boldsymbol{\alpha}\)&lt;/span&gt;で成立する。
即ち&lt;span class="math"&gt;\(\boldsymbol{\alpha} = \boldsymbol{0}\)&lt;/span&gt;の時、
&lt;span class="math"&gt;\(g_{i}(\boldsymbol{v}^{\star}) \geq 0\)&lt;/span&gt;と併せて&lt;span class="math"&gt;\(\boldsymbol{\alpha}^{\star\mathsf{T}}\boldsymbol{g}(\boldsymbol{v}^{\star}) = 0\)&lt;/span&gt;が成立する。
更に、 ここで関係式&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned} {\cal L}(\boldsymbol{v}, \boldsymbol{\alpha}^{\star}) - {\cal L}(\boldsymbol{v}^{\star}, \boldsymbol{\alpha}^{\star}) \leq \left( \frac{\partial {\cal L}(\boldsymbol{v}^{\star}, \boldsymbol{\alpha})}{\partial \boldsymbol{v}} \right)^{\mathsf{T}} (\boldsymbol{v} - \boldsymbol{v}^{\star}) \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を用いる（証明は後術）と、
鞍点であることから&lt;span class="math"&gt;\(\displaystyle\frac{\partial {\cal L}(\boldsymbol{v}^{\star}, \boldsymbol{\alpha})}{\partial \boldsymbol{v}} = \boldsymbol{0}\)&lt;/span&gt;であり、
また、
&lt;span class="math"&gt;\(\boldsymbol{\alpha}^{\star\mathsf{T}}\boldsymbol{g}(\boldsymbol{v}^{\star}) = 0\)&lt;/span&gt;より、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned} {\cal L}(\boldsymbol{v}, \boldsymbol{\alpha}^{\star}) - {\cal L}(\boldsymbol{v}^{\star}, \boldsymbol{\alpha}^{\star}) &amp;amp;= {\cal L}(\boldsymbol{v}, \boldsymbol{\alpha}^{\star}) - f(\boldsymbol{v}^{\star}) \leq 0 \iff f(\boldsymbol{v}^{\star}) \geq {\cal L}(\boldsymbol{v}, \boldsymbol{\alpha}^{\star}) \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成り立つ。 更に、
もとより&lt;span class="math"&gt;\(\boldsymbol{\alpha}^{\star\mathsf{T}}\boldsymbol{g}(\boldsymbol{v}) \geq 0\)&lt;/span&gt;なので、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned} f(\boldsymbol{v}) \leq f(\boldsymbol{v}) + \boldsymbol{\alpha}^{\star\mathsf{T}}\boldsymbol{g}(\boldsymbol{v}) = {\cal L}(\boldsymbol{v}, \boldsymbol{\alpha}^{\star}) \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;従って&lt;span class="math"&gt;\(f(\boldsymbol{v}^{\star}) \geq f(\boldsymbol{v})\)&lt;/span&gt;が任意の&lt;span class="math"&gt;\(\boldsymbol{v}\)&lt;/span&gt;で成立し、&lt;span class="math"&gt;\((\boldsymbol{v}^{\star}, \boldsymbol{\alpha}^{\star})\)&lt;/span&gt;が最適点となる事が示された。
次いで (＊) を証明する。&lt;span class="math"&gt;\({\cal L}(\boldsymbol{v}, \boldsymbol{\alpha})\)&lt;/span&gt;が凸関数ならば、
&lt;span class="math"&gt;\({\cal L}(t\boldsymbol{v}^{\prime}+(1-t)\boldsymbol{v}^{\prime\prime}, \boldsymbol{\alpha}^{\star}) \geq t {\cal L}(\boldsymbol{v}^{\prime}, \boldsymbol{\alpha}^{\star}) + (1-t) {\cal L}(\boldsymbol{v}^{\prime}, \boldsymbol{\alpha}^{\star})\)&lt;/span&gt;が&lt;span class="math"&gt;\(t \in [0,1]\)&lt;/span&gt;で成立する。
よって、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
t{\cal L}(\boldsymbol{v}^{\prime}, \boldsymbol{\alpha}^{\star}) \leq t{\cal L}(\boldsymbol{v}^{\prime\prime}, \boldsymbol{\alpha}^{\star}) - {\cal L}(\boldsymbol{v}^{\prime\prime}, \boldsymbol{\alpha}^{\star}) + {\cal L}(t\boldsymbol{v}^{\prime}+(1-t)\boldsymbol{v}^{\prime\prime}, \boldsymbol{\alpha}^{\star}) \iff {\cal L}(\boldsymbol{v}^{\prime}, \boldsymbol{\alpha}^{\star}) \leq {\cal L}(\boldsymbol{v}^{\prime\prime}, \boldsymbol{\alpha}^{\star}) + \frac{{\cal L}(\boldsymbol{v}^{\prime\prime} + t(\boldsymbol{v}^{\prime}-\boldsymbol{v}^{\prime\prime}), \boldsymbol{\alpha}^{\star}) - {\cal L}(\boldsymbol{v}^{\prime\prime}, \boldsymbol{\alpha}^{\star})}{t}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで&lt;span class="math"&gt;\(t \to 0\)&lt;/span&gt;ならしめれば、
方向微分と勾配の関係式より、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
{\cal L}(\boldsymbol{v}^{\prime}, \boldsymbol{\alpha}^{\star}) - {\cal L}(\boldsymbol{v}^{\prime\prime}, \boldsymbol{\alpha}^{\star}) \leq \left( \frac{\partial {\cal L}(\boldsymbol{v}^{\prime\prime}, \boldsymbol{\alpha}^{\star})}{\partial \boldsymbol{v}} \right)^{\mathsf{T}} (\boldsymbol{v}^{\prime} - \boldsymbol{v}^{\prime\prime})
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;を得る。&lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id39" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id11"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;互いに同一平面上&lt;strong&gt;以外&lt;/strong&gt;の位置にある事。
例えば、2 次元空間では同一直線上以外の位置であり、3 次元空間では同一平面上以外の位置である。異なるクラスのサンプルが一般位置にあれば、もとより線形分離可能である。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id40" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id12"&gt;[7]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;有限個数&lt;span class="math"&gt;\(N&amp;lt;\infty\)&lt;/span&gt;のサンプルに対し、&lt;span class="math"&gt;\((\boldsymbol{G})\_{ij} = K(\boldsymbol{x}\_{i}, \boldsymbol{x}\_{j})\)&lt;/span&gt;、即ち&lt;span class="math"&gt;\((i,j)\)&lt;/span&gt;成分の値が&lt;span class="math"&gt;\(K(\boldsymbol{x}\_{i}, \boldsymbol{x}\_{j})\)&lt;/span&gt;となっている行列&lt;span class="math"&gt;\(\boldsymbol{G}\)&lt;/span&gt;をグラム（カーネル）行列という。特徴写像が有限次元ならば、グラム行列が（有限）正定値行列ならば&lt;span class="math"&gt;\(K\)&lt;/span&gt;はカーネル関数となる。特徴写像が無限次元の場合のカーネル関数の条件がマーサーの定理である。
その内容は、入力空間&lt;span class="math"&gt;\(X\subset \mathbb{R}^{n}\)&lt;/span&gt;が有界閉集合（&lt;span class="math"&gt;\(\iff\)&lt;/span&gt;コンパクト）であるとし、対象な連続関数&lt;span class="math"&gt;\(K\)&lt;/span&gt;が正定値、即ち任意の二乗可積分（二乗積分可能）な関数&lt;span class="math"&gt;\(f\)&lt;/span&gt;に対し&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
  \int_{X\times X}K(x, z)f(x)f(z)dxdz \geq 0\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ならば、ヒルベルト空間の正規直交基底&lt;span class="math"&gt;\(\phi_{j}\ (j=1, 2, \dots)\)&lt;/span&gt;で次式が一様収束するものが存在する場合、&lt;span class="math"&gt;\(K\)&lt;/span&gt;はカーネル関数である。&lt;/p&gt;
&lt;div class="last math"&gt;
\begin{equation*}
\begin{aligned} K(x, z) = \sum_{j=1}^{\infty} \phi_{j}(x)\phi_{j}(z) \end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id41" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id14"&gt;[8]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;サンプルに現れない未知のデータでももれなく識別できる能力&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id42" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id15"&gt;[9]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;双対問題において、
&lt;span class="math"&gt;\(C_{1}, C_{2} \to \infty\)&lt;/span&gt;とすると、ハードマージン SVM に一致することが分かる&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id43" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id18"&gt;[10]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;サンプルに最も当てはまる曲線（面）を探す問題。もう少し形式的に言うと、各サンプル&lt;span class="math"&gt;\(\boldsymbol{x}\_{i}\)&lt;/span&gt;でのラベル&lt;span class="math"&gt;\(y_{i}\)&lt;/span&gt;の平均値を表す関数&lt;span class="math"&gt;\(f\)&lt;/span&gt;を学習する問題。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id44" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id25"&gt;[11]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;（証明） -
最適化対象について、&lt;span class="math"&gt;\(\displaystyle \frac{1}{2}\boldsymbol{w}^{\mathsf{T}}\boldsymbol{w} = \frac{1}{2} \sum_{i=1}^{n} w_{i}^{2}\)&lt;/span&gt;より（&lt;span class="math"&gt;\(\boldsymbol{w}=[w_{1}\dots w_{n}]^\mathsf{T}\)&lt;/span&gt;）、
明らかに下に凸である。 -
制約条件について、&lt;span class="math"&gt;\(W_{i} = \{ \boldsymbol{w} | y_{i}(\boldsymbol{w}^{\mathsf{T}}\boldsymbol{x}\_{i}+b) \geq 1 \}\)&lt;/span&gt;とおくと、&lt;span class="math"&gt;\(\forall \boldsymbol{w}^{\prime}, \boldsymbol{w}^{\prime\prime} \in W_{i}, \forall t \in [0, 1]\)&lt;/span&gt;に対して、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned} y_{i} \left[ \left( t\boldsymbol{w}^{\prime\mathsf{T}} + (1-t) \boldsymbol{w}^{\prime\prime\mathsf{T}} \right) \boldsymbol{x}\_{i} + b \right] = y_{i} \left[ t(\boldsymbol{w}^{\prime\mathsf{T}}\boldsymbol{x}\_{i} - \boldsymbol{w}^{\prime\prime\mathsf{T}}\boldsymbol{x}\_{i}) + \boldsymbol{w}^{\prime\prime\mathsf{T}}\boldsymbol{x}\_{i} + b \right] \\
            = y_{i} \left[ t\left( (\boldsymbol{w}^{\prime\mathsf{T}}\boldsymbol{x}\_{i} + b) - (\boldsymbol{w}^{\prime\prime\mathsf{T}}\boldsymbol{x}\_{i} + b) \right) + \boldsymbol{w}^{\prime\prime\mathsf{T}}\boldsymbol{x}\_{i} + b \right] \\
            = t y_{i} (\boldsymbol{w}^{\prime\mathsf{T}}\boldsymbol{x}\_{i} + b) + (1-t) y_{i}(\boldsymbol{w}^{\prime\prime\mathsf{T}}\boldsymbol{x}\_{i} + b) \\
            \geq t + (1-t) = 1\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;よって、&lt;span class="math"&gt;\(t\boldsymbol{w}^{\prime} + (1-t) \boldsymbol{w}^{\prime\prime} \in W_{i}\)&lt;/span&gt;より&lt;span class="math"&gt;\(W_{i}\)&lt;/span&gt;は凸集合。
最適化問題においては、
&lt;span class="math"&gt;\(W_{i}\)&lt;/span&gt;の共通部分&lt;span class="math"&gt;\(\bigcap_{i=1}^{N} W_{i}\)&lt;/span&gt;を考えれば良く、
&lt;strong&gt;凸集合の積集合もまた凸集合&lt;/strong&gt; なので、
制約条件も凸集合となる。以上の 2 点より、 マージン最大化は凸計画問題。
（凸集合の積集合もまた凸集合であることの証明）2 つの凸集合を&lt;span class="math"&gt;\(A_{1},A_{2}\)&lt;/span&gt;とする。
両者の集合の積&lt;span class="math"&gt;\(A_{1}\cap A_{2}\)&lt;/span&gt;が空集合ならば、
空集合は凸集合と定義されるので命題は成立する。
一般に&lt;span class="math"&gt;\(A_{1}\cap A_{2}\)&lt;/span&gt;から 2 点&lt;span class="math"&gt;\(x,y\)&lt;/span&gt;をとると ,
&lt;span class="math"&gt;\(x, y\)&lt;/span&gt;を結ぶ線分は、
&lt;span class="math"&gt;\(A_{1}, A_{2}\)&lt;/span&gt;は共に凸集合なので、
&lt;span class="math"&gt;\(A_{1}\)&lt;/span&gt;にも&lt;span class="math"&gt;\(A_{2}\)&lt;/span&gt;にも属していて飛び出ることはない。
これは集合の積&lt;span class="math"&gt;\(A_{1}\cap A_{2}\)&lt;/span&gt;が凸集合であることを示している。&lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id45" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id26"&gt;[12]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;ただし学習率&lt;span class="math"&gt;\(\eta\)&lt;/span&gt;の決め方は問題依存である。一般に、&lt;span class="math"&gt;\(\eta\)&lt;/span&gt;が小さすぎると学習が進行せず、大きすぎると極値を飛び越えてしまい学習が収束しない。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id46" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id32"&gt;[13]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;span class="math"&gt;\(y = 0\)&lt;/span&gt;の場合の判断を明確にしている書類がない。ここでは正と判定する。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="記事"></category><category term="機械学習"></category></entry><entry><title>MCMC（マルコフ連鎖モンテカルロ）法</title><link href="/mcmcmarukohulian-suo-montekarurofa.html" rel="alternate"></link><published>2020-04-23T12:20:00+09:00</published><updated>2020-04-30T14:30:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-23:/mcmcmarukohulian-suo-montekarurofa.html</id><summary type="html">&lt;p class="first last"&gt;MCMC法の概要について。実装はなく、ちょっと理論寄り。&lt;/p&gt;
</summary><content type="html">&lt;p&gt;本稿では MCMC 法の解説のため、MC 法による積分の計算方法（モンテカルロ積分）から、MCMC による手法の概要を見ていく。MCMC 法は有名かつ知り尽くされた手法で、多くの良質な説明資料 &lt;a class="footnote-reference" href="#id39" id="id1"&gt;[1]&lt;/a&gt;, &lt;a class="footnote-reference" href="#id40" id="id2"&gt;[2]&lt;/a&gt;, &lt;a class="footnote-reference" href="#id41" id="id3"&gt;[3]&lt;/a&gt;, &lt;a class="footnote-reference" href="#id42" id="id4"&gt;[4]&lt;/a&gt;, &lt;a class="footnote-reference" href="#id43" id="id5"&gt;[5]&lt;/a&gt; が存在している。従ってここの説明は読まずに、資料を見てもらった方が理解が早いかもしれない。&lt;/p&gt;
&lt;p&gt;一般に &lt;strong&gt;MC（Monte-Calro, モンテカルロ）法&lt;/strong&gt;
は、サンプリング（サンプルを乱数から生成すること）によってシミュレーションや数値計算を行う手法である。特に確率分布が関わる積分値 &lt;a class="footnote-reference" href="#id44" id="id6"&gt;[6]&lt;/a&gt; を近似的に求める MC 法はモンテカルロ積分と呼ばれる。モンテカルロ積分は確率的な推論の一種であり、大数の法則 &lt;a class="footnote-reference" href="#id45" id="id7"&gt;[7]&lt;/a&gt; によって、十分なサンプル数をとれば近似精度をいくらでも良くする事ができる。サンプリングの手間がある為、近似分布をあらかじめ仮定する様な決定論的な推論よりも遥かに推論が遅い。しかし、MC は近似分布が求められないような場合にも適用可能であり、汎用性が高いと言える。&lt;/p&gt;
&lt;p&gt;MC 法によって原理的には任意の解を求められるが、十分なサンプル数の要求というのが大きな問題を孕んでいる。サンプリングの自由度（範囲及び次元）が大きくなると、解の計算にあまり寄与しない（無駄な）サンプルが増えてしまう。計算を現実的かつ効率的に行うためには、サンプルの選択が重要になる。&lt;/p&gt;
&lt;p&gt;そして &lt;strong&gt;MCMC（Markov Chain Monte-Calro, マルコフ連鎖モンテカルロ）法&lt;/strong&gt;
は、新しいサンプルを以前に生成したサンプルに確率的に依存して（サンプルの列がマルコフ連鎖となる様に）生成する MC 法である。MCMC では、新しく生成したサンプルを採択（採用）するか棄却（捨てる）するかも確率的に判断する。この手続きによって、無駄なサンプルを極力減らすようにサンプリングを実行することができる。&lt;/p&gt;
&lt;div class="contents local topic" id="id8"&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#mc" id="id65"&gt;MC 法による積分 - モンテカルロ積分&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id13" id="id66"&gt;重点サンプリング&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id14" id="id67"&gt;MCMC&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id16" id="id68"&gt;遷移確率の条件 - 詳細釣り合い条件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id22" id="id69"&gt;メトロポリス - ヘイスティングス法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id27" id="id70"&gt;ギブスサンプリング&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id30" id="id71"&gt;MCMC による最適化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id31" id="id72"&gt;焼きなまし法&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id32" id="id73"&gt;補足&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id33" id="id74"&gt;エルゴード的なマルコフ連鎖の定常分布&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id37" id="id75"&gt;詳細釣り合い条件の証明&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id38" id="id76"&gt;脚注&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="mc"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id65"&gt;MC 法による積分 - モンテカルロ積分&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;確率変数を&lt;span class="math"&gt;\(d\)&lt;/span&gt;次元の実数値ベクトル &lt;a class="footnote-reference" href="#id46" id="id9"&gt;[8]&lt;/a&gt;
&lt;span class="math"&gt;\(\boldsymbol{x} = [x_{1},\dots,x_{d}]^{\mathsf{T}} \in X \subset \mathbb{R}^{d}\)&lt;/span&gt;とする。ここで&lt;span class="math"&gt;\(X\)&lt;/span&gt;は全事象 &lt;a class="footnote-reference" href="#id47" id="id10"&gt;[9]&lt;/a&gt;
の集合である。&lt;span class="math"&gt;\(\boldsymbol{x}\)&lt;/span&gt;の確率分布を&lt;span class="math"&gt;\(r(\boldsymbol{x})\)&lt;/span&gt;とし、関数&lt;span class="math"&gt;\(h\)&lt;/span&gt;の確率分布&lt;span class="math"&gt;\(r\)&lt;/span&gt;による平均（期待値）&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
I = \int_{X} h(\boldsymbol{x})r(\boldsymbol{x}) d\boldsymbol{x} = \mathrm{E}_{r}[h(\boldsymbol{x})] \tag{1}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を求めることを考える。ここで、&lt;span class="math"&gt;\(\mathrm{E}_{p}[\cdot]\)&lt;/span&gt;は確率分布&lt;span class="math"&gt;\(p\)&lt;/span&gt;による平均を表す。&lt;span class="math"&gt;\(I\)&lt;/span&gt;において、関数&lt;span class="math"&gt;\(h\)&lt;/span&gt;の形に制約を与えておらず積分として様々な値が計算できる。例を挙げると :&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;span class="math"&gt;\(h(\boldsymbol{x}) = \boldsymbol{x}\)&lt;/span&gt; :
この場合は&lt;span class="math"&gt;\(\mathrm{E}_{r}[\boldsymbol{x}]\)&lt;/span&gt;、即ち&lt;span class="math"&gt;\(\boldsymbol{x}\)&lt;/span&gt;の平均を求める&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(h(\boldsymbol{x}) = (\boldsymbol{x} - \mathrm{E_{r}}[\boldsymbol{x}])(\boldsymbol{x} - \mathrm{E_{r}}[\boldsymbol{x}])^{\mathsf{T}}\)&lt;/span&gt;
: &lt;span class="math"&gt;\(\boldsymbol{x}\)&lt;/span&gt;の分散を求める&lt;/li&gt;
&lt;li&gt;… その他  &lt;a class="footnote-reference" href="#id48" id="id11"&gt;[10]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;もし&lt;span class="math"&gt;\(r(\boldsymbol{x})\)&lt;/span&gt;が既知で、分布&lt;span class="math"&gt;\(r\)&lt;/span&gt;から簡単に独立にサンプリングできる &lt;a class="footnote-reference" href="#id49" id="id12"&gt;[11]&lt;/a&gt; ならば、&lt;span class="math"&gt;\(r(\boldsymbol{x})\)&lt;/span&gt;からの独立な（他のサンプルに依存して生成しない）&lt;span class="math"&gt;\(n\)&lt;/span&gt;個のサンプルを&lt;span class="math"&gt;\(\boldsymbol{x}_{1}, \boldsymbol{x}_{2}, \dots, \boldsymbol{x}_{n}\)&lt;/span&gt;と書くと、&lt;span class="math"&gt;\(I\)&lt;/span&gt;の標本平均による近似値&lt;span class="math"&gt;\(\hat{I}\)&lt;/span&gt;は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hat{I} = \frac{1}{n} \sum_{i=1}^{n} h(\boldsymbol{x}_{i}) \tag{2}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;で計算できる。大数の法則により、サンプル数の極限を取れば標本平均は真の平均に一致する :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\lim_{n \to \infty} \hat{I} = I
\end{equation*}
&lt;/div&gt;
&lt;p&gt;この様にして平均を求める方法を &lt;strong&gt;モンテカルロ積分 (Monte-Carlo
Integration)&lt;/strong&gt; という。一般にモンテカルロ法 (Monte-Carlo
Method) はサンプリングによってシミュレーションや数値計算を行う事を指す。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id13"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id66"&gt;重点サンプリング&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;モンテカルロ積分によって、原理的には&lt;span class="math"&gt;\(\hat{I}\)&lt;/span&gt;を多くのサンプルで計算する事で&lt;span class="math"&gt;\(I\)&lt;/span&gt;を精度良く計算できる。しかし実際確率分布&lt;span class="math"&gt;\(r(\boldsymbol{x})\)&lt;/span&gt;は複雑であることが多く、その場合&lt;span class="math"&gt;\(r(\boldsymbol{x})\)&lt;/span&gt;から直接サンプリングするのは困難となる。そこで、より簡単でサンプリング可能な確率分布（&lt;strong&gt;提案分布&lt;/strong&gt;
という）&lt;span class="math"&gt;\(q(\boldsymbol{x})\)&lt;/span&gt;を用意して、そこからサンプリングする事を考える。&lt;span class="math"&gt;\(q(\boldsymbol{x})\)&lt;/span&gt;を使えば、&lt;span class="math"&gt;\(I\)&lt;/span&gt;は次の様に変形できる :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
I = \int_{X} h(\boldsymbol{x})\frac{r(\boldsymbol{x})}{q(\boldsymbol{x})} q(\boldsymbol{x}) d\boldsymbol{x} = \mathrm{E}_{q}\left[ h(\boldsymbol{x})\frac{r(\boldsymbol{x})}{q(\boldsymbol{x})} \right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;モンテカルロ積分の時と同じ様にに考え、次は&lt;span class="math"&gt;\(\boldsymbol{x}_{1},\dots,\boldsymbol{x}_{n}\)&lt;/span&gt;を&lt;span class="math"&gt;\(q(\boldsymbol{x})\)&lt;/span&gt;からの独立な&lt;span class="math"&gt;\(n\)&lt;/span&gt;個のサンプルにすれば、&lt;span class="math"&gt;\(I\)&lt;/span&gt;の近似値&lt;span class="math"&gt;\(\hat{I}_{IS}\)&lt;/span&gt;として&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hat{I}_{IS} = \frac{1}{n} \sum_{i=1}^{n} h(\boldsymbol{x}_{i}) \frac{r(\boldsymbol{x}_{i})}{q(\boldsymbol{x}_{i})} = \frac{1}{n} \sum_{i=1}^{n} h(\boldsymbol{x}_{i}) w(\boldsymbol{x}_{i}) \tag{3}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が得られる。ここで&lt;span class="math"&gt;\(w(\boldsymbol{x}_{i}) = r(\boldsymbol{x}_{i})/q(\boldsymbol{x}_{i})\)&lt;/span&gt;はサンプル&lt;span class="math"&gt;\(\boldsymbol{x}_{i}\)&lt;/span&gt;に対する重みと見ることができる。この様に、重みが付いたサンプルで平均を求める手法を
&lt;strong&gt;重点サンプリング (Importance Sampling)&lt;/strong&gt;
という。重点サンプリングにおいても、&lt;span class="math"&gt;\(q(\boldsymbol{x})\)&lt;/span&gt;がある条件を満たしていれば、大数の法則によって&lt;span class="math"&gt;\(\displaystyle\lim_{n \to \infty} \hat{I}_{IS} = I\)&lt;/span&gt;となることが保証されている。&lt;/p&gt;
&lt;div class="section" id="id14"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id67"&gt;MCMC&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;重点サンプリングの考え方によって、確率分布&lt;span class="math"&gt;\(r\)&lt;/span&gt;が複雑でも替わりに提案分布&lt;span class="math"&gt;\(q\)&lt;/span&gt;を用いてサンプリングを行えばモンテカルロ積分が計算できる事が確かめられた。しかし、&amp;quot;
&lt;span class="math"&gt;\(r\)&lt;/span&gt;より簡単でサンプリング可能な&lt;span class="math"&gt;\(q\)&lt;/span&gt;&amp;quot;
を構成する事自体が一般に困難である。特に次元&lt;span class="math"&gt;\(d\)&lt;/span&gt;が増加すれば&lt;span class="math"&gt;\(r\)&lt;/span&gt;が複雑になるのはもちろん、全事象&lt;span class="math"&gt;\(X\)&lt;/span&gt;の自由度が増加し次元の呪い &lt;a class="footnote-reference" href="#id50" id="id15"&gt;[12]&lt;/a&gt; を引き起こす。即ち、&lt;span class="math"&gt;\(r\)&lt;/span&gt;を&lt;span class="math"&gt;\(q\)&lt;/span&gt;で良く近似出来てない時に毎回独立にサンプリングを行っていると、空間&lt;span class="math"&gt;\(X\)&lt;/span&gt;から当てずっぽうなサンプルを取得しているのと同様な状態になる。&lt;/p&gt;
&lt;p&gt;そこで、簡単な提案分布&lt;span class="math"&gt;\(q\)&lt;/span&gt;を用いて、かつ逐次的に以前のサンプルを使用して新しくサンプルを生成する手法が 90 年代以降使われる様になってきた。この場合、サンプル列はマルコフ連鎖 (Markov
Chain) をなす。そして、マルコフ連鎖で生成したサンプルによる MC 法を MCMC（Markov
Chain
Monte-Calro）法という。サンプル間の独立性は担保されなくなる為に MC 法の基本原理が成立しなくなるが、提案分布（マルコフ連鎖の遷移確率）がある性質を満たせば、十分なサンプル数で確率分布&lt;span class="math"&gt;\(r\)&lt;/span&gt;からのサンプリングが実現できる。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id16"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id68"&gt;遷移確率の条件 - 詳細釣り合い条件&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;概要でも既に述べたが、MCMC は生成したサンプル列がマルコフ連鎖をなすように生成する。今、サンプル列&lt;span class="math"&gt;\(\boldsymbol{x}_{0}, \boldsymbol{x}_{1}, \dots\)&lt;/span&gt;はマルコフ連鎖をなすので、生成した時刻（ステップ）で実際に観測した状態を&lt;span class="math"&gt;\(\boldsymbol{e}_{0}, \boldsymbol{e}_{1}, \dots \ (\boldsymbol{e}_{i} \in X \ i=0,1,\dots)\)&lt;/span&gt;と書くと、任意の時刻&lt;span class="math"&gt;\(n \geq 0\)&lt;/span&gt;で、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
P(\boldsymbol{x}_{n+1} = \boldsymbol{e}_{n+1}|\boldsymbol{x}_{0} = \boldsymbol{e}_{0}, \boldsymbol{x}_{1} = \boldsymbol{e}_{1}, \dots, \boldsymbol{x}_{n} = \boldsymbol{e}_{n}) = P(\boldsymbol{x}_{n+1} = \boldsymbol{e}_{n+1}|\boldsymbol{x}_{n} = \boldsymbol{e}_{n})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成り立つ（この性質をマルコフ性 &lt;a class="footnote-reference" href="#id51" id="id17"&gt;[13]&lt;/a&gt; という）。即ち、サンプルは直前のサンプルのみに依存して生成する。この様にサンプルを生成する場合、実はマルコフ連鎖が
&lt;strong&gt;エルゴード的 (ergodic)&lt;/strong&gt;
という性質を満たせば、大量のサンプルを用いた時にある分布（&lt;strong&gt;定常分布&lt;/strong&gt;）&lt;span class="math"&gt;\(\pi\)&lt;/span&gt;からサンプリングしているのと同様になる。&lt;/p&gt;
&lt;p&gt;マルコフ連鎖がエルゴード的であるとは、規約性（どの状態からでも任意の状態へ遷移できる）と正再帰性（任意の状態へ何回でも遷移できる）非周期性（任意の状態は一回の遷移で元に戻れる）を全て同時に満たすことを言う &lt;a class="footnote-reference" href="#id52" id="id18"&gt;[14]&lt;/a&gt;。
エルゴード的なマルコフ連鎖と定常分布&lt;span class="math"&gt;\(\pi\)&lt;/span&gt;の関係は、次の定理で表せる :&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;strong&gt;マルコフ連鎖の収束&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;マルコフ連鎖&lt;span class="math"&gt;\(\boldsymbol{x}_{0}, \boldsymbol{x}_{1}, \dots\)&lt;/span&gt;がエルゴード的であり、その遷移確率行列を&lt;span class="math"&gt;\(\boldsymbol{P}\)&lt;/span&gt;とおく。&lt;span class="math"&gt;\(\pi\)&lt;/span&gt;を&lt;span class="math"&gt;\(\boldsymbol{P}\)&lt;/span&gt;の定常（不変）分布とした時、任意の初期状態から始まるマルコフ連鎖はサンプル数の極限において定常分布&lt;span class="math"&gt;\(\pi\)&lt;/span&gt;に収束する。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;ここで遷移確率行列&lt;span class="math"&gt;\(\boldsymbol{P}\)&lt;/span&gt;とは、その&lt;span class="math"&gt;\((i,j)\)&lt;/span&gt;要素&lt;span class="math"&gt;\((\boldsymbol{P})\_{ij} = p_{ij}\ (i,j \in X)\)&lt;/span&gt;が任意の時刻&lt;span class="math"&gt;\(t \geq 0\)&lt;/span&gt;で&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
(\boldsymbol{P})_{ij} = p_{ij} = P(\boldsymbol{x}_{t+1}=j|\boldsymbol{x}_{t}=i)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たすような行列である &lt;a class="footnote-reference" href="#id53" id="id19"&gt;[15]&lt;/a&gt;。
また、定常分布とは時刻が経過しようとも不変なマルコフ連鎖（一般に確率過程）の各状態の確率分布である &lt;a class="footnote-reference" href="#id54" id="id20"&gt;[16]&lt;/a&gt;。即ち、十分に長いマルコフ連鎖を観測すれば、どの状態にいる傾向があるのかを定常分布によって知ることができる。&lt;/p&gt;
&lt;p&gt;上記の議論により、マルコフ連鎖がエルゴード的であればサンプリングが定常分布に従う事は分かったが、次は遷移確率の設計が問題となる。遷移確率を規約性と正再帰性と非周期性とを満たすように設定するのは案外容易 &lt;a class="footnote-reference" href="#id55" id="id21"&gt;[17]&lt;/a&gt; であるが、それだけでは定常分布の存在のみを保証するので、その定常分布が希望する分布に一致するとは限らない。次に問題となるのは、希望の確率分布&lt;span class="math"&gt;\(r\)&lt;/span&gt;を定常分布とするように遷移確率を設計することである。その問題は次の
&lt;strong&gt;詳細釣り合い条件 (detailed balance condition)&lt;/strong&gt;
という条件によって解決できる。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;strong&gt;詳細釣り合い条件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;希望する確率分布&lt;span class="math"&gt;\(r\)&lt;/span&gt;と遷移確率&lt;span class="math"&gt;\(p\)&lt;/span&gt;が次の条件を満たす時、そのマルコフ連鎖の定常分布&lt;span class="math"&gt;\(\pi\)&lt;/span&gt;は&lt;span class="math"&gt;\(r\)&lt;/span&gt;に一致する :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
r_{i} p_{ij} = r_{j} p_{ji}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで&lt;span class="math"&gt;\(r_{i} = r(\boldsymbol{x} = i)\)&lt;/span&gt;である（証明は&lt;a class="reference external" href="# 詳細釣り合い条件の証明 "&gt;補足&lt;/a&gt;に示した）。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;詳細釣り合い条件を満たす遷移確率を用いさえすれば、十分大きな&lt;span class="math"&gt;\(m&amp;gt;0\)&lt;/span&gt;を取った時に、マルコフ連鎖&lt;span class="math"&gt;\(\boldsymbol{x}_{m}, \boldsymbol{x_{m+1}},\dots\)&lt;/span&gt;は&lt;span class="math"&gt;\(r\)&lt;/span&gt;からのサンプルとなる。
次の節で紹介するアルゴリズムの遷移確率は、いずれも詳細釣り合い条件を満たすように設計されている。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id22"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id69"&gt;メトロポリス - ヘイスティングス法&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;メトロポリス - ヘイスティングス法は、サンプルは重点サンプリングの時と同じように提案分布によって生成し、そして新しく生成したサンプルを
&lt;strong&gt;採択&lt;/strong&gt;（採用）するか、もしくは &lt;strong&gt;棄却&lt;/strong&gt; （捨てる）のかを
&lt;strong&gt;採択確率 (acceptance rate)&lt;/strong&gt;
と呼ばれる確率によって決め、採択された場合は新しい状態に遷移し、棄却された場合には遷移は行わずに（状態を変えずに）もう一度サンプリングし直す、という手続きを繰り返す手法である。&lt;/p&gt;
&lt;p&gt;メトロポリス - ヘイスティングス法の更新規則を導出してみる。
まず、状態&lt;span class="math"&gt;\(i \in X\)&lt;/span&gt;から状態&lt;span class="math"&gt;\(j \in X\)&lt;/span&gt;に遷移する時の提案分布を条件付き確率&lt;span class="math"&gt;\(q(\boldsymbol{x}_{n+1}=j|\boldsymbol{x}_{n}=i) = q_{ij}\)&lt;/span&gt;と書き、また状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;にいる時に状態&lt;span class="math"&gt;\(j\)&lt;/span&gt;を採択する確率（採択確率）を&lt;span class="math"&gt;\(\alpha(i \to j)\)&lt;/span&gt;と表す。すると、&lt;span class="math"&gt;\(i\)&lt;/span&gt;から&lt;span class="math"&gt;\(j\)&lt;/span&gt;への遷移確率&lt;span class="math"&gt;\(p_{ij}\)&lt;/span&gt;は&lt;span class="math"&gt;\(q_{ij}\)&lt;/span&gt;と&lt;span class="math"&gt;\(\alpha(i \to j)\)&lt;/span&gt;の積で表せる :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
p_{ij} = q_{ij} \alpha(i \to j) \tag{4}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;そして、詳細釣り合い条件から、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\frac{p_{ij}}{p_{ji}} = \frac{r_{j}}{r_{i}} &amp;amp;\iff \frac{q_{ij}\alpha(i \to j)}{q_{ji}\alpha(j \to i)} = \frac{r_{j}}{r_{i}} \\
&amp;amp;\iff \frac{\alpha(i \to j)}{\alpha(j \to i)} = \frac{r_{j}q_{ji}}{r_{i}q_{ij}}
\end{align*}
&lt;/div&gt;
&lt;p&gt;となる。採択確率はこの条件を満たす様に設計する。メトロポリス - ヘイスティングス法では特に、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\alpha(i \to j) = \min \left( 1, \frac{r_{j}q_{ji}}{r_{i}q_{ij}} \right) \tag{5}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とする &lt;a class="footnote-reference" href="#id56" id="id23"&gt;[18]&lt;/a&gt;。アルゴリズムの実行中には、この式によって採択確率を計算し、&lt;span class="math"&gt;\([0,1]\)&lt;/span&gt;の範囲の一様乱数を発生させて採択 / 棄却を判断する。&lt;/p&gt;
&lt;p&gt;これでメトロポリス - ヘイスティングス法が実行できるが、その利点を 2 つ挙げる :&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(r\)&lt;/span&gt;が厳密計算出来なくても良い
&lt;span class="math"&gt;\(r\)&lt;/span&gt;は一般に複雑なので直接的な計算は難しいが、上の採択確率の式は確率の比率のみに注目している。従って分布が厳密に計算できなくてもアルゴリズムを実行できる。比率さえ一致すれば良いので、分布&lt;span class="math"&gt;\(r\)&lt;/span&gt;の近似分布&lt;span class="math"&gt;\(\hat{r}\)&lt;/span&gt;として&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hat{r} = \frac{1}{Z_{r}} r
\end{equation*}
&lt;/div&gt;
&lt;p&gt;としても良い事になる (&lt;span class="math"&gt;\(Z_{r}\)&lt;/span&gt;: 正規化定数 )。特に、近似分布をボルツマン - ギブス分布&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hat{r}(\boldsymbol{x}) = \frac{1}{Z_{r}} \exp(-r(\boldsymbol{x})/T)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とする場合が多い。ここで、&lt;span class="math"&gt;\(T&amp;gt;0\)&lt;/span&gt;は温度パラメタ &lt;a class="footnote-reference" href="#id57" id="id24"&gt;[19]&lt;/a&gt; である。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(q_{ij} = q_{ji}\)&lt;/span&gt;が成り立つ場合には、より簡単にサンプリングできる
&lt;span class="math"&gt;\(q_{ij} = q_{ji}\)&lt;/span&gt;が成立する提案分布で有名なものに&lt;strong&gt;酔歩連鎖 (random
walk chain)&lt;/strong&gt;がある :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
q_{ij} = {\cal N}(i, \sigma^{2}\boldsymbol{I})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;即ち平均（中心）を現在状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;、分散を&lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; &lt;a class="footnote-reference" href="#id58" id="id25"&gt;[20]&lt;/a&gt;
とした正規分布からの乱択でサンプリングを行う &lt;a class="footnote-reference" href="#id59" id="id26"&gt;[21]&lt;/a&gt; 。
正規分布以外でも、&lt;span class="math"&gt;\(i\)&lt;/span&gt;を平均とした一様分布、多変量&lt;span class="math"&gt;\(t\)&lt;/span&gt;分布でも実行できる。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="id27"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id70"&gt;ギブスサンプリング&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;ギブスサンプリング (Gibbs Sampling,
熱浴法とも ) は提案分布の変数を 1 個ずつ更新していく手法である。
主に多次元確率分布 &lt;a class="footnote-reference" href="#id60" id="id28"&gt;[22]&lt;/a&gt; の推定に用いられる事が多い。説明のため、現在の状態を組&lt;span class="math"&gt;\(\boldsymbol{x} = (x_{1}, x_{2}, \dots, x_{d})\)&lt;/span&gt;と書く。状態の更新の際には、変数を 1 つ選び出し &lt;a class="footnote-reference" href="#id61" id="id29"&gt;[23]&lt;/a&gt; て&lt;span class="math"&gt;\(x_{i} \to x_{i}^{\prime}\)&lt;/span&gt;と遷移させる (&lt;span class="math"&gt;\(i=1,\dots,d\)&lt;/span&gt;)。更新後の状態を&lt;span class="math"&gt;\(\boldsymbol{x}^{\prime} = (x_{1}, \dots, x_{i-1}, x_{i}^{\prime}, x_{i+1}, \dots, x_{d})\)&lt;/span&gt;と書く。ここで、遷移確率&lt;span class="math"&gt;\(q(\boldsymbol{x}^{\prime}|\boldsymbol{x})\)&lt;/span&gt;は次で定義される :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
q(\boldsymbol{x}^{\prime}|\boldsymbol{x}) &amp;amp;= \frac{r(\boldsymbol{x}^{\prime})}{\sum_{x_{i}} r(\boldsymbol{x})} \\
&amp;amp;= r(x^{\prime}_{i}|x_{1},\dots,x_{i-1},x_{i+1},\dots,x_{d}) \quad (\because ベイズの定理 )
\end{align*}
&lt;/div&gt;
&lt;p&gt;即ち、選択した変数&lt;span class="math"&gt;\(x_{i}\)&lt;/span&gt;以外を全て `` 固定 ’’ した確率分布&lt;span class="math"&gt;\(r\)&lt;/span&gt;から&lt;span class="math"&gt;\(x_{i}^{\prime}\)&lt;/span&gt;を新しくサンプリングする。上記右辺が計算できる場合にのみ、ギブスサンプリングは適用可能となる。&lt;/p&gt;
&lt;p&gt;この更新規則が詳細釣り合い条件を満たすことは、再びベイズの定理を用いて、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
r(\boldsymbol{x})q(\boldsymbol{x}^{\prime}|\boldsymbol{x}) &amp;amp;= r(\boldsymbol{x}) r(x^{\prime}_{i}|x_{1},\dots,x_{i-1},x_{i+1},\dots,x_{d}) \\
&amp;amp;= r(\boldsymbol{x})\frac{r(\boldsymbol{x}^{\prime})}{\sum_{{x}_{i}}r(\boldsymbol{x})} = r(\boldsymbol{x}^{\prime}) \frac{r(\boldsymbol{x})}{\sum_{x_{i}^{\prime}}r(\boldsymbol{x}^{\prime})} \\
&amp;amp;= r(\boldsymbol{x}^{\prime}) q(\boldsymbol{x}|\boldsymbol{x}^{\prime})
\end{align*}
&lt;/div&gt;
&lt;p&gt;により確認できる。また、メトロポリス - ヘイスティングス法の採択確率の式から、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\alpha(\boldsymbol{x} \to \boldsymbol{x}^{\prime}) &amp;amp;= \min \left(1, \frac{r(\boldsymbol{x}^{\prime})q(\boldsymbol{x}|\boldsymbol{x}^{\prime})}{r(\boldsymbol{x})q(\boldsymbol{x}^{\prime}|\boldsymbol{x})} \right) \\
&amp;amp;= \min (1, 1) = 1
\end{align*}
&lt;/div&gt;
&lt;p&gt;となり、ギブスサンプリングはメトロポリス - ヘイスティングス法で採択確率を&lt;span class="math"&gt;\(1\)&lt;/span&gt;（必ず採択）するようにした特別の場合である事が分かる。採択 / 棄却の手順を踏まくくても良く、しかも遷移確率&lt;span class="math"&gt;\(q\)&lt;/span&gt;は予め計算できるので、高速な推定ができるようになっている。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id30"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id71"&gt;MCMC による最適化&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;MCMC は関数最適化に用いることもできる。今、サンプリングを行う確率分布をボルツマン - ギブス分布&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
r(\boldsymbol{x}) = \frac{1}{Z_{r}} \exp(-f(\boldsymbol{x})/T)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とした時、定義式により、&lt;span class="math"&gt;\(f(\boldsymbol{x})\)&lt;/span&gt;が小さな値を与える点ではその確率&lt;span class="math"&gt;\(r(\boldsymbol{x})\)&lt;/span&gt;は同時に大きくことが即座に観察できる。従って、MCMC によって&lt;span class="math"&gt;\(r(\boldsymbol{x})\)&lt;/span&gt;からのサンプリングを行えば、&lt;span class="math"&gt;\(f(\boldsymbol{x})\)&lt;/span&gt;が小さな値をとる点を集中してサンプリングできる事から、&lt;span class="math"&gt;\(f(\boldsymbol{x})\)&lt;/span&gt;の最小化（最大化の場合は&lt;span class="math"&gt;\(-f(\boldsymbol{x})\)&lt;/span&gt;の最小化に置き換えれば良い）を考える事ができる。実際、関数&lt;span class="math"&gt;\(f\)&lt;/span&gt;の最小値を与える点を&lt;span class="math"&gt;\(\boldsymbol{x}^{\ast}\)&lt;/span&gt;と表せば、サンプル数&lt;span class="math"&gt;\(N\)&lt;/span&gt;の極限において最小値&lt;span class="math"&gt;\(f(\boldsymbol{x}^{\ast})\)&lt;/span&gt;が確率 1 で得られる事 :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\lim_{N \to \infty} P(\min(f(\boldsymbol{x}_{1}), f(\boldsymbol{x}_{2}), \dots, f(\boldsymbol{x}_{N})) = f(\boldsymbol{x}^{\ast})) = 1
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が示せる。以下、その証明を示す。&lt;/p&gt;
&lt;p&gt;（証明）
MCMC において、定常分布を&lt;span class="math"&gt;\(r\)&lt;/span&gt;とする様に（詳細釣り合い条件を満たす様に）サンプリングを行う。この時マルコフ連鎖&lt;span class="math"&gt;\(\boldsymbol{x}_{1}, \boldsymbol{x}_{2}, \dots, \boldsymbol{x}_{n},\dots\)&lt;/span&gt;は、十分大きな&lt;span class="math"&gt;\(n &amp;gt; 1\)&lt;/span&gt;においては&lt;span class="math"&gt;\(r(\boldsymbol{x})\)&lt;/span&gt;からのサンプルとみなせる。関数&lt;span class="math"&gt;\(f\)&lt;/span&gt;に最小値&lt;span class="math"&gt;\(f(\boldsymbol{x}^{\ast})\)&lt;/span&gt;が存在すれば、&lt;span class="math"&gt;\(\boldsymbol{x}^{\ast}\)&lt;/span&gt;をサンプリングする確率&lt;span class="math"&gt;\(r(\boldsymbol{x}^{\ast})\)&lt;/span&gt;も存在が保証され、分布の中で最大の確率を与えている。従って、&lt;span class="math"&gt;\(n\)&lt;/span&gt;回目以降のマルコフ連鎖&lt;span class="math"&gt;\(\boldsymbol{x}_{n}, \boldsymbol{x}_{n+1},\dots\)&lt;/span&gt;において、&lt;span class="math"&gt;\(m \geq n\)&lt;/span&gt;回目に初めて&lt;span class="math"&gt;\(\boldsymbol{x}^{\ast}\)&lt;/span&gt;がサンプリングできる確率&lt;span class="math"&gt;\(P(\boldsymbol{x}_{m} = \boldsymbol{x}^{\ast})\)&lt;/span&gt;は、幾何分布と同じ様に、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
P(\boldsymbol{x}_{m} = \boldsymbol{x}^{\ast}) = r(\boldsymbol{x})\left\{ 1-r(\boldsymbol{x}^{\ast}) \right\}^{m-n}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;によって計算できる。また、初めて&lt;span class="math"&gt;\(\boldsymbol{x^{\ast}}\)&lt;/span&gt;がサンプリングできるまでの回数が&lt;span class="math"&gt;\(N \geq n\)&lt;/span&gt;回以内となる確率は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
P(\boldsymbol{x}_{n} = \boldsymbol{x}^{\ast}) + P(\boldsymbol{x}_{n+1} = \boldsymbol{x}^{\ast}) + \dots + P(\boldsymbol{x}_{N} = \boldsymbol{x}^{\ast}) &amp;amp;=  \sum_{m=n}^{N} P(\boldsymbol{x}_{N} = \boldsymbol{x}^{\ast}) \\
&amp;amp;= \sum_{k=0}^{N-n} r(\boldsymbol{x}^{\ast})\left\{ 1-r(\boldsymbol{x}^{\ast}) \right\}^{k}
\end{align*}
&lt;/div&gt;
&lt;p&gt;となる。
ここでサンプル数の極限&lt;span class="math"&gt;\(N \to \infty\)&lt;/span&gt;をとると、初項&lt;span class="math"&gt;\(r(\boldsymbol{x}^{\ast})\)&lt;/span&gt;、項比&lt;span class="math"&gt;\(1-r(\boldsymbol{x}^{\ast})\)&lt;/span&gt;とした等比級数の和の公式より、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\lim_{N \to \infty} \sum_{k=0}^{N-n} r(\boldsymbol{x}^{\ast})\left\{ 1-r(\boldsymbol{x}^{\ast}) \right\}^{k} = \frac{r(\boldsymbol{x}^{\ast})}{1-\left\{1-r(\boldsymbol{x}^{\ast})\right\}} = 1
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が得られる。即ち、サンプリングを無限に繰り返せば&lt;span class="math"&gt;\(\boldsymbol{x}^{\ast}\)&lt;/span&gt;が確率 1 で得られることが示された。この結果は、サンプルの関数列&lt;span class="math"&gt;\(f(\boldsymbol{x}_{1}), f(\boldsymbol{x}_{2}), \dots\)&lt;/span&gt;の中に少なくとも 1 つ&lt;span class="math"&gt;\(f(\boldsymbol{x}^{\ast})\)&lt;/span&gt;が存在する事と同値である。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id31"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id72"&gt;焼きなまし法&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;以上で MCMC による最適化が理論的に可能なことが示されたが、最適化の際に特に問題となるのは分布&lt;span class="math"&gt;\(r\)&lt;/span&gt;の温度パラメタ&lt;span class="math"&gt;\(T\)&lt;/span&gt;である。&lt;span class="math"&gt;\(T\)&lt;/span&gt;が大きければ、&lt;span class="math"&gt;\(\exp\)&lt;/span&gt;内部の&lt;span class="math"&gt;\(f(\boldsymbol{x})\)&lt;/span&gt;の値に影響されず&lt;span class="math"&gt;\(r(\boldsymbol{x})\)&lt;/span&gt;は一様分布に近くなり、一様乱数からのサンプリングと殆ど変わらなくなる。逆に&lt;span class="math"&gt;\(T\)&lt;/span&gt;が&lt;span class="math"&gt;\(0\)&lt;/span&gt;に近いと&lt;span class="math"&gt;\(r(\boldsymbol{x})\)&lt;/span&gt;は&lt;span class="math"&gt;\(f(\boldsymbol{x})\)&lt;/span&gt;の値に大きく影響されるが、サンプリングが特定の場所だけに集中してしまって局所最適値しか得られない場合がある。この様に&lt;span class="math"&gt;\(T\)&lt;/span&gt;は適切に決定する必要があるが、&lt;span class="math"&gt;\(T\)&lt;/span&gt;の適切な決定法は存在せず、問題依存となる場合が多い。&lt;/p&gt;
&lt;p&gt;そこで、最初は&lt;span class="math"&gt;\(T\)&lt;/span&gt;（温度）を高い状態から初めてサンプリングの度に少しずつ&lt;span class="math"&gt;\(T\)&lt;/span&gt;を下げていくやり方があり、これを焼きなまし法（Simulated
Annealing,
SA）と呼ぶ。この様に&lt;span class="math"&gt;\(T\)&lt;/span&gt;を変化させると最初は空間全体の中から大雑把な&lt;span class="math"&gt;\(f\)&lt;/span&gt;の値を取得し、後に最適値の近傍を集中してサンプリングすることができるために効率的な探索が期待できる。証明は省くが、温度パラメタの系列&lt;span class="math"&gt;\(T_{1}, T_{2}, \dots\)&lt;/span&gt;が次の条件を満たせばサンプリングによって&lt;span class="math"&gt;\(\boldsymbol{x}^{\ast}\)&lt;/span&gt;が得られる事（収束定理）が示されている :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\sum_{n=1}^{\infty} \exp(-D/T_{n}) = \infty
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで、&lt;span class="math"&gt;\(D\)&lt;/span&gt;は問題によって決まる定数である。&lt;/p&gt;
&lt;div class="section" id="id32"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id73"&gt;補足&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id33"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id74"&gt;エルゴード的なマルコフ連鎖の定常分布&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;上記の議論で、「マルコフ連鎖がエルゴード的ならば、一意な定常分布が存在する」という事に触れた。この定理についての証明を述べていくが、準備として確率過程についての用語や記法の定義、基本的な定理の証明を行う。大方の証明は&lt;a class="reference external" href="http://www-lsm.naist.jp/~kasahara/lecture/isp/part1.pdf"&gt;ここ&lt;/a&gt;を参照した。なお、状態空間（全事象）&lt;span class="math"&gt;\(X\)&lt;/span&gt;は有限集合であるとする。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;strong&gt;離散時間マルコフ連鎖&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;確率過程（サンプル列）
&lt;span class="math"&gt;\(\boldsymbol{x}_{0}, \boldsymbol{x}_{1}, \dots\)&lt;/span&gt;
が次を満たす時、離散時間マルコフ連鎖という。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\forall n \geq 0, \forall i_{0}, \dots, i_{n+1} \in X.\ P(\boldsymbol{x}_{n+1} = i_{n+1} |\boldsymbol{x}_{0} = i_{0}, \boldsymbol{x}_{1} = i_{1}, \dots, \boldsymbol{x}_{n} = i_{n}) = P(\boldsymbol{x}_{n+1}=i_{n+1}|\boldsymbol{x}_{n}=i_{n})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;またこの性質をマルコフ性という。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;!-- 空白のためのコメント ... --&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;strong&gt;遷移確率の斉時性、n ステップ遷移確率&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;任意の状態&lt;span class="math"&gt;\(i,j \in X\)&lt;/span&gt;と非負整数&lt;span class="math"&gt;\(n \geq 0\)&lt;/span&gt;に対して&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
p_{ij}(n) = P(\boldsymbol{x}_{n+1}=j|\boldsymbol{x}_{n}=i)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を、状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;から状態&lt;span class="math"&gt;\(j\)&lt;/span&gt;への遷移確率という。&lt;span class="math"&gt;\(p_{ij}(n)\)&lt;/span&gt;が&lt;span class="math"&gt;\(n\)&lt;/span&gt;と独立で常に&lt;span class="math"&gt;\(p_{ij}(n) = p_{ij}(0) = p_{ij}\)&lt;/span&gt;となる時、離散時間マルコフ連鎖は斉時であるという。今後、遷移確率は&lt;span class="math"&gt;\(p_{ij}\)&lt;/span&gt;を用いて表す。また、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
p_{ij}^{(n)} = P(\boldsymbol{x}_{n}=j|\boldsymbol{x}_{0}=i)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;は状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;から始まって&lt;span class="math"&gt;\(n\)&lt;/span&gt;ステップ後に状態が&lt;span class="math"&gt;\(j\)&lt;/span&gt;になる確率を表しており、&lt;span class="math"&gt;\(n\)&lt;/span&gt;ステップ遷移確率と呼ぶ。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;!-- 空白のためのコメント ... --&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;strong&gt;チャップマン − コルモゴロフ方程式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;任意の状態&lt;span class="math"&gt;\(i,j \in X\)&lt;/span&gt;に対し、&lt;span class="math"&gt;\(n\)&lt;/span&gt;ステップ遷移確率&lt;span class="math"&gt;\(p_{ij}^{(n)}\)&lt;/span&gt;は次を満たす :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
p_{ij}^{(n)} = \sum_{r \in X} p_{ir}^{(k)}p_{rj}^{(n-k)} \quad 0 \leq k \leq n
\end{equation*}
&lt;/div&gt;
&lt;p&gt;（証明）&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
p_{ij}^{(n)} &amp;amp;= P(\boldsymbol{x}_{n}=j|\boldsymbol{x}_{0}=i) =  \sum_{r \in X} P(\boldsymbol{x}_{n}=j, \boldsymbol{x}_{k}=r|\boldsymbol{x}_{0}=i) \quad (\because 確率分布の周辺化 ) \\
&amp;amp;= \sum_{r\in S} P(\boldsymbol{x}_{n}=j|\boldsymbol{x}_{k}=r, \boldsymbol{x}_{0}=i) P(\boldsymbol{x}_{k}=r|\boldsymbol{x}_{0}=i) \quad (\because ベイズの定理 ) \\
&amp;amp;= \sum_{r\in S} P(\boldsymbol{x}_{n}=j|\boldsymbol{x}_{k}=r) P(\boldsymbol{x}_{k}=r|\boldsymbol{x}_{0}=i) \quad (\because マルコフ性 ) \\
&amp;amp;= \sum_{r\in S} P(\boldsymbol{x}_{n-k}=j|\boldsymbol{x}_{0}=r) P(\boldsymbol{x}_{k}=r|\boldsymbol{x}_{0}=i) \quad (\because 斉時性 ) \\
&amp;amp;= \sum_{r\in S} p_{rj}^{(n-k)}p_{ir}^{(k)}
\end{align*}
&lt;/div&gt;
&lt;hr class="docutils" /&gt;
&lt;!-- 空白のためのコメント ... --&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;strong&gt;到達可能、連結&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ある状態&lt;span class="math"&gt;\(i,j \in X\)&lt;/span&gt;に対して&lt;span class="math"&gt;\(p_{ij}^{(n)} &amp;gt; 0\)&lt;/span&gt;なる非負整数&lt;span class="math"&gt;\(n \geq 0\)&lt;/span&gt;が存在する時、状態&lt;span class="math"&gt;\(j\)&lt;/span&gt;は状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;から到達可能であると言い、&lt;span class="math"&gt;\(i\to j\)&lt;/span&gt;と表す。
また&lt;span class="math"&gt;\(i \to j \land j \to i\)&lt;/span&gt;ならば、&lt;span class="math"&gt;\(i\)&lt;/span&gt;と&lt;span class="math"&gt;\(j\)&lt;/span&gt;は連結しているといい、&lt;span class="math"&gt;\(i \leftrightarrow j\)&lt;/span&gt;と表す。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;連結関係は、反射性 (&lt;span class="math"&gt;\(i \leftrightarrow i\)&lt;/span&gt;)、対称性 (&lt;span class="math"&gt;\(i \leftrightarrow j \Leftrightarrow j \leftrightarrow i\)&lt;/span&gt;)、推移性 (&lt;span class="math"&gt;\(i \leftrightarrow j \land j \leftrightarrow k \Rightarrow i \leftrightarrow k\)&lt;/span&gt;) が成り立つ。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;strong&gt;連結クラス（連結成分）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(X\)&lt;/span&gt;の部分集合&lt;span class="math"&gt;\(C \subseteq X\)&lt;/span&gt;において、&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;span class="math"&gt;\(i \in C \land j \in C \implies i \leftrightarrow j\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(i \in C \land i \leftrightarrow j \implies j \in C\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;が常に成立する時、&lt;span class="math"&gt;\(C\)&lt;/span&gt;を&lt;span class="math"&gt;\(X\)&lt;/span&gt;の連結クラス（連結成分）という。定義より、&lt;span class="math"&gt;\(C\)&lt;/span&gt;の要素は互いに連結している。また、連結クラス&lt;span class="math"&gt;\(C\)&lt;/span&gt;の任意の状態&lt;span class="math"&gt;\(i \in C\)&lt;/span&gt;から&lt;span class="math"&gt;\(j \notin C\)&lt;/span&gt;に到達できない時、&lt;span class="math"&gt;\(C\)&lt;/span&gt;は閉じていると言う。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;!-- 空白のためのコメント ... --&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;strong&gt;規約性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(X\)&lt;/span&gt;内の全ての状態が単一の閉じた連結クラスに属する、即ち&lt;span class="math"&gt;\(X\)&lt;/span&gt;の全ての要素が互いに連結している時、そのマルコフ連鎖は規約であるという。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;!-- 空白のためのコメント ... --&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;strong&gt;周期性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;状態&lt;span class="math"&gt;\(i \in X\)&lt;/span&gt;に対して&lt;span class="math"&gt;\(p_{ii}^{(n)} &amp;gt; 0\)&lt;/span&gt;となる（&lt;span class="math"&gt;\(n\)&lt;/span&gt;ステップ後に元の状態に戻る）&lt;span class="math"&gt;\(n\)&lt;/span&gt;の最大公約数&lt;span class="math"&gt;\(d\)&lt;/span&gt;を、状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;の周期と呼ぶ。&lt;span class="math"&gt;\(d = 1\)&lt;/span&gt;の時は状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;は非周期的と呼ばれ、&lt;span class="math"&gt;\(d \geq 2\)&lt;/span&gt;の時は周期的であると呼ばれる。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;!-- 空白のためのコメント ... --&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;strong&gt;再帰的、過渡的&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;確率変数&lt;span class="math"&gt;\(T_{j}\)&lt;/span&gt;を次で定義する :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
T_{j} = \min_{n} \{ n &amp;gt; 0 | \boldsymbol{x}_{n} = j \}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;即ち、離散時間マルコフ連鎖が初めて状態&lt;span class="math"&gt;\(j\)&lt;/span&gt;を訪れる時刻を表す。また、&lt;span class="math"&gt;\(T_{i}\)&lt;/span&gt;を用いて次の値を定義する :&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
f_{i} &amp;amp;= P(T_{i} &amp;lt; \infty | \boldsymbol{x}_{0} = i) = \sum_{n=1}^{\infty}P(T_{i} = n|\boldsymbol{x}_{0}=i) \\
m_{i} &amp;amp;= \mathrm{E}[T_{i}|\boldsymbol{x}_{0}=i] = \sum_{k=0}^{\infty} k P(T_{i}=k|\boldsymbol{x}_{0}=i)
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(f_{i}\)&lt;/span&gt;は将来状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;に戻ってくる確率を表しており、&lt;span class="math"&gt;\(f_{i}=1\)&lt;/span&gt;ならば確率&lt;span class="math"&gt;\(1\)&lt;/span&gt;で状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;を訪れる（無限にしばしば訪れる）ので状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;は再帰的であるという。&lt;span class="math"&gt;\(f_{i} &amp;lt; 1\)&lt;/span&gt;ならば状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;は過渡的であるという。また、&lt;span class="math"&gt;\(m_{i}\)&lt;/span&gt;は初期状態が&lt;span class="math"&gt;\(i\)&lt;/span&gt;の時に、再び状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;に戻るまでの時間の期待値を表しており、&lt;span class="math"&gt;\(m_{i} &amp;lt; \infty\)&lt;/span&gt;ならば状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;は正再帰的（有限時間で&lt;span class="math"&gt;\(i\)&lt;/span&gt;に戻る）であるといい、&lt;span class="math"&gt;\(m_{i} = \infty\)&lt;/span&gt;ならば状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;は零再帰的であるという。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;!-- 空白のためのコメント ... --&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;strong&gt;エルゴード的な離散時間マルコフ連鎖&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;離散時間マルコフ連鎖&lt;span class="math"&gt;\(\boldsymbol{x}_{0}, \boldsymbol{x}_{1},\dots\)&lt;/span&gt;が規約かつ正再帰かつ非周期的であるならば、この離散時間マルコフ連鎖はエルゴード的とも呼ばれる&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;ここまでで用語の定義は揃ったので、それではエルゴード的なマルコフ連鎖の定常分布の存在についての定理を証明する。&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;strong&gt;エルゴード的な離散時間マルコフ連鎖の定常分布&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;離散時間マルコフ連鎖&lt;span class="math"&gt;\(\boldsymbol{x}_{0}, \boldsymbol{x}_{1}, \dots\)&lt;/span&gt;がエルゴード的ならば、任意の状態&lt;span class="math"&gt;\(i, j \in X\)&lt;/span&gt;について次が成り立つ :&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\displaystyle\lim_{n \to \infty} p_{ij}^{(n)} = \lim_{n \to \infty} p_{jj}^{(n)} = \frac{1}{m_{j}} = \pi_{j}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\pi_{j}\)&lt;/span&gt;は&lt;span class="math"&gt;\(\displaystyle \pi_{j} = \sum_{i \in X} \pi_{i} p_{ij}\)&lt;/span&gt;と&lt;span class="math"&gt;\(\displaystyle\sum_{j \in X}\pi_{j} = 1\)&lt;/span&gt;を満たす解であり、唯一に定まる。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;2. を満たす&lt;span class="math"&gt;\(\pi_{j}\)&lt;/span&gt;を極限分布（定常状態分布）と言う。&lt;/p&gt;
&lt;p&gt;一方、初期分布として&lt;span class="math"&gt;\(P(\boldsymbol{x}_{0} = j) = \pi_{j}\)&lt;/span&gt;を持つ離散時間マルコフ連鎖では、任意の&lt;span class="math"&gt;\(n \geq 1\)&lt;/span&gt;に対して&lt;span class="math"&gt;\(P(\boldsymbol{x}_{n}=j) = \pi_{j}\)&lt;/span&gt;が成り立ち、&lt;span class="math"&gt;\(\boldsymbol{x}_{n}\)&lt;/span&gt;は&lt;span class="math"&gt;\(n\)&lt;/span&gt;と独立した分布を持つ。この様に、時間に関して不変な分布&lt;span class="math"&gt;\(\pi_{j} = P(\boldsymbol{x}_{n} = j)\ n = 0,1,\dots\)&lt;/span&gt;を
&lt;strong&gt;定常分布&lt;/strong&gt; と呼ぶ。&lt;/p&gt;
&lt;p&gt;（証明）まず 1. から考える。最初に&lt;span class="math"&gt;\(i\neq j\)&lt;/span&gt;なる状態に対して&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
u_{k} = P(T_{j} = k|\boldsymbol{x}_{0} = i)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を（初期状態が&lt;span class="math"&gt;\(i\)&lt;/span&gt;で、初めて&lt;span class="math"&gt;\(j\)&lt;/span&gt;に訪れる時刻が&lt;span class="math"&gt;\(k\)&lt;/span&gt;となる確率）おく。この時、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
p_{ij}^{(1)} &amp;amp;= u_{1} \\
p_{ij}^{(2)} &amp;amp;= u_{2} + u_{1} p_{jj}^{(1)} \\
p_{ij}^{(3)} &amp;amp;= u_{3} + u_{2}p_{jj}^{(1)} + u_{1}p_{jj}^{(2)} \\
&amp;amp;\vdots
\end{align*}
&lt;/div&gt;
&lt;p&gt;の観察により、&lt;span class="math"&gt;\(n \geq 1\)&lt;/span&gt;なる&lt;span class="math"&gt;\(n\)&lt;/span&gt;に対して帰納的に&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
p_{ij}^{(n)} = \sum_{k=1}^{n} u_{k} p_{jj}^{(n-k)}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成立する（最初の&lt;span class="math"&gt;\(k\)&lt;/span&gt;ステップで状態&lt;span class="math"&gt;\(j\)&lt;/span&gt;に行き、その後&lt;span class="math"&gt;\(n-k\)&lt;/span&gt;ステップ後に再び&lt;span class="math"&gt;\(j\)&lt;/span&gt;に行く）ことが分かる。また、任意の&lt;span class="math"&gt;\(i\)&lt;/span&gt;と&lt;span class="math"&gt;\(j\)&lt;/span&gt;は連結している（&lt;span class="math"&gt;\(i \leftrightarrow j\)&lt;/span&gt;）ので、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\sum_{k=1}^{\infty} u_{k} = P(\exists n \geq 0.\ \boldsymbol{x}_{n} = j | \boldsymbol{x}_{0} =i) = 1
\end{equation*}
&lt;/div&gt;
&lt;p&gt;（状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;から始まり、&lt;span class="math"&gt;\(j\)&lt;/span&gt;へいつかは訪れる確率は&lt;span class="math"&gt;\(1\)&lt;/span&gt;）が成り立つ。一方&lt;span class="math"&gt;\(p_{jj}^{(n)}\)&lt;/span&gt;は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
p_{jj}^{(n)} &amp;amp;= P(\boldsymbol{x}_{n} = j|\boldsymbol{x}_{0}=j) \\
&amp;amp;= \sum_{k=1}^{n}P(\boldsymbol{x}_{n}=j, T_{j} = k|\boldsymbol{x}_{0}=j) \quad (\because 確率分布の周辺化 ) \\
&amp;amp;= \sum_{k=1}^{n}P(\boldsymbol{x}_{n}=j|T_{j}=k, \boldsymbol{x}_{0}=j)P(T_{j}=k|\boldsymbol{x}_{0}=j) \quad (\because ベイズの定理 ) \\
&amp;amp;= \sum_{k=1}^{n}P(\boldsymbol{x}_{n}=j|\boldsymbol{x}_{k}=j, \boldsymbol{x}_{0}=j)P(T_{j}=k|\boldsymbol{x}_{0}=j) \quad (\because T_{j} = k \implies \boldsymbol{x}_{k} = j) \\
&amp;amp;= \sum_{k=1}^{n}P(\boldsymbol{x}_{n}=j|\boldsymbol{x}_{k}=j)P(T_{j}=k|\boldsymbol{x}_{0}=j) \quad (\because マルコフ性 ) \\
&amp;amp;= \sum_{k=1}^{n}p_{jj}^{(n-k)} u_{k}
\end{align*}
&lt;/div&gt;
&lt;p&gt;と展開できる。数列&lt;span class="math"&gt;\(p_{jj}^{(n)}\)&lt;/span&gt;の極限&lt;span class="math"&gt;\(\displaystyle\lim_{n \to \infty} p_{jj}^{(n)}\)&lt;/span&gt;を求める為、ここでは数列の
&lt;strong&gt;母関数&lt;/strong&gt;を定義し、（片側）Z 変換の最終値定理  &lt;a class="footnote-reference" href="#id62" id="id34"&gt;[24]&lt;/a&gt;
を用いる。その為、今、&lt;span class="math"&gt;\(\displaystyle G(z) = \sum_{n=0}^{\infty}p_{jj}^{(n)}z^{n},\ U(z) = \sum_{n=1}^{\infty}u_{n}z^{n}\)&lt;/span&gt;なる母関数を定義し、上式の両辺に&lt;span class="math"&gt;\(z^{n}\)&lt;/span&gt;を掛けて&lt;span class="math"&gt;\(n=1,2,\dots\)&lt;/span&gt;についての和を取ると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
（左辺）\sum_{n=1}^{\infty} p_{jj}^{(n)}z^{n} &amp;amp;= \sum_{n=1}^{\infty} p_{jj}^{(n)}z^{n} = \sum_{n=0}^{\infty}p_{jj}^{(n)}z^{n} - p_{jj}^{(0)} \\
&amp;amp;= G(z) - 1 \\
（右辺）\sum_{n=1}^{\infty} \sum_{k=1}^{n} p_{jj}^{(n-k)}u_{k}z^{n} &amp;amp;= \sum_{n=1}^{\infty} \sum_{k=1}^{n} p_{jj}^{(n-k)}z^{n-k}u_{k}z^{k} \\
&amp;amp;= G(z)U(z) \\
\therefore G(z) &amp;amp;= \frac{1}{1-U(z)}
\end{align*}
&lt;/div&gt;
&lt;p&gt;ここで、右辺式の最後の式変形には冪級数の積の公式 &lt;a class="footnote-reference" href="#id63" id="id35"&gt;[25]&lt;/a&gt; を用いている。最終値定理を適用する事を考えると、この場合は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\lim_{n \to \infty} p_{jj}^{(n)} = \lim_{z \to 1}(1-z)G(z)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成立する &lt;a class="footnote-reference" href="#id64" id="id36"&gt;[26]&lt;/a&gt;
ので、&lt;span class="math"&gt;\(\displaystyle\lim_{n \to \infty} p_{jj}^{(n)}\)&lt;/span&gt;の結果として、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\lim_{n \to \infty} p_{jj}^{(n)} &amp;amp;= \lim_{z \to 1}(1-z)G(z) = \lim_{z \to 1}\frac{1-z}{1-U(z)} \\
&amp;amp;= \lim_{z \to 1}\frac{\frac{d(1-z)}{dz}}{\frac{d(1-U(z))}{dz}} \quad (\because ロピタルの定理 ) \\
&amp;amp;= \lim_{z \to 1}\frac{1}{\frac{dU(z)}{dz}} = \frac{1}{m_{j}} = \pi_{j} \\
\because \lim_{z \to 1} \frac{dU(z)}{dz} &amp;amp;= \lim_{z \to 1}\sum_{n=1}^{\infty}n u_{n} z^{n-1} = \lim_{z \to 1}\sum_{n=0}^{\infty} n u_{n} z^{n} = \sum_{n=0}^{\infty}n u_{n} = m_{j}
\end{align*}
&lt;/div&gt;
&lt;p&gt;が得られる。さて、この結果より、任意の正数&lt;span class="math"&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt;に対して&lt;span class="math"&gt;\(n \geq N\)&lt;/span&gt;なる全ての&lt;span class="math"&gt;\(n\)&lt;/span&gt;が&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
|p_{jj}^{(n)} - \pi_{j}| \leq \frac{\epsilon}{2} \quad かつ \quad \sum_{k = N+1}^{\infty} u_{k} \leq \frac{\epsilon}{2}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を同時に満たすような&lt;span class="math"&gt;\(N\)&lt;/span&gt;を取ることができる。今、&lt;span class="math"&gt;\(n \geq 2N\)&lt;/span&gt;に対し、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
|p_{ij}^{(n)} - \pi_{j}| &amp;amp;= | \sum_{k=1}^{n} u_{k} p_{jj}^{(n-k)} - \pi_{j}| = | \sum_{k=1}^{n} u_{k} p_{jj}^{(n-k)} - \sum_{k=1}^{\infty}u_{k}\pi_{j}| \\
&amp;amp;= |\sum_{k=1}^{n-N}u_{k}(p_{jj}^{(n-k)}-\pi_{j}) + \sum_{k=n-N+1}^{n} u_{k}(p_{jj}^{(n-k)} - \pi_{j}) -\sum_{k=n+1}^{\infty}u_{k}\pi_{j}| \\
&amp;amp;\leq \sum_{k=1}^{n-N}u_{k}|p_{jj}^{(n-k)}-\pi_{j}| + \sum_{k=n-N+1}^{n} u_{k}|p_{jj}^{(n-k)} - \pi_{j}| + \sum_{k=n+1}^{\infty}|u_{k}\pi_{j}| \\
&amp;amp;\leq \sum_{k=1}^{n-N}u_{k}\frac{\epsilon}{2} + \sum_{k=n-N+1}^{n} u_{k} + \sum_{k=n+1}^{\infty}u_{k} = \frac{\epsilon}{2}\sum_{k=1}^{n-N}u_{k} + \sum_{k=n-N+1}^{\infty} u_{k} \\
&amp;amp;\leq \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon
\end{align*}
&lt;/div&gt;
&lt;p&gt;よって、&lt;span class="math"&gt;\(\displaystyle \lim_{n \to \infty} p_{ij}^{(n)} = \pi_{j} = \lim_{n \to \infty} p_{jj}^{(n)}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;次に 2.
の&lt;span class="math"&gt;\(\pi_{j}\)&lt;/span&gt;の一意性を示す。まず、&lt;span class="math"&gt;\(\displaystyle \sum_{j \in X}p_{ij}^{(n)} = 1\)&lt;/span&gt;（どこかの状態には確率 1 で遷移している）より、この式で&lt;span class="math"&gt;\(n \to \infty\)&lt;/span&gt;ならしめれば、1.
により&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\sum_{j \in X} \pi_{j} = 1
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を得る。また、&lt;span class="math"&gt;\(a_{j}(n) = P(\boldsymbol{x}_{n} = j)\)&lt;/span&gt;（時刻&lt;span class="math"&gt;\(n\)&lt;/span&gt;で状態&lt;span class="math"&gt;\(j\)&lt;/span&gt;を訪れる確率）とおくと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
a_{j}(n) &amp;amp;= \sum_{i \in X}P(\boldsymbol{x}_{0}=i)P(\boldsymbol{x}_{n}=j|\boldsymbol{x}_{0}=i) = \sum_{i \in X}P(\boldsymbol{x}_{0}=i)p_{ij}^{(n)} \\
\therefore \lim_{n \to \infty} a_{j}(n) &amp;amp;= \sum_{i \in X}P(\boldsymbol{x}_{0}=i) \lim_{n \to \infty}p_{ij}^{(n)} = \pi_{j} \sum_{i \in X} P(\boldsymbol{x}_{0} = i) = \pi_{j}
\end{align*}
&lt;/div&gt;
&lt;p&gt;が成立し、チャップマン − コルモゴロフ方程式により、&lt;span class="math"&gt;\(n, m \geq0\)&lt;/span&gt;なる整数に対し、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
a_{j}(m+n) &amp;amp;= \sum_{r \in X}P(\boldsymbol{x}_{0}=r)P(\boldsymbol{x_{m+n}}=j|\boldsymbol{x}_{0}=r) = \sum_{r \in X} P(\boldsymbol{x}_{0} = r) p_{rj}^{(m+n)} \\
&amp;amp;= \sum_{r \in X} P(\boldsymbol{x}_{0}=r) \sum_{i \in X} p_{ri}^{(m)}p_{ij}^{(n)} \quad (\because チャップマン - コルモゴロフ方程式を使用 ) \\
&amp;amp;= \sum_{i \in X}\sum_{r \in X}P(\boldsymbol{x}_{0}=r)p_{ri}^{(m)} p_{ij}^{(n)} = \sum_{i \in X} a_{i}(m) p_{ij}^{(n)}
\end{align*}
&lt;/div&gt;
&lt;p&gt;この式の両辺を&lt;span class="math"&gt;\(m \to \infty\)&lt;/span&gt;ならしめれば、極限と和の交換法則より、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\pi_{j} = \sum_{i \in X}\pi_{i} p_{ij}^{(n)}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を得る。特に&lt;span class="math"&gt;\(n=1\)&lt;/span&gt;とすれば、&lt;span class="math"&gt;\(\displaystyle \pi_{j} = \sum_{i \in X} \pi_{j} p_{ij}\)&lt;/span&gt;が得られる。
次に一意性を示す。今、&lt;span class="math"&gt;\(\pi_{i}^{\prime}\ (i \in X)\)&lt;/span&gt;が、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\pi_{j}^{\prime} = \sum_{i \in X}\pi_{i}^{\prime} p_{ij} \quad かつ \quad \sum_{i \in X} \pi_{i}^{\prime} = 1
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たすとする。上述の議論により、全ての正整数&lt;span class="math"&gt;\(n \geq 0\)&lt;/span&gt;に対し、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\pi_{j}^{\prime} = \sum_{i \in X}\pi_{i}^{\prime} p_{ij}^{(n)}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を得る。&lt;span class="math"&gt;\(n \to \infty\)&lt;/span&gt;とすると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\pi_{j}^{\prime} = \left(\sum_{i \in X}\pi_{i}^{\prime}\right) \pi_{j} = \pi_{j}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となって、一意性が示される。&lt;/p&gt;
&lt;/div&gt;
&lt;hr class="docutils" /&gt;
&lt;div class="section" id="id37"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id75"&gt;詳細釣り合い条件の証明&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;最後に詳細釣り合い条件を示す。今、確率分布&lt;span class="math"&gt;\(r\)&lt;/span&gt;と遷移確率が&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
r_{i} p_{ij} = r_{j} p_{ji}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を満たしているとする。この時両辺ともに状態&lt;span class="math"&gt;\(i\)&lt;/span&gt;について和をとると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\sum_{i \in X} r_{i} p_{ij} = r_{j} \sum_{i \in X} p_{ji} = r_{j}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;2. により、&lt;span class="math"&gt;\(r\)&lt;/span&gt;は定常分布の解となっている事が分かる。&lt;/p&gt;
&lt;div class="section" id="id38"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id76"&gt;脚注&lt;/a&gt;&lt;/h3&gt;
&lt;table class="docutils footnote" frame="void" id="id39" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://ebsa.ism.ac.jp/ebooks/sites/default/files/ebook/1881/pdf/vol3_ch10.pdf"&gt;古澄英雄 , 「21 世紀の統計科学」第 Ⅲ 巻 第 10 章
マルコフ連鎖モンテカルロ法入門&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id40" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://www-lsm.naist.jp/~kasahara/lecture/isp/part1.pdf"&gt;笠原正治 ,
確率過程論基礎&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id41" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://www.r.dl.itc.u-tokyo.ac.jp/~nakagawa/SML1/sampling1.pdf"&gt;中川裕志 ,
マルコフ連鎖モンテカルロ法&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id42" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id4"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://maildbs.c.u-tokyo.ac.jp/~fukushima/FSwiki/wiki.cgi?action=ATTACH&amp;amp;page=%BD%B8%C3%E6%B9%D6%B5%C1%A1%F7%C5%EC%B9%A9%C2%E7&amp;amp;file=TIT-2005-huku.pdf"&gt;福島孝治 ,
マルコフ連鎖モンテカルロ法の実践&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id43" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id5"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://www.slideshare.net/teramonagi/ss-5190440"&gt;tera monagi,
マルコフ連鎖モンテカルロ法入門 -1&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id44" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id6"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;主に、確率分布の平均（期待値）、分散が対象となる&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id45" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id7"&gt;[7]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;十分な回数の独立な試行を行った経験分布は理論的（真の）分布に一致する、という法則。例えばコイン投げをひたすら繰り返せば、表及び裏が出る
&lt;strong&gt;頻度の比率&lt;/strong&gt;
はそれぞれ&lt;span class="math"&gt;\(1/2\)&lt;/span&gt;に近づいていく。厳密には大数の法則は 2 種類（強、弱法則）あり、確率の応用において非常に非常に重要な法則であるが、ここでは説明をしない。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id46" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id9"&gt;[8]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;確率変数のとる値が実数値でなくとも、事象が有限個存在（&lt;span class="math"&gt;\(\iff\)&lt;/span&gt;全事象が有限集合）する場合（例。サイコロとかコインを投げる試行）は議論で用いている分布を離散確率分布で考えれば良い。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id47" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id10"&gt;[9]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;起こりえる全ての事象の集合。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id48" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id11"&gt;[10]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;他の個人的に興味深い例：強化学習において&lt;span class="math"&gt;\(X\)&lt;/span&gt;を選択した行動列の集合、&lt;span class="math"&gt;\(h:X \to \mathbb{R}\)&lt;/span&gt;を報酬関数とすれば、&lt;span class="math"&gt;\(h(\boldsymbol{x})\)&lt;/span&gt;で行動列の報酬が計算でき、&lt;span class="math"&gt;\(I\)&lt;/span&gt;の計算結果は報酬の期待値となる。報酬の期待値が計算できることはエージェントの行動決定において大変有用である。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id49" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id12"&gt;[11]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;一様分布や正規分布等のよく知られた分布は、サンプリングアルゴリズムも確立されている。一様分布はメルセンヌ・ツイスタ、正規分布にはボックス - ミューラー法といった具合である。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id50" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id15"&gt;[12]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;空間の次元が増加すると、その空間の自由度が直感に反して &lt;strong&gt;指数的&lt;/strong&gt;
に増加すること。例えば、ユークリッド空間で一辺の長さが&lt;span class="math"&gt;\(a\)&lt;/span&gt;の&lt;span class="math"&gt;\(n\)&lt;/span&gt;次元超立方体を占める直径&lt;span class="math"&gt;\(a\)&lt;/span&gt;の超球体の割合を計算してみると&lt;span class="math"&gt;\(\frac{\sqrt{(\pi(a/2)^{2})^{n}}}{a^{n} \Gamma(\frac{n}{2}+1)}\)&lt;/span&gt;であり、&lt;span class="math"&gt;\(n\)&lt;/span&gt;を増加させると階乗オーダー（即ち、指数オーダーよりも早く）で減少する事が分かる。従って、一様乱数を用いていると、&lt;span class="math"&gt;\(n\)&lt;/span&gt;次元空間で超球体の内部にサンプルが入る確率が階乗オーダーで小さくなる。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id51" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id17"&gt;[13]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;厳密には、直前の 1 つのサンプルのみに依存するので 1 階マルコフ性と呼ばれる。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id52" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id18"&gt;[14]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;詳細は&lt;a class="reference external" href="# 補足 "&gt;補足&lt;/a&gt;で述べる。一般にエルゴード的とは、長時間に渡って観測した状態の平均（長時間平均）と、状態空間の平均（位相平均）が一致するという事を表す概念である。エルゴード理論がある様に、厳密な数学理論が展開されるが、ここではマルコフ連鎖以外については詳しくは説明しない（筆者がついていけてない）。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id53" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id19"&gt;[15]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;連続な状態空間では、遷移確率行列の代わりに&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
P(\boldsymbol{x}_{t+1} \in C|\boldsymbol{x}_{t} = \boldsymbol{e}_{t}) = \int_{C} T(\boldsymbol{e}_{t}, \boldsymbol{y}) d \boldsymbol{y} \quad C \subset X, \boldsymbol{e}_{t} \in X
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;となる様な条件付き確率分布&lt;span class="math"&gt;\(T(\boldsymbol{x}, \boldsymbol{y})\)&lt;/span&gt;（遷移核）を用いれば良い。&lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id54" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id20"&gt;[16]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;形式的に書くと、状態&lt;span class="math"&gt;\(j \in X\)&lt;/span&gt;の定常分布&lt;span class="math"&gt;\(\pi_{j}\)&lt;/span&gt;は&lt;span class="math"&gt;\(\pi_{j} = P(\boldsymbol{x}_{n} = j)\ n=0,1,\dots\)&lt;/span&gt;と表される。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id55" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id21"&gt;[17]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;例えば、現在状態を中心とした正規分布からでの乱択でも 3 つの性質を満たし、マルコフ連鎖はエルゴード的となる。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id56" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id23"&gt;[18]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;これが詳細釣り合い条件を満たすことは、場合分けにより分かる :&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\alpha(i \to j) = 1\)&lt;/span&gt;の時： &lt;span class="math"&gt;\(\alpha(j \to i) = \frac{r_{i}q_{ij}}{r_{j}q_{ji}}\)&lt;/span&gt;となるので、&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;
\begin{equation*}
p_{ji} = q_{ji} \alpha(j \to i) = q_{ji} \frac{r_{i}q_{ij}}{r_{j}q_{ji}} = \frac{r_{i}}{r_{j}}q_{ij} = \frac{r_{i}}{r_{j}} p_{ij}  \iff r_{i}p_{ij} = r_{j}p_{ji}
\end{equation*}
&lt;/div&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\alpha(i \to j) = \frac{r_{j}q_{ji}}{r_{i}q_{ij}}\)&lt;/span&gt;の時： &lt;span class="math"&gt;\(\alpha(j \to i) = 1\)&lt;/span&gt;となるので、&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="last math"&gt;
\begin{equation*}
p_{ij} = q_{ij} \alpha(i \to j) = q_{ij} \frac{r_{j}q_{ji}}{r_{i}q_{ij}} = \frac{r_{j}}{r_{i}}q_{ji} = \frac{r_{j}}{r_{i}} p_{ji}  \iff r_{i}p_{ij} = r_{j}p_{ji}
\end{equation*}
&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id57" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id24"&gt;[19]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;温度パラメタの調節は非常に難しい事が知られている。実験結果を見て経験的に設定される事がほとんどである。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id58" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id25"&gt;[20]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;分散パラメタの調節も非常に難しい。分散を大きくすると遷移幅（ステップサイズという）が大きくなって定常分布に落ち着くまでに時間が掛かり、分散を小さくし過ぎると遷移の動きが小さく、探索が十分に行われない危険性がある。一般に分散パラメタと温度パラメタにはトレードオフの関係がある。&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id59" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id26"&gt;[21]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(q_{ij} = q_{ji}\)&lt;/span&gt;が成立する理由は、この場合&lt;span class="math"&gt;\(j\)&lt;/span&gt;は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
j = i + \varepsilon \quad \varepsilon \sim {\cal N}(\boldsymbol{0}, \sigma^{2} \boldsymbol{I})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と書けるので、平均が&lt;span class="math"&gt;\(\boldsymbol{0}\)&lt;/span&gt;かつ正規分布の対称性により、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
i = j - \varepsilon = j + \varepsilon
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;よって&lt;span class="math"&gt;\(q_{ij} = {\cal N}(i, \sigma^{2}\boldsymbol{I}) = {\cal N}(j, \sigma^{2}\boldsymbol{I}) = q_{ji}\)&lt;/span&gt;を満たす&lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id60" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id28"&gt;[22]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;機械学習では、ベイジアンネットワークやボルツマンマシン（深層学習の一部）等のモデル学習に使われる&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id61" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id29"&gt;[23]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;毎回ランダムで選んでも、順番に全変数を 1 個ずつ選んでも良い&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id62" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id34"&gt;[24]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;数列&lt;span class="math"&gt;\(a_{n}\)&lt;/span&gt;の母関数を&lt;span class="math"&gt;\(F(z) = \displaystyle\sum_{n=0}^{\infty}a_{n}z^{n}\)&lt;/span&gt;とする。今、複素数&lt;span class="math"&gt;\(s \in \mathbb{C}\)&lt;/span&gt;を用いて&lt;span class="math"&gt;\(z = \exp(-s)\)&lt;/span&gt;とおき、&lt;span class="math"&gt;\(n\)&lt;/span&gt;の和を&lt;span class="math"&gt;\(t\)&lt;/span&gt;の積分に置き換えると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F(\exp(-s)) = \int_{0}^{\infty} a_{t}\exp(-st) dt
\end{equation*}
&lt;/div&gt;
&lt;p class="last"&gt;これは数列&lt;span class="math"&gt;\(a_{t}\)&lt;/span&gt;のラプラス変換に他ならない。従ってラプラス変換の最終値定理を適用できる。離散の場合のラプラス変換を（片側）Z 変換と呼ぶ。&lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id63" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id35"&gt;[25]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;2 つの冪級数を&lt;span class="math"&gt;\(\displaystyle\sum_{n=0}^{\infty}a_{n}z^{n}, \sum_{n=0}^{\infty}b_{n}z^{n}\)&lt;/span&gt;とし、積の結果を&lt;span class="math"&gt;\(\displaystyle\sum_{n=0}^{\infty}c_{n}z^{n}\)&lt;/span&gt;とする。等号を立てると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\left(\sum_{n=0}^{\infty}a_{n}z^{n}\right)\left(\sum_{n=0}^{\infty}b_{n}z^{n} \right) &amp;amp;= a_{0}b_{0}z^{0} + (a_{0}b_{1} + a_{1}b_{0})z^{1} + (a_{0}b_{2}+a_{1}b_{1}+a_{2}b_{0})z^{2} + \dots \\
  &amp;amp;= \sum_{n=0}^{\infty}c_{n}z^{n} = c_{0}z^{0} + c_{1}z^{1} + c_{2}z^{2} + \dots
\end{align*}
&lt;/div&gt;
&lt;p class="last"&gt;係数比較により、&lt;span class="math"&gt;\(c_{0} = a_{0}b_{0},\ c_{1} = a_{0}b_{1} + a_{1}b_{0},\ \dots\)&lt;/span&gt;が成立し、よって&lt;span class="math"&gt;\(c_{n} = \displaystyle \sum_{k=0}^{n}a_{k}b_{n-k}\)&lt;/span&gt;となる。ここの例では、&lt;span class="math"&gt;\(a_{k} = u_{k}z^{k},\ b_{k} = p_{jj}^{(k)}z^{k}\)&lt;/span&gt;とおけば良い。&lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id64" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id36"&gt;[26]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;p class="first"&gt;（証明）母関数（Z 変換）を&lt;span class="math"&gt;\(F(z) = \displaystyle \sum_{n=0}^{\infty}a_{n}z^{n}\)&lt;/span&gt;とおくと、&lt;/p&gt;
&lt;div class="last math"&gt;
\begin{align*}
\lim_{z \to 1} (1-z) F(z) &amp;amp;= \lim_{z \to 1}(1-z) \sum_{n=0}^{\infty} a_{n}z^{n} = \lim_{z \to 1} \sum_{n=0}^{\infty} a_{n} (z^{n} - z^{n+1}) = \lim_{z \to 1} \lim_{n \to \infty} \sum_{k=0}^{n} a_{k} (z^{k} - z^{k+1}) \\
&amp;amp;= \lim_{z \to 1} \lim_{n \to \infty} \sum_{k=0}^{n} (a_{k} - a_{k-1}) z^{k} \quad (\because a_{-1} = 0, また a_{0}(z^{0}-z^{1}) + a_{1}(z^{1}-z^{2}) +\dots = a_{0}z^{0} + (a_{0}-a_{1})z^{1} + \dots) \\
&amp;amp;= \lim_{n \to \infty} \sum_{k=0}^{n} (a_{k} - a_{k-1}) = \lim_{n \to \infty} a_{n}
\end{align*}
&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="記事"></category><category term="統計"></category></entry><entry><title>LPC（Linear Predictive Coding, 線形予測符号化）</title><link href="/lpclinear-predictive-coding-xian-xing-yu-ce-fu-hao-hua.html" rel="alternate"></link><published>2020-04-23T12:10:00+09:00</published><updated>2020-04-23T12:10:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-23:/lpclinear-predictive-coding-xian-xing-yu-ce-fu-hao-hua.html</id><summary type="html">&lt;p class="first last"&gt;線形予測符号化についての理論的概要とかんたんな実装例。ハイパー古い技術。&lt;/p&gt;
</summary><content type="html">&lt;p&gt;線形予測分析等とも言及される。&lt;/p&gt;
&lt;p&gt;英語版で決定的に簡単な資料は&lt;a class="reference external" href="http://www.emptyloop.com/technotes/A%20tutorial%20on%20linear%20prediction%20and%20Levinson-Durbin.pdf"&gt;ここ&lt;/a&gt;で見れます。ここの解説はその日本語訳以下の何かです。英語が読める人はそっちを見たほうが絶対早いです。&lt;/p&gt;
&lt;p&gt;ここよりも良い資料が有ります：（&lt;a class="reference external" href="http://aidiary.hatenablog.com/entry/20120415/1334458954"&gt;人工知能に関する断創録&lt;/a&gt;）&lt;/p&gt;
&lt;div class="contents local topic" id="id1"&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id13"&gt;アルゴリズムの導出&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id14"&gt;問題設定&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id15"&gt;誤差の最小化&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id16"&gt;偏微分&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#levinson-durbin-levinson-durbin-recursion" id="id17"&gt;Levinson-Durbin 再帰（Levinson-Durbin recursion）へ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#levinson-durbin" id="id18"&gt;Levinson-Durbin 再帰&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#k-1" id="id19"&gt;k=1 の時&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#k" id="id20"&gt;一般の k の時&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id21"&gt;アルゴリズム&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id7" id="id22"&gt;補足&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id8" id="id23"&gt;周波数特性の導出&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id9" id="id24"&gt;標本自己相関の計算&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id10" id="id25"&gt;参考資料リスト&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id11" id="id26"&gt;実装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id12" id="id27"&gt;実験&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id13"&gt;アルゴリズムの導出&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id14"&gt;問題設定&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;時間について離散化した信号が&lt;span class="math"&gt;\(y_{0}, y_{1}, ..., y_{n}\)&lt;/span&gt;として得られたとする。ここで、&lt;span class="math"&gt;\(y_{n}\)&lt;/span&gt;を直前の&lt;span class="math"&gt;\(y_{i}\ (i=0,...,n-1)\)&lt;/span&gt;によって予測する事を考える。&lt;/p&gt;
&lt;p&gt;予測にあたって、線形予測では&lt;span class="math"&gt;\(k\)&lt;/span&gt;個の係数&lt;span class="math"&gt;\(a_{1},...,a_{k}\)&lt;/span&gt;を用いた単純な線形結合&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
-a_{1}y_{n-1} - a_{2}y_{n-2} - ... - a_{k}y_{n-k} = - \sum_{i=1}^{k} a_{i} y_{n-i}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;によって&lt;span class="math"&gt;\(y_{n}\)&lt;/span&gt;を近似する：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
y_{n} \approx - \sum_{i=1}^{k} a_{i} y_{n-i}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;（係数に負号&lt;span class="math"&gt;\(-\)&lt;/span&gt;が付いているのは、システムのフィードバック係数として捉えた時は負を付けるのが常識となっているからと考えられる。全ての係数の符号を反転させれば通常の和に戻るので、以下の導出にとって本質的な問題にならない。）&lt;/p&gt;
&lt;p&gt;予測の&lt;strong&gt;誤差&lt;/strong&gt;は、全ての&lt;span class="math"&gt;\(n\)&lt;/span&gt;における&lt;strong&gt;二乗誤差&lt;/strong&gt;の和&lt;span class="math"&gt;\(E\)&lt;/span&gt;によって測る：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{split}
E &amp;amp;= \sum_{n=-\infty}^{\infty} \left[ y_{n} - \left\{ -\sum_{i=1}^{k} a_{i} y_{n-i} \right\} \right]^{2} \\
&amp;amp;= \sum_{n=-\infty}^{\infty} \left\{ y_{n} + \sum_{i=1}^{k}a_{i}y_{n-i} \right\}^{2}
\end{split}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで&lt;span class="math"&gt;\(a_{0} = 1\)&lt;/span&gt;と定義すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
E = \sum_{n=-\infty}^{\infty} \left\{\sum_{i=0}^{k}a_{i}y_{n-i}\right\}^{2}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とまとめられる。後は、この&lt;span class="math"&gt;\(E\)&lt;/span&gt;を最小化するように係数&lt;span class="math"&gt;\(a_{1},...,a_{k}\)&lt;/span&gt;を定めれば良い。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id15"&gt;誤差の最小化&lt;/a&gt;&lt;/h3&gt;
&lt;div class="section" id="id5"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id16"&gt;偏微分&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;誤差の最小化を考える。常套手段ではあるが、&lt;span class="math"&gt;\(E\)&lt;/span&gt;を&lt;span class="math"&gt;\(a_{j} \ (j=1,...,k)\)&lt;/span&gt;によって偏微分し、その結果を&lt;span class="math"&gt;\(0\)&lt;/span&gt;とおいて解くことを考える。まず、&lt;span class="math"&gt;\(E\)&lt;/span&gt;の偏微分は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{split}
\frac{\partial E}{\partial a_{j}} &amp;amp;= \sum_{n=-\infty}^{\infty} \frac{\partial}{\partial a_{j}} \left\{\sum_{i=0}^{k}a_{i}y_{n-i} \right\}^{2} \\
&amp;amp;= \sum_{n=-\infty}^{\infty} \frac{\partial}{\partial a_{j}} \left\{ a_{0}y_{n} + ... + a_{j}y_{n-j} + ... + a_{k}y_{n-k} \right\}^{2} \\
&amp;amp;= \sum_{n=-\infty}^{\infty} 2 y_{n-j} \sum_{i=0}^{k}a_{i}y_{n-i} \\
&amp;amp;= 2 \sum_{i=0}^{k}a_{i} \sum_{n=-\infty}^{\infty} y_{n-j} y_{n-i} \quad (\because \text{ 和の順序交換 }) \\
&amp;amp;= 2 \sum_{i=0}^{k}a_{i} \sum_{n^{\prime}=-\infty}^{\infty} y_{n^{\prime}} y_{n^{\prime}+j-i} \quad (n^{\prime} = n-j \ \text{ とおいた })
\end{split}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで、&lt;span class="math"&gt;\(R_{l}\)&lt;/span&gt;を次の式で定義する：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
R_{l} = \sum_{n=-\infty}^{\infty} y_{n} y_{n+l}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;（&lt;strong&gt;自己相関&lt;/strong&gt;
という。）&lt;span class="math"&gt;\(R_{l}\)&lt;/span&gt;を用いることで、偏微分の結果は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\frac{\partial E}{\partial a_{j}} = 2 \sum_{i=0}^{k} a_{i}R_{|j-i|}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表せる。&lt;/p&gt;
&lt;p&gt;次に、&lt;span class="math"&gt;\(\displaystyle\frac{\partial E}{\partial a_{j}} = 0\ (j=1,...,k)\)&lt;/span&gt;とおいて解く事を考える。和の前に付いている係数&lt;span class="math"&gt;\(2\)&lt;/span&gt;は両辺&lt;span class="math"&gt;\(2\)&lt;/span&gt;で割ることで消すことが出来る。その上で&lt;span class="math"&gt;\(j=1,...,k\)&lt;/span&gt;での式を並べてみると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{split}
a_{0}R_{|0-1|} + a_{1}R_{|1-1|} + ... + a_{k}R_{|k-1|} &amp;amp;= 0 \\
a_{0}R_{|0-2|} + a_{1}R_{|1-2|} + ... + a_{k}R_{|k-2|} &amp;amp;= 0 \\
\vdots \\
a_{0}R_{|0-k|} + a_{1}R_{|1-k|} + ... + a_{k}R_{|k-k|} &amp;amp;= 0 \\
\end{split}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;より、行列形式で&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{bmatrix}
R_{1} &amp;amp; R_{0} &amp;amp; R_{1} &amp;amp; ... &amp;amp; R_{k-1} \\
R_{2} &amp;amp; R_{1} &amp;amp; R_{0} &amp;amp; ... &amp;amp; R_{k-2} \\
\vdots &amp;amp;      &amp;amp;  &amp;amp; \ddots   &amp;amp; \vdots  \\
R_{k} &amp;amp; R_{k-1} &amp;amp; R_{k-2} &amp;amp; ... &amp;amp; R_{0}
\end{bmatrix}
\begin{bmatrix}
1 \\ a_{1} \\ a_{2} \\ \vdots \\ a_{k}
\end{bmatrix}
= \vec{0}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表せられる。以下、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
M =
\begin{bmatrix}
R_{1} &amp;amp; R_{0} &amp;amp; ... &amp;amp; R_{k-1} \\
R_{2} &amp;amp; R_{1} &amp;amp; ... &amp;amp; R_{k-2} \\
\vdots &amp;amp;      &amp;amp;  \ddots &amp;amp; \vdots  \\
R_{k} &amp;amp; R_{k-1} &amp;amp; ... &amp;amp; R_{0}
\end{bmatrix}
\ , \
\vec{a}_{k} =
\begin{bmatrix}
1 \\ a_{1} \\ a_{2} \\ \vdots \\ a_{k}
\end{bmatrix}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;として、&lt;span class="math"&gt;\(M\vec{a}_{k} = \vec{0}\)&lt;/span&gt;を解くことを考える。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="levinson-durbin-levinson-durbin-recursion"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id17"&gt;Levinson-Durbin 再帰（Levinson-Durbin recursion）へ&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;上までで求まった連立方程式&lt;span class="math"&gt;\(M\vec{a}\_{k+1} = \vec{0}\)&lt;/span&gt;をもう少し整理していく。数値解法的には、&lt;span class="math"&gt;\(M\)&lt;/span&gt;は正方行列にしておくのが望ましい。そこで、&lt;span class="math"&gt;\(M\)&lt;/span&gt;の一番上の行に&lt;span class="math"&gt;\([R_{0} R_{1} ... R_{k}]\)&lt;/span&gt;を追加すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\begin{split}
M\vec{a}_{k} &amp;amp;=
\begin{bmatrix}
R_{1} &amp;amp; R_{0} &amp;amp; ... &amp;amp; R_{k-1} \\
R_{2} &amp;amp; R_{1} &amp;amp; ... &amp;amp; R_{k-2} \\
\vdots &amp;amp;      &amp;amp;  \ddots &amp;amp; \vdots  \\
R_{k} &amp;amp; R_{k-1} &amp;amp; ... &amp;amp; R_{0}
\end{bmatrix}
\begin{bmatrix}
1 \\ a_{1} \\ a_{2} \\ \vdots \\ a_{k}
\end{bmatrix}
\\&amp;amp;=
\begin{bmatrix}
R_{0} &amp;amp; R_{1} &amp;amp; ... &amp;amp; R_{k}   \\
R_{1} &amp;amp; R_{0} &amp;amp; ... &amp;amp; R_{k-1} \\
\vdots &amp;amp;       &amp;amp; \ddots   &amp;amp; \vdots  \\
R_{k} &amp;amp; R_{k-1} &amp;amp; ... &amp;amp; R_{0}
\end{bmatrix}
\begin{bmatrix}
1 \\ a_{1} \\ a_{2} \\ \vdots \\ a_{k}
\end{bmatrix}
-\begin{bmatrix}
\sum_{i=0}^{k}a_{i}R_{i} \\ 0 \\ 0 \\ \vdots \\ 0
\end{bmatrix}
= \vec{0}
\end{split}
\end{align*}
&lt;/div&gt;
&lt;p&gt;と変形できる。よって、次の連立方程式を解くことに帰着できる：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{bmatrix}
R_{0} &amp;amp; R_{1} &amp;amp; ... &amp;amp; R_{k}   \\
R_{1} &amp;amp; R_{0} &amp;amp; ... &amp;amp; R_{k-1} \\
\vdots &amp;amp;       &amp;amp; \ddots   &amp;amp; \vdots  \\
R_{k} &amp;amp; R_{k-1} &amp;amp; ... &amp;amp; R_{0}
\end{bmatrix}
\begin{bmatrix}
1 \\ a_{1} \\ a_{2} \\ \vdots \\ a_{k}
\end{bmatrix}
=\begin{bmatrix}
\sum_{i=0}^{k}a_{i}R_{i} \\ 0 \\ 0 \\ \vdots \\ 0
\end{bmatrix}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;この連立方程式を高速に解くアルゴリズムが、Levinson-Durbin 再帰法である。以下、&lt;span class="math"&gt;\(e_{k} = \sum_{i=0}^{k} a_{i} R_{i}\)&lt;/span&gt;とし、また行列&lt;span class="math"&gt;\(N_{k}\)&lt;/span&gt;を次で定義する：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
N_{k} =
\begin{bmatrix}
R_{0} &amp;amp; R_{1} &amp;amp; ... &amp;amp; R_{k}   \\
R_{1} &amp;amp; R_{0} &amp;amp; ... &amp;amp; R_{k-1} \\
\vdots &amp;amp;       &amp;amp; \ddots   &amp;amp; \vdots  \\
R_{k} &amp;amp; R_{k-1} &amp;amp; ... &amp;amp; R_{0}
\end{bmatrix}
\end{equation*}
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="levinson-durbin"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id18"&gt;Levinson-Durbin 再帰&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;このアルゴリズムは、数学的帰納法によく似ている：&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;span class="math"&gt;\(k=1\)&lt;/span&gt;の場合で係数を求める&lt;/li&gt;
&lt;li&gt;一般の&lt;span class="math"&gt;\(k\)&lt;/span&gt;で係数が求まったとし、その結果から&lt;span class="math"&gt;\(k+1\)&lt;/span&gt;で係数を求める&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;（&lt;a class="reference external" href="http://www.emptyloop.com/technotes/A%20tutorial%20on%20linear%20prediction%20and%20Levinson-Durbin.pdf"&gt;参考資料&lt;/a&gt;で筆者は、「Levinson-Durbin 帰納法と言ったほうがいいんじゃないか」と書いてあった。）ここでは、1. および 2. の場合の解をそれぞれ見ていく。&lt;/p&gt;
&lt;div class="section" id="k-1"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id19"&gt;k=1 の時&lt;/a&gt;&lt;/h4&gt;
&lt;div class="math"&gt;
\begin{equation*}
\vec{a}_{1}=
\begin{bmatrix}
 1 \\
 a_{1}
\end{bmatrix}
,\
N_{1}\vec{a}_{1}=
\begin{bmatrix}
 e_{1} \\
 0
\end{bmatrix}
,\
N_{1}=
\begin{bmatrix}
 R_{0} &amp;amp; R_{1} \\
 R_{1} &amp;amp; R_{0}
\end{bmatrix}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;より、実際に&lt;span class="math"&gt;\(N_{1}\vec{a}_{1}\)&lt;/span&gt;を計算してみると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
N_{1}\vec{a}_{1}=
\begin{bmatrix}
 R_{0} + R_{1}a_{1} \\
 R_{1} + R_{0}a_{1}
\end{bmatrix}=
\begin{bmatrix}
 e_{1} \\
 0
\end{bmatrix}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;より、&lt;span class="math"&gt;\(e_{1} = R_{0} + R_{1}a_{1}\)&lt;/span&gt;、及び&lt;span class="math"&gt;\(R_{1} + R_{0}a_{1} = 0\)&lt;/span&gt;から&lt;span class="math"&gt;\(a_{1} = -\displaystyle\frac{R_{1}}{R_{0}}\)&lt;/span&gt;と求められる。（&lt;span class="math"&gt;\(R_{0} = \displaystyle\sum_{n=-\infty}^{\infty}y_{n}^{2} &amp;gt; 0\)&lt;/span&gt;より、至る所ゼロ除算の心配はない）&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="k"&gt;
&lt;h4&gt;&lt;a class="toc-backref" href="#id20"&gt;一般の k の時&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;仮定として、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
N_{k}\vec{a}_{k}=
\begin{bmatrix}
R_{0} &amp;amp; R_{1} &amp;amp; ... &amp;amp; R_{k}   \\
R_{1} &amp;amp; R_{0} &amp;amp; ... &amp;amp; R_{k-1} \\
\vdots &amp;amp;       &amp;amp; \ddots   &amp;amp; \vdots  \\
R_{k} &amp;amp; R_{k-1} &amp;amp; ... &amp;amp; R_{0}
\end{bmatrix}
\begin{bmatrix}
1 \\ a_{1} \\ a_{2} \\ \vdots \\ a_{k}
\end{bmatrix}
=\begin{bmatrix}
e_{k} \\ 0 \\ 0 \\ \vdots \\ 0
\end{bmatrix}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成立していたとする。&lt;span class="math"&gt;\(k+1\)&lt;/span&gt;の時、行列&lt;span class="math"&gt;\(N_{k+1}\)&lt;/span&gt;は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
N_{k+1}=
\begin{bmatrix}
R_{0} &amp;amp; R_{1} &amp;amp; ... &amp;amp; R_{k} &amp;amp; R_{k+1}   \\
R_{1} &amp;amp; R_{0} &amp;amp; ... &amp;amp; R_{k-1} &amp;amp; R_{k} \\
\vdots &amp;amp;       &amp;amp; \ddots  &amp;amp; &amp;amp; \vdots  \\
R_{k} &amp;amp; R_{k-1} &amp;amp; ... &amp;amp; R_{0} &amp;amp; R_{1} \\
R_{k+1} &amp;amp; R_{k} &amp;amp; ... &amp;amp; R_{1} &amp;amp; R_{0}
\end{bmatrix}=
\left[
\begin{array}{cccc|c}
 &amp;amp; &amp;amp; &amp;amp; &amp;amp; R_{k+1}   \\
 &amp;amp; N_{k} &amp;amp; &amp;amp; &amp;amp; R_{k} \\
 &amp;amp; &amp;amp; &amp;amp; &amp;amp; \vdots  \\
 &amp;amp; &amp;amp; &amp;amp; &amp;amp; R_{1} \\\hline
R_{k+1} &amp;amp; R_{k} &amp;amp; ... &amp;amp; R_{1} &amp;amp; R_{0}
\end{array}
\right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となり、&lt;span class="math"&gt;\(N_{k}\)&lt;/span&gt;の行・列共に 1 つ増えた行列となる。&lt;/p&gt;
&lt;p&gt;一方の&lt;span class="math"&gt;\(\vec{a}_{k+1}\)&lt;/span&gt;は未知である。そこで、技巧的ではあるが次&lt;span class="math"&gt;\(\vec{a}\_{k}\)&lt;/span&gt;を&lt;span class="math"&gt;\(0\)&lt;/span&gt;を追加する事で拡張した次のベクトル&lt;span class="math"&gt;\(\vec{u}\_{k+1}, \vec{v}\_{k+1}\)&lt;/span&gt;を用いる事を考える：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\vec{u}_{k+1}=
\begin{bmatrix}
1 \\ a_{1} \\ a_{2} \\ \vdots \\ a_{k} \\ 0
\end{bmatrix}\ ,\
\vec{v}_{k+1}=
\begin{bmatrix}
0 \\ a_{k} \\ \vdots \\ a_{2} \\ a_{1} \\ 1
\end{bmatrix}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\vec{u}\_{k+1}, \vec{v}\_{k+1}\)&lt;/span&gt;は互いに要素を反転したベクトルである（互いに&lt;strong&gt;一次独立&lt;/strong&gt;で有ることにも注目）。これら&lt;span class="math"&gt;\(\vec{u}\_{k+1}, \vec{v}\_{k+1}\)&lt;/span&gt;を用いて&lt;span class="math"&gt;\(N\_{k+1}\vec{u}\_{k+1}\)&lt;/span&gt;と&lt;span class="math"&gt;\(N_{k+1}\vec{v}\_{k+1}\)&lt;/span&gt;を計算すると、まず&lt;span class="math"&gt;\(N\_{k+1}\vec{u}\_{k+1}\)&lt;/span&gt;は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
\begin{split}
N_{k+1}\vec{u}_{k+1}&amp;amp;=
\left[
\begin{array}{cccc|c}
 &amp;amp; &amp;amp; &amp;amp; &amp;amp; R_{k+1}   \\
 &amp;amp; N_{k} &amp;amp; &amp;amp; &amp;amp; R_{k} \\
 &amp;amp; &amp;amp; &amp;amp; &amp;amp; \vdots  \\
 &amp;amp; &amp;amp; &amp;amp; &amp;amp; R_{1} \\\hline
R_{k+1} &amp;amp; R_{k} &amp;amp; ... &amp;amp; R_{1} &amp;amp; R_{0}
\end{array}
\right]
\begin{bmatrix}
1 \\ a_{1} \\ a_{2} \\ \vdots \\ a_{k} \\ 0
\end{bmatrix}\\
&amp;amp;=
\begin{bmatrix}
 \\  \\ N_{k}\vec{a}_{k} \\  \\  \\ \hline [R_{k+1} R_{k} ... R_{1}] \vec{a}_{k}
\end{bmatrix}=
\begin{bmatrix}
e_{k} \\ 0 \\ \vdots \\ 0 \\  \displaystyle\sum_{j=0}^{k} a_{j} R_{k+1-j}
\end{bmatrix}
\end{split}
\end{align*}
&lt;/div&gt;
&lt;p&gt;であり、もう一方の&lt;span class="math"&gt;\(N\_{k+1}\vec{v}\_{k+1}\)&lt;/span&gt;は、&lt;span class="math"&gt;\(N\_{k+1}\)&lt;/span&gt;が&lt;strong&gt;対称行列&lt;/strong&gt;なので&lt;span class="math"&gt;\(N\_{k+1}\vec{u}\_{k+1}\)&lt;/span&gt;の結果を反転したベクトルとなる：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
N_{k+1}\vec{v}_{k+1}=
\begin{bmatrix}
\displaystyle\sum_{j=0}^{k} a_{j} R_{k+1-j} \\ 0 \\ \vdots \\ 0 \\ e_{k}
\end{bmatrix}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;そして、&lt;span class="math"&gt;\(\vec{a}\_{k+1}\)&lt;/span&gt;は&lt;span class="math"&gt;\(\vec{u}\_{k+1}\)&lt;/span&gt;と&lt;span class="math"&gt;\(\vec{v}\_{k+1}\)&lt;/span&gt;の線形結合で表現できる：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\vec{a}_{k+1} = \vec{u}_{k+1} + \lambda \vec{v}_{k+1} \quad (\lambda : 実数 )
\end{equation*}
&lt;/div&gt;
&lt;p&gt;これは、実際に&lt;span class="math"&gt;\(N\_{k+1}(\vec{u}\_{k+1} + \lambda \vec{v}\_{k+1})\)&lt;/span&gt;を計算することで確かめられる：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
N_{k+1}(\vec{u}_{k+1} + \lambda \vec{v}_{k+1}) = N_{k+1}\vec{u}_{k+1} + N_{k+1}\lambda \vec{v}_{k+1}=
\begin{bmatrix}
e_{k} + \lambda \displaystyle\sum_{j=0}^{k} a_{j} R_{k+1-j} \\ 0 \\ \vdots \\ 0 \\ \displaystyle\sum_{j=0}^{k} a_{j} R_{k+1-j} + \lambda e_{k}
\end{bmatrix}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで&lt;span class="math"&gt;\(\lambda = - \displaystyle\frac{\sum_{j=0}^{k} a_{j} R_{k+1-j}}{e_{k}}\)&lt;/span&gt;とすれば、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
N_{k+1}(\vec{u}_{k+1} + \lambda \vec{v}_{k+1}) =
\begin{bmatrix}
e_{k} - \lambda^{2} e_{k} \\ 0 \\ \vdots \\ 0 \\ \displaystyle\sum_{j=0}^{k} a_{j} R_{k+1-j} - \displaystyle\sum_{j=0}^{k} a_{j} R_{k+1-j}
\end{bmatrix}=
\begin{bmatrix}
(1-\lambda^{2}) e_{k} \\ 0 \\ \vdots  \\ 0
\end{bmatrix}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となって&lt;span class="math"&gt;\(e\_{k+1}\)&lt;/span&gt;が求まる。同時に右辺の結果を与える&lt;span class="math"&gt;\(\lambda\)&lt;/span&gt;は唯一つしか存在しないので、この時の&lt;span class="math"&gt;\(\vec{u}\_{k+1} + \lambda \vec{v}\_{k+1}\)&lt;/span&gt;は&lt;span class="math"&gt;\(\vec{a}\_{k+1}\)&lt;/span&gt;と一致する。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id21"&gt;アルゴリズム&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;以上の導出結果をまとめると、&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(k=1\)&lt;/span&gt;の時：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
a_{1} = - \frac{R_{1}}{R_{0}} \ , \ e_{1} = R_{0} + R_{1}a_{1}
\end{equation*}
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;span class="math"&gt;\(k\)&lt;/span&gt;が求まった時、&lt;span class="math"&gt;\(k+1\)&lt;/span&gt;は：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;
\begin{equation*}
\lambda = - \displaystyle\frac{\sum_{j=0}^{k}a_{j}R_{k+1-j}}{e_{k}} \ , \ e_{k+1} = (1-\lambda^{2})e_{k}\ ,\ \vec{a}_{k+1} = \vec{u}_{k+1} + \lambda \vec{v}_{k+1}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
R_{l} = \sum_{n=-\infty}^{\infty} y_{n}y_{n+l}\ ,\
\vec{u}_{k+1}=
\begin{bmatrix}
1 \\ a_{1} \\ \vdots \\ a_{k} \\ 0
\end{bmatrix}\ ,\
\vec{v}_{k+1}=
\begin{bmatrix}
0 \\ a_{k} \\ \vdots \\ a_{1} \\ 1
\end{bmatrix}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となる。&lt;/p&gt;
&lt;p&gt;自己相関&lt;span class="math"&gt;\(R_{l}\)&lt;/span&gt;は過去から未来までの無限の信号和になっているので現実の計算機では計算出来ない。実際には自己相関の代わりに次の&lt;strong&gt;標本自己相関&lt;/strong&gt;&lt;span class="math"&gt;\(\tilde{R}\_{l}\)&lt;/span&gt;を用いる：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\tilde{R}_{l} = \sum_{i=0}^{n} y_{i}y_{i-l} \quad (l = 0, ..., k)
\end{equation*}
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id22"&gt;補足&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id8"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id23"&gt;周波数特性の導出&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;近似式は誤差項&lt;span class="math"&gt;\(e_{n}\)&lt;/span&gt;を用いて次の等式で書き表せる：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{split}
y_{n} = - a_{1}y_{n-1} - a_{2}y_{n-2} - \dots -a_{k}y_{n-k} + e_{n} \\
y_{n} = - \sum_{i=1}^{k} a_{i}y_{n-k} + e_{n}
\end{split}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;この式を両辺 z 変換すると、次の伝達関数を得る：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{split}
Y(z) = - \sum_{i=1}^{k} a_{i}z^{-i}Y(z) + E(z) \\
\iff \frac{Y(z)}{E(z)} = \frac{1}{1+ \sum_{i=1}^{k}a_{i}z^{-i}}
\end{split}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;この結果は、予測誤差を入力することで出力音声が得られるシステムを表している。人間の声帯から発せられた音声を&lt;span class="math"&gt;\(E(z)\)&lt;/span&gt;とすれば、この伝達関数は声道の共鳴する特性をモデル化していると考えることができる。共鳴が発生する周波数では伝達関数のパワー（振幅、ゲイン）が高くなり、この結果からフォルマント分析を行うことができる。&lt;/p&gt;
&lt;p&gt;伝達関数の周波数特性を求めるには、z 変換の結果に&lt;span class="math"&gt;\(z=\exp(j\omega), (\omega=2\pi f: 角周波数 )\)&lt;/span&gt;を代入する：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{split}
\frac{Y(z)}{E(z)} = \frac{1}{1+ \sum_{i=1}^{k} a_{i} \exp(-j i \omega) }
\end{split}
\end{equation*}
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id24"&gt;標本自己相関の計算&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;標本自己相関は自分自身との相関を計算するので&lt;span class="math"&gt;\(O(N^{2})\)&lt;/span&gt;の計算量があるが、ウィーナー・ヒンチンの定理（信号のパワースペクトラムは、その自己相関に等しい）を使って自己相関を計算すれば、実質 FFT と同等の計算量&lt;span class="math"&gt;\(O(N \log N)\)&lt;/span&gt;で抑えることもできる。但し、巡回畳み込みや、パワースペクトラムの平均処理を考慮する必要がある。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id25"&gt;参考資料リスト&lt;/a&gt;&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;LPC について：&lt;a class="reference external" href="http://ahclab.naist.jp/lecture/2014/sp/material/sp2nd-2.pdf"&gt;東京大学
音情報処理論&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ウィーナー・ヒンチンの定理：&lt;a class="reference external" href="http://manabukano.brilliant-future.net/lecture/appliedmathF2/slide/Slide07_PowerSpctrum.pdf"&gt;京都大学
工業数学&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id11"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id26"&gt;実装&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;実装は C 言語です（リファレンスは LL で書くべきだった …）&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;math.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;stdlib.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;string.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;float.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;

&lt;span class="cm"&gt;/* （標本）自己相関の計算 */&lt;/span&gt;
&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;
&lt;span class="nf"&gt;calc_auto_correlation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;auto_corr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;num_sample&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;max_order&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="cm"&gt;/* Levinson-Durbin 再帰計算 */&lt;/span&gt;
&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;
&lt;span class="nf"&gt;levinson_durbin_recursion&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;lpc_coef&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;auto_corr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;max_order&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;num_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="cm"&gt;/* サンプル数 */&lt;/span&gt;
  &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;max_delay&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;  &lt;span class="cm"&gt;/* LPC 係数の数 */&lt;/span&gt;

  &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;     &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;malloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num_sample&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;malloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num_sample&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;auto_cor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;malloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_delay&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
  &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;coff&lt;/span&gt;     &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;malloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_delay&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
  &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="cm"&gt;/* 波形の生成 */&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;num_sample&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;cos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;4.0f&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/* 自己相関・ Levinson-Durbin 再帰計算 */&lt;/span&gt;
  &lt;span class="n"&gt;calc_auto_correlation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;auto_cor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_sample&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_delay&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;levinson_durbin_recursion&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;auto_cor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_delay&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="cm"&gt;/* 予測テスト */&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;num_sample&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;max_delay&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="cm"&gt;/* 最初の max_delay ステップ分は元信号を単純コピー */&lt;/span&gt;
      &lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="cm"&gt;/* 以降は予測 */&lt;/span&gt;
      &lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
      &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_delay&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;max_delay&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coff&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
      &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/* 誤差計算・結果表示 */&lt;/span&gt;
  &lt;span class="n"&gt;error&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;num_sample&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;error&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;pow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;No:%d Data: %f Predict: %f &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Error : %f &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_sample&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;

  &lt;span class="n"&gt;free&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="n"&gt;free&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;free&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;auto_cor&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="n"&gt;free&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coff&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;levinson_durbin_recursion&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;lpc_coef&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;auto_corr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;max_order&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;lambda&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;u_vec&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;v_vec&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;a_vec&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;e_vec&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lpc_coef&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;auto_corr&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;fprintf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Data or result pointer point to NULL. &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/*&lt;/span&gt;
&lt;span class="cm"&gt;   * 0 次自己相関（信号の二乗和）が 0 に近い場合、入力信号は無音と判定&lt;/span&gt;
&lt;span class="cm"&gt;   * =&amp;gt; 予測誤差 , LPC 係数は全て 0 として無音出力システムを予測 .&lt;/span&gt;
&lt;span class="cm"&gt;   */&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fabs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;auto_corr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;FLT_EPSILON&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_delay&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;max_order&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;lpc_coef&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/* 初期化 */&lt;/span&gt;
  &lt;span class="n"&gt;a_vec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;malloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_order&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt; &lt;span class="cm"&gt;/* a_0, a_k+1 を含めると max_order+2 */&lt;/span&gt;
  &lt;span class="n"&gt;e_vec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;malloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_order&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt; &lt;span class="cm"&gt;/* e_0, e_k+1 を含めると max_order+2 */&lt;/span&gt;
  &lt;span class="n"&gt;u_vec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;malloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_order&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
  &lt;span class="n"&gt;v_vec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;malloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_order&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_delay&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;max_order&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;u_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;v_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/* 最初のステップの係数をセット */&lt;/span&gt;
  &lt;span class="n"&gt;a_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;e_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;auto_corr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
  &lt;span class="n"&gt;a_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;auto_corr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;auto_corr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
  &lt;span class="n"&gt;e_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;auto_corr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;auto_corr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;a_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
  &lt;span class="n"&gt;u_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;u_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;v_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;v_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="cm"&gt;/* 再帰処理 */&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;delay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;delay&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;max_order&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;lambda&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_delay&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;lambda&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;a_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;auto_corr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;lambda&lt;/span&gt; &lt;span class="o"&gt;/=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;e_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
    &lt;span class="n"&gt;e_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;lambda&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;lambda&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;e_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;

    &lt;span class="cm"&gt;/* u_vec, v_vec の更新 */&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_delay&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;u_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;v_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;u_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;u_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;v_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;v_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="cm"&gt;/* result の更新 */&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_delay&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
       &lt;span class="n"&gt;a_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;u_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;lambda&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;v_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_delay&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/* 結果の取得 */&lt;/span&gt;
  &lt;span class="n"&gt;memcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lpc_coef&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;a_vec&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_order&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;

  &lt;span class="n"&gt;free&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;u_vec&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="n"&gt;free&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v_vec&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;free&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a_vec&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="n"&gt;free&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e_vec&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;calc_auto_correlation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;auto_corr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;num_sample&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;max_order&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;delay_time&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_order&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_sample&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;fprintf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Max order(%zu) is larger than number of samples(%zu). &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_order&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_sample&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;auto_corr&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;fprintf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Data or result pointer point to NULL. &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/* （標本）自己相関の計算 */&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;delay_time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;delay_time&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;max_order&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;delay_time&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;auto_corr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;delay_time&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;delay_time&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;num_sample&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;auto_corr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;delay_time&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_sample&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;delay_time&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id12"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id27"&gt;実験&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;実際に走らせた結果のグラフは以下。 &lt;img alt="result" src="./images/lpc_result.png" /&gt;&lt;/p&gt;
&lt;p&gt;原信号が簡単すぎたのか、係数は少なめでも十分に予測できている。しかし、適当な係数の数の取り方を決める手法がないと、実信号で使い物になりそうにない。とりあえず、自己相関を使いこなした N.
Wiener is GOD.（結言）&lt;/p&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="記事"></category><category term="LPC"></category><category term="信号処理"></category><category term="ロスレス音声"></category></entry><entry><title>離散フーリエ変換（DFT）</title><link href="/li-san-huriebian-huan-dft.html" rel="alternate"></link><published>2020-04-23T12:00:00+09:00</published><updated>2020-04-23T12:00:00+09:00</updated><author><name>aiki</name></author><id>tag:None,2020-04-23:/li-san-huriebian-huan-dft.html</id><summary type="html">&lt;p class="first last"&gt;教科書で出てくる離散フーリエ変換の式が出てくるところまでの導出。超関数に関しては不完全。&lt;/p&gt;
</summary><content type="html">&lt;p&gt;離散時間かつ離散周波数でのフーリエ変換を離散フーリエ変換という。&lt;/p&gt;
&lt;div class="contents local topic" id="id1"&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id6"&gt;準備：時間領域で離散化すると、周波数領域では周期的になる&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id7"&gt;離散フーリエ変換・離散フーリエ逆変換&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id8"&gt;離散化の仮定&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id9"&gt;離散フーリエ変換の導出&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id6"&gt;準備：時間領域で離散化すると、周波数領域では周期的になる&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span class="math"&gt;\(f(t)\)&lt;/span&gt;を離散化した信号を&lt;span class="math"&gt;\(g(t)\)&lt;/span&gt;とおく。離散化には、サンプリング周期&lt;span class="math"&gt;\(t_{s}\)&lt;/span&gt;の周期的デルタ関数&lt;span class="math"&gt;\(\delta_{t_{s}}(t)\)&lt;/span&gt;を用いて&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
g(t) = f(t) \delta_{t_s}(t) = \sum_{n=-\infty}^{\infty} f(t) \delta(t - nt_{s})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;とする。デルタ関数&lt;span class="math"&gt;\(\delta(t)\)&lt;/span&gt;は関数&lt;span class="math"&gt;\(f(t)\)&lt;/span&gt;に対して次が成り立つ（超）関数である：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\int^{\infty}_{-\infty} f(t) \delta(t) dt = f(0)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(t_{s}\)&lt;/span&gt;の逆数はサンプリングレート（&lt;span class="math"&gt;\(f_{s} = 1/t_{s}\)&lt;/span&gt;）そのものである。また、周期的デルタ関数の（複素）フーリエ級数は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{aligned}
\delta_{t_{s}}(t) &amp;amp;= \sum_{n=-\infty}^{\infty} c_{n} \exp(j\omega_{s}t)dt \\
c_{n} &amp;amp;= \frac{1}{t_{s}} \int^{t_{s}/2}_{-t_{s}/2} \delta_{t_{s}}(t) \exp(-jn\omega_{s}t)dt
\end{aligned}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と表せる。ここで&lt;span class="math"&gt;\(\omega_{s}=2\pi/t_{s}\)&lt;/span&gt;（サンプリング角周波数）である。&lt;span class="math"&gt;\(c_{n}\)&lt;/span&gt;の計算を考えると、積分範囲&lt;span class="math"&gt;\([-t_{s}/2, t_{s}/2]\)&lt;/span&gt;に唯一つのインパルスが存在する事に留意すれば、次の結果を得る：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
c_{n} = \frac{1}{t_{s}} \int^{t_{s}/2}_{-t_{s}/2} \delta(t) \exp(-jn\omega_{s}t)dt = \frac{1}{t_{s}}\exp(0) = \frac{1}{t_{s}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;よって、周期的デルタ関数の複素フーリエ級数は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\delta_{t_s}(t) = \frac{1}{t_{s}} \sum_{n=-\infty}^{\infty} \exp(j n \omega_{s} t) = \frac{1}{t_{s}} \sum_{n=-\infty}^{\infty} \exp(j 2\pi n t)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;であり、この結果を用いると、&lt;span class="math"&gt;\(g(t)\)&lt;/span&gt;のフーリエ変換&lt;span class="math"&gt;\({\cal F}[g(t)]\)&lt;/span&gt;は、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{split}
{\cal F}[g(t)] &amp;amp;= \frac{1}{t_{s}} \sum_{n=-\infty}^{\infty} {\cal F} \left[ f(t) \exp(j n \omega_{s} t) \right] \\
&amp;amp;= \frac{1}{t_{s}} \sum_{n=-\infty}^{\infty} \int_{-\infty}^{\infty} f(t) \exp[ -j (\omega - n\omega_{s}) t] dt
\\
&amp;amp;= \frac{1}{t_{s}} \sum_{n=-\infty}^{\infty} F(\omega - n\omega_{s})
\end{split}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで、&lt;span class="math"&gt;\(F(\omega)\)&lt;/span&gt;は&lt;span class="math"&gt;\(f(t)\)&lt;/span&gt;をフーリエ変換した結果を表している。この結果は、離散化した信号のフーリエ変換は周波数領域で&lt;strong&gt;周期&lt;/strong&gt; &lt;span class="math"&gt;\(\omega_{s}\)&lt;/span&gt; &lt;strong&gt;で&lt;/strong&gt; &lt;span class="math"&gt;\(F(\omega)\)&lt;/span&gt; &lt;strong&gt;を繰り返す&lt;/strong&gt;事を示している。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;離散フーリエ変換・離散フーリエ逆変換&lt;/a&gt;&lt;/h2&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id8"&gt;離散化の仮定&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;時間領域で離散化した信号&lt;span class="math"&gt;\(f[n]\)&lt;/span&gt;を次の様に定義する：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f[n] = f(nt_{s}) \quad n = 0,...,N-1
\end{equation*}
&lt;/div&gt;
&lt;p&gt;ここで、&lt;span class="math"&gt;\(N\)&lt;/span&gt;はサンプリング個数である。重要な仮定として、&lt;span class="math"&gt;\(f(t)\)&lt;/span&gt;は&lt;span class="math"&gt;\(N\)&lt;/span&gt;このサンプリング期間で周期的であるとする。即ち、&lt;span class="math"&gt;\(f(t)\)&lt;/span&gt;の周期を&lt;span class="math"&gt;\(T\)&lt;/span&gt;とおくと、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
T = Nt_{s}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;が成立する。更に、&lt;strong&gt;周波数領域についても&lt;/strong&gt;&lt;span class="math"&gt;\(\omega_{s}\)&lt;/span&gt;&lt;strong&gt;を&lt;/strong&gt;&lt;span class="math"&gt;\(N\)&lt;/span&gt;&lt;strong&gt;分割&lt;/strong&gt;
し、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\omega_{k} = \frac{\omega_{s}}{N} k = \frac{2\pi}{Nt_{s}}k \quad k = 0,...,N-1
\end{equation*}
&lt;/div&gt;
&lt;p&gt;として、周波数領域で離散化した信号&lt;span class="math"&gt;\(F[k]\)&lt;/span&gt;を次の様に定義する：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F[k] = F(\omega_{k}) \quad k = 0,...,N-1
\end{equation*}
&lt;/div&gt;
&lt;p&gt;分割の個数&lt;span class="math"&gt;\(N\)&lt;/span&gt;が時間領域と周波数領域で異なる場合、変換対が対称にならないので高速フーリエ変換の時に不都合が生じる。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id9"&gt;離散フーリエ変換の導出&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;離散化の仮定のもとで、フーリエ変換は次の様に計算できる：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F[k] = \int_{-\infty}^{\infty} f(t) \exp(-j\omega_{k}t) dt = \int_{-\infty}^{\infty} f(t) \exp\left(-j\frac{2\pi k}{Nt_{s}} t \right) dt
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(f(t)\)&lt;/span&gt;は周期&lt;span class="math"&gt;\(T\)&lt;/span&gt;で繰り返すので、積分範囲は 1 周期分とする（なぜ一周期か：フーリエ係数の仮定から。係数は 1 周期の積分で良い。三角関数の完全性を見よ）：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F[k] = \int^{T}_{0} f(t) \exp \left(-j \frac{2\pi k}{Nt_{s}} t \right)dt
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(t = nt_{s}\)&lt;/span&gt;と変数変換すると（&lt;span class="math"&gt;\(n\)&lt;/span&gt;を積分変数とする）、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F[k] = t_{s}\int^{N}_{0} f(nt_{s}) \exp \left(-j \frac{2\pi k}{N} n\right)dn
\end{equation*}
&lt;/div&gt;
&lt;p&gt;この積分は、次の和で近似できる。&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
F[k] \approx t_{s}\sum^{N-1}_{n=0} f(nt_{s}) \exp \left(-j \frac{2\pi k}{N} n\right) = t_{s} \sum^{N-1}_{n=0} f[n] \exp \left(-j \frac{2\pi nk}{N} \right)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;この式が離散フーリエ変換の式となる。逆変換については、複素フーリエ級数&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\left\{ \begin{array}{l}
f(nt_{s})  = \displaystyle \sum_{k=-\infty}^{\infty} c_{n} \exp(j\omega_{k}kn t) \\
c_{n} = \displaystyle \frac{1}{T} \int^{T}_{0} f(t) \exp(-j n\omega_{k} t) dt
\end{array} \right.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;から、&lt;span class="math"&gt;\(c_{n}\)&lt;/span&gt;を消去すると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{align*}
f(nt_{s}) = \sum_{k=-\infty}^{\infty} \left\{ \frac{1}{T} \int^{T}_{0} f(t) \exp\left( -j \frac{2\pi kt}{T} \right) dt \right\} \exp\left( \frac{j2\pi k}{T} nt_{s} \right) \\
f(nt_{s}) = \frac{\omega_{s}}{2 \pi N} \sum_{k=-\infty}^{\infty} F[k] \exp\left(j \frac{2\pi nk}{N} \right)
\end{align*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(F[k]\)&lt;/span&gt;の周期は&lt;span class="math"&gt;\(\omega_{s}\)&lt;/span&gt;なので、1 周期分は&lt;span class="math"&gt;\(k = 0,...,N-1\)&lt;/span&gt;となる。再び 1 周期分のみを考えると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
f[n] = \frac{\omega_{s}}{2 \pi N} \sum_{k=0}^{N-1} F[k] \exp\left(j \frac{2\pi nk}{N} \right)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;この式が離散フーリエ逆変換の式となる。変換の式をまとめると、&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\left\{ \begin{array}{l}
\displaystyle F[k] = t_{s} \sum^{N-1}_{n=0} f[n] \exp \left(-j \frac{2\pi nk}{N} \right) \\
\displaystyle f[n] = \frac{\omega_{s}}{2 \pi N} \sum_{k=0}^{N-1} F[k] \exp\left(j \frac{2\pi nk}{N} \right)
\end{array} \right.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;これがフーリエ変換対となり、一方に他方を代入するとちゃんと逆に戻る事が確認できる：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{split}
f[n] &amp;amp;= \frac{\omega_{s}}{2\pi N}\sum_{k=0}^{N-1}F[k]\exp\left(j\frac{2\pi nk}{N}\right) \\
&amp;amp;= \frac{2\pi t_{s}}{2\pi t_{s}N}\sum_{k=0}^{N-1}\left\{ \sum^{N-1}_{n^\prime=0} f[n^\prime] \exp \left(-j \frac{2\pi n^\prime k}{N} \right) \right\} \exp\left(j\frac{2\pi nk}{N}\right) \\
&amp;amp;= \frac{1}{N} \sum_{n^{\prime}=0}^{N-1} f[n^\prime] \sum_{k=0}^{N-1} \exp\left[ -j (n-n^\prime) \frac{2\pi k}{N} \right]
\end{split}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\sum_{k=0}^{N-1} \exp\left[ -j (n-n^\prime) \frac{2\pi k}{N} \right]\)&lt;/span&gt;の値ついては&lt;span class="math"&gt;\(k\)&lt;/span&gt;の積分&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\int^{N}_{0} \exp\left[ -j (n-n^\prime) \frac{2\pi k}{N} \right] dk
\end{equation*}
&lt;/div&gt;
&lt;p&gt;と考えれば、&lt;span class="math"&gt;\(n=n^\prime\)&lt;/span&gt;の時は明らかに&lt;span class="math"&gt;\(N\)&lt;/span&gt;であり、残りの&lt;span class="math"&gt;\(n \neq n^\prime\)&lt;/span&gt;の時は&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\begin{split}
\int^{N}_{0} \exp\left[ -j (n-n^\prime) \frac{2\pi k}{N} \right] dk
&amp;amp;= - \frac{1}{j(n-n^\prime)\frac{2\pi}{N}}
\left[ \exp\left[ -j(n-n^\prime)\frac{2\pi k}{N} \right] \right]_{0}^{N} \\
&amp;amp;= - \frac{1}{j(n-n^\prime)\frac{2\pi}{N}} \left\{ \exp[-j2(n-n^\prime)\pi] - \exp(0)\right\} \\
&amp;amp;= 0
\end{split}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;となるので、最終的に&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\frac{1}{N} \sum_{n^{\prime}=0}^{N-1} f[n^\prime] \sum_{k=0}^{N-1} \exp\left[ -j (n-n^\prime) \frac{2\pi k}{N} \right] = \frac{1}{N} f[n] N = f[n]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;を得る。
また&lt;span class="math"&gt;\(t_{s}=1\)&lt;/span&gt;とおくと、&lt;span class="math"&gt;\(\omega_{s} = 2\pi\)&lt;/span&gt;となって、DFT のよく見る変換式が得られる：&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\left\{ \begin{array}{l}
\displaystyle F[k] = \sum^{N-1}_{n=0} f[n] \exp \left(-j \frac{2\pi nk}{N} \right) \\
\displaystyle f[n] = \frac{1}{N} \sum_{k=0}^{N-1} F[k] \exp\left(j \frac{2\pi nk}{N} \right)
\end{array} \right.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;これらの式を実装するのは簡単である。じゃあ、実装しようか …（暗黒微笑）&lt;/p&gt;
&lt;p&gt;（デルタ関数から導く方法だと、どうしても正規化定数&lt;span class="math"&gt;\(1/N\)&lt;/span&gt;が出てこない。正規化定数は本質的では無いとかいうけど、計算上は無視できない。）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="記事"></category><category term="DFT"></category><category term="信号処理"></category></entry></feed>