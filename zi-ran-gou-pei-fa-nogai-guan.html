<!DOCTYPE html>
<html lang="ja" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>自然勾配法の概観 - Aiki's Blog</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">



<link rel="canonical" href="/zi-ran-gou-pei-fa-nogai-guan.html">

        <meta name="author" content="aiki" />
        <meta name="keywords" content="機械学習,情報幾何" />
        <meta name="description" content="自然勾配法の概略。だいたい Fisher Information Matrix と Natural Gradient Descent から持ってきている。" />

        <meta property="og:site_name" content="Aiki's Blog" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="自然勾配法の概観"/>
        <meta property="og:url" content="/zi-ran-gou-pei-fa-nogai-guan.html"/>
        <meta property="og:description" content="自然勾配法の概略。だいたい Fisher Information Matrix と Natural Gradient Descent から持ってきている。"/>
        <meta property="article:published_time" content="2020-05-23" />
            <meta property="article:section" content="記事" />
            <meta property="article:tag" content="機械学習" />
            <meta property="article:tag" content="情報幾何" />
            <meta property="article:author" content="aiki" />



    <!-- Bootstrap -->
        <link rel="stylesheet" href="/theme/css/bootstrap.min.css" type="text/css"/>
    <link href="/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="/theme/css/pygments/native.css" rel="stylesheet">
    <link href="/theme/tipuesearch/tipuesearch.css" rel="stylesheet">
    <link rel="stylesheet" href="/theme/css/style.css" type="text/css"/>

        <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Aiki's Blog ATOM Feed"/>

        <link href="/feeds/ji-shi.atom.xml" type="application/atom+xml" rel="alternate"
              title="Aiki's Blog 記事 ATOM Feed"/>
</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="/" class="navbar-brand">
Aiki's Blog            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                        <li class="active">
                            <a href="/category/ji-shi.html">記事</a>
                        </li>
                        <li >
                            <a href="/category/shi-yan.html">実験</a>
                        </li>
                        <li >
                            <a href="/category/za-ji.html">雑記</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
              <li><span>
                <form class="navbar-search" action="/search.html">
                  <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input" required>
                </form></span>
              </li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<!-- Banner -->
<!-- End Banner -->

<!-- Content Container -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="/zi-ran-gou-pei-fa-nogai-guan.html"
                       rel="bookmark"
                       title="Permalink to 自然勾配法の概観">
                        自然勾配法の概観
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2020-05-23T11:40:00+09:00"> Sat 23 May 2020</time>
    </span>





<span class="label label-default">Tags</span>
	<a href="/tag/ji-jie-xue-xi.html">機械学習</a>
        /
	<a href="/tag/qing-bao-ji-he.html">情報幾何</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <div class="math">
\begin{equation*}
\newcommand\innerp[2]{\langle #1, #2 \rangle}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\parfrac[2]{\frac{\partial #1}{\partial #2}}
\newcommand\mean[2]{\mathrm{E}_{#1} \left[ #2 \right]}
\newcommand\KL[2]{\mathrm{KL} \left[ #1 \ \middle| \middle| \ #2 \right]}
\end{equation*}
</div>
<p>自然勾配法の概略。だいたい <a class="reference external" href="https://wiseodd.github.io/techblog/2018/03/11/fisher-information/">Fisher Information Matrix</a> と <a class="reference external" href="https://wiseodd.github.io/techblog/2018/03/14/natural-gradient/">Natural Gradient Descent</a> から持ってきている。</p>
<p>パラメタベクトル <span class="math">\(\ve{\theta}\)</span> を持つ確率密度関数 <span class="math">\(p(\ve{x}|\ve{\theta})\)</span> を考える。対数尤度関数 <span class="math">\(\log p(\ve{x}|\ve{\theta})\)</span> の <span class="math">\(\ve{\theta}\)</span> におけるへッシアン <span class="math">\(\ve{H}_{\ve{\theta}}\)</span> は、</p>
<div class="math">
\begin{align*}
\ve{H}_{\ve{\theta}} \log p(\ve{x} | \ve{\theta}) &amp;= \left(\parfrac{}{\ve{\theta}} \right) \left(\parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \log p(\ve{x} | \ve{\theta}) \\
&amp;= \left(\parfrac{}{\ve{\theta}} \right) \frac{\left(\parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})} \\
&amp;= \frac{\left\{ \left(\parfrac{}{\ve{\theta}} \right) \left(\parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} p(\ve{x} | \ve{\theta}) \right\} p(\ve{x} | \ve{\theta}) - \left(\parfrac{}{\ve{\theta}} \right) p(\ve{x} | \ve{\theta}) \left(\parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} p(\ve{x} | \ve{\theta}) }{p(\ve{x} | \ve{\theta})^{2}} \\
&amp;= \frac{\ve{H}_{\ve{\theta}} p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})} - \left\{ \frac{\left(\parfrac{}{\ve{\theta}} \right) p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})} \right\} \left\{ \frac{\left(\parfrac{}{\ve{\theta}} \right) p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})} \right\}^{\mathsf{T}} \\
&amp;= \frac{\ve{H}_{\ve{\theta}} p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})} - \left( \parfrac{}{\ve{\theta}} \log p(\ve{x} | \ve{\theta}) \right) \left( \parfrac{}{\ve{\theta}} \log p(\ve{x} | \ve{\theta}) \right)^{\mathsf{T}}
\end{align*}
</div>
<p>両辺分布 <span class="math">\(p(\ve{x}|\ve{\theta})\)</span> について平均をとる。このとき右辺第二項はスコア関数の分散になりフィッシャー情報行列 <span class="math">\(\ve{F}\)</span> そのものになることに注意すると、</p>
<div class="math">
\begin{align*}
\mean{p(\ve{x}|\ve{\theta})}{\ve{H}_{\ve{\theta}} \log p(\ve{x} | \ve{\theta})} &amp;= \mean{p(\ve{x}|\ve{\theta})}{\frac{\ve{H}_{\ve{\theta}} p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})}} - \mean{p(\ve{x}|\ve{\theta})}{\left( \parfrac{}{\ve{\theta}} \log p(\ve{x} | \ve{\theta}) \right) \left( \parfrac{}{\ve{\theta}} \log p(\ve{x} | \ve{\theta}) \right)^{\mathsf{T}}} \\
&amp;= \mean{p(\ve{x}|\ve{\theta})}{\frac{\ve{H}_{\ve{\theta}} p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})}} - \ve{F} \\
&amp;= \int p(\ve{x}|\ve{\theta}) \frac{\ve{H}_{\ve{\theta}} p(\ve{x} | \ve{\theta})}{p(\ve{x} | \ve{\theta})} \mathrm{d}\ve{x} - \ve{F} = \int \ve{H}_{\ve{\theta}} p(\ve{x} | \ve{\theta}) \mathrm{d}\ve{x} - \ve{F} \\
&amp;= \ve{H}_{\ve{\theta}} \int p(\ve{x} | \ve{\theta}) \mathrm{d}\ve{x} - \ve{F} \quad(\because \text{ 微分と積分の入れ替えを可能（正則条件）とする }) \\
&amp;= \ve{H}_{\ve{\theta}} 1 - \ve{F} \\
&amp;= - \ve{F}
\end{align*}
</div>
<p>従って、 <strong>対数尤度関数のへッシアンの平均に負号をつけるとフィッシャー情報行列に一致する。</strong></p>
<p>つぎに、異なるパラメタ <span class="math">\(\ve{\theta}, \ve{\theta}^{\prime}\)</span> をもつ確率分布 <span class="math">\(p(\ve{x}|\ve{\theta}), p(\ve{x}|\ve{\theta}^{\prime})\)</span> 間の違いを測るダイバージェンスとして KL ダイバージェンスを使ったとき、</p>
<div class="math">
\begin{align*}
\KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta}^{\prime})} &amp;= \int p(\ve{x}|\ve{\theta}) \log \left( \frac{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta}^{\prime})} \right) \mathrm{d}\ve{x} \\
&amp;= \mean{p(\ve{x}|\ve{\theta})}{\log p(\ve{x}|\ve{\theta})} - \mean{p(\ve{x}|\ve{\theta})}{\log p(\ve{x}|\ve{\theta}^{\prime})}
\end{align*}
</div>
<p>となる。 <span class="math">\(\ve{\theta}\)</span> を固定し、パラメタ <span class="math">\(\ve{\theta}^{\prime}\)</span> に関するへッシアン <span class="math">\(\ve{H}_{\ve{\theta}^{\prime}}\)</span> を求めると、</p>
<div class="math">
\begin{align*}
\ve{H}_{\ve{\theta}^{\prime}} \KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta}^{\prime})} &amp;= \left( \parfrac{}{\ve{\theta}^{\prime}} \right) \left( \parfrac{}{\ve{\theta}^{\prime}} \right)^{\mathsf{T}} \KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta}^{\prime})} \\
&amp;= \left( \parfrac{}{\ve{\theta}^{\prime}} \right) \left\{ \left( \parfrac{}{\ve{\theta}^{\prime}} \right)^{\mathsf{T}} \mean{p(\ve{x}|\ve{\theta})}{\log p(\ve{x}|\ve{\theta})} - \left( \parfrac{}{\ve{\theta}^{\prime}} \right)^{\mathsf{T}} \mean{p(\ve{x}|\ve{\theta})}{\log p(\ve{x}|\ve{\theta}^{\prime})}\right\} \\
&amp;= - \left( \parfrac{}{\ve{\theta}^{\prime}} \right) \mean{p(\ve{x}|\ve{\theta})}{\left( \parfrac{}{\ve{\theta}^{\prime}} \right)^{\mathsf{T}} \log p(\ve{x}|\ve{\theta}^{\prime})} = - \mean{p(\ve{x}|\ve{\theta})}{\left( \parfrac{}{\ve{\theta}^{\prime}} \right)\left( \parfrac{}{\ve{\theta}^{\prime}} \right)^{\mathsf{T}} \log p(\ve{x}|\ve{\theta}^{\prime})} \\
&amp;= -\mean{p(\ve{x}|\ve{\theta})}{\ve{H}_{\ve{\theta}^{\prime}} \log p(\ve{x}|\ve{\theta}^{\prime})}
\end{align*}
</div>
<p>ここで <span class="math">\(\ve{\theta}^{\prime} \to \ve{\theta}\)</span> と近づけていくと、最後の式はフィッシャー情報行列 <span class="math">\(\ve{F}\)</span> にいくらでも近づく。よって、</p>
<div class="math">
\begin{equation*}
\lim_{\ve{\theta}^{\prime} \to \ve{\theta}} \ve{H}_{\ve{\theta}^{\prime}} \KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta}^{\prime})} = \ve{F}
\end{equation*}
</div>
<p>次に、 <span class="math">\(\ve{\theta}\)</span> 近傍での対数尤度関数の挙動を見ていく。 <span class="math">\(\ve{h}\)</span> を微小なベクトルとして、 <span class="math">\(\log p(\ve{x}|\ve{\theta} + \ve{h})\)</span> を 2 次の項までテイラー展開すると、</p>
<div class="math">
\begin{align*}
\log p(\ve{x}|\ve{\theta} + \ve{h}) &amp;\approx \log p(\ve{x} | \ve{\theta}) + \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \log p(\ve{x} | \ve{\theta})  \ve{h} + \frac{1}{2} \ve{h}^{\mathsf{T}} \left( \parfrac{}{\ve{\theta}} \right) \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \log p(\ve{x} | \ve{\theta}) \ve{h} \\
\Rightarrow \log p(\ve{x}|\ve{\theta} + \ve{h}) - \log p(\ve{x} | \ve{\theta}) &amp;\approx \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \log p(\ve{x} | \ve{\theta})  \ve{h} + \frac{1}{2} \ve{h}^{\mathsf{T}} \left( \parfrac{}{\ve{\theta}} \right) \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \log p(\ve{x} | \ve{\theta}) \ve{h} \\
&amp;= \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \log p(\ve{x} | \ve{\theta}) \ve{h} + \frac{1}{2} \ve{h}^{\mathsf{T}} \ve{H}_{\ve{\theta}} \log p(\ve{x} | \ve{\theta}) \ve{h}
\end{align*}
</div>
<p>両辺 <span class="math">\(p(\ve{x}|\ve{\theta})\)</span> について平均をとると、</p>
<div class="math">
\begin{align*}
\mean{p(\ve{x}|\ve{\theta})}{\log p(\ve{x}|\ve{\theta} + \ve{h}) - \log p(\ve{x} | \ve{\theta})} &amp;= \mean{p(\ve{x}|\ve{\theta})}{\log\left( \frac{p(\ve{x}|\ve{\theta} + \ve{h})}{p(\ve{x} | \ve{\theta})} \right)} \\
&amp;= \int p(\ve{x}|\ve{\theta}) \log\left[ \frac{p(\ve{x}|\ve{\theta} + \ve{h})}{p(\ve{x} | \ve{\theta})} \right] \mathrm{d}\ve{x} = -\int p(\ve{x}|\ve{\theta}) \log\left[ \frac{p(\ve{x} | \ve{\theta})}{p(\ve{x}|\ve{\theta} + \ve{h})} \right] \mathrm{d}\ve{x} \\
&amp;= -\KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta} + \ve{h})} \\
\mean{p(\ve{x}|\ve{\theta})}{\left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \log p(\ve{x} | \ve{\theta}) \ve{h}} &amp;= \int p(\ve{x}|\ve{\theta}) \frac{\left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta})} \mathrm{d}\ve{x}\ \ve{h} \\
&amp;= \int \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} p(\ve{x}|\ve{\theta}) \mathrm{d}\ve{x}\  \ve{h} = \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} \int p(\ve{x}|\ve{\theta}) \mathrm{d}\ve{x}\  \ve{h} \quad (\because \text{ 正則条件 }) \\
&amp;= \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} 1 \ve{h} \\
&amp;= 0 \\
\mean{p(\ve{x}|\ve{\theta})}{\frac{1}{2} \ve{h}^{\mathsf{T}} \ve{H}_{\ve{\theta}} \log p(\ve{x} | \ve{\theta}) \ve{h}} &amp;= \frac{1}{2} \ve{h}^{\mathsf{T}} \mean{p(\ve{x}|\ve{\theta})}{\ve{H}_{\ve{\theta}} \log p(\ve{x} | \ve{\theta})} \ve{h} \\
&amp;= -\frac{1}{2} \ve{h}^{\mathsf{T}} \ve{F} \ve{h}
\end{align*}
</div>
<p>よって、</p>
<div class="math">
\begin{equation*}
\KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta} + \ve{h})} \approx \frac{1}{2} \ve{h}^{\mathsf{T}} \ve{F} \ve{h}
\end{equation*}
</div>
<p><span class="math">\(\ve{\theta}\)</span> の近傍においてはフィッシャー情報行列が支配的になっていることがわかる。また、これにより確率分布のなす多様体のリーマン計量はフィッシャー情報行列であることがわかり、ここから情報幾何学が始まっていく。</p>
<p>以上の議論を基に、確率分布間の違いを KL ダイバージェンスで測ったとき、損失関数 <span class="math">\(l(\ve{\theta})\)</span> を最も減らす方向を考える。それは次の方向 <span class="math">\(\ve{h}^{\ast}\)</span> を見つけることに等しい：</p>
<div class="math">
\begin{equation*}
\ve{h}^{\ast} = \underset{\ve{h}\ \mathrm{s.t.} \KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta} + \ve{h})} = c}{\mathrm{argmin}} l(\ve{\theta} + \ve{h})
\end{equation*}
</div>
<p>式の気持ちとしては、「KL ダイバージェンスが定数 <span class="math">\(c\)</span> を取る中で、最も <span class="math">\(l(\ve{\theta})\)</span> を減らすベクトル <span class="math">\(\ve{h}\)</span> 」 である。これは制約付き最適化問題だから、ラグランジェの未定定数法により解くことを考える。ラグランジアン <span class="math">\(\mathcal{L}\)</span> は、</p>
<div class="math">
\begin{align*}
\mathcal{L} &amp;= l(\ve{\theta} + \ve{h}) + \lambda \left\{ \KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta} + \ve{h})} - c \right\} \\
&amp;\approx l(\ve{\theta}) + \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} l(\ve{\theta}) \ve{h} + \lambda \left\{ \KL{p(\ve{x}|\ve{\theta})}{p(\ve{x}|\ve{\theta} + \ve{h})} - c \right\} \quad \text{（1 次の項までテイラー展開）} \\
&amp;\approx l(\ve{\theta}) + \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} l(\ve{\theta}) \ve{h} + \lambda \left\{ \frac{1}{2} \ve{h}^{\mathsf{T}} \ve{F} \ve{h} - c \right\}
\end{align*}
</div>
<p><span class="math">\(\mathcal{L}\)</span> を <span class="math">\(\ve{h}\)</span> で偏微分すると、</p>
<div class="math">
\begin{align*}
\parfrac{}{\ve{h}} \mathcal{L} &amp;\approx \parfrac{}{\ve{h}} l(\ve{\theta}) + \parfrac{}{\ve{h}} \left( \parfrac{}{\ve{\theta}} \right)^{\mathsf{T}} l(\ve{\theta}) \ve{h} + \lambda  \left\{ \parfrac{}{\ve{h}} \frac{1}{2} \ve{h}^{\mathsf{T}} \ve{F} \ve{h} - \parfrac{}{\ve{h}} c \right\} \\
&amp;= \parfrac{}{\ve{\theta}} l(\ve{\theta}) + \lambda \ve{F} \ve{h}
\end{align*}
</div>
<p><span class="math">\(\parfrac{}{\ve{h}} \mathcal{L} = \ve{0}\)</span> とおいて <span class="math">\(\ve{h}\)</span> について解くと、</p>
<div class="math">
\begin{equation*}
\ve{h}^{\ast} = - \frac{1}{\lambda} \ve{F}^{-1} \parfrac{}{\ve{\theta}} l(\ve{\theta})
\end{equation*}
</div>
<p>が得られる。 <span class="math">\(\lambda\)</span> はスカラーだからベクトルの方向を変えない。よって、 <span class="math">\(\ve{F}^{-1} \parfrac{}{\ve{\theta}} l(\ve{\theta})\)</span> が最急勾配であることが分かる。この勾配を <strong>自然勾配 (Natural Gradient)</strong> という。</p>
<div class="section" id="id2">
<h2>ニュートン法と何が違うのか？</h2>
<p>「 <a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.8668&amp;rep=rep1&amp;type=pdf">Adaptive Method of Realizing Natural Gradient Learning for Multilayer Perceptrons</a> 」によると、
ニュートン法は教師信号を明示的に含んだ損失関数のへッシアンを使うが、自然勾配法は近似対象の標的関数とは独立した確率分布の空間 S の計量を使っているところが違うらしい。しかし一方で、対数尤度を損失関数、かつモデルが最適パラメタによって生成された教師信号 y を生成するときはフィッシャー情報行列はヘッセ行列に一致する。このため、最適点において自然勾配法はニュートン法に一致する。とある。</p>
<p>自分なりの解釈として線形回帰問題を考える。
誤差が ◯◯ 分布に従って発生すると考えた瞬間に確率分布の空間が定まり、この空間の計量たるフィッシャー情報行列に従って学習するのが自然勾配学習法。一方、各点の損失関数のヘッセ行列（2 階微分）を求めて最適化を進めるのがニュートン法。でいいのか？
恐らく、各点の損失関数を計算できるのならばニュートン法の方が優れている。</p>
<p>発想としても差異があって、ニュートン法は損失関数の 2 次のテイラー展開から最適な勾配を求めるのに対し、自然勾配法は KL ダイバージェンスが一定という制約のもとで最適な勾配を求めている（自然勾配法を導出するとき、損失関数の 1 次の項までしかテイラー展開していないのがミソ。2 次まで展開すると損失関数のへッシアンが出てきてニュートン法と変わらない）。</p>
</div>
<script type='text/javascript'>if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            </div>
            <!-- /.entry-content -->
<section class="well" id="related-posts">
    <h4>Related Posts:</h4>
    <ul>
        <li><a href="/paseputoronxi-hua.html">パーセプトロン昔話</a></li>
        <li><a href="/zui-da-entoropimoderu.html">最大エントロピーモデル</a></li>
        <li><a href="/svmsapotobekutorumashin.html">SVM（サポートベクトルマシン）</a></li>
    </ul>
</section>
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://github.com/aikiriao/"><i class="fa fa-github-square fa-lg"></i> GitHub</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->

<!-- Sidebar/Tag Cloud -->
<li class="list-group-item">
  <a href="/"><h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Tags</span></h4></a>
  <ul class="list-group " id="tags">
    <li class="list-group-item tag-0">
      <a href="/tag/lms.html">LMS</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="/tag/empirical-fisher.html">Empirical Fisher</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="/tag/signedlms.html">SignedLMS</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="/tag/natural-gradient.html">Natural Gradient</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/irls.html">IRLS</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/l1norumu.html">L1ノルム</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/rls.html">RLS</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/regularization.html">Regularization</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/lad.html">LAD</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/ji-jie-xue-xi.html">機械学習</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/lossless-audio.html">Lossless Audio</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/hessian.html">Hessian</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/xin-hao-chu-li.html">信号処理</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/rosuresuyin-sheng.html">ロスレス音声</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/manifold.html">Manifold</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/sla.html">SLA</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/signed-lms.html">Signed LMS</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/lms-algorithm.html">LMS Algorithm</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/poemu.html">ポエム</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/githubio.html">githubio</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/pelican.html">pelican</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/supasufu-hao-hua.html">スパース符号化</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/fisher-information-matrix.html">Fisher Information Matrix</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/qing-bao-ji-he.html">情報幾何</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/hetsusexing-lie.html">ヘッセ行列</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/test.html">test</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/fuzzy-clustering.html">Fuzzy Clustering</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/dft.html">DFT</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/ji-chu.html">基礎</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/jupyter.html">Jupyter</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/gu-shi-ji.html">古事記</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/information-geometry.html">Information Geometry</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/tong-ji.html">統計</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/sse.html">SSE</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/lpc.html">LPC</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Tag Cloud -->

<!-- Sidebar/Links -->
<li class="list-group-item">
  <h4><i class="fa fa-external-link-square fa-lg"></i><span class="icon-label">Links</span></h4>
  <ul class="list-group" id="links">
    <li class="list-group-item">
      <a href="http://getpelican.com/" target="_blank">Pelican</a>
    </li>
    <li class="list-group-item">
      <a href="http://python.org/" target="_blank">Python.org</a>
    </li>
    <li class="list-group-item">
      <a href="http://jinja.pocoo.org/" target="_blank">Jinja2</a>
    </li>
    <li class="list-group-item">
      <a href="https://policies.google.com/technologies/partner-sites" target="_blank">Google Analytics</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Links -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<!-- End Content Container -->

<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2020 aiki
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>              <p><small>Unless otherwise stated, all articles are published under the <a href="http://www.wtfpl.net/about/">WTFPL</a> license. ブログ記述は誤りを含むのでご注意ください。</small></p>
         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="/theme/js/respond.min.js"></script>


    <!-- Google Analytics -->
    <script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-169927697-1']);
        _gaq.push(['_trackPageview']);

        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script>
    <!-- End Google Analytics Code -->


</body>
</html>