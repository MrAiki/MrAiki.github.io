var tipuesearch = {"pages":[{"title":"最大エントロピーモデル","text":"（Q****にマジギレして移行） 最大エントロピーモデルの導出過程、学習の更新則、素性選択についての理論的側面を述べる。記述の大部分は 1 を参照し、一部 2 3 も参照している。 最大エントロピーモデルは、データの特徴を 素性関数(feature function) によって記述し、素性関数がある 制約(constraint) を満たし、かつ、モデルを表現する確率分布のエントロピーが最大となる（最大エントロピー原理を満たす）モデルである。 エントロピーを最大にする事により、制約を満たしながら最大エントロピーモデルの確率分布が最も一様に分布する様になり、未知データに対する確率を無下に \\(0\\) にすることが無くなるため、高い汎用性（汎化性能）が期待できる。 モデルを表現する確率分布の導出 まず、サンプル（事例）データのドメイン（定義域）を \\(X\\) 、データに付与されたラベルのドメインを \\(Y\\) と書く。例えば、次に来る単語を予測させたい場合には、サンプル \\(X\\) は1つ前までの単語の並び、ラベル \\(Y\\) は今の単語となる。 データとラベルを組にすることで1つの学習サンプルが構成され、また、モデルに与える \\(m\\) 個の学習サンプルの集合 \\(Z_{m} \\subset 2&#94;{X\\times Y}\\) を次で表す: $$ Z_{m} = \\{ (x_{1}, y_{1}), (x_{2}, y_{2}), \\dots, (x_{m}, y_{m}) \\} $$ このようなサンプルに対し、 素性関数（素性） の集合 \\({\\cal F}\\) は次で定義される: $$ {\\cal F} = \\{ f_{i} : X \\times Y \\to \\{0,1\\}, i \\in \\{1,2,\\dots,n\\} \\} $$ 即ち \\({\\cal F}\\) は、データとラベルの組 \\((x,y) \\in X \\times Y\\) を受け取って \\(\\{0,1\\}\\) いずれかを返す関数の集合である。ここでは \\(f\\) の値域は議論の簡略化のため \\(\\{0,1\\}\\) としたが、値域は \\(\\{0,\\alpha\\} (\\alpha > 0)\\) 、即ち \\(0\\) と \\(0\\) 以外の正数実数を取るようにもできる。また、素性が条件を満たし正の値を取る時は、素性が活性化しているという。 素性の例を挙げると、 \\(n\\) 個の単語列 \\(w_{1},\\dots,w_{n}\\) から、直前の \\(N-1\\) 個の単語列 \\(w_{n-N+1},\\dots,w_{n-1}\\) のみを用いて今の単語 \\(w_{n}\\) を予測する（ \\(N\\) -グラムの）場合は、素性は次の様に表現出来る。 $$ \\begin{align} f_{x_{1}x_{2}\\dots x_{N}}(w_{1},\\dots,w_{n-1},w_{n}) = \\left\\{ \\begin{array}{ll} 1 & w_{n-N+1} = x_{1}, w_{n-N+2} = x_{2}, \\dots, w_{n-1} = x_{N-1}, w_{n} = x_{N} \\\\ 0 & {\\rm otherwise} \\end{array} \\right. \\end{align} $$ ここで \\(f\\) のインデックス \\(x_{1}\\dots x_{N}\\) は整数との対応を適当に取ることで、容易に実現できる。 最大エントロピーモデルの制約として与えられる条件は、素性の平均（期待値）が、モデルと経験確率で一致することである。この条件を数式で表現する事を考える。 定義域 \\(X\\times Y\\) 上に定義されるモデルの確率分布を \\(P(x,y)\\) と書き、経験確率分布を \\(\\tilde{P}(x,y)\\) と書く。ここで経験確率分布 \\(\\tilde{P}\\) は、頻度確率で与える。即ち、学習サンプルに現れた \\((x,y)\\) の組の回数を \\(C(x,y)\\) と書くと、 $$ \\tilde{P}(x,y) = \\frac{C(x,y)}{m} $$ と表せる。モデルの確率分布は後で導出する。 ある素性 \\(f_{i}\\) の分布 \\(p\\) による平均を \\(E_{p}[f_{i}]\\) と書くと、経験分布とモデルの確率分布のそれぞれの平均は $$ \\begin{align} E_{\\tilde{P}}[f_{i}] &= \\sum_{x,y} \\tilde{P}(x,y) f_{i}(x,y) \\\\ E_{P}[f_{i}] &= \\sum_{x,y} P(x,y) f_{i}(x,y) \\end{align} $$ と表せられ、従って制約を数式で表現すると, $$ \\begin{align} E_{\\tilde{P}}[f_{i}] &= E_{P}[f_{i}] \\ \\ (i=1,\\dots,n) \\\\ \\iff \\sum_{x,y} \\tilde{P}(x,y) f_{i}(x,y) &= \\sum_{x,y} P(x,y) f_{i}(x,y) \\ \\ (i=1,\\dots,n) \\end{align} $$ となる。最大エントロピーモデルの候補となる集合 \\({\\cal P}\\) は、全ての素性に関する制約を満たすモデルの集合となる: $$ {\\cal P} = \\{ P | E_{P}[f_{i}] = E_{\\tilde{P}}[f_{i}], i = \\{1,\\dots,n\\} \\} $$ 明らかに、2つのモデル \\(P,P&#94;{\\prime} \\in {\\cal P}\\) に対して、 \\(E_{P}[f_{i}] = E_{\\tilde{P}}[f_{i}] = E_{P&#94;{\\prime}}[f_{i}]\\ \\ (i=1,\\dots,n)\\) （候補となるモデルの素性の平均は同一）となる。 更に考慮すべき点は、最大エントロピーモデルの名の通り、モデル（確率分布 \\(P\\) ）のエントロピーを最大にする必要がある。モデルのエントロピーを \\(H(P)\\) と書くと、確率分布のエントロピーの式から, $$ H(P) = -\\sum_{x,y}P(x,y) \\log P(x,y) $$ と表現できる。集合 \\({\\cal P}\\) の中で最もエントロピーが高いものが得るべきモデル \\(P&#94;{\\ast}\\) である: $$ P&#94;{\\ast} = \\underset{P \\in {\\cal P}}{\\rm argmax}\\ H(P) $$ この式を 最大エントロピー原理(maximum entropy principle) と呼ぶ。集合 \\({\\cal P}\\) は無限集合だが最大エントロピー原理を満たすモデルは解析的に求められ、かつ一意に存在する（後術）。 最大エントロピー原理を満たすモデルの確率分布 \\(P\\) を求める事を考える。これは制約付き非線形最適化問題であることから、ラグランジェの未定定数法が適用できる。 \\(P\\) が満たすべき制約を列挙すると $$ \\begin{align} 1:& \\quad E_{P}[f_{i}] = E_{\\tilde{P}}[f_{i}] \\ \\ (i=1,\\dots,n) \\\\ 2:& \\quad P(x,y) \\geq 0 \\\\ 3:& \\quad \\sum_{x,y}P(x,y) = 1 \\end{align} $$ であり（2,3は \\(P\\) が確率分布となる為の条件）、 \\(n\\) 個の制約に対応する未定定数を \\(\\Lambda = \\{\\lambda_{1},\\dots,\\lambda_{n}\\}\\) と書くと、ラグランジアン（ラグランジュ関数） \\({\\cal L}(P,\\Lambda)\\) は $$ \\begin{align} {\\cal L}(P, \\Lambda) &= H(P) + \\sum_{i=1}&#94;{n} \\lambda_{i} (E_{P}[f_{i}] - E_{\\tilde{P}}[f_{i}]) \\\\ &= -\\sum_{x,y}P(x,y)\\log P(x,y) + \\sum_{i=1}&#94;{n} \\lambda_{i} \\left\\{ \\sum_{x,y} P(x,y) f_{i}(x,y) - \\sum_{x,y} \\tilde{P}(x,y) f_{i}(x,y) \\right\\} \\end{align} $$ と書ける。最大値を得るため、 \\(P(x,y)\\) によって偏微分すると, $$ \\frac{\\partial {\\cal L}(P,\\Lambda)}{\\partial P(x,y)} = -\\log P(x,y) - 1 + \\sum_{i=1}&#94;{n} \\lambda_{i} f_{i}(x,y) $$ この式を \\(0\\) とおいて \\(P(x,y)\\) について解くと $$ P(x,y) = \\exp \\left[ -1 + \\sum_{i=1}&#94;{n} \\lambda_{i} f_{i}(x,y) \\right] $$ を得る。確率分布が指数関数で表現される為条件2の非負条件は満たされるが、条件3の全確率が1になることが保証されていない。そこで \\(\\sum_{x,y}P(x,y) = Z_{\\Lambda}\\) なる正規化項(normalization factor)を導入し \\(P(x,y)\\) の \\(x,y\\) についての総和が1になるようにする。従ってモデルの確率分布は次で表される: $$ \\begin{align} P(x,y) &= \\frac{ \\exp \\left[ -1 + \\sum_{i=1}&#94;{n} \\lambda_{i} f_{i}(x,y) \\right] }{ \\sum_{x,y} \\exp \\left[ -1 + \\sum_{i=1}&#94;{n} \\lambda_{i} f_{i}(x,y) \\right] } \\\\ &= \\frac{1}{Z_{\\Lambda}} \\exp \\left[ \\sum_{i} \\lambda_{i} f_{i}(x,y) \\right] \\\\ Z_{\\Lambda} &= \\sum_{x,y} \\exp \\left[ \\sum_{i} \\lambda_{i} f_{i}(x,y) \\right] \\end{align} $$ （以下、 \\(\\sum_{i=1}&#94;{n} \\equiv \\sum_{i}\\) とする）得られた確率分布はMRF(Markov Random Fields、マルコフ確率場)のクリークサイズを1とした時、即ち節点ポテンシャル（連想ポテンシャル）のみを考えた結合確率に一致する。従って最大エントロピーモデルはMRFのサブクラスとして捉えられる。 最大のエントロピー原理の性質と最尤推定 最大エントロピー原理を満たすモデルは上述の議論で求められたが、このモデルが唯一に定まる事を示す。まず、上述の議論で得られた確率分布を持つモデルの集合を \\({\\cal Q}\\) と書く: $$ {\\cal Q} = \\left\\{ P \\left| P(x,y) = \\frac{1}{Z_{\\Lambda}} \\exp\\left[ \\sum_{i} \\lambda_{i}f_{i}(x,y) \\right] \\right. \\right\\} $$ 集合 \\({\\cal Q}\\) の要素に制約は陽に表れていない。そして、 \\({\\cal P,Q}\\) と最大エントロピー原理について次の定理が成り立つ: 最大エントロピーモデルの唯一存在性 \\(P&#94;{\\ast} \\in {\\cal P} \\cap {\\cal Q}\\) ならば, $$ P&#94;{\\ast} = \\underset{P \\in {\\cal P}}{\\rm argmax} \\ H(P) $$ が成り立ち、かつ \\(P&#94;{\\ast}\\) は唯一に定まる。 （証明）まず補助定理として、 \\(R, S \\in {\\cal P}, T \\in {\\cal Q}\\) ならば, $$ \\sum_{x,y} R(x,y) \\log T(x,y) = \\sum_{x,y} S(x,y) \\log T(x,y) $$ を示す。 \\(T \\in {\\cal Q}\\) より \\(T(x,y) = \\displaystyle\\frac{1}{Z_{\\Lambda}} \\exp\\left[ \\sum_{i} \\lambda_{i} f_{i}(x,y) \\right]\\) と表せるので、 $$ \\begin{align} （左辺） &= \\sum_{x,y} R(x,y) \\left[ \\sum_{i} \\lambda_{i} f_{i}(x,y) - \\log Z_{\\Lambda} \\right] = \\sum_{i} \\lambda_{i} \\sum_{x,y} R(x,y) f_{i}(x,y) - \\log Z_{\\Lambda} \\sum_{x,y}R(x,y) \\\\ &= \\sum_{i} \\lambda_{i} E_{R}[f_{i}] - \\log Z_{\\Lambda} \\\\ &= \\sum_{i} \\lambda_{i} E_{S}[f_{i}] - \\log Z_{\\Lambda} \\ \\ (\\because E_{R}[f_{i}] = E_{\\tilde{P}}[f_{i}] = E_{S}[f_{i}]） \\\\ &= \\sum_{x,y} S(x,y) \\left[\\sum_{i} \\lambda_{i} f_{i}(x,y) \\right] - \\sum_{x,y} S(x,y) \\log Z_{\\Lambda} \\\\ &= \\sum_{x,y} S(x,y) \\log T(x,y) = （右辺） \\end{align} $$ 補助定理を用いて、定理の証明を行う。 \\(P \\in {\\cal P}, P&#94;{\\ast} \\in {\\cal P} \\cap {\\cal Q}\\) とすると, $$ \\begin{align} H(P&#94;{\\ast}) - H(P) &= -\\sum_{x,y} P&#94;{\\ast}(x,y) \\log P&#94;{\\ast}(x,y) + \\sum_{x,y} P(x,y) \\log P(x,y) \\\\ &= -\\sum_{x,y} P(x,y) \\log P&#94;{\\ast}(x,y) + \\sum_{x,y} P(x,y) \\log P(x,y) \\ \\ （\\because 補助定理） \\\\ &= \\sum_{x,y} P(x,y) \\log \\left[ \\frac{P(x,y)}{P&#94;{\\ast}(x,y)} \\right] \\\\ &= {\\rm KL}(P || P&#94;{\\ast}) \\geq 0\\ \\ （{\\rm KL}:KLダイバージェンス） \\end{align} $$ よって \\(H(P&#94;{\\ast}) \\geq H(P)\\) が成立する。また \\(H(P&#94;{\\ast}) = H(P)\\) ならばKLダイバージェンスの性質により \\(P&#94;{\\ast} = P\\) となる。以上により、定理の成立が示された。 生成モデルの学習に関連して、最大エントロピー原理を満たすモデル \\(P&#94;{\\ast}\\) は、経験確率分布 \\(\\tilde{P}\\) が与えられた時に最大尤度を持つ事も示されている。モデルの尤度の式を導く事を考えると、まず経験確率分布 \\(\\tilde{P}\\) に対するモデル \\(P\\) の経験誤差はKLダイバージェンス \\({\\rm KL}(\\tilde{P} || P)\\) で与えられる 3 ので, $$ \\begin{align} {\\rm KL}(\\tilde{P} || P) &= \\sum_{x,y} \\tilde{P}(x,y) \\log \\left[ \\frac{\\tilde{P}(x,y)}{P(x,y)} \\right] \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\log \\tilde{P}(x,y) - \\sum_{x,y} \\tilde{P}(x,y) \\log P(x,y) \\end{align} $$ なる。大数の弱法則より、サンプル数の極限 \\(m\\to \\infty\\) を取ることにより経験確率分布は標的概念の確率分布に一致し、また経験誤差は汎化誤差に一致する。今 \\({\\rm KL}(\\tilde{P} || P) \\geq 0\\) であり、かつ、 \\(\\tilde{P}\\) は観測により固定されるので、経験誤差を最小にするには下段の式の第2項を最大化すれば良いことになる。そして、下段式の第2項は対数尤度（経験対数尤度）と呼ばれる。モデル \\(P\\) の対数尤度を \\(L(P)\\) と書くと、 $$ L(P) = \\sum_{x,y} \\tilde{P}(x,y) \\log P(x,y) $$ と表すことができる。尤度との関連として、最大エントロピー原理を満たすモデル \\(P&#94;{\\ast}\\) は次を満たす: 最大尤度を持つ最大エントロピーモデル \\(P&#94;{\\ast} \\in {\\cal P} \\cap {\\cal Q}\\) ならば、 $$ P&#94;{\\ast} = \\underset{Q \\in {\\cal Q}}{\\rm argmax} \\ L(Q) $$ が成り立ち、かつ \\(P&#94;{\\ast}\\) は唯一に定まる。 （証明）前の定理と同様の方針と、補助定理により, $$ \\begin{align} L(P&#94;{\\ast}) - L(P) &= \\sum_{x,y} \\tilde{P}(x,y) \\log P&#94;{\\ast}(x,y) - \\sum_{x,y} \\tilde{P}(x,y) \\log P(x,y) \\\\ &= \\sum_{x,y} P&#94;{\\ast}(x,y) \\log P&#94;{\\ast}(x,y) - \\sum_{x,y} P&#94;{\\ast}(x,y) \\log P(x,y) \\ \\ (\\because 反射性 E_{\\tilde{P}}[f_{i}] = E_{\\tilde{P}}[f_{i}]により、\\tilde{P} \\in {\\cal P}) \\\\ &= \\sum_{x,y} P&#94;{\\ast}(x,y) \\log \\left[ \\frac{P&#94;{\\ast}(x,y)}{P(x,y)} \\right] \\\\ &= {\\rm KL}(P&#94;{\\ast} || P) \\geq 0 \\end{align} $$ よって \\(L(P&#94;{\\ast}) \\geq L(P)\\) であり、再びKLダイバージェンスの性質により、 \\(L(P&#94;{\\ast}) = L(P)\\) ならば \\(P&#94;{\\ast} = P\\) が成り立つので唯一性も示される。従って定理の成立が示された。 定理1と2により、次の性質が成り立つ: $$ P&#94;{\\ast} = \\underset{P \\in {\\cal P}}{\\rm argmax} \\ H(P) = \\underset{Q \\in {\\cal Q}}{\\rm argmax} \\ L(Q) $$ 即ち、モデルの最大エントロピー原理は最尤推定の枠組みで捉える事もでき、尤度を最大化したモデルが最大のエントロピーを持つ。よって、モデルの学習には通常の生成モデルの学習と同じ様に、 \\({\\cal Q}\\) の要素で表現されるモデルの尤度最大化を考えれば良いことになる。 最大のエントロピーモデルの学習 - 反復スケーリング法 最尤推定法に基づく最大エントロピーモデルの学習は、モデルの尤度が最大になるようにモデル \\(P\\) のパラメタ \\(\\Lambda\\) を調節してやれば良い。単純なアプローチとしては、対数尤度 \\(L(P)\\) をパラメタ \\(\\Lambda=\\{\\lambda_{1},\\cdots,\\lambda_{n}\\}\\) で偏微分し、最急上昇法によって最大値を得る方法がある。実際に計算してみると, $$ \\begin{align} \\frac{\\partial L(P)}{\\partial \\lambda_{i}} &= \\sum_{x,y} \\tilde{P}(x,y) \\frac{\\partial}{\\partial \\lambda_{i}} \\log P(x,y) \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\frac{\\partial}{\\partial \\lambda_{i}} \\left[ \\sum_{j} \\lambda_{j} f_{j}(x,y) - \\log Z_{\\Lambda} \\right] \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\left[ f_{i}(x,y) - \\frac{1}{Z_{\\Lambda}} \\sum_{x&#94;{\\prime},y&#94;{\\prime}} f_{i}(x&#94;{\\prime},y&#94;{\\prime}) \\exp \\left( \\sum_{j} \\lambda_{j} f_{j}(x&#94;{\\prime},y&#94;{\\prime}) \\right) \\right] \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\left( f_{i}(x,y) - E_{P}[f_{i}] \\right) \\\\ &= E_{\\tilde{P}}[f_{i}] - E_{P}[f_{i}] \\end{align} $$ であり（最適時には制約が満たされることが分かる）、ステップ \\(t\\) におけるパラメタ \\(\\lambda_{i}&#94;{t}\\) の更新規則は次の様に得られる: $$ \\begin{align} \\lambda_{i}&#94;{t+1} &= \\lambda_{i}&#94;{t} + \\eta \\frac{\\partial L(P)}{\\partial \\lambda_{i}&#94;{t}} \\\\ &= \\lambda_{i}&#94;{t} + \\eta ( E_{\\tilde{P}}[f_{i}] - E_{P}[f_{i}] ) \\end{align} $$ ここで \\(\\eta\\) は収束の早さを決める学習率(learning rate)であり、ヒューリスティックに決める必要がある。 この様に再急上昇法による学習は単純だが、学習（収束）が遅く、 \\(\\eta\\) を決めなければならないという問題がある。 \\(\\eta\\) を大きく設定し過ぎると勾配の谷を越えてしまい発散を招き、逆に小さく設定すると学習がいつまでたっても終わらない。現状、最大エントロピーモデルの学習では、反復スケーリング法(iterative scaling)という学習手法が伝統的に用いられている。 反復スケーリング法の基本的な考え方は、まずパラメタ \\(\\Lambda\\) を \\(\\Lambda+\\Delta\\) に変化させた時の対数尤度の変化量の下限 \\(A(\\Lambda,\\Delta)\\) を計算し、次にこの \\(A(\\Lambda,\\Delta)\\) を最大にする \\(\\Delta\\) を求める事で、結果増加量を最大にするようにしている。この考え方には学習率の様なヒューリスティックは介在せず、かつ毎ステップの対数尤度の増加量を最大にするようにパラメタを更新できる。 それでは反復スケーリング法の更新式を導くことを考える。各パラメタの更新量を \\(\\Delta=\\{\\delta_{1},\\cdots,\\delta_{n}\\}\\) と表すものとし、まず、パラメタ更新時の対数尤度の変化量 \\(L(P_{\\Lambda+\\Delta})-L(P_{\\Lambda})\\) は, $$ \\begin{align} L(P_{\\Lambda+\\Delta})-L(P_{\\Lambda}) &= \\sum_{x,y} \\tilde{P}(x,y) \\log P_{\\Lambda+\\Delta}(x,y) - \\sum_{x,y} \\tilde{P}(x,y) \\log P_{\\Lambda}(x,y) \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\log \\left[ \\frac{P_{\\Lambda+\\Delta}(x,y)}{P_{\\Delta}(x,y)} \\right] \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\log \\left[ \\frac{Z_{\\Lambda}}{Z_{\\Lambda+\\Delta}} \\frac{\\exp\\left[ \\sum_{i}(\\lambda_{i} + \\delta_{i}) f_{i}(x,y) \\right]}{\\exp\\left[ \\sum_{i}\\lambda_{i}f_{i}(x,y) \\right] } \\right] \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\left[ \\sum_{i} \\delta_{i} f_{i}(x,y) - \\log\\left(\\frac{Z_{\\Lambda+\\Delta}}{Z_{\\Lambda}} \\right) \\right] \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\sum_{i} \\delta_{i} f_{i}(x,y) - \\log \\left(\\frac{Z_{\\Lambda+\\Delta}}{Z_{\\Lambda}} \\right) \\\\ &\\geq \\sum_{x,y} \\tilde{P}(x,y) \\sum_{i} \\delta_{i} f_{i}(x,y) + 1 - \\frac{Z_{\\Lambda+\\Delta}}{Z_{\\Lambda}} \\ \\ (\\because -\\log x \\geq 1-x) \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\sum_{i} \\delta_{i} f_{i}(x,y) + 1 - \\frac{\\sum_{x,y}\\exp\\left[ \\sum_{i}(\\lambda_{i} + \\delta_{i})f_{i}(x,y) \\right]}{\\sum_{x,y}\\exp\\left[ \\sum_{i}\\lambda_{i}f_{i}(x,y) \\right]} \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\sum_{i} \\delta_{i} f_{i}(x,y) + 1 - \\frac{Z_{\\Lambda}\\sum_{x,y}P_{\\Lambda}(x,y)\\exp\\left[ \\sum_{i}\\delta_{i}f_{i}(x,y) \\right]}{Z_{\\Lambda} \\sum_{x,y}P_{\\Lambda}(x,y)} \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\sum_{i} \\delta_{i} f_{i}(x,y) + 1 - \\sum_{x,y}P_{\\Lambda}(x,y)\\exp\\left[ \\sum_{i}\\delta_{i}f_{i}(x,y) \\right] \\end{align} $$ 素性 \\(f_{i}(x,y)\\) の \\(i\\) についての和 \\(f&#94;{\\\\#}(x,y) = \\sum_{i=1}&#94;{n}f_{i}(x,y)\\) を用いると、 $$ L(P_{\\Lambda+\\Delta})-L(P_{\\Lambda}) = \\sum_{x,y} \\tilde{P}(x,y) \\sum_{i} \\delta_{i} f_{i}(x,y) + 1 - \\sum_{x,y}P_{\\Lambda}(x,y)\\exp\\left[ \\sum_{i}\\frac{f_{i}(x,y)}{f&#94;{\\#}(x,y)}\\delta_{i}f&#94;{\\#}(x,y) \\right] $$ と書ける。今 \\(f_{i}(x,y)/f&#94;{\\\\#}(x,y)\\) は確率分布となることから、 \\(\\sum_{i}\\frac{f_{i}(x,y)}{f&#94;{\\\\#}(x,y)}\\delta_{i}f&#94;{\\\\#}(x,y)\\) は \\(\\delta_{i}f&#94;{\\\\#}(x,y)\\) についての平均と読み取れる。更に \\(\\exp\\) は明らかに凸関数であることから、イェンセンの不等式 \\(\\exp(E[X]) \\leq E[\\exp(X)]\\) を用いて最終的な下限の式を得る。 $$ \\begin{align} L(P_{\\Lambda+\\Delta})-L(P_{\\Lambda}) &\\geq \\sum_{x,y} \\tilde{P}(x,y) \\sum_{i} \\delta_{i} f_{i}(x,y) + 1 - \\sum_{x,y}P_{\\Lambda}(x,y)\\sum_{i}\\frac{f_{i}(x,y)}{f&#94;{\\#}(x,y)}\\exp\\left[ \\delta_{i}f&#94;{\\#}(x,y) \\right] \\\\ &= A(\\Lambda, \\Delta) \\end{align} $$ 次に \\(A(\\Lambda, \\Delta)\\) を \\(\\delta_{i}\\) で偏微分することで下限の最大化を考える。 $$ \\begin{align} \\frac{\\partial A(\\Lambda, \\Delta)}{\\partial \\delta_{i}} &= \\sum_{x,y} \\tilde{P}(x,y) f_{i}(x,y) - \\sum_{x,y} P_{\\Lambda}(x,y) f_{i}(x,y) \\exp \\left[ \\delta_{i}f&#94;{\\#}(x,y) \\right] \\\\ &= E_{\\tilde{P}}[f_{i}] - \\sum_{x,y} P_{\\Lambda}(x,y) f_{i}(x,y) \\exp \\left[ \\delta_{i}f&#94;{\\#}(x,y) \\right] \\end{align} $$ この式を \\(0\\) とおき \\(\\delta_{i}\\) について解くことで変化量を求める事ができる。この式は \\(\\delta_{i}\\) について閉じた形をしていないので、基本的には数値解析によって極値を求める。しかし、もしも任意の \\((x,y)\\) に対し \\(f&#94;{\\\\#}(x,y) = C\\) （定数）となるならば、 \\(\\delta_{i}\\) について解く事ができ、次の結果を得る。 $$ \\begin{align} & E_{\\tilde{P}}[f_{i}] - \\sum_{x,y} P_{\\Lambda}(x,y) f_{i}(x,y) \\exp \\left[ \\delta_{i}f&#94;{\\#}(x,y) \\right] = 0 \\\\ &\\implies \\exp \\left[C \\delta_{i} \\right] \\sum_{x,y} P_{\\Lambda}(x,y) f_{i}(x,y) = E_{\\tilde{P}}[f_{i}] \\iff \\exp \\left[C \\delta_{i} \\right] = \\frac{E_{\\tilde{P}}[f_{i}]}{E_{P}[f_{i}]} \\\\ &\\iff \\delta_{i} = \\frac{1}{C} \\log \\left( \\frac{E_{\\tilde{P}}[f_{i}]}{E_{P}[f_{i}]} \\right) \\end{align} $$ 任意の \\((x,y)\\) で \\(f&#94;{\\\\#}(x,y)\\) が定数にならない場合でも、実は \\(C = \\displaystyle\\max_{x,y} f&#94;{\\\\#}(x,y)\\) とし、新しい素性 \\(f_{n+1}(x,y)\\) を \\(f_{n+1}(x,y) = C - f&#94;{\\\\#}(x,y)\\) とおけば、変更後の和 \\(f&#94;{\\\\#\\prime}(x,y)\\) は \\(f&#94;{\\\\#\\prime}(x,y)=C\\) となる事が知られている。 \\(f&#94;{\\\\#\\prime}(x,y)\\) について検算を行ってみると, $$ \\begin{align} f&#94;{\\#\\prime}(x,y) &= \\sum_{i=1}&#94;{n+1} f_{i}(x,y) = \\sum_{i=1}&#94;{n} f_{i}(x,y) + f_{n+1}(x,y) \\\\ &= f&#94;{\\#}(x,y) + C - f&#94;{\\#}(x,y) = C \\end{align} $$ となって、定数 \\(C\\) を取ることが確かめられた。 条件付き最大エントロピーモデル 前節までのモデルはあるパターン \\((x,y)\\) を生成する結合確率を表現しているが、応用上は何らかの入力 \\(x\\) に対して出力 \\(y\\) の結果を得たいというケースが多い。例えば、再び単語予測の例を挙げると、一つ前までの単語を \\(x\\) として入力として、今の単語 \\(y\\) を予測するというタスクである。そのような場合はモデルの条件付き確率 \\(P(y|x)\\) が用いられる。このモデルは \\(y\\) の識別を行うので生成識別モデルと呼ばれ、条件付き最大エントロピーモデルはCRF(Conditional Random Fields、条件付き確率場)のサブクラスとして捉えられる。 条件付き最大エントロピーモデルの確率分布 \\(P_{\\Lambda}(y|x)\\) は、 \\(P_{\\Lambda}(x,y)\\) とベイズの定理から得られる。 $$ \\begin{align} P_{\\Lambda}(y|x) &= \\frac{P_{\\Lambda}(x,y)}{P_{\\Lambda}(x)} \\\\ &= \\frac{\\exp\\left[ \\sum_{i}\\lambda_{i}f_{i}(x,y) \\right]}{Z_{\\Lambda}} \\left( \\sum_{y} \\frac{\\exp\\left[ \\sum_{i}\\lambda_{i}f_{i}(x,y) \\right]}{Z_{\\Lambda}} \\right)&#94;{-1} \\\\ &= \\frac{1}{Z_{\\Lambda}(x)} \\exp\\left[ \\sum_{i}\\lambda_{i}f_{i}(x,y) \\right] \\\\ Z_{\\Lambda}(x) &= \\sum_{y}\\exp\\left[\\sum_{i}\\lambda_{i}f_{i}(x,y)\\right] \\end{align} $$ このモデルを用いた素性の平均 \\(E_{P}[f_{i}]\\) は次の様に計算できる。 $$ \\begin{align} E_{P}[f_{i}] &= \\sum_{x,y} P(x,y) f_{i}(x,y) = \\sum_{x,y} P(y|x)P(x)f_{i}(x,y) \\\\ &= \\sum_{x} P(x) \\sum_{y} P(y|x) f_{i}(x,y) \\end{align} $$ 外側の \\(P(x)\\) の和は、考えうる全ての入力 \\(x \\in X\\) についての和を取らねばならず、その計算は現実的に不可能である。従って経験確率による近似 \\(P(x) \\approx \\tilde{P}(x)\\) を用いて、平均は $$ E_{P}[f_{i}] \\approx \\sum_{x}\\tilde{P}(x) \\sum_{y} P(y|x) f_{i}(x,y) $$ とする。この近似を用いることで、 \\(x\\) については学習データに現れるものだけの和を取ればよく、また \\(y\\) についても素性関数が非零の時のみ和を取れば良ため、計算の効率化が望める。 平均だけでなく、正規化項 \\(Z_{\\Lambda}(x)\\) の計算もボトルネックな部分であり、効率化が望まれる。そこで、文献 1 5 による効率的な正規化項の計算手法を見ていく。まず、素性関数の集合 \\({\\cal F}\\) を次の2つに分割する: $$ \\begin{align} {\\cal F}_{m} &= \\{ f_{i} | \\forall{w,x,y} \\ f_{i}(x,y) = f_{i}(w,y) \\} \\ \\ \\text{（周辺素性(marginalized feature)の集合）} \\\\ {\\cal F}_{c} = {\\cal F}_{m}&#94;{c} &= \\{ f_{i} | \\exists{w,x,y} \\ f_{i}(x,y) \\neq f_{i}(w,y) \\} \\ \\ \\text{（条件付き素性(conditional feature)の集合）} \\end{align} $$ 周辺素性は \\(y\\) の値のみによって決まる素性であり、 \\(y\\) の関数として捉えられる。集合演算の性質により、 \\({\\cal F}\\_{m} \\cap {\\cal F}_{c} = \\emptyset\\) は自明に成り立つ。次に、 \\(y\\) の値域 \\(Y\\) についても次の分割を行う: $$ \\begin{align} Y_{m} &= \\{ y | \\exists f_{i} \\in {\\cal F}_{m} \\ f_{i}(y) \\neq 0 \\} \\ \\ \\text{（周辺素性が活性化される$Y$の要素）} \\\\ Y(x) &= \\{ y | \\exists f_{i} \\in {\\cal F}_{c} \\ f_{i}(x,y) \\neq 0 \\} \\ \\ \\text{（$x$を固定した時に,条件付き素性が活性化される$Y$の要素）} \\end{align} $$ 定義より $$ Y_{m}&#94;{c} = \\{ y | \\forall{f_{i}} \\in {\\cal F}_{m} \\ f_{i}(y) = 0 \\} $$ （どの周辺素性に対しても活性化されない \\(Y\\) の要素）は自明に成り立つ。また、一般には \\(Y_{m} \\cap Y(x) \\neq \\emptyset\\) である。即ち周辺素性と条件付き素性を同時に活性化させる \\(Y\\) の要素は存在する。 以上の集合分割を考慮しつつ、正規化項 \\(Z_{\\Lambda}(x) = \\sum_{y}\\exp\\left[\\sum_{i}\\lambda_{i}f_{i}(x,y)\\right]\\) の計算を考えていくが、表記の簡略化の為、文献と同じように次の表記を用いる: $$ z(y|x) = \\exp\\left[ \\sum_{i}\\lambda_{i} f_{i}(x,y) \\right] \\ ,\\ z(y) = \\exp\\left[ \\sum_{f_{i} \\in {\\cal F}_{m}} \\lambda_{i} f_{i}(y) \\right] $$ 正規化項 \\(Z_{\\Lambda}(x)\\) の計算式は次のように展開される。 $$ \\begin{align} Z_{\\Lambda}(x) &= \\sum_{y \\in Y}z(y|x) \\\\ &= \\sum_{y \\in Y_{m}&#94;{c} \\cap Y(x)&#94;{c}} z(y|x) + \\sum_{y \\in Y_{m} \\cap Y(x)&#94;{c}} z(y|x) + \\sum_{y \\in Y(x)} z(y|x) \\\\ \\end{align} $$ ここで、 $$ \\begin{align} y \\in Y(x)&#94;{c} &\\implies z(y|x) = z(y) \\\\ &\\because z(y|x) = \\exp\\left[ \\sum_{f_{i} \\in {\\cal F}_{m}} \\lambda_{i} f_{i}(y) + \\sum_{f_{i} \\in {\\cal F}_{c}} \\lambda_{i} 0 \\right] = \\exp \\left[ \\sum_{f_{i} \\in {\\cal F}_{m}} \\lambda_{i} f_{i}(y) \\right] = z(y) \\end{align} $$ が成立するので、 $$ Z_{\\Lambda}(x) = \\sum_{y \\in Y_{m}&#94;{c} \\cap Y(x)&#94;{c}} z(y) + \\sum_{y \\in Y_{m} \\cap Y(x)&#94;{c}} z(y) +\\sum_{y \\in Y(x)} z(y|x) $$ となり、さらに集合の包含関係に注目すれば、 $$ \\begin{align} \\sum_{y \\in Y} z(y) &= \\sum_{y \\in Y_{m} \\cap Y(x)&#94;{c}} z(y) + \\sum_{y \\in Y_{m}&#94;{c} \\cap Y(x)&#94;{c}} z(y) + \\sum_{y \\in Y(x)} z(y) \\\\ &= \\sum_{y \\in Y_{m}} z(y) + \\sum_{y \\in Y_{m}&#94;{c}} z(y) \\\\ \\therefore \\sum_{y \\in Y_{m} \\cap Y(x)&#94;{c}} z(y) + \\sum_{y \\in Y_{m}&#94;{c} \\cap Y(x)&#94;{c}} z(y) &= \\sum_{y \\in Y_{m}} z(y) + \\sum_{y \\in Y_{m}&#94;{c}} z(y) - \\sum_{y \\in Y(x)} z(y) \\end{align} $$ が成立するので、 $$ Z_{\\Lambda}(x) = \\sum_{y \\in Y_{m}&#94;{c}} z(y) + \\sum_{y \\in Y_{m}} z(y) + \\sum_{y \\in Y(x)} \\left\\{ z(y|x) -z(y) \\right\\} $$ となり、更に \\(Y_{m}&#94;{c}\\) の要素の性質 $$ \\begin{align} y \\in Y_{m}&#94;{c} &\\implies z(y) = 1 \\\\ &\\because z(y) = \\exp\\left[ \\sum_{f_{i} \\in {\\cal F}_{m}} \\lambda 0 \\right] = 1 \\end{align} $$ を用いて、次の最終結果を得る。 $$ \\begin{align} Z_{\\Lambda}(x) &= \\sum_{y \\in Y_{m}&#94;{c}} 1 + \\sum_{y \\in Y_{m}} z(y) + \\sum_{y \\in Y(x)} \\left\\{ z(y|x) -z(y) \\right\\} \\\\ &= |Y-Y_{m}| + \\sum_{y \\in Y_{m}}z(y) + \\sum_{y \\in Y(x)} \\left\\{ z(y|x) -z(y) \\right\\} \\end{align} $$ ここで \\(Y-Y_{m}=Y \\cap Y_{m}&#94;{c}\\) は集合演算の意味での差である。この計算式は、第1項と第2項は予め計算しておくことができ、しかも第3項については \\(Y\\) の部分集合 \\(Y(x)\\) の和を考えれば良い。結果、ナイーブな計算（計算量 \\(O(|X||Y|)\\) ）を行うよりも効率的（計算量 \\(O(|X||Y(x)|+|X|)\\) ）に計算を行うことができる。 素性の自動選択 前節までは、最大エントロピーモデルの学習について考えてきたが、モデルの構成要素となる素性については触れてなかった。観測された経験確率分布 \\(\\tilde{P}(x,y)\\) に対し、素性の組み合わせによって実現可能な最大尤度が異なり、従って尤度が最大になる素性集合 \\({\\cal F}\\) を選び出さなければならない。 しかし素性の候補となる集合 \\({\\cal F}_{0}\\) は非常に大きくなる為に、網羅的に全ての素性の組み合わせを試していくのは現実的に不可能である。また、サンプルで出現頻度が高い素性を選択する手法も存在するが、これでは尤度を厳密に最大化できない。そこで、逐次的にモデルの尤度が増加する様に素性を追加する手法が基本的に用いられており、その手順の概要は以下の様になる。 モデルの素性集合 \\({\\cal F}\\) を空集合とする: \\({\\cal F} \\leftarrow \\emptyset\\) （反復スケーリング法等の学習手法によって）素性集合 \\({\\cal F}\\) における最大尤度モデル \\(P_{\\cal F}\\) を得る。 素性集合の候補 \\({\\cal F}\\_{0}\\) の各要素 \\(f_{0} \\in {\\cal F}_{0}\\) について、以下を行う。 素性を加えたモデルを学習し \\(P_{{\\cal F} \\cup f_{0}}\\) を得る。 対数尤度の増分 \\(\\Delta L({\\cal F}, f_{0})\\) を計算する: \\(\\Delta L({\\cal F}, f_{0}) \\leftarrow L(P_{{\\cal F} \\cup f_{0}}) - L(P_{\\cal F})\\) 最大の増分 \\(\\Delta L({\\cal F}, \\hat{f})\\) を与える \\(\\hat{f} = \\underset{f \\in {\\cal F}_{0}}{\\rm argmax}\\ \\Delta L({\\cal F}, f)\\) を選び出し、素性集合に加える: \\({\\cal F} \\leftarrow {\\cal F} \\cup \\hat{f}\\) 最大増分がある閾値以下になったら終了し、それ以外は2.に戻る。 逐次的に計算が行える為に手続き的に実行しやすいものの、結局手順3,4において \\({\\cal F}_{0}\\) を走査しているので依然として膨大な計算量が必要になる。文献 1 4 では対数尤度の増分を近似的に求める手法を述べているが、それでも本質的に計算量を削減できたとは言えず、効率的な素性選択の手法については研究の対象となっていた 6 8 。 ここでは元の文献 1 4 に述べられていた、増分の近似による手法を見ていく。近似の仮定としては、元のモデル \\(P_{\\cal F}\\) とそのパラメタ集合 \\(\\Lambda\\) に \\(f \\in {\\cal F}\\) とそれに付随するパラメタ \\(\\alpha\\) を加えたモデル \\(P_{{\\cal F} \\cup f}\\) においても、最大尤度を与える元のパラメタ \\(\\Lambda\\) は変化しないというものである。実際には素性を加える事で最大尤度を与えるパラメタ \\(\\Lambda\\) は変化するが、この変化を無視することでモデル \\(P_{{\\cal F} \\cup f}\\) の最大尤度 \\(L(P_{{\\cal F} \\cup f})\\) の計算を回避する。素性を追加することにより尤度は増えこそすれ減ることはないので（ \\(\\because\\) 経験分布に適合しない素性に対しては学習の結果 \\(\\alpha = 0\\) となり、元のモデルと一致するので尤度増分は0） 、近似的増分を最大にする \\(\\alpha\\) を探索する問題に帰着される。 仮定の下で、素性集合 \\({\\cal F} \\cup f\\) に対するモデル \\(P_{{\\cal F} \\cup f}&#94;{\\alpha}\\) の確率分布は次の様に書ける。 $$ \\begin{align} P_{ {\\cal F} \\cup f}&#94;{\\alpha}(y|x) &= \\frac{1}{Z_{\\alpha}(x)} P_{\\cal F} (y|x) \\exp \\left[ \\alpha f(x,y) \\right] \\\\ Z_{\\alpha}(x) &= \\sum_{y} P_{\\cal F}(y|x) \\exp \\left[ \\alpha f(x,y) \\right] \\end{align} $$ 対数尤度の近似的増分 \\(G_{{\\cal F} \\cup f}(\\alpha)\\) は, $$ \\begin{align} G_{{\\cal F} \\cup f}(\\alpha) &= L(P_{{\\cal F}\\cup f}&#94;{\\alpha}) - L(P_{\\cal F}) \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\log P_{{\\cal F} \\cup f}&#94;{\\alpha}(x,y) - \\sum_{x,y} \\tilde{P}(x,y) \\log P_{\\cal F}(x,y) \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\left\\{ \\log P_{\\cal F}(x,y) + \\alpha f(x,y) - \\log Z_{\\alpha}(x) - \\log P_{\\cal F}(x,y) \\right\\} \\\\ &= \\alpha \\sum_{x,y} \\tilde{P}(x,y) f(x,y) - \\sum_{x} \\log Z_{\\alpha}(x) \\sum_{y} \\tilde{P}(x,y) \\\\ &= \\alpha E_{\\tilde{P}}[f] - \\sum_{x} \\tilde{P}(x) \\log Z_{\\alpha}(x) \\end{align} $$ となる、 \\(G_{{\\cal F} \\cup f}(0) = 0\\) は \\(Z_{0}(x) = 1\\) より容易に確かめられる。増分最大化の為、偏微分 \\(\\frac{\\partial G_{{\\cal F} \\cup f}}{\\partial \\alpha} = G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha)\\) を計算すると, $$ \\begin{align} G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha) &= E_{\\tilde{P}}[f] - \\sum_{x} P(x) \\frac{\\partial \\log Z_{\\alpha}(x)}{\\partial \\alpha} \\\\ &= E_{\\tilde{P}}[f] - \\sum_{x} \\tilde{P}(x) \\frac{1}{Z_{\\alpha}(x)} \\sum_{y} P_{\\cal F}(y|x) \\exp\\left[ \\alpha f(x,y) \\right] f(x,y) \\\\ &= E_{\\tilde{P}}[f] - \\sum_{x} \\tilde{P}(x) \\sum_{y} P_{ {\\cal F} \\cup f}&#94;{\\alpha}(y|x) f(x,y)\\ \\ (= E_{\\tilde{P}}[f] - E_{P_{ {\\cal F} \\cup f}}[f]) \\\\ &= E_{\\tilde{P}}[f] - \\sum_{x} \\tilde{P}(x) Q_{ {\\cal F} \\cup f}&#94;{\\alpha} (f|x) \\end{align} $$ ここで、文献にもあるように \\(Q_{ {\\cal F} \\cup f}&#94;{\\alpha} (h|x) = \\sum_{y} P_{ {\\cal F} \\cup f}&#94;{\\alpha}(y|x) h(x,y)\\) （分布 \\(P_{ {\\cal F} \\cup f}\\) による、 \\(h\\) の \\(y\\) における平均）とおいている。 \\(G_{{\\cal F} \\cup f}&#94;{\\prime}(0)\\) の値は \\(P_{ {\\cal F} \\cup f}&#94;{0}(y|x) = P_{\\cal F}(y|x)\\) により \\(G_{{\\cal F}\\cup f}&#94;{\\prime}(0) = E_{\\tilde{P}}[f] - E_{P_{\\cal F}}[f]\\) となる。更に2階微分 \\(G_{{\\cal F} \\cup f}&#94;{\\prime \\prime}(\\alpha)\\) を計算すると, $$ \\begin{align} G_{{\\cal F} \\cup f}&#94;{\\prime \\prime}(\\alpha) &= - \\sum_{x} P(x) \\frac{1}{Z_{\\alpha}&#94;{2}(x)} \\left[ \\left\\{ \\sum_{y} P_{\\cal F}(y|x) \\exp\\left[ \\alpha f(x,y) \\right] f&#94;{2}(x,y) \\right\\} Z_{\\alpha}(x) \\right. \\\\ & \\left. - \\left\\{ \\sum_{y} P_{\\cal F}(y|x)\\exp\\left[ \\alpha f(x,y) \\right] f(x,y) \\right\\}&#94;{2} \\right] \\\\ &= - \\sum_{x} \\tilde{P}(x) \\left[ Q_{ {\\cal F} \\cup f}&#94;{\\alpha} (f&#94;{2}|x) - \\left\\{Q_{ {\\cal F} \\cup f}&#94;{\\alpha}(f|x) \\right\\}&#94;{2} \\right] \\\\ &= - \\sum_{x} \\tilde{P}(x) Q_{ {\\cal F} \\cup f}&#94;{\\alpha} \\left( (f - Q_{ {\\cal F} \\cup f}&#94;{\\alpha}(f|x))&#94;{2} | x \\right) \\end{align} $$ ここで最下段の式変形には、分散と平均の関係 \\(E[(X-E[X])&#94;{2}] = E[X&#94;{2}] - \\{E[X]\\}&#94;{2}\\) を用いている。 \\((f - Q_{ {\\cal F} \\cup f}&#94;{\\alpha}(f|x))&#94;{2} \\geq 0\\) より、 \\(G_{{\\cal F} \\cup f}&#94;{\\prime \\prime}(\\alpha) \\leq 0\\) が成立し、 \\(G_{{\\cal F} \\cup f}(\\alpha)\\) は上に凸な関数であり、極大値がそのまま大域的な最大値となる事が分かる。 上述の議論により、 \\(G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha&#94;{\\ast}) = 0\\) を満たす \\(\\alpha&#94;{\\ast}\\) を得れば良いことになるが、解くべき式が \\(\\alpha\\) について閉じた形をしていない為、数値解析的な手法を用いることになる。文献 1 4 7 によると、 \\(G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha)\\) は \\(\\alpha\\) に対して凸関数ではないが、 \\(\\exp(\\alpha)\\) に関しては下に凸の減少関数、かつ \\(\\exp(-\\alpha)\\) に関しては上に凸の増加関数となる事が示されているので、 \\(\\exp(\\alpha)、\\exp(-\\alpha)\\) の数列に対してニュートン法を適用する事を考える。偏微分の連鎖律を用いることで, $$ \\begin{align} \\frac{\\partial G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha)}{\\partial \\exp(\\alpha)} &= \\frac{\\partial G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha)}{\\partial \\alpha} \\frac{\\partial \\alpha}{\\partial \\exp(\\alpha)} \\\\ &= \\frac{\\log t}{t} G_{{\\cal F} \\cup f}&#94;{\\prime \\prime}(\\alpha) \\ \\ (t = \\exp(\\alpha)) \\\\ &= \\frac{1}{t} G_{{\\cal F} \\cup f}&#94;{\\prime \\prime}(\\alpha) = \\exp(-\\alpha) G_{{\\cal F} \\cup f}&#94;{\\prime \\prime}(\\alpha) \\end{align} $$ が成り立つので、ニュートン法の更新則は、 $$ \\begin{align} \\exp(\\alpha_{n+1}) &= \\exp(\\alpha_{n}) - \\frac{G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{\\frac{\\partial G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{\\partial \\exp(\\alpha_{n})}} = \\exp(\\alpha_{n}) \\left[ 1 - \\frac{G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{G_{{\\cal F} \\cup f}&#94;{\\prime\\prime}(\\alpha_{n})} \\right] \\\\ \\iff \\alpha_{n+1} &= \\alpha_{n} + \\log \\left[ 1 - \\frac{G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{G_{{\\cal F} \\cup f}&#94;{\\prime\\prime}(\\alpha_{n})} \\right] \\\\ \\exp(-\\alpha_{n+1}) &= \\exp(-\\alpha_{n}) - \\frac{G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{\\frac{\\partial G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{\\partial \\exp(-\\alpha_{n})}} = \\exp(-\\alpha_{n}) \\left[ 1 + \\frac{G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{G_{{\\cal F} \\cup f}&#94;{\\prime\\prime}(\\alpha_{n})} \\right] \\\\ \\iff \\alpha_{n+1} &= \\alpha_{n} - \\log \\left[ 1 + \\frac{G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{G_{{\\cal F} \\cup f}&#94;{\\prime\\prime}(\\alpha_{n})} \\right] \\end{align} $$ となる。最適値 \\(\\alpha&#94;{\\ast}\\) が \\(\\alpha&#94;{\\ast} > 0\\) の場合（ \\(E_{\\tilde{P}}[f] > E_{P_{\\cal F}}[f]\\) 9 ）には上の更新式を用いれば良く、 \\(\\alpha&#94;{\\ast} < 0\\) の場合（ \\(E_{\\tilde{P}}[f] < E_{P_{\\cal F}}[f]\\) ）には下の更新式を用いれば良い。 当機立断！ こんな記事見てる暇があるなら今すぐ幕張に行けってことさ！ ユ\"メ\"ッ！！ おう、ライブ行くんだよ、あくしろよ。フォロチケ返さねえぞこの野郎。 脚注・参考文献 北研二、辻井潤一、``確率的言語モデル''、東京大学出版会、1999 ↩ ↩ ↩ ↩ ↩ 高村大也、奥村学、``言語処理のための機械学習入門''、コロナ社、2010 ↩ 高橋治久、堀田一弘、``学習理論'' コロナ社、2009 ↩ ↩ Berger, Adam L., Vincent J, Della Pietra, and Stephen A. Della Pietra. \"A maximum entropy approach to natural language processing.\" Computational linguistics 22.1 (1996): 39-71. ↩ ↩ ↩ Wu, Jun, and Sanjeev Khudanpur, \"Efficient training methods for maximum entropy language modeling.\" INTERSPEECH. 2000. ↩ Zhou, Yaqian, et al. \"A fast algorithm for feature selection in conditional maximum entropy modeling.\" Proceedings of the 2003 conference on Empirical methods in natural language processing. Association for Computational Linguistics, 2003. ↩ Pietra, Stephen Della, Vincent Della Pietra, and John Lafferty. \"Inducing features of random fields.\" Pattern Analysis and Machine Intelligence、IEEE Transactions on 19.4 (1997): 380-393. ↩ 谷垣宏一, 渡邉圭輔, and 石川泰, ``最大エントロピー法による発話理解のための効率的モデル構築 (< 特集> 音声言語情報処理とその応用).'' 情報処理学会論文誌 43.7 (2002): 2138-2146. ↩ \\(G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha)\\) は \\(\\alpha\\) に関して単調減少するので、 \\(G_{{\\cal F} \\cup f}&#94;{\\prime}(0) = E_{\\tilde{P}}[f] - E_{P_{\\cal F}}[f]>0\\) ならば、かつその時に限り最適値 \\(\\alpha&#94;{\\ast}\\) は正の値をとる。 ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"記事","url":"/zui-da-entoropimoderu.html","loc":"/zui-da-entoropimoderu.html"},{"title":"SVM（サポートベクトルマシン）","text":"（Q****にマジギレして移行） SVM(Support Vector Machine, サポートベクトルマシン) は、深層学習の影に隠れがちではあるものの、現在使われている識別学習モデルの中でも比較的認識性能が優れ、実用に供される事はもちろん、様々な研究でも比較対象となる手法の一つである。 SVMの大雑把な理論的概要を述べると、SVMは与えられた学習サンプルを最も適切に分離（識別）する境界面（ 識別面 ）を発見する手法である。その識別面は凸計画問題に帰着して求める事ができるので、どの様なサンプルにおいても（存在するならば）最適な識別面を構成できる。 本稿では、最初に基本となる線形SVMの定式化を行い、次に汎用性をより高めた非線形SVMとソフトマージンSVMを説明し、最後にSVMを回帰問題に適用したSVR(Support Vector Regression, サポートベクトル回帰)を説明する。最後にC言語による実装例を挙げる。 SVMも知り尽くされており、文献・資料は大量に存在する。ここでは、参考書籍 1 2 を挙げる。 線形SVM マージンの定式化 識別の例として、まずは図にあるような、2次元空間 \\(X\\times Z\\) に存在する2クラスのサンプルデータ（以下サンプル）を仮定する。各クラスは二値のラベル付け \\(y=\\{-1, 1\\}\\) がなされており、識別面（2次元空間では直線） \\(ax+bz+c=0\\) の上半領域（ \\(ax+bz+c>0\\) ）にラベル \\(y=1\\) のサンプルが、下半領域（ \\(ax+bz+c<0\\) ）にラベル \\(y=-1\\) のサンプルが分布するようにする。 更に、 \\(n\\) 次元空間の元（ベクトル） \\(\\boldsymbol{x} \\in \\mathbb{R}&#94;{n}\\) で表されるサンプルに対しても一般化でき、 \\(n\\) 次元の係数ベクトル \\(\\boldsymbol{w} \\in \\mathbb{R}&#94;{n}\\) を用いることで、 識別面は $$ \\begin{aligned} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x} + b = 0 \\end{aligned} $$ と表現できる。ここで \\(b \\in \\mathbb{R}\\) は切片（しきい値、 バイアス）である。 概要でも述べたとおり、識別面は異なるラベルが付いたサンプルを互いに分離さえできていれば良いので、識別面の候補は無限に存在してしまう（上の2次元の例でも明らかである）。しかし、 その全てが適切な識別面とは限らない。 SVMでは、次の2点を最適な識別面の条件とする。 各クラスの、最も識別面に近いサンプル（ サポートベクトル ）までの距離を最大にする。 また、 その距離を各クラスで同一にする。 この2点を満たす識別面ならば、 丁度クラス間の中心を区切ることが出来、適切な識別面といえる。 また、図に示す様に、サポートベクトル間の距離を マージン （余白）という。 SVMは、このマージンを最大化することが目的となる。 それでは、 マージンの定式化を考える。 \\(n\\) 次元空間上に \\(N\\) 個存在するサンプルを \\(\\boldsymbol{x}\\_{i} \\in \\mathbb{R}&#94;{n} \\ (i=1, \\dots, N)\\) と書き、またそのデータに対応する二値ラベルを \\(y_{i} \\in \\{-1, 1\\}\\ (i=1, \\dots, N)\\) とかく。全てのサンプルが正しく識別されている時には、 $$ \\begin{aligned} y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) \\geq 0 \\quad (i = 1, \\dots, N) \\end{aligned} $$ が明らかに成立する。 そして、異なる2クラスのサポートベクトル \\(\\boldsymbol{x}\\_{s}, \\boldsymbol{x}\\_{t}\\) が $$ \\begin{aligned} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{s} + b = l , \\quad \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{t} + b = -l\\end{aligned} $$ が成立すると仮定する 3 と（ \\(l>0\\) ）、 \\(\\boldsymbol{x}\\_{s}\\) と \\(\\boldsymbol{x}\\_{t}\\) の、識別面に対して平行な距離がマージンとして計算できる。マージンを \\(\\gamma\\) と書くと、 平面の単位法ベクトルは \\(\\boldsymbol{w}/||\\boldsymbol{w}||\\) （ \\(||\\boldsymbol{w}|| = \\sqrt{\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w}}\\) ）で与えられるので、マージンは $$ \\begin{aligned} & \\boldsymbol{w}&#94;{\\mathsf{T}}(\\boldsymbol{x}_{t} + \\gamma \\frac{\\boldsymbol{w}}{||\\boldsymbol{w}||}) + b = \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{s} + b \\nonumber \\\\ &\\iff \\gamma \\frac{\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w}}{||\\boldsymbol{w}||} = \\gamma ||\\boldsymbol{w}|| = (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{s}+b) - (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{t}+b) = 2l \\nonumber \\\\ &\\therefore \\gamma = \\frac{2l}{||\\boldsymbol{w}||}\\end{aligned} $$ で求められる。 マージン最大化 前節でも既に述べたが、 SVMの目的はマージン \\(\\gamma\\) を最大化することである。単純には \\(\\max \\gamma\\) と書けるが、 最適化を行いやすくするため、 \\(1/\\gamma\\) の最小化に置き換え、 \\(l\\) は最適化に関与しないので \\(l=1\\) とし、更に \\(||\\boldsymbol{w}||\\) が最小化された時は \\(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w}\\) も最小化されるので、考えるべき最適化問題は次のように書ける: $$ \\begin{aligned} & \\max_{\\scriptsize \\boldsymbol{w}} \\gamma = \\frac{2l}{||\\boldsymbol{w}||} \\quad \\text{subject to : } y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) \\geq l \\nonumber \\\\ &\\implies \\min_{\\scriptsize \\boldsymbol{w}} \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} \\quad \\text{subject to : } y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) \\geq 1 \\quad (i=1, \\dots, N)\\end{aligned} $$ この最適化問題は、 凸計画問題 4 であり、不等式制約付き非線形計画問題なので、 KKT条件(Karush-Kuhn-Tucker condition)を用いる。KKT条件はラグランジェの未定乗数法（等式制約）の一般化であり、次の定理で表される: KKT条件 \\(\\boldsymbol{v}&#94;{\\star}\\) を \\(f(\\boldsymbol{v})\\) に関しての最適化問題の最適解とするならば、次の条件を満たす最適重みベクトル \\(\\boldsymbol{\\alpha}&#94;{\\star}=[\\alpha_{1}&#94;{\\star}, \\cdots, \\alpha_{N}&#94;{\\star}]&#94;{\\mathsf{T}}\\ (\\alpha_{i} \\geq 0)\\) が存在する。 $$ \\begin{aligned} \\left\\{ \\begin{array}{ll} \\displaystyle\\frac{\\partial{\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star})}{\\partial \\boldsymbol{v}} &= 0 \\\\ \\boldsymbol{\\alpha}&#94;{\\star\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}&#94;{\\star}) &= 0 \\end{array} \\right. \\end{aligned} $$ ここで \\(\\boldsymbol{g}(\\boldsymbol{v})\\) は制約条件式 \\(\\boldsymbol{g}(\\boldsymbol{v}) = [g_{1}(\\boldsymbol{v}), \\cdots, g_{N}(\\boldsymbol{v})]&#94;{\\mathsf{T}}\\) , \\({\\cal L}\\) はラグランジアン（ラグランジェ関数）であり以下の様に表される。 $$ \\begin{aligned} g_{i}(\\boldsymbol{v}) &\\geq 0\\ \\ (i = 1, \\dots, N) \\\\ {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}) &= f(\\boldsymbol{v}) + \\boldsymbol{\\alpha}&#94;{\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}) \\end{aligned} $$ \\({\\cal L}\\) が凸関数ならば、最適点 \\((\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star})\\) は鞍点にあり、 \\(\\displaystyle\\max_{\\scriptsize \\boldsymbol{v}} {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}&#94;{\\star})\\) を主問題とする時、 \\(\\displaystyle\\min_{\\scriptsize \\boldsymbol{\\alpha}}{\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha})\\) を主問題に対する双対問題という。 5 それでは実際にKKT条件を適用し、最適化問題を主問題(式)から双対問題へ変換する事を考える。 まず制約条件から $$ \\begin{aligned} g_{i}(\\boldsymbol{w}) = 1 - y_{i} (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) \\leq 0\\end{aligned} $$ （最小化を考えているので、 符号が逆転している事に注意）より、ラグランジアンは、 $$ \\begin{aligned} {\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\alpha}) &= \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} + \\boldsymbol{\\alpha}&#94;{\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{w}) \\\\ &= \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} + \\sum_{i=1}&#94;{N}\\alpha_{i} \\{ 1 - y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) \\}\\end{aligned} $$ と表現でき、 \\({\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\alpha})\\) の \\(\\boldsymbol{w}, b\\) による偏微分は、 $$ \\begin{aligned} \\frac{\\partial {\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\alpha})}{\\partial \\boldsymbol{w}} = \\boldsymbol{w} - \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i}\\boldsymbol{x}_{i}, \\quad \\frac{\\partial {\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\alpha})}{\\partial b} = \\sum_{i=1}&#94;{N}\\alpha_{i}y_{i}\\end{aligned} $$ となる。 \\(\\displaystyle\\frac{\\partial {\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\alpha})}{\\partial \\boldsymbol{w}} = \\boldsymbol{0}\\) とおくことで最適時の係数 \\(\\boldsymbol{w}&#94;{\\star}\\) が求まる: $$ \\begin{aligned} \\boldsymbol{w}&#94;{\\star} = \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i}\\boldsymbol{x}_{i}\\end{aligned} $$ また、 \\(\\displaystyle\\frac{\\partial {\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\alpha})}{\\partial b} = 0\\) により双対変数 \\(\\boldsymbol{\\alpha}\\) の制約条件が得られる: $$ \\begin{aligned} \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0\\end{aligned} $$ これらの関係式をラグランジアンに代入することで、 双対問題式を得る: $$ \\begin{aligned} {\\cal L}(\\boldsymbol{w}&#94;{\\star}、 \\boldsymbol{\\alpha}) &= \\frac{1}{2} \\boldsymbol{w}&#94;{\\star\\mathsf{T}}\\boldsymbol{w}&#94;{\\star} + \\boldsymbol{\\alpha}&#94;{\\mathsf{T}} \\boldsymbol{g}(\\boldsymbol{w}&#94;{\\star}) \\\\ &= \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\boldsymbol{x}_{j}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + \\sum_{i=1}&#94;{N} \\alpha_{i} \\left\\{ 1 - y_{i} \\left( \\sum_{j=1}&#94;{N}\\alpha_{j}y_{j}\\boldsymbol{x}_{j}&#94;{\\mathsf{T}} \\boldsymbol{x}_{i} + b \\right) \\right\\} \\\\ &= \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\boldsymbol{x}_{i}&#94;{\\mathsf{T}}\\boldsymbol{x}_{j} + \\sum_{i=1}&#94;{N} \\alpha_{i} - b\\sum_{i=1}&#94;{N} \\alpha_{i} y_{i} - \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\boldsymbol{x}_{i}&#94;{\\mathsf{T}} \\boldsymbol{x}_{j} \\\\ &= \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\boldsymbol{x}_{i}&#94;{\\mathsf{T}}\\boldsymbol{x}_{j}\\end{aligned} $$ （途中の式変形において、内積の対称性（ \\(\\boldsymbol{x}&#94;{\\mathsf{T}}\\_{j}\\boldsymbol{x}\\_{i} = \\boldsymbol{x}&#94;{\\mathsf{T}}\\_{i}\\boldsymbol{x}\\_{j}\\) ）を用いている。）よって、 双対問題は $$ \\begin{aligned} & \\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\boldsymbol{x}_{i}&#94;{\\mathsf{T}}\\boldsymbol{x}_{j} \\right] \\\\ & \\text{subject to : } \\alpha_{i} \\geq 0, \\ \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0 \\quad (i = 1, \\dots, N) \\nonumber\\end{aligned} $$ と表現できる。双対問題は非負制約 \\(\\alpha_{i} \\geq 0\\) の中で \\(\\boldsymbol{\\alpha}\\) を動かし、その最大値を得れば良いので、 主問題を直接解くよりも容易に、数値最適化によって解を求める（学習する）ことができる。実際の実装については後に述べる。 非線形SVM 前節までの議論は、入力データと同じ空間（次元）で適切な識別面を発見するSVMであり、これを特に 線形SVM という。 線形SVMの場合、識別面は入力データ空間の次元 \\(n\\) に対し \\(n-1\\) 次元の平面（ 超平面 ）であり（例:2次元空間では直線、3次元空間では平面）、図の様に、異なるクラスのサンプルが入り組んだ状態では識別面を構成できない（ 線形分離不可能 ）。 この場合、入力データの空間 \\(\\mathbb{R}&#94;{n}\\) から高次元空間 \\(\\mathbb{R}&#94;{h}\\) ( \\(h \\gg n\\) )への高次元な非線形写像（ 特徴写像 ） \\(\\boldsymbol{\\phi} : \\mathbb{R}&#94;{n} \\to \\mathbb{R}&#94;{h}\\) を用いて高次元空間（特徴空間）へ写像すれば、線形分離不可能だったサンプルを一般位置 6 に写し、識別面を構成できる（線形分離可能）ようになる（図参照）。 図では、入力空間は1次元（数直線）、 特徴空間は2次元（平面）である。入力空間で線形分離不可能なサンプルが、 特徴写像によって一般位置に写され、線形分離可能になっている。 この様に、 入力データ次元で線形分離不可能なサンプルを、特徴写像によって写して識別面を構成し、元の次元に戻すSVMを 非線形SVM という。 この場合、識別面は曲がった形状を持つ（超曲面）。 それでは非線形SVMの定式化を見ていく。特徴写像を用いてサンプルを写像することで、高次元空間内のサンプル（特徴サンプル） \\(\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})\\ (i =1, \\dots, N)\\) が得られる。後は線形SVMの時と全く同様の議論を適用し、 双対問題は次の様に表現される: $$ \\begin{aligned} &\\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{j}) \\right] \\\\ &\\text{subject to : } \\alpha_{i} \\geq 0,\\ \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0 \\quad (i = 1, \\dots, N) \\nonumber\\end{aligned} $$ さて、 この様にして非線形SVMが実現できるが、 一般に、入力次元 \\(n\\) はもとより特徴空間の次元 \\(h\\) は非常に大きくなる（ \\(\\infty\\) 次元にすらなりうる）。特徴写像 \\(\\boldsymbol{\\phi}\\) を構成する \\(h\\) 個の非線形な基底を用意するのは、非常に困難であり、 実用上大変な不便が生じる。 そこで、特徴写像同士の内積 \\(\\boldsymbol{\\phi}(\\boldsymbol{x}\\_{i})&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}\\_{j})\\) の計算結果はノルムなので、その内積を計算するのではなく、 天下り的に、最初から内積値を与えてしまうやり方がある。 即ち、 特徴写像同士の内積値を、 カーネル関数 \\(K : \\mathbb{R}&#94;{n} \\times \\mathbb{R}&#94;{n} \\to \\mathbb{R}\\) で定める: $$ \\begin{aligned} K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) = \\langle \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\boldsymbol{\\phi}(\\boldsymbol{x}_{j}) \\rangle = \\boldsymbol{\\phi}(\\boldsymbol{x}_{i})&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{j})\\end{aligned} $$ ここで \\(K\\) は入力データのみで記述されるので、特徴写像はカーネル関数の中に閉じ込められてしまい、 陽に現れない。 即ち、特徴写像を構成する必要がないというのが大きなメリットである。任意の関数がカーネルになるとは限らず、 マーサーの定理 7 という条件をカーネル関数は満たす必要がある。代表的なカーネル関数を以下に挙げる: 線形カーネル: $$ \\begin{aligned} K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) = \\langle \\boldsymbol{x}_{i}, \\boldsymbol{x}_{j} \\rangle \\end{aligned} $$ 入力次元における標準内積もカーネルとなり、 線形カーネルと呼ばれる。 ガウシアン（Radial Basis Function、 RBF:放射基底関数）カーネル: $$ \\begin{aligned} K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) = \\exp\\left(-\\frac{||\\boldsymbol{x}_{i}-\\boldsymbol{x}_{j}||&#94;{2}}{2\\sigma&#94;{2}}\\right) \\end{aligned} $$ 分散パラメタ \\(\\sigma\\) を伴ってガウス関数に従った分布を示す。実用上よく用いられる。 多項式カーネル: $$ \\begin{aligned} K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) = (\\langle \\boldsymbol{x}_{i}, \\boldsymbol{x}_{j} \\rangle + c)&#94;{k} \\end{aligned} $$ 正定数 \\(c\\) と多項式の次数 \\(k\\) によって構成されるカーネルである。ガウシアンカーネルよりも性能がパラメタに依存しない特徴を持つ。 カーネル関数 \\(K\\) を用いる事で、 非線形SVMの双対問題は次で表される: $$ \\begin{aligned} &\\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}K(\\boldsymbol{x}_{i}、 \\boldsymbol{x}_{j}) \\right] \\\\ &\\text{subject to : } \\alpha_{i} \\geq 0、\\ \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0 \\quad (i = 1, \\dots, N) \\nonumber\\end{aligned} $$ ソフトマージンSVM 前節までのSVMは、 マージンの内部にサンプルが入る事を一切許さないので、これを特に ハードマージンSVM ということがある。カーネルを用いた非線形ハードマージンSVMは、線形分離不可能なサンプルにでも強引に曲がりくねった識別面を構成する。これは実用に供する場合に問題になることがある。 例えば、データに雑音が乗っていたり、 一部のラベルを付け間違えたりする場合であり、これらは実データを扱う場合、 往々にして起こりうる事である。この様な雑音を拾いすぎてしまうとSVMの汎化性能 8 が悪化してしまうので、マージンの制約を緩め、一部のサンプルはマージンの内部に入っても良いようにSVMを改善する事を考える。マージンの内部にサンプルが入ることを許すSVMを ソフトマージンSVM と呼ぶことがある。 ハードマージンSVMの制約を緩める事を考える。サンプル \\(\\boldsymbol{x}\\_{i}\\) に対応するスラック（緩衝）変数 \\(\\eta_{i} \\geq 0\\ (i=1, \\dots, N)\\) を用意して、 SVMの制約を $$ \\begin{aligned} y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}\\_{i}) + b) \\geq 1 - \\eta_{i} \\quad (i = 1, \\dots, N)\\end{aligned} $$ とする（最初から、サンプルは特徴写像 \\(\\boldsymbol{\\phi}\\) によって写像されている場合を考える）。スラック変数はサンプルがマージンに食い込んでいる距離を表しており、もちろん、 \\(\\eta_{i}\\) は小さい方が良く、 \\(\\eta_{i} = 0\\) の時はハードマージンに一致する。 そして、 \\(\\eta_{i}\\) も同時に最適化に組み込んでしまう事で、ソフトマージンSVMが実現できる。 多くの文献では、スラック変数のノルムの取り方で異なる2種類のソフトマージンSVMの式を提示している: 1ノルムソフトマージンSVM・主問題 $$ \\begin{aligned} & \\min_{\\scriptsize \\boldsymbol{w}} \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} + C_{1}\\sum_{i=1}&#94;{N} \\eta_{i} \\\\ & \\text{subject to : } y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) \\geq 1 - \\eta_{i}, \\ \\eta_{i} \\geq 0 \\quad (i=1, \\dots, N) \\end{aligned} $$ 2ノルムソフトマージンSVM・主問題 $$ \\begin{aligned} &\\min_{\\scriptsize \\boldsymbol{w}} \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} + \\frac{C_{2}}{2}\\sum_{i=1}&#94;{N} \\eta_{i}&#94;{2} \\quad \\\\ &\\text{subject to : } y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) \\geq 1 - \\eta_{i} \\quad (i=1, \\dots, N) \\end{aligned} $$ ここで、 \\(C_{1}, C_{2}\\) はハードマージンとソフトマージンのトレードオフを与える定数 9 で、最適な値は実験等によって求める必要がある。 双対問題の導出は、前節までの議論と同様に、 KKT条件に当てはめる事により得られる: 1ノルムソフトマージンSVM・双対問題の導出 ラグランジアンは、 \\(\\beta_{i} \\geq 0\\) なる双対変数を導入して、 \\(-\\beta_{i}\\eta_{i} \\leq 0\\) より、 $$ \\begin{aligned} {\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}, \\boldsymbol{\\alpha}, \\boldsymbol{\\beta}) = \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{w} + C_{1} \\sum_{i=1}&#94;{N}\\eta_{i} + \\sum_{i=1}&#94;{N} \\alpha_{i} \\left\\{ 1 - \\eta_{i} - y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) \\right\\} + \\sum_{i=1}&#94;{N}(-\\beta_{i}\\eta_{i}) \\end{aligned} $$ より、 \\({\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}, \\boldsymbol{\\alpha}, \\boldsymbol{\\beta})\\) の \\(\\boldsymbol{w}, b, \\eta_{i},\\) による偏微分 \\(\\displaystyle\\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}}, \\frac{\\partial \\cal L}{\\partial b}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}}\\) は、 $$ \\begin{aligned} \\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}} = \\boldsymbol{w} - \\sum_{i=1}&#94;{N} y_{i} \\alpha_{i} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad \\frac{\\partial \\cal L}{\\partial b} = \\sum_{i=1}&#94;{N}\\alpha_{i}y_{i}, \\quad \\frac{\\partial \\cal L}{\\partial \\eta_{i}} = C_{1} - \\alpha_{i} - \\beta_{i} \\end{aligned} $$ \\(\\displaystyle\\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}} = \\boldsymbol{0}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}} = 0\\) とおくことで、最適時パラメタは、 $$ \\begin{aligned} \\boldsymbol{w}&#94;{\\star} = \\sum_{i=1}&#94;{N} y_{i} \\alpha_{i} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad C_{1} = \\alpha_{i} + \\beta_{i} \\end{aligned} $$ \\(\\boldsymbol{w}&#94;{\\star}\\) をラグランジアンに代入すると、 $$ \\begin{aligned} {\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\eta}&#94;{\\star}、 \\boldsymbol{\\alpha}、 \\boldsymbol{\\beta}) &= \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) + \\sum_{i=1}&#94;{N} (C_{1} - \\alpha_{i} - \\beta_{i}) \\eta_{i} \\\\ &= \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\end{aligned} $$ 制約条件 \\(\\alpha_{i}, \\beta_{i} \\geq 0\\) を含めて考えると、 \\(\\beta_{i} = C_{1} - \\alpha_{i} \\geq 0\\) より、 \\(\\alpha_{i}\\) についての制約 \\(0 \\leq \\alpha_{i} \\leq C_{1}\\) が得られ、結局、普通のSVMの双対問題に \\(\\alpha_{i}\\) についての制約を加えるだけで、1ノルムソフトマージンSVMが実現できる。 1ノルムソフトマージンSVM・双対問題 $$ \\begin{aligned} &\\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\right] \\\\ &\\text{subject to : } 0 \\leq \\alpha_{i} \\leq C_{1}, \\ \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0 \\quad (i = 1, \\dots, N) \\nonumber\\end{aligned} $$ 2ノルムソフトマージンSVM・双対問題の導出 ラグランジアンは、 $$ \\begin{aligned} {\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}, \\boldsymbol{\\alpha}) = \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{w} + \\frac{C_{2}}{2} \\sum_{i=1}&#94;{N}\\eta_{i}&#94;{2} + \\sum_{i=1}&#94;{N} \\alpha_{i} \\left\\{ 1 - \\eta_{i} - y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) \\right\\} \\end{aligned} $$ より、 \\({\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}, \\boldsymbol{\\alpha})\\) の \\(\\boldsymbol{w}, b, \\eta_{i}\\) による偏微分 \\(\\displaystyle\\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}}, \\frac{\\partial \\cal L}{\\partial b}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}}\\) は、 $$ \\begin{aligned} \\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}} = \\boldsymbol{w} - \\sum_{i=1}&#94;{N} y_{i} \\alpha_{i} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad \\frac{\\partial \\cal L}{\\partial b} = \\sum_{i=1}&#94;{N}\\alpha_{i}y_{i}, \\quad \\frac{\\partial \\cal L}{\\partial \\eta_{i}} = C_{2}\\eta_{i} - \\alpha_{i} \\end{aligned} $$ \\(\\displaystyle\\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}} = \\boldsymbol{0}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}} = 0\\) とおくことで、最適時パラメタは、 $$ \\begin{aligned} \\boldsymbol{w}&#94;{\\star} = \\sum_{i=1}&#94;{N} y_{i} \\alpha_{i} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad \\eta_{i}&#94;{\\star} = \\frac{\\alpha_{i}}{C_{2}} \\end{aligned} $$ これをラグランジアンに代入すると、 $$ \\begin{aligned} {\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\eta}&#94;{\\star}, \\boldsymbol{\\alpha}) &= \\sum_{i=1}&#94;{N} \\alpha_{i} + \\frac{1}{2C_{2}} \\sum_{i=1}&#94;{N} \\alpha_{i}&#94;{2} + \\sum_{i=1}&#94;{N} \\alpha_{i} \\left[ - \\frac{\\alpha_{i}}{C_{2}} - y_{i} \\sum_{j=1}&#94;{N} y_{j}\\alpha_{j} K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\right] + \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\\\ &= \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2C_{2}} \\sum_{i=1}&#94;{N} \\alpha_{i}&#94;{2} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\end{aligned} $$ ここで \\(y_{i}y_{j} \\in \\{-1, 1\\}\\) に注目すれば、 $$ \\begin{aligned} {\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\eta}&#94;{\\star}, \\boldsymbol{\\alpha}) = \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\left( K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) + \\frac{1}{C_{2}}\\delta_{ij} \\right) \\end{aligned} $$ と整理できる。ここで \\(\\delta_{ij}\\) はディラックのデルタであり、 $$ \\begin{aligned} \\delta_{ij} = \\left\\{ \\begin{array}{ll} 1 & i = j \\\\ 0 & otherwise \\end{array} \\right. \\end{aligned} $$ を満たす。 2ノルムソフトマージンSVMも、 結局、カーネル関数を簡単に書き換える事で実現できる。 2ノルムソフトマージンSVM・双対問題 $$ \\begin{aligned} &\\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\left(K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) + \\frac{1}{C_{2}}\\delta_{ij} \\right) \\right] \\\\ &\\text{subject to : } \\alpha_{i} \\geq 0, \\ \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0 \\quad (i = 1,\\dots,N) \\nonumber \\end{aligned} $$ SVR 一般にSVMは識別器として用いられる事がほとんどだが、ラベルを実数とした回帰問題 10 にも適用することができる。SVMによる回帰モデルのことを、 SVR （Support Vector Regression, サポートベクトル回帰）という。 基本的な考え方としては、図の様に、識別面（回帰面）を中心に幅 \\(2\\varepsilon\\) の\"帯\"に多くのサンプルが入るようにすれば良い。 帯を考慮して制約を表現すると、 $$ \\begin{aligned} | y_{i} - (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})+b) | \\leq \\varepsilon \\quad (i = 1, \\dots, N) \\end{aligned} $$ となる。 これはハードマージン的な制約であり、幅 \\(2\\varepsilon\\) の帯に全てのサンプルが入る事を要求している。もちろん \\(\\varepsilon\\) を十分に大きくとれば全てのサンプルは帯に入るが、帯が広すぎるために自由度が大きく、 結果汎化性能の悪化に繋がってしまう。ラベルが実数となり、 雑音の影響をより受けやすくなることから、SVRにおいては、 最初からスラック変数を用いて、ソフトマージン的に定式化することが多い。 スラック変数を用いて、帯から飛び出た距離 \\(\\eta_{i}&#94;{+}, \\eta_{i}&#94;{-} \\geq 0\\) を次で定義する（図参照）: $$ \\begin{aligned} \\eta_{i}&#94;{+} = \\left\\{ \\begin{array}{ll} y_{i} - \\varepsilon - (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})+b) & y_{i} \\geq (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})+b) + \\varepsilon \\\\ 0 & otherwise \\end{array} \\right. \\\\ \\eta_{i}&#94;{-} = \\left\\{ \\begin{array}{ll} (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})+b) - y_{i} - \\varepsilon & y_{i} \\leq (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})+b) - \\varepsilon \\\\ 0 & otherwise \\end{array} \\right. \\end{aligned} $$ なお、サンプルは帯からどちらか一方にしか飛び出ないので、 \\(\\eta_{i}&#94;{+}, \\eta_{i}&#94;{-}\\) のいずれか一方は必ず \\(0\\) となり、サンプルが帯に収まっている時は両方共 \\(0\\) となる。スラック変数を用いる事で、 制約は次のように表現できる: $$ \\begin{aligned} \\left\\{ \\begin{array}{l} (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})+b) - y_{i} \\leq \\varepsilon + \\eta_{i}&#94;{-} \\\\ y_{i} - (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})+b) \\leq \\varepsilon + \\eta_{i}&#94;{+} \\end{array} \\right. \\end{aligned} $$ ソフトマージンの時と同様に考える事で、 最適化問題が定式化できる: 1ノルムSVR・主問題 $$ \\begin{aligned} &\\min_{\\scriptsize \\boldsymbol{w}} \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} + C_{1}\\sum_{i=1}&#94;{N} (\\eta_{i}&#94;{+} + \\eta_{i}&#94;{-}) \\\\ &\\text{subject to : } (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) - y_{i} \\leq \\varepsilon + \\eta_{i}&#94;{-}, \\ y_{i} - (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) \\leq \\varepsilon + \\eta_{i}&#94;{+} \\quad (i=1,\\dots,N) \\end{aligned} $$ 2ノルムSVR・主問題 $$ \\begin{aligned} &\\min_{\\scriptsize \\boldsymbol{w}} \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} + \\frac{C_{2}}{2}\\sum_{i=1}&#94;{N} \\left\\{ (\\eta_{i}&#94;{+})&#94;{2} + (\\eta_{i}&#94;{-})&#94;{2} \\right\\} \\\\ &\\text{subject to : } (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) - y_{i} \\leq \\varepsilon + \\eta_{i}&#94;{-}, \\ y_{i} - (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) \\leq \\varepsilon + \\eta_{i}&#94;{+} \\quad (i=1, \\dots, N) \\end{aligned} $$ 後はKKT条件にぶち込むだけの流れ作業である。よし、じゃあぶち込んでやるぜ！ 1ノルムSVR・双対問題の導出 $$ \\begin{aligned} \\begin{split} &{\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}&#94;{+}, \\boldsymbol{\\eta}&#94;{-}, \\boldsymbol{\\alpha}&#94;{+}, \\boldsymbol{\\alpha}&#94;{-}, \\boldsymbol{\\beta}&#94;{+}, \\boldsymbol{\\beta}&#94;{-}) = \\\\ &\\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{w} + C_{1} \\sum_{i=1}&#94;{N}(\\eta_{i}&#94;{+}+\\eta_{i}&#94;{-}) + \\sum_{i=1}&#94;{N}(-\\beta_{i}&#94;{+}\\eta_{i}&#94;{+} -\\beta_{i}&#94;{-}\\eta_{i}&#94;{-} ) \\\\ &+ \\sum_{i=1}&#94;{N} \\left[ \\alpha_{i}&#94;{-} \\left\\{ (\\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) - y_{i} - \\varepsilon - \\eta_{i}&#94;{-} \\right\\} + \\alpha_{i}&#94;{+} \\left\\{ y_{i} - (\\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) - \\varepsilon - \\eta_{i}&#94;{+} \\right\\} \\right] \\end{split} \\end{aligned} $$ より、 \\({\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}&#94;{+}, \\boldsymbol{\\eta}&#94;{-}, \\boldsymbol{\\alpha}&#94;{+}, \\boldsymbol{\\alpha}&#94;{-}, \\boldsymbol{\\beta}&#94;{+}, \\boldsymbol{\\beta}&#94;{-})\\) の \\(\\boldsymbol{w}, b, \\eta_{i}&#94;{+}, \\eta_{i}&#94;{-}\\) による偏微分 \\(\\displaystyle\\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}}, \\frac{\\partial \\cal L}{\\partial b}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{+}}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{-}}\\) は、 $$ \\begin{aligned} \\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}} = \\boldsymbol{w} + \\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-} - \\alpha_{i}&#94;{+}) \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad \\frac{\\partial \\cal L}{\\partial b} = \\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-} - \\alpha_{i}&#94;{+}) \\\\ \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{+}} = C_{1} - \\alpha_{i}&#94;{+} - \\beta_{i}&#94;{+}, \\quad \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{-}} = C_{1} - \\alpha_{i}&#94;{-} - \\beta_{i}&#94;{-} \\end{aligned} $$ それぞれ \\(0\\) とおくと、 $$ \\begin{aligned} \\boldsymbol{w}&#94;{\\star} = \\sum_{i=1}&#94;{N} (\\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-}) \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad \\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-} - \\alpha_{i}&#94;{+}) = 0, \\quad C_{1} = \\alpha_{i}&#94;{+} + \\beta_{i}&#94;{+} = \\alpha_{i}&#94;{-} + \\beta_{i}&#94;{-} \\end{aligned} $$ これをラグランジアンに代入すると、 $$ \\begin{aligned} \\begin{split} &{\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\eta}&#94;{+\\star}, \\boldsymbol{\\eta}&#94;{-\\star}, \\boldsymbol{\\alpha}&#94;{+}, \\boldsymbol{\\alpha}&#94;{-}, \\boldsymbol{\\beta}&#94;{+}, \\boldsymbol{\\beta}&#94;{-}) = \\\\ &\\frac{1}{2} \\sum_{i、j=1}&#94;{N} (\\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-})(\\alpha_{j}&#94;{+} - \\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) + C_{1} \\sum_{i=1}&#94;{N}(\\eta_{i}&#94;{+}+\\eta_{i}&#94;{-}) - \\sum_{i=1}&#94;{N}(\\beta_{i}&#94;{+}\\eta_{i}&#94;{+} + \\beta_{i}&#94;{-}\\eta_{i}&#94;{-}) \\\\ &+\\sum_{i=1}&#94;{N} \\left[ \\alpha_{i}&#94;{-}\\sum_{j=1}&#94;{N}(\\alpha_{j}&#94;{+}-\\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) - \\alpha_{i}&#94;{+}\\sum_{j=1}&#94;{N}(\\alpha_{j}&#94;{+}-\\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\right] \\\\ &+\\sum_{i=1}&#94;{N}\\left[ \\alpha_{i}&#94;{-} (-\\varepsilon-\\eta_{i}&#94;{-}-y_{i}) + \\alpha_{i}&#94;{+} (-\\varepsilon-\\eta_{i}&#94;{+}+y_{i}) \\right] \\end{split} \\end{aligned} $$ \\(C_{1} = \\alpha_{i}&#94;{+} + \\beta_{i}&#94;{+} = \\alpha_{i}&#94;{-} + \\beta_{i}&#94;{-}\\) を用いて整理すると、 $$ \\begin{aligned} \\begin{split} &{\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\eta}&#94;{+\\star}, \\boldsymbol{\\eta}&#94;{-\\star}, \\boldsymbol{\\alpha}&#94;{+}, \\boldsymbol{\\alpha}&#94;{-}, \\boldsymbol{\\beta}&#94;{+}, \\boldsymbol{\\beta}&#94;{-}) = \\\\ &\\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{+}-\\alpha_{i}&#94;{-}) - \\varepsilon\\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-}+\\alpha_{i}&#94;{+}) - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} (\\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-})(\\alpha_{j}&#94;{+} - \\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\end{split} \\end{aligned} $$ ところで、上でも既に述べたが \\(\\eta_{i}&#94;{+}, \\eta_{i}&#94;{-}\\) のどちらか一方は必ず \\(0\\) となるので、その場合は対応する \\(\\alpha_{i}&#94;{+}, \\alpha_{i}&#94;{-}\\) の制約条件はなくなり、従って、 \\(\\alpha_{i}&#94;{+}, \\alpha_{i}&#94;{-}\\) のどちらか一方も \\(0\\) となる。この事から \\(\\alpha_{i} = \\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-}\\) とおけば、 \\(\\alpha_{i}&#94;{-} + \\alpha_{i}&#94;{+} = |\\alpha_{i}|\\) と表現できるので、双対問題は以下の様に表現できる。 1ノルムSVR・双対問題 $$ \\begin{aligned} &\\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N}y_{i}\\alpha_{i} - \\varepsilon\\sum_{i=1}&#94;{N}|\\alpha_{i}| - \\frac{1}{2} \\sum_{i、j=1}&#94;{N}\\alpha_{i}\\alpha_{j}K(\\boldsymbol{x}_{i}、 \\boldsymbol{x}_{j}) \\right] \\\\ &\\text{subject to : } \\sum_{i=1}&#94;{N}\\alpha_{i} = 0, \\ -C_{1} \\leq \\alpha_{i} \\leq C_{1} \\quad (i = 1、\\dots、N) \\nonumber \\end{aligned} $$ 2ノルムSVR・双対問題の導出 $$ \\begin{aligned} &{\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}&#94;{+}, \\boldsymbol{\\eta}&#94;{-}, \\boldsymbol{\\alpha}&#94;{+}, \\boldsymbol{\\alpha}&#94;{-}) = \\\\ &\\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{w} + \\frac{C_{2}}{2} \\sum_{i=1}&#94;{N} \\{ (\\eta_{i}&#94;{+})&#94;{2} + (\\eta_{i}&#94;{-})&#94;{2} \\} \\\\ &+\\sum_{i=1}&#94;{N} \\left[ \\alpha_{i}&#94;{-} \\left\\{ (\\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) - y_{i} - \\varepsilon - \\eta_{i}&#94;{-} \\right\\} + \\alpha_{i}&#94;{+} \\left\\{ y_{i} - (\\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) - \\varepsilon - \\eta_{i}&#94;{+} \\right\\} \\right] \\end{aligned} $$ より、 \\({\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}&#94;{+}, \\boldsymbol{\\eta}&#94;{-}, \\boldsymbol{\\alpha}&#94;{+}, \\boldsymbol{\\alpha}&#94;{-})\\) の \\(\\boldsymbol{w}, b, \\eta_{i}&#94;{+}, \\eta_{i}&#94;{-}\\) による偏微分 \\(\\displaystyle\\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}}, \\frac{\\partial \\cal L}{\\partial b}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{+}}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{-}}\\) は、 $$ \\begin{aligned} \\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}} = \\boldsymbol{w} + \\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-} - \\alpha_{i}&#94;{+}) \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad \\frac{\\partial \\cal L}{\\partial b} = \\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-} - \\alpha_{i}&#94;{+}) \\\\ \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{+}} = C_{2}\\eta_{i}&#94;{+} - \\alpha_{i}&#94;{+}, \\quad \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{-}} = C_{2}\\eta_{i}&#94;{-} - \\alpha_{i}&#94;{-} \\end{aligned} $$ それぞれ \\(0\\) とおくと、 $$ \\begin{aligned} \\boldsymbol{w}&#94;{\\star} = \\sum_{i=1}&#94;{N} (\\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-}) \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad \\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-} - \\alpha_{i}&#94;{+}) = 0, \\quad \\eta_{i}&#94;{+\\star} = \\frac{\\alpha_{i}&#94;{+}}{C_{2}}, \\quad \\eta_{i}&#94;{-\\star} = \\frac{\\alpha_{i}&#94;{-}}{C_{2}} \\end{aligned} $$ \\(\\boldsymbol{w}&#94;{\\star}\\) をラグランジアンに代入すると、 $$ \\begin{aligned} \\begin{split} &{\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\eta}&#94;{+\\star}, \\boldsymbol{\\eta}&#94;{-\\star}, \\boldsymbol{\\alpha}&#94;{+},\\boldsymbol{\\alpha}&#94;{-}) = \\\\ &\\frac{1}{2} \\sum_{i、j=1}&#94;{N} (\\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-})(\\alpha_{j}&#94;{+} - \\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) + \\frac{1}{C_{2}} \\sum_{i=1}&#94;{N}\\left\\{ (\\alpha_{i}&#94;{+})&#94;{2}+(\\alpha_{i}&#94;{-})&#94;{2} \\right\\} \\\\ &+\\sum_{i=1}&#94;{N} \\left[ \\alpha_{i}&#94;{-}\\sum_{j=1}&#94;{N}(\\alpha_{j}&#94;{+}-\\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) - \\alpha_{i}&#94;{+}\\sum_{j=1}&#94;{N}(\\alpha_{j}&#94;{+}-\\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\right] \\\\ &+\\sum_{i=1}&#94;{N}\\left[ \\alpha_{i}&#94;{-} (-\\varepsilon - \\frac{\\alpha_{i}&#94;{-}}{C_{2}} - y_{i}) + \\alpha_{i}&#94;{+} (- \\varepsilon - \\frac{\\alpha_{i}&#94;{+}}{C_{2}} +y_{i}) \\right] \\\\ &=\\sum_{i=1}&#94;{N} (\\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-})y_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N}(\\alpha_{i}&#94;{+}-\\alpha_{i}&#94;{-})(\\alpha_{j}&#94;{+}-\\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\\\ &-\\varepsilon\\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-} + \\alpha_{i}&#94;{+}) - \\frac{1}{2C_{2}}\\sum_{i=1}&#94;{N}\\left\\{ (\\alpha_{i}&#94;{-})&#94;{2} + (\\alpha_{i}&#94;{+})&#94;{2} \\right\\} \\end{split} \\end{aligned} $$ 1ノルムSVRの時と同様に、 \\(\\alpha_{i} = \\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-}\\) とおくと、 \\((\\alpha_{i}&#94;{+})&#94;{2} + (\\alpha_{i}&#94;{-})&#94;{2} = \\alpha_{i}&#94;{2}\\) が成り立つので、双対問題は以下の様に表現できる。 2ノルムSVR・双対問題 $$ \\begin{aligned} & \\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N}y_{i}\\alpha_{i} - \\varepsilon\\sum_{i=1}&#94;{N}|\\alpha_{i}| - \\frac{1}{2} \\sum_{i, j=1}&#94;{N}\\alpha_{i}\\alpha_{j}\\left( K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) + \\frac{1}{C_{2}} \\right) \\right] \\\\ & \\text{subject to : } \\sum_{i=1}&#94;{N}\\alpha_{i} = 0 \\quad (i = 1, \\dots, N) \\nonumber \\end{aligned} $$ 実装の例 実装例は ここ にある。本稿では要点を絞って見ていく。 学習 学習則の導出 SVMの学習は、双対問題 $$ \\begin{aligned} &\\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{j}) \\right] = \\max_{\\scriptsize \\boldsymbol{\\alpha}} {\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\alpha}) \\\\ &\\text{subject to : } \\alpha_{i} \\geq 0,\\ \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0 \\quad (i = 1, \\dots, N) \\end{aligned} $$ を解けば良いことになる。 脚注 4 で既に触れたが、SVMのマージン最大化は凸計画問題である。従って局所最適解が存在せず、極大値が大域的な最大値に一致する。 ソフトマージンに対応する時は、1ノルムソフトマージンの際には係数に値域 \\(0 \\geq \\alpha_{i} \\geq C_{1}\\ (i=1,...,N)\\) を設け、2ノルムの際にはカーネル関数 \\(K\\) を次のように書き換えれば良い： $$ K'(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) = K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) + \\frac{\\delta_{ij}}{C_{2}} $$ ここでは簡単な 最急勾配法 によって解を求めることを考える。 最急勾配法の原理は単純である。 \\(F(\\boldsymbol{\\alpha}) = {\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\alpha})\\) とおくと、その \\(\\boldsymbol{\\alpha}\\) による偏微分 \\(\\frac{\\partial F(\\boldsymbol{\\alpha})}{\\partial \\boldsymbol{\\alpha}}\\) は 勾配 、即ち \\(F(\\boldsymbol{\\alpha})\\) の最も上昇する方向を指すベクトルとなるので、係数の更新量 \\(\\Delta\\boldsymbol{\\alpha}\\) は学習率 \\(\\eta > 0\\) を用いて $$ \\Delta \\boldsymbol{\\alpha} = \\eta \\frac{\\partial F(\\boldsymbol{\\alpha})}{\\partial \\boldsymbol{\\alpha}} $$ とすれば良い 11 。学習の収束判定は、例えば \\(||\\Delta \\boldsymbol{\\alpha}||\\) が十分小さくなった時とすれば良く、その時は極大値が得られている。 実際に \\(\\frac{\\partial F(\\boldsymbol{\\alpha})}{\\partial \\boldsymbol{\\alpha}}\\) を計算することを考える。 \\(\\frac{\\partial F(\\boldsymbol{\\alpha})}{\\partial \\alpha_{i}}\\ (i=1,...,N)\\) は、 $$ \\begin{aligned} \\frac{\\partial F(\\boldsymbol{\\alpha})}{\\partial \\alpha_{i}} &= 1 - \\frac{1}{2} \\frac{\\partial}{\\partial \\alpha_{i}} \\left( \\alpha_{1} \\alpha_{1} y_{1} y_{1} \\boldsymbol{x}_{1}&#94;{\\mathsf{T}} \\boldsymbol{x}_{1} + ... + \\alpha_{i} \\alpha_{1} y_{i} y_{1} \\boldsymbol{x}_{i}&#94;{\\mathsf{T}} \\boldsymbol{x}_{1} + ... + \\alpha_{i} \\alpha_{N} y_{i} y_{N} \\boldsymbol{x}_{i}&#94;{\\mathsf{T}} \\boldsymbol{x}_{N} + ... + \\alpha_{1} \\alpha_{i} y_{1} y_{i} \\boldsymbol{x}_{1}&#94;{\\mathsf{T}} \\boldsymbol{x}_{i} + ... + \\alpha_{N} \\alpha_{i} y_{N} y_{i} \\boldsymbol{x}_{N}&#94;{\\mathsf{T}} \\boldsymbol{x}_{i} + ... + \\alpha_{N} \\alpha_{N} y_{N} y_{N} \\boldsymbol{x}_{N}&#94;{\\mathsf{T}} \\boldsymbol{x}_{N} \\right) \\\\ &= 1 - \\sum_{j=1}&#94;{N} \\alpha_{j} y_{i} y_{j} \\boldsymbol{x}_{i}&#94;{\\mathsf{T}} \\boldsymbol{x}_{j} \\end{aligned} $$ よって、ステップ \\(t\\) 時の係数 \\(\\alpha_{i}(t)\\ (i=1,...,N)\\) について以下の更新規則に従って学習を行えば良い： $$ \\alpha_{i}(t+1) = \\alpha_{i}(t) + \\eta \\left( 1 - \\sum_{j=1}&#94;{N} \\alpha_{j} y_{i} y_{j} \\boldsymbol{x}_{i}&#94;{\\mathsf{T}} \\boldsymbol{x}_{j} \\right) $$ 実装 学習を行っている箇所を抜粋すると次の様になる： /* 勾配値の計算 */ diff_dist = 0.0f ; for ( i_x = 0 ; i_x < handle -> sample_num ; ++ i_x ) { diff_sum = 0.0f ; for ( i_y = 0 ; i_y < handle -> sample_num ; ++ i_y ) { /* C2を踏まえたカーネル関数値を計算 */ kernel_val = GRAM_MATRIX_AT ( handle -> gram_matrix , handle -> sample_num , i_x , i_y ); if ( i_x == i_y ) { kernel_val += ( 1.0f / soft_margin_C2 ); } diff_sum += handle -> dual_coef [ i_y ] * handle -> sample_label [ i_y ] * kernel_val ; } diff_sum *= handle -> sample_label [ i_x ]; diff_dual_coef [ i_x ] = 1.0f - diff_sum ; diff_dist += ( 1.0f - diff_sum ) * ( 1.0f - diff_sum ); } /* 双対係数の更新 */ for ( i_sample = 0 ; i_sample < handle -> sample_num ; ++ i_sample ) { if ( handle -> sample_label [ i_sample ] == 0 ) { continue ; } /* printf(\"dual_coef[%d]:%f -> \", i_sample, handle->dual_coef[i_sample]); */ handle -> dual_coef [ i_sample ] += handle -> learning_rate * ( diff_dual_coef [ i_sample ] + SMPSVM_MOMENT_RATE * pre_diff_dual_coef [ i_sample ]); /* printf(\"%f \\n\", handle->dual_coef[i_sample]); */ /* 非数,無限チェック */ if ( isnan ( handle -> dual_coef [ i_sample ]) || isinf ( handle -> dual_coef [ i_sample ]) ) { fprintf ( stderr , \"Detected NaN or Inf Dual-Coffience. \\n \" ); return - 3 ; } } 既にコメントが付いているが、特筆すべき点について補足する。 /* C2を踏まえたカーネル関数値を計算 */ kernel_val = GRAM_MATRIX_AT ( handle -> gram_matrix , handle -> sample_num , i_x , i_y ); 予め計算しておいたカーネル関数値をグラム行列から取り出している。学習中は何度もカーネル関数値を計算するため、グラム行列を用意しておくことで若干高速化できる。 if ( i_x == i_y ) { kernel_val += ( 1.0f / soft_margin_C2 ); } 2ノルムソフトマージンのカーネル関数値を加味している。2ノルムソフトマージンを使用しない場合は soft_margin_C2 == FLT_MAX となっているため、無視できる。 handle -> dual_coef [ i_sample ] += handle -> learning_rate * ( diff_dual_coef [ i_sample ] + SMPSVM_MOMENT_RATE * pre_diff_dual_coef [ i_sample ]); 係数更新を行っている。ここでは、単純な最急勾配分のみだけではなく、前回の勾配値に定数を乗じて加えた モーメント法 を使用している。一般にモーメント法を使用したほうが学習が早くなることが知られている。 制約条件の考慮 学習則は単純に見えても実装時に落とし穴になるのが制約条件である。 正例と負例の双対係数の和を等しくする KKT条件から導かれる \\(\\boldsymbol{\\alpha}\\) についての制約 $$ \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0 $$ を実現するのが案外難しい。上の制約から、 $$ \\begin{aligned} &\\sum_{y_{i}=1} \\alpha_{i} - \\sum_{y_{i}=-1} \\alpha_{i} = 0 \\\\ &\\iff \\sum_{y_{i}=1} \\alpha_{i} = \\sum_{y_{i}=-1} \\alpha_{i} \\end{aligned} $$ が導かれるため、正例と負例の双対係数の和は等しくなる事が分かる。 本実装では、 \\(\\alpha_{i}y_{i}\\) の平均を取り、全係数 \\(\\alpha_{i}\\ (i=1,...,N)\\) をその平均に寄せることで上記の制約を満たすように係数を修正している。 /* 制約1: 正例と負例の双対係数和を等しくする. */ dual_coef_average = 0.0f ; for ( i_sample = 0 ; i_sample < handle -> sample_num ; ++ i_sample ) { dual_coef_average += ( handle -> sample_label [ i_sample ] * handle -> dual_coef [ i_sample ]); } dual_coef_average /= handle -> sample_num ; for ( i_sample = 0 ; i_sample < handle -> sample_num ; ++ i_sample ) { if ( handle -> sample_label [ i_sample ] == 0 ) { continue ; } handle -> dual_coef [ i_sample ] -= ( dual_coef_average / handle -> sample_label [ i_sample ]); } この制約を満たすための実装はこの限りではない。 双対係数は非負 双対係数は非負でなければならないため、負になった係数は全て0に修正してしまう。 学習が進むに連れて0の係数が増えていくが、それはSVMの持つスパース学習の効果が現れている状態である。学習が収束した時、0に潰れず非負値となった係数に対応するサンプルが サポートベクトル である。 /* 制約2: 双対係数は非負 */ coef_dist = 0.0f ; for ( i_sample = 0 ; i_sample < handle -> sample_num ; ++ i_sample ) { if ( handle -> dual_coef [ i_sample ] < 0.0f ) { handle -> dual_coef [ i_sample ] = 0.0f ; } else if ( handle -> dual_coef [ i_sample ] > soft_margin_C1 ) { /* C1ノルムの制約を適用 */ handle -> dual_coef [ i_sample ] = soft_margin_C1 ; } /* ここで最終結果が出る. 前回との変化を計算 */ coef_diff = pre_dual_coef [ i_sample ] - handle -> dual_coef [ i_sample ]; coef_dist += ( coef_diff * coef_diff ); } 本実装では、非負条件に咥えて1ノルムソフトマージンの制約も追加で判定している。1ノルムソフトマージンを使用しない時は soft_margin_C1 == FLT_MAX となっているため、無視できる。 識別 マージンの定式化 で述べたが、SVMのクラス識別は出力値 \\(y\\) の正負によって判断する 12 。SVMの出力式 $$ g(\\boldsymbol{x}, \\boldsymbol{w}) = \\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{x} + b $$ に、KKT条件における最適条件 \\(\\boldsymbol{w}&#94;{\\star} = \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i}\\boldsymbol{x}_{i}\\) を代入すれば、次の 双対表現 が得られる： $$ g(\\boldsymbol{x}, \\boldsymbol{w}&#94;{\\star}) = \\sum_{i=1}&#94;{N} \\alpha_{i} y_{i} K(\\boldsymbol{x}_{i}, \\boldsymbol{x}) + b $$ 識別の際には、学習済みの係数 \\(\\boldsymbol{\\alpha}\\) を使用して上式を計算し、その正負を判定すれば良い。実装としては次の様になる： /* ネットワーク出力計算 */ network_output = 0.0f ; for ( i_sample = 0 ; i_sample < handle -> sample_num ; ++ i_sample ) { /* 係数が正に相当するサンプル（サポートベクトル） * のみを計算する */ if ( handle -> dual_coef [ i_sample ] > 0.0f ) { network_output += handle -> sample_label [ i_sample ] * handle -> dual_coef [ i_sample ] * handle -> kernel_function ( handle -> sample_data [ i_sample ], normalized_data , data_dim , handle -> kernel_parameter ); } } /* 識別 */ * result = ( network_output >= 0.0f ) ? 1 : - 1 ; 脚注 高村大也、 奥村学、 \"言語処理のための機械学習入門\"、 コロナ社、 2010 ↩ 高橋治久、 堀田一弘、 \"学習理論\" コロナ社、 2009 ↩ くどいかもしれないが、 サポートベクトルは最も識別面に近いサンプルなので、この仮定により \\(y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}+b) \\geq l \\quad (i=1, \\dots, N)\\) が成り立つ。 ↩ （証明） - 最適化対象について、 \\(\\displaystyle \\frac{1}{2}\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} = \\frac{1}{2} \\sum_{i=1}&#94;{n} w_{i}&#94;{2}\\) より（ \\(\\boldsymbol{w}=[w_{1}\\dots w_{n}]&#94;\\mathsf{T}\\) ）、 明らかに下に凸である。 - 制約条件について、 \\(W_{i} = \\{ \\boldsymbol{w} | y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}\\_{i}+b) \\geq 1 \\}\\) とおくと、 \\(\\forall \\boldsymbol{w}&#94;{\\prime}, \\boldsymbol{w}&#94;{\\prime\\prime} \\in W_{i}, \\forall t \\in [0, 1]\\) に対して、 $$\\begin{aligned} y_{i} \\left[ \\left( t\\boldsymbol{w}&#94;{\\prime\\mathsf{T}} + (1-t) \\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}} \\right) \\boldsymbol{x}\\_{i} + b \\right] = y_{i} \\left[ t(\\boldsymbol{w}&#94;{\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} - \\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i}) + \\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b \\right] \\\\ = y_{i} \\left[ t\\left( (\\boldsymbol{w}&#94;{\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b) - (\\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b) \\right) + \\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b \\right] \\\\ = t y_{i} (\\boldsymbol{w}&#94;{\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b) + (1-t) y_{i}(\\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b) \\\\ \\geq t + (1-t) = 1\\end{aligned}$$ よって、 \\(t\\boldsymbol{w}&#94;{\\prime} + (1-t) \\boldsymbol{w}&#94;{\\prime\\prime} \\in W_{i}\\) より \\(W_{i}\\) は凸集合。 最適化問題においては、 \\(W_{i}\\) の共通部分 \\(\\bigcap_{i=1}&#94;{N} W_{i}\\) を考えれば良く、 凸集合の積集合もまた凸集合 なので、 制約条件も凸集合となる。以上の2点より、 マージン最大化は凸計画問題。 （凸集合の積集合もまた凸集合であることの証明）2つの凸集合を \\(A_{1},A_{2}\\) とする。 両者の集合の積 \\(A_{1}\\cap A_{2}\\) が空集合ならば、 空集合は凸集合と定義されるので命題は成立する。 一般に \\(A_{1}\\cap A_{2}\\) から2点 \\(x,y\\) をとると, \\(x, y\\) を結ぶ線分は、 \\(A_{1}, A_{2}\\) は共に凸集合なので、 \\(A_{1}\\) にも \\(A_{2}\\) にも属していて飛び出ることはない。 これは集合の積 \\(A_{1}\\cap A_{2}\\) が凸集合であることを示している。 ↩ ↩ （鞍点 \\((\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star})\\) が最適点となる事の証明） \\((\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star})\\) は鞍点なので、 $$\\begin{aligned} {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}&#94;{\\star}) \\leq {\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star}) \\leq {\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}) \\end{aligned}$$ を満たす。 従って右側の不等式から \\(\\boldsymbol{\\alpha}&#94;{\\star\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}&#94;{\\star}) \\leq \\boldsymbol{\\alpha}&#94;{\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}&#94;{\\star})\\) が任意の \\(\\boldsymbol{\\alpha}\\) で成立する。 即ち \\(\\boldsymbol{\\alpha} = \\boldsymbol{0}\\) の時、 \\(g_{i}(\\boldsymbol{v}&#94;{\\star}) \\geq 0\\) と併せて \\(\\boldsymbol{\\alpha}&#94;{\\star\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}&#94;{\\star}) = 0\\) が成立する。 更に、 ここで関係式 $$\\begin{aligned} {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}&#94;{\\star}) - {\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star}) \\leq \\left( \\frac{\\partial {\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha})}{\\partial \\boldsymbol{v}} \\right)&#94;{\\mathsf{T}} (\\boldsymbol{v} - \\boldsymbol{v}&#94;{\\star}) \\end{aligned}$$ を用いる（証明は後術）と、 鞍点であることから \\(\\displaystyle\\frac{\\partial {\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha})}{\\partial \\boldsymbol{v}} = \\boldsymbol{0}\\) であり、 また、 \\(\\boldsymbol{\\alpha}&#94;{\\star\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}&#94;{\\star}) = 0\\) より、 $$\\begin{aligned} {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}&#94;{\\star}) - {\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star}) &= {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}&#94;{\\star}) - f(\\boldsymbol{v}&#94;{\\star}) \\leq 0 \\iff f(\\boldsymbol{v}&#94;{\\star}) \\geq {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}&#94;{\\star}) \\end{aligned}$$ が成り立つ。 更に、 もとより \\(\\boldsymbol{\\alpha}&#94;{\\star\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}) \\geq 0\\) なので、 $$\\begin{aligned} f(\\boldsymbol{v}) \\leq f(\\boldsymbol{v}) + \\boldsymbol{\\alpha}&#94;{\\star\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}) = {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}&#94;{\\star}) \\end{aligned}$$ 従って \\(f(\\boldsymbol{v}&#94;{\\star}) \\geq f(\\boldsymbol{v})\\) が任意の \\(\\boldsymbol{v}\\) で成立し、 \\((\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star})\\) が最適点となる事が示された。 次いで(＊)を証明する。 \\({\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha})\\) が凸関数ならば、 \\({\\cal L}(t\\boldsymbol{v}&#94;{\\prime}+(1-t)\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) \\geq t {\\cal L}(\\boldsymbol{v}&#94;{\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) + (1-t) {\\cal L}(\\boldsymbol{v}&#94;{\\prime}, \\boldsymbol{\\alpha}&#94;{\\star})\\) が \\(t \\in [0,1]\\) で成立する。 よって、 $$t{\\cal L}(\\boldsymbol{v}&#94;{\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) \\leq t{\\cal L}(\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) - {\\cal L}(\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) + {\\cal L}(t\\boldsymbol{v}&#94;{\\prime}+(1-t)\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) \\iff {\\cal L}(\\boldsymbol{v}&#94;{\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) \\leq {\\cal L}(\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) + \\frac{{\\cal L}(\\boldsymbol{v}&#94;{\\prime\\prime} + t(\\boldsymbol{v}&#94;{\\prime}-\\boldsymbol{v}&#94;{\\prime\\prime}), \\boldsymbol{\\alpha}&#94;{\\star}) - {\\cal L}(\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star})}{t} $$ ここで \\(t \\to 0\\) ならしめれば、 方向微分と勾配の関係式より、 $${\\cal L}(\\boldsymbol{v}&#94;{\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) - {\\cal L}(\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) \\leq \\left( \\frac{\\partial {\\cal L}(\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star})}{\\partial \\boldsymbol{v}} \\right)&#94;{\\mathsf{T}} (\\boldsymbol{v}&#94;{\\prime} - \\boldsymbol{v}&#94;{\\prime\\prime})$$ を得る。 ↩ 互いに同一平面上 以外 の位置にある事。 例えば、2次元空間では同一直線上以外の位置であり、3次元空間では同一平面上以外の位置である。異なるクラスのサンプルが一般位置にあれば、もとより線形分離可能である。 ↩ 有限個数 \\(N<\\infty\\) のサンプルに対し、 \\((\\boldsymbol{G})\\_{ij} = K(\\boldsymbol{x}\\_{i}, \\boldsymbol{x}\\_{j})\\) 、即ち \\((i,j)\\) 成分の値が \\(K(\\boldsymbol{x}\\_{i}, \\boldsymbol{x}\\_{j})\\) となっている行列 \\(\\boldsymbol{G}\\) をグラム（カーネル）行列という。特徴写像が有限次元ならば、グラム行列が（有限）正定値行列ならば \\(K\\) はカーネル関数となる。特徴写像が無限次元の場合のカーネル関数の条件がマーサーの定理である。 その内容は、入力空間 \\(X\\subset \\mathbb{R}&#94;{n}\\) が有界閉集合（ \\(\\iff\\) コンパクト）であるとし、対象な連続関数 \\(K\\) が正定値、即ち任意の二乗可積分（二乗積分可能）な関数 \\(f\\) に対し $$\\begin{aligned} \\int_{X\\times X}K(x, z)f(x)f(z)dxdz \\geq 0\\end{aligned}$$ ならば、ヒルベルト空間の正規直交基底 \\(\\phi_{j}\\ (j=1, 2, \\dots)\\) で次式が一様収束するものが存在する場合、 \\(K\\) はカーネル関数である。 $$ \\begin{aligned} K(x, z) = \\sum_{j=1}&#94;{\\infty} \\phi_{j}(x)\\phi_{j}(z) \\end{aligned} $$ ↩ サンプルに現れない未知のデータでももれなく識別できる能力 ↩ 双対問題において、 \\(C_{1}, C_{2} \\to \\infty\\) とすると、ハードマージンSVMに一致することが分かる ↩ サンプルに最も当てはまる曲線（面）を探す問題。もう少し形式的に言うと、各サンプル \\(\\boldsymbol{x}\\_{i}\\) でのラベル \\(y_{i}\\) の平均値を表す関数 \\(f\\) を学習する問題。 ↩ ただし学習率 \\(\\eta\\) の決め方は問題依存である。一般に、 \\(\\eta\\) が小さすぎると学習が進行せず、大きすぎると極値を飛び越えてしまい学習が収束しない。 ↩ \\(y = 0\\) の場合の判断を明確にしている書類がない。ここでは正と判定する。 ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"記事","url":"/svmsapotobekutorumashin.html","loc":"/svmsapotobekutorumashin.html"},{"title":"MCMC（マルコフ連鎖モンテカルロ）法","text":"（Q****にマジギレして移行） 本稿ではMCMC法の解説のため、MC法による積分の計算方法（モンテカルロ積分）から、MCMCによる手法の概要を見ていく。MCMC法は有名かつ知り尽くされた手法で、多くの良質な説明資料 1 2 3 4 5 が存在している。従ってここの説明は読まずに、資料を見てもらった方が理解が早いかもしれない。 一般に MC（Monte-Calro, モンテカルロ）法 は、サンプリング（サンプルを乱数から生成すること）によってシミュレーションや数値計算を行う手法である。特に確率分布が関わる積分値 6 を近似的に求めるMC法はモンテカルロ積分と呼ばれる。モンテカルロ積分は確率的な推論の一種であり、大数の法則 7 によって、十分なサンプル数をとれば近似精度をいくらでも良くする事ができる。サンプリングの手間がある為、近似分布をあらかじめ仮定する様な決定論的な推論よりも遥かに推論が遅い。しかし、MCは近似分布が求められないような場合にも適用可能であり、汎用性が高いと言える。 MC法によって原理的には任意の解を求められるが、十分なサンプル数の要求というのが大きな問題を孕んでいる。サンプリングの自由度（範囲及び次元）が大きくなると、解の計算にあまり寄与しない（無駄な）サンプルが増えてしまう。計算を現実的かつ効率的に行うためには、サンプルの選択が重要になる。 そして MCMC（Markov Chain Monte-Calro, マルコフ連鎖モンテカルロ）法 は、新しいサンプルを以前に生成したサンプルに確率的に依存して（サンプルの列がマルコフ連鎖となる様に）生成するMC法である。MCMCでは、新しく生成したサンプルを採択（採用）するか棄却（捨てる）するかも確率的に判断する。この手続きによって、無駄なサンプルを極力減らすようにサンプリングを実行することができる。 MC法による積分 - モンテカルロ積分 確率変数を \\(d\\) 次元の実数値ベクトル 8 \\(\\boldsymbol{x} = [x_{1},\\dots,x_{d}]&#94;{\\mathsf{T}} \\in X \\subset \\mathbb{R}&#94;{d}\\) とする。ここで \\(X\\) は全事象 9 の集合である。 \\(\\boldsymbol{x}\\) の確率分布を \\(r(\\boldsymbol{x})\\) とし、関数 \\(h\\) の確率分布 \\(r\\) による平均（期待値） $$ I = \\int_{X} h(\\boldsymbol{x})r(\\boldsymbol{x}) d\\boldsymbol{x} = \\mathrm{E}_{r}[h(\\boldsymbol{x})] \\tag{1} $$ を求めることを考える。ここで、 \\(\\mathrm{E}_{p}[\\cdot]\\) は確率分布 \\(p\\) による平均を表す。 \\(I\\) において、関数 \\(h\\) の形に制約を与えておらず積分として様々な値が計算できる。例を挙げると: \\(h(\\boldsymbol{x}) = \\boldsymbol{x}\\) : この場合は \\(\\mathrm{E}_{r}[\\boldsymbol{x}]\\) 、即ち \\(\\boldsymbol{x}\\) の平均を求める \\(h(\\boldsymbol{x}) = (\\boldsymbol{x} - \\mathrm{E_{r}}[\\boldsymbol{x}])(\\boldsymbol{x} - \\mathrm{E_{r}}[\\boldsymbol{x}])&#94;{\\mathsf{T}}\\) : \\(\\boldsymbol{x}\\) の分散を求める ... その他 10 もし \\(r(\\boldsymbol{x})\\) が既知で、分布 \\(r\\) から簡単に独立にサンプリングできる 11 ならば、 \\(r(\\boldsymbol{x})\\) からの独立な（他のサンプルに依存して生成しない） \\(n\\) 個のサンプルを \\(\\boldsymbol{x_{1}}, \\boldsymbol{x_{2}}, \\dots, \\boldsymbol{x_{n}}\\) と書くと、 \\(I\\) の標本平均による近似値 \\(\\hat{I}\\) は $$ \\hat{I} = \\frac{1}{n} \\sum_{i=1}&#94;{n} h(\\boldsymbol{x_{i}}) \\tag{2} $$ で計算できる。大数の法則により、サンプル数の極限を取れば標本平均は真の平均に一致する: $$ \\lim_{n \\to \\infty} \\hat{I} = I $$ この様にして平均を求める方法を モンテカルロ積分(Monte-Carlo Integration) という。一般にモンテカルロ法(Monte-Carlo Method)はサンプリングによってシミュレーションや数値計算を行う事を指す。 重点サンプリング モンテカルロ積分によって、原理的には \\(\\hat{I}\\) を多くのサンプルで計算する事で \\(I\\) を精度良く計算できる。しかし実際確率分布 \\(r(\\boldsymbol{x})\\) は複雑であることが多く、その場合 \\(r(\\boldsymbol{x})\\) から直接サンプリングするのは困難となる。そこで、より簡単でサンプリング可能な確率分布（ 提案分布 という） \\(q(\\boldsymbol{x})\\) を用意して、そこからサンプリングする事を考える。 \\(q(\\boldsymbol{x})\\) を使えば、 \\(I\\) は次の様に変形できる: $$ I = \\int_{X} h(\\boldsymbol{x})\\frac{r(\\boldsymbol{x})}{q(\\boldsymbol{x})} q(\\boldsymbol{x}) d\\boldsymbol{x} = \\mathrm{E}_{q}\\left[ h(\\boldsymbol{x})\\frac{r(\\boldsymbol{x})}{q(\\boldsymbol{x})} \\right] $$ モンテカルロ積分の時と同じ様にに考え、次は \\(\\boldsymbol{x_{1}},\\dots,\\boldsymbol{x_{n}}\\) を \\(q(\\boldsymbol{x})\\) からの独立な \\(n\\) 個のサンプルにすれば、 \\(I\\) の近似値 \\(\\hat{I}_{IS}\\) として $$ \\hat{I}_{IS} = \\frac{1}{n} \\sum_{i=1}&#94;{n} h(\\boldsymbol{x_{i}}) \\frac{r(\\boldsymbol{x_{i}})}{q(\\boldsymbol{x_{i}})} = \\frac{1}{n} \\sum_{i=1}&#94;{n} h(\\boldsymbol{x_{i}}) w(\\boldsymbol{x_{i}}) \\tag{3} $$ が得られる。ここで \\(w(\\boldsymbol{x_{i}}) = r(\\boldsymbol{x_{i}})/q(\\boldsymbol{x_{i}})\\) はサンプル \\(\\boldsymbol{x_{i}}\\) に対する重みと見ることができる。この様に、重みが付いたサンプルで平均を求める手法を 重点サンプリング(Importance Sampling) という。重点サンプリングにおいても、 \\(q(\\boldsymbol{x})\\) がある条件を満たしていれば、大数の法則によって \\(\\displaystyle\\lim_{n \\to \\infty} \\hat{I}_{IS} = I\\) となることが保証されている。 MCMC 重点サンプリングの考え方によって、確率分布 \\(r\\) が複雑でも替わりに提案分布 \\(q\\) を用いてサンプリングを行えばモンテカルロ積分が計算できる事が確かめられた。しかし、\" \\(r\\) より簡単でサンプリング可能な \\(q\\) \" を構成する事自体が一般に困難である。特に次元 \\(d\\) が増加すれば \\(r\\) が複雑になるのはもちろん、全事象 \\(X\\) の自由度が増加し次元の呪い 12 を引き起こす。即ち、 \\(r\\) を \\(q\\) で良く近似出来てない時に毎回独立にサンプリングを行っていると、空間 \\(X\\) から当てずっぽうなサンプルを取得しているのと同様な状態になる。 そこで、簡単な提案分布 \\(q\\) を用いて、かつ逐次的に以前のサンプルを使用して新しくサンプルを生成する手法が90年代以降使われる様になってきた。この場合、サンプル列はマルコフ連鎖(Markov Chain)をなす。そして、マルコフ連鎖で生成したサンプルによるMC法をMCMC（Markov Chain Monte-Calro）法という。サンプル間の独立性は担保されなくなる為にMC法の基本原理が成立しなくなるが、提案分布（マルコフ連鎖の遷移確率）がある性質を満たせば、十分なサンプル数で確率分布 \\(r\\) からのサンプリングが実現できる。 遷移確率の条件 - 詳細釣り合い条件 概要でも既に述べたが、MCMCは生成したサンプル列がマルコフ連鎖をなすように生成する。今、サンプル列 \\(\\boldsymbol{x_{0}}, \\boldsymbol{x_{1}}, \\dots\\) はマルコフ連鎖をなすので、生成した時刻（ステップ）で実際に観測した状態を \\(\\boldsymbol{e_{0}}, \\boldsymbol{e_{1}}, \\dots \\ (\\boldsymbol{e_{i}} \\in X \\ i=0,1,\\dots)\\) と書くと、任意の時刻 \\(n \\geq 0\\) で、 $$ P(\\boldsymbol{x_{n+1}} = \\boldsymbol{e_{n+1}}|\\boldsymbol{x_{0}} = \\boldsymbol{e_{0}}, \\boldsymbol{x_{1}} = \\boldsymbol{e_{1}}, \\dots, \\boldsymbol{x_{n}} = \\boldsymbol{e_{n}}) = P(\\boldsymbol{x_{n+1}} = \\boldsymbol{e_{n+1}}|\\boldsymbol{x_{n}} = \\boldsymbol{e_{n}}) $$ が成り立つ（この性質をマルコフ性 13 という）。即ち、サンプルは直前のサンプルのみに依存して生成する。この様にサンプルを生成する場合、実はマルコフ連鎖が エルゴード的(ergodic) という性質を満たせば、大量のサンプルを用いた時にある分布（ 定常分布 ） \\(\\pi\\) からサンプリングしているのと同様になる。 マルコフ連鎖がエルゴード的であるとは、規約性（どの状態からでも任意の状態へ遷移できる）と正再帰性（任意の状態へ何回でも遷移できる）非周期性（任意の状態は一回の遷移で元に戻れる）を全て同時に満たすことを言う 14 。 エルゴード的なマルコフ連鎖と定常分布 \\(\\pi\\) の関係は、次の定理で表せる: マルコフ連鎖の収束 マルコフ連鎖 \\(\\boldsymbol{x_{0}}, \\boldsymbol{x_{1}}, \\dots\\) がエルゴード的であり、その遷移確率行列を \\(\\boldsymbol{P}\\) とおく。 \\(\\pi\\) を \\(\\boldsymbol{P}\\) の定常（不変）分布とした時、任意の初期状態から始まるマルコフ連鎖はサンプル数の極限において定常分布 \\(\\pi\\) に収束する。 ここで遷移確率行列 \\(\\boldsymbol{P}\\) とは、その \\((i,j)\\) 要素 \\((\\boldsymbol{P})\\_{ij} = p_{ij}\\ (i,j \\in X)\\) が任意の時刻 \\(t \\geq 0\\) で $$ (\\boldsymbol{P})_{ij} = p_{ij} = P(\\boldsymbol{x_{t+1}}=j|\\boldsymbol{x_{t}}=i) $$ を満たすような行列である 15 。 また、定常分布とは時刻が経過しようとも不変なマルコフ連鎖（一般に確率過程）の各状態の確率分布である 16 。即ち、十分に長いマルコフ連鎖を観測すれば、どの状態にいる傾向があるのかを定常分布によって知ることができる。 上記の議論により、マルコフ連鎖がエルゴード的であればサンプリングが定常分布に従う事は分かったが、次は遷移確率の設計が問題となる。遷移確率を規約性と正再帰性と非周期性とを満たすように設定するのは案外容易 17 であるが、それだけでは定常分布の存在のみを保証するので、その定常分布が希望する分布に一致するとは限らない。次に問題となるのは、希望の確率分布 \\(r\\) を定常分布とするように遷移確率を設計することである。その問題は次の 詳細釣り合い条件(detailed balance condition) という条件によって解決できる。 詳細釣り合い条件 希望する確率分布 \\(r\\) と遷移確率 \\(p\\) が次の条件を満たす時、そのマルコフ連鎖の定常分布 \\(\\pi\\) は \\(r\\) に一致する: $$ r_{i} p_{ij} = r_{j} p_{ji} $$ ここで \\(r_{i} = r(\\boldsymbol{x} = i)\\) である（証明は 補足 に示した）。 詳細釣り合い条件を満たす遷移確率を用いさえすれば、十分大きな \\(m>0\\) を取った時に、マルコフ連鎖 \\(\\boldsymbol{x_{m}}, \\boldsymbol{x_{m+1}},\\dots\\) は \\(r\\) からのサンプルとなる。 次の節で紹介するアルゴリズムの遷移確率は、いずれも詳細釣り合い条件を満たすように設計されている。 メトロポリス-ヘイスティングス法 メトロポリス-ヘイスティングス法は、サンプルは重点サンプリングの時と同じように提案分布によって生成し、そして新しく生成したサンプルを 採択 （採用）するか、もしくは 棄却 （捨てる）のかを 採択確率(acceptance rate) と呼ばれる確率によって決め、採択された場合は新しい状態に遷移し、棄却された場合には遷移は行わずに（状態を変えずに）もう一度サンプリングし直す、という手続きを繰り返す手法である。 メトロポリス-ヘイスティングス法の更新規則を導出してみる。 まず、状態 \\(i \\in X\\) から状態 \\(j \\in X\\) に遷移する時の提案分布を条件付き確率 \\(q(\\boldsymbol{x_{n+1}}=j|\\boldsymbol{x_{n}}=i) = q_{ij}\\) と書き、また状態 \\(i\\) にいる時に状態 \\(j\\) を採択する確率（採択確率）を \\(\\alpha(i \\to j)\\) と表す。すると、 \\(i\\) から \\(j\\) への遷移確率 \\(p_{ij}\\) は \\(q_{ij}\\) と \\(\\alpha(i \\to j)\\) の積で表せる: $$ p_{ij} = q_{ij} \\alpha(i \\to j) \\tag{4} $$ そして、詳細釣り合い条件から、 $$ \\begin{align} \\frac{p_{ij}}{p_{ji}} = \\frac{r_{j}}{r_{i}} &\\iff \\frac{q_{ij}\\alpha(i \\to j)}{q_{ji}\\alpha(j \\to i)} = \\frac{r_{j}}{r_{i}} \\\\ &\\iff \\frac{\\alpha(i \\to j)}{\\alpha(j \\to i)} = \\frac{r_{j}q_{ji}}{r_{i}q_{ij}} \\end{align} $$ となる。採択確率はこの条件を満たす様に設計する。メトロポリス-ヘイスティングス法では特に、 $$ \\alpha(i \\to j) = \\min \\left( 1, \\frac{r_{j}q_{ji}}{r_{i}q_{ij}} \\right) \\tag{5} $$ とする 18 。アルゴリズムの実行中には、この式によって採択確率を計算し、 \\([0,1]\\) の範囲の一様乱数を発生させて採択/棄却を判断する。 これでメトロポリス-ヘイスティングス法が実行できるが、その利点を2つ挙げる: \\(r\\) が厳密計算出来なくても良い \\(r\\) は一般に複雑なので直接的な計算は難しいが、上の採択確率の式は確率の比率のみに注目している。従って分布が厳密に計算できなくてもアルゴリズムを実行できる。比率さえ一致すれば良いので、分布 \\(r\\) の近似分布 \\(\\hat{r}\\) として $$ \\hat{r} = \\frac{1}{Z_{r}} r $$ としても良い事になる( \\(Z_{r}\\) :正規化定数)。特に、近似分布をボルツマン-ギブス分布 $$ \\hat{r}(\\boldsymbol{x}) = \\frac{1}{Z_{r}} \\exp(-r(\\boldsymbol{x})/T) $$ とする場合が多い。ここで、 \\(T>0\\) は温度パラメタ 19 である。 \\(q_{ij} = q_{ji}\\) が成り立つ場合には、より簡単にサンプリングできる \\(q_{ij} = q_{ji}\\) が成立する提案分布で有名なものに 酔歩連鎖(random walk chain) がある: $$ q_{ij} = {\\cal N}(i, \\sigma&#94;{2}\\boldsymbol{I}) $$ 即ち平均（中心）を現在状態 \\(i\\) 、分散を \\(\\sigma\\) 20 とした正規分布からの乱択でサンプリングを行う 21 。 正規分布以外でも、 \\(i\\) を平均とした一様分布、多変量 \\(t\\) 分布でも実行できる。 ギブスサンプリング ギブスサンプリング(Gibbs Sampling, 熱浴法とも)は提案分布の変数を1個ずつ更新していく手法である。 主に多次元確率分布 22 の推定に用いられる事が多い。説明のため、現在の状態を組 \\(\\boldsymbol{x} = (x_{1}, x_{2}, \\dots, x_{d})\\) と書く。状態の更新の際には、変数を1つ選び出し 23 て \\(x_{i} \\to x_{i}&#94;{\\prime}\\) と遷移させる( \\(i=1,\\dots,d\\) )。更新後の状態を \\(\\boldsymbol{x}&#94;{\\prime} = (x_{1}, \\dots, x_{i-1}, x_{i}&#94;{\\prime}, x_{i+1}, \\dots, x_{d})\\) と書く。ここで、遷移確率 \\(q(\\boldsymbol{x}&#94;{\\prime}|\\boldsymbol{x})\\) は次で定義される: $$ \\begin{align} q(\\boldsymbol{x}&#94;{\\prime}|\\boldsymbol{x}) &= \\frac{r(\\boldsymbol{x}&#94;{\\prime})}{\\sum_{x_{i}} r(\\boldsymbol{x})} \\\\ &= r(x&#94;{\\prime}_{i}|x_{1},\\dots,x_{i-1},x_{i+1},\\dots,x_{d}) \\quad (\\because ベイズの定理) \\end{align} $$ 即ち、選択した変数 \\(x_{i}\\) 以外を全て``固定''した確率分布 \\(r\\) から \\(x_{i}&#94;{\\prime}\\) を新しくサンプリングする。上記右辺が計算できる場合にのみ、ギブスサンプリングは適用可能となる。 この更新規則が詳細釣り合い条件を満たすことは、再びベイズの定理を用いて、 $$ \\begin{align} r(\\boldsymbol{x})q(\\boldsymbol{x}&#94;{\\prime}|\\boldsymbol{x}) &= r(\\boldsymbol{x}) r(x&#94;{\\prime}_{i}|x_{1},\\dots,x_{i-1},x_{i+1},\\dots,x_{d}) \\\\ &= r(\\boldsymbol{x})\\frac{r(\\boldsymbol{x}&#94;{\\prime})}{\\sum_{{x}_{i}}r(\\boldsymbol{x})} = r(\\boldsymbol{x}&#94;{\\prime}) \\frac{r(\\boldsymbol{x})}{\\sum_{x_{i}&#94;{\\prime}}r(\\boldsymbol{x}&#94;{\\prime})} \\\\ &= r(\\boldsymbol{x}&#94;{\\prime}) q(\\boldsymbol{x}|\\boldsymbol{x}&#94;{\\prime}) \\end{align} $$ により確認できる。また、メトロポリス-ヘイスティングス法の採択確率の式から、 $$ \\begin{align} \\alpha(\\boldsymbol{x} \\to \\boldsymbol{x}&#94;{\\prime}) &= \\min \\left(1, \\frac{r(\\boldsymbol{x}&#94;{\\prime})q(\\boldsymbol{x}|\\boldsymbol{x}&#94;{\\prime})}{r(\\boldsymbol{x})q(\\boldsymbol{x}&#94;{\\prime}|\\boldsymbol{x})} \\right) \\\\ &= \\min (1, 1) = 1 \\end{align} $$ となり、ギブスサンプリングはメトロポリス-ヘイスティングス法で採択確率を \\(1\\) （必ず採択）するようにした特別の場合である事が分かる。採択/棄却の手順を踏まくくても良く、しかも遷移確率 \\(q\\) は予め計算できるので、高速な推定ができるようになっている。 MCMCによる最適化 MCMCは関数最適化に用いることもできる。今、サンプリングを行う確率分布をボルツマン-ギブス分布 $$ r(\\boldsymbol{x}) = \\frac{1}{Z_{r}} \\exp(-f(\\boldsymbol{x})/T) $$ とした時、定義式により、 \\(f(\\boldsymbol{x})\\) が小さな値を与える点ではその確率 \\(r(\\boldsymbol{x})\\) は同時に大きくことが即座に観察できる。従って、MCMCによって \\(r(\\boldsymbol{x})\\) からのサンプリングを行えば、 \\(f(\\boldsymbol{x})\\) が小さな値をとる点を集中してサンプリングできる事から、 \\(f(\\boldsymbol{x})\\) の最小化（最大化の場合は \\(-f(\\boldsymbol{x})\\) の最小化に置き換えれば良い）を考える事ができる。実際、関数 \\(f\\) の最小値を与える点を \\(\\boldsymbol{x}&#94;{\\ast}\\) と表せば、サンプル数 \\(N\\) の極限において最小値 \\(f(\\boldsymbol{x}&#94;{\\ast})\\) が確率1で得られる事: $$ \\lim_{N \\to \\infty} P(\\min(f(\\boldsymbol{x_{1}}), f(\\boldsymbol{x_{2}}), \\dots, f(\\boldsymbol{x_{N}})) = f(\\boldsymbol{x}&#94;{\\ast})) = 1 $$ が示せる。以下、その証明を示す。 （証明） MCMCにおいて、定常分布を \\(r\\) とする様に（詳細釣り合い条件を満たす様に）サンプリングを行う。この時マルコフ連鎖 \\(\\boldsymbol{x_{1}}, \\boldsymbol{x_{2}}, \\dots, \\boldsymbol{x_{n}},\\dots\\) は、十分大きな \\(n > 1\\) においては \\(r(\\boldsymbol{x})\\) からのサンプルとみなせる。関数 \\(f\\) に最小値 \\(f(\\boldsymbol{x}&#94;{\\ast})\\) が存在すれば、 \\(\\boldsymbol{x}&#94;{\\ast}\\) をサンプリングする確率 \\(r(\\boldsymbol{x}&#94;{\\ast})\\) も存在が保証され、分布の中で最大の確率を与えている。従って、 \\(n\\) 回目以降のマルコフ連鎖 \\(\\boldsymbol{x_{n}}, \\boldsymbol{x_{n+1}},\\dots\\) において、 \\(m \\geq n\\) 回目に初めて \\(\\boldsymbol{x}&#94;{\\ast}\\) がサンプリングできる確率 \\(P(\\boldsymbol{x_{m}} = \\boldsymbol{x}&#94;{\\ast})\\) は、幾何分布と同じ様に、 $$ P(\\boldsymbol{x_{m}} = \\boldsymbol{x}&#94;{\\ast}) = r(\\boldsymbol{x})\\left\\{ 1-r(\\boldsymbol{x}&#94;{\\ast}) \\right\\}&#94;{m-n} $$ によって計算できる。また、初めて \\(\\boldsymbol{x&#94;{\\ast}}\\) がサンプリングできるまでの回数が \\(N \\geq n\\) 回以内となる確率は、 $$ \\begin{align} P(\\boldsymbol{x_{n}} = \\boldsymbol{x}&#94;{\\ast}) + P(\\boldsymbol{x_{n+1}} = \\boldsymbol{x}&#94;{\\ast}) + \\dots + P(\\boldsymbol{x_{N}} = \\boldsymbol{x}&#94;{\\ast}) &= \\sum_{m=n}&#94;{N} P(\\boldsymbol{x_{N}} = \\boldsymbol{x}&#94;{\\ast}) \\\\ &= \\sum_{k=0}&#94;{N-n} r(\\boldsymbol{x}&#94;{\\ast})\\left\\{ 1-r(\\boldsymbol{x}&#94;{\\ast}) \\right\\}&#94;{k} \\end{align} $$ となる。 ここでサンプル数の極限 \\(N \\to \\infty\\) をとると、初項 \\(r(\\boldsymbol{x}&#94;{\\ast})\\) 、項比 \\(1-r(\\boldsymbol{x}&#94;{\\ast})\\) とした等比級数の和の公式より、 $$ \\begin{align} \\lim_{N \\to \\infty} \\sum_{k=0}&#94;{N-n} r(\\boldsymbol{x}&#94;{\\ast})\\left\\{ 1-r(\\boldsymbol{x}&#94;{\\ast}) \\right\\}&#94;{k} &= \\frac{r(\\boldsymbol{x}&#94;{\\ast})}{1-\\left\\{1-r(\\boldsymbol{x}&#94;{\\ast})\\right\\}} = 1 \\end{align} $$ が得られる。即ち、サンプリングを無限に繰り返せば \\(\\boldsymbol{x}&#94;{\\ast}\\) が確率1で得られることが示された。この結果は、サンプルの関数列 \\(f(\\boldsymbol{x_{1}}), f(\\boldsymbol{x_{2}}), \\dots\\) の中に少なくとも1つ \\(f(\\boldsymbol{x}&#94;{\\ast})\\) が存在する事と同値である。 焼きなまし法 以上でMCMCによる最適化が理論的に可能なことが示されたが、最適化の際に特に問題となるのは分布 \\(r\\) の温度パラメタ \\(T\\) である。 \\(T\\) が大きければ、 \\(\\exp\\) 内部の \\(f(\\boldsymbol{x})\\) の値に影響されず \\(r(\\boldsymbol{x})\\) は一様分布に近くなり、一様乱数からのサンプリングと殆ど変わらなくなる。逆に \\(T\\) が \\(0\\) に近いと \\(r(\\boldsymbol{x})\\) は \\(f(\\boldsymbol{x})\\) の値に大きく影響されるが、サンプリングが特定の場所だけに集中してしまって局所最適値しか得られない場合がある。この様に \\(T\\) は適切に決定する必要があるが、 \\(T\\) の適切な決定法は存在せず、問題依存となる場合が多い。 そこで、最初は \\(T\\) （温度）を高い状態から初めてサンプリングの度に少しずつ \\(T\\) を下げていくやり方があり、これを焼きなまし法（Simulated Annealing, SA）と呼ぶ。この様に \\(T\\) を変化させると最初は空間全体の中から大雑把な \\(f\\) の値を取得し、後に最適値の近傍を集中してサンプリングすることができるために効率的な探索が期待できる。証明は省くが、温度パラメタの系列 \\(T_{1}, T_{2}, \\dots\\) が次の条件を満たせばサンプリングによって \\(\\boldsymbol{x}&#94;{\\ast}\\) が得られる事（収束定理）が示されている: $$ \\sum_{n=1}&#94;{\\infty} \\exp(-D/T_{n}) = \\infty $$ ここで、 \\(D\\) は問題によって決まる定数である。 補足 エルゴード的なマルコフ連鎖の定常分布 上記の議論で、「マルコフ連鎖がエルゴード的ならば、一意な定常分布が存在する」という事に触れた。この定理についての証明を述べていくが、準備として確率過程についての用語や記法の定義、基本的な定理の証明を行う。大方の証明は ここ を参照した。なお、状態空間（全事象） \\(X\\) は有限集合であるとする。 離散時間マルコフ連鎖 確率過程（サンプル列） \\(\\boldsymbol{x_{0}}, \\boldsymbol{x_{1}}, \\dots\\) が次を満たす時、離散時間マルコフ連鎖という。 $$ \\forall n \\geq 0, \\forall i_{0}, \\dots, i_{n+1} \\in X.\\ P(\\boldsymbol{x_{n+1}} = i_{n+1} |\\boldsymbol{x_{0}} = i_{0}, \\boldsymbol{x_{1}} = i_{1}, \\dots, \\boldsymbol{x_{n}} = i_{n}) = P(\\boldsymbol{x_{n+1}}=i_{n+1}|\\boldsymbol{x_{n}}=i_{n}) $$ またこの性質をマルコフ性という。 遷移確率の斉時性、nステップ遷移確率 任意の状態 \\(i,j \\in X\\) と非負整数 \\(n \\geq 0\\) に対して $$ p_{ij}(n) = P(\\boldsymbol{x_{n+1}}=j|\\boldsymbol{x_{n}}=i) $$ を、状態 \\(i\\) から状態 \\(j\\) への遷移確率という。 \\(p_{ij}(n)\\) が \\(n\\) と独立で常に \\(p_{ij}(n) = p_{ij}(0) = p_{ij}\\) となる時、離散時間マルコフ連鎖は斉時であるという。今後、遷移確率は \\(p_{ij}\\) を用いて表す。また、 $$ p_{ij}&#94;{(n)} = P(\\boldsymbol{x_{n}}=j|\\boldsymbol{x_{0}}=i) $$ は状態 \\(i\\) から始まって \\(n\\) ステップ後に状態が \\(j\\) になる確率を表しており、 \\(n\\) ステップ遷移確率と呼ぶ。 チャップマン−コルモゴロフ方程式 任意の状態 \\(i,j \\in X\\) に対し、 \\(n\\) ステップ遷移確率 \\(p_{ij}&#94;{(n)}\\) は次を満たす: $$ p_{ij}&#94;{(n)} = \\sum_{r \\in X} p_{ir}&#94;{(k)}p_{rj}&#94;{(n-k)} \\quad 0 \\leq k \\leq n $$ （証明） $$ \\begin{align} p_{ij}&#94;{(n)} &= P(\\boldsymbol{x_{n}}=j|\\boldsymbol{x_{0}}=i) = \\sum_{r \\in X} P(\\boldsymbol{x_{n}}=j, \\boldsymbol{x_{k}}=r|\\boldsymbol{x_{0}}=i) \\quad (\\because 確率分布の周辺化) \\\\ &= \\sum_{r\\in S} P(\\boldsymbol{x_{n}}=j|\\boldsymbol{x_{k}}=r, \\boldsymbol{x_{0}}=i) P(\\boldsymbol{x_{k}}=r|\\boldsymbol{x_{0}}=i) \\quad (\\because ベイズの定理) \\\\ &= \\sum_{r\\in S} P(\\boldsymbol{x_{n}}=j|\\boldsymbol{x_{k}}=r) P(\\boldsymbol{x_{k}}=r|\\boldsymbol{x_{0}}=i) \\quad (\\because マルコフ性) \\\\ &= \\sum_{r\\in S} P(\\boldsymbol{x_{n-k}}=j|\\boldsymbol{x_{0}}=r) P(\\boldsymbol{x_{k}}=r|\\boldsymbol{x_{0}}=i) \\quad (\\because 斉時性) \\\\ &= \\sum_{r\\in S} p_{rj}&#94;{(n-k)}p_{ir}&#94;{(k)} \\end{align} $$ 到達可能、連結 ある状態 \\(i,j \\in X\\) に対して \\(p_{ij}&#94;{(n)} > 0\\) なる非負整数 \\(n \\geq 0\\) が存在する時、状態 \\(j\\) は状態 \\(i\\) から到達可能であると言い、 \\(i\\to j\\) と表す。 また \\(i \\to j \\land j \\to i\\) ならば、 \\(i\\) と \\(j\\) は連結しているといい、 \\(i \\leftrightarrow j\\) と表す。 連結関係は、反射性( \\(i \\leftrightarrow i\\) )、対称性( \\(i \\leftrightarrow j \\Leftrightarrow j \\leftrightarrow i\\) )、推移性( \\(i \\leftrightarrow j \\land j \\leftrightarrow k \\Rightarrow i \\leftrightarrow k\\) )が成り立つ。 連結クラス（連結成分） \\(X\\) の部分集合 \\(C \\subseteq X\\) において、 \\(i \\in C \\land j \\in C \\implies i \\leftrightarrow j\\) \\(i \\in C \\land i \\leftrightarrow j \\implies j \\in C\\) が常に成立する時、 \\(C\\) を \\(X\\) の連結クラス（連結成分）という。定義より、 \\(C\\) の要素は互いに連結している。また、連結クラス \\(C\\) の任意の状態 \\(i \\in C\\) から \\(j \\notin C\\) に到達できない時、 \\(C\\) は閉じていると言う。 規約性 \\(X\\) 内の全ての状態が単一の閉じた連結クラスに属する、即ち \\(X\\) の全ての要素が互いに連結している時、そのマルコフ連鎖は規約であるという。 周期性 状態 \\(i \\in X\\) に対して \\(p_{ii}&#94;{(n)} > 0\\) となる（ \\(n\\) ステップ後に元の状態に戻る） \\(n\\) の最大公約数 \\(d\\) を、状態 \\(i\\) の周期と呼ぶ。 \\(d = 1\\) の時は状態 \\(i\\) は非周期的と呼ばれ、 \\(d \\geq 2\\) の時は周期的であると呼ばれる。 再帰的、過渡的 確率変数 \\(T_{j}\\) を次で定義する: $$ T_{j} = \\min_{n} \\{ n > 0 | \\boldsymbol{x_{n}} = j \\} $$ 即ち、離散時間マルコフ連鎖が初めて状態 \\(j\\) を訪れる時刻を表す。また、 \\(T_{i}\\) を用いて次の値を定義する: $$ \\begin{align} f_{i} &= P(T_{i} < \\infty | \\boldsymbol{x_{0}} = i) = \\sum_{n=1}&#94;{\\infty}P(T_{i} = n|\\boldsymbol{x_{0}}=i) \\\\ m_{i} &= \\mathrm{E}[T_{i}|\\boldsymbol{x_{0}}=i] = \\sum_{k=0}&#94;{\\infty} k P(T_{i}=k|\\boldsymbol{x_{0}}=i) \\end{align} $$ \\(f_{i}\\) は将来状態 \\(i\\) に戻ってくる確率を表しており、 \\(f_{i}=1\\) ならば確率 \\(1\\) で状態 \\(i\\) を訪れる（無限にしばしば訪れる）ので状態 \\(i\\) は再帰的であるという。 \\(f_{i} < 1\\) ならば状態 \\(i\\) は過渡的であるという。また、 \\(m_{i}\\) は初期状態が \\(i\\) の時に、再び状態 \\(i\\) に戻るまでの時間の期待値を表しており、 \\(m_{i} < \\infty\\) ならば状態 \\(i\\) は正再帰的（有限時間で \\(i\\) に戻る）であるといい、 \\(m_{i} = \\infty\\) ならば状態 \\(i\\) は零再帰的であるという。 エルゴード的な離散時間マルコフ連鎖 離散時間マルコフ連鎖 \\(\\boldsymbol{x_{0}}, \\boldsymbol{x_{1}},\\dots\\) が規約かつ正再帰かつ非周期的であるならば、この離散時間マルコフ連鎖はエルゴード的とも呼ばれる ここまでで用語の定義は揃ったので、それではエルゴード的なマルコフ連鎖の定常分布の存在についての定理を証明する。 エルゴード的な離散時間マルコフ連鎖の定常分布 離散時間マルコフ連鎖 \\(\\boldsymbol{x_{0}}, \\boldsymbol{x_{1}}, \\dots\\) がエルゴード的ならば、任意の状態 \\(i, j \\in X\\) について次が成り立つ: \\(\\displaystyle\\lim_{n \\to \\infty} p_{ij}&#94;{(n)} = \\lim_{n \\to \\infty} p_{jj}&#94;{(n)} = \\frac{1}{m_{j}} = \\pi_{j}\\) \\(\\pi_{j}\\) は \\(\\displaystyle \\pi_{j} = \\sum_{i \\in X} \\pi_{i} p_{ij}\\) と \\(\\displaystyle\\sum_{j \\in X}\\pi_{j} = 1\\) を満たす解であり、唯一に定まる。 2.を満たす \\(\\pi_{j}\\) を極限分布（定常状態分布）と言う。 一方、初期分布として \\(P(\\boldsymbol{x_{0}} = j) = \\pi_{j}\\) を持つ離散時間マルコフ連鎖では、任意の \\(n \\geq 1\\) に対して \\(P(\\boldsymbol{x_{n}}=j) = \\pi_{j}\\) が成り立ち、 \\(\\boldsymbol{x_{n}}\\) は \\(n\\) と独立した分布を持つ。この様に、時間に関して不変な分布 \\(\\pi_{j} = P(\\boldsymbol{x_{n}} = j)\\ n = 0,1,\\dots\\) を 定常分布 と呼ぶ。 （証明）まず1.から考える。最初に \\(i\\neq j\\) なる状態に対して $$ u_{k} = P(T_{j} = k|\\boldsymbol{x_{0}} = i) $$ を（初期状態が \\(i\\) で、初めて \\(j\\) に訪れる時刻が \\(k\\) となる確率）おく。この時、 $$ \\begin{align} p_{ij}&#94;{(1)} &= u_{1} \\\\ p_{ij}&#94;{(2)} &= u_{2} + u_{1} p_{jj}&#94;{(1)} \\\\ p_{ij}&#94;{(3)} &= u_{3} + u_{2}p_{jj}&#94;{(1)} + u_{1}p_{jj}&#94;{(2)} \\\\ &\\vdots \\end{align} $$ の観察により、 \\(n \\geq 1\\) なる \\(n\\) に対して帰納的に $$ p_{ij}&#94;{(n)} = \\sum_{k=1}&#94;{n} u_{k} p_{jj}&#94;{(n-k)} $$ が成立する（最初の \\(k\\) ステップで状態 \\(j\\) に行き、その後 \\(n-k\\) ステップ後に再び \\(j\\) に行く）ことが分かる。また、任意の \\(i\\) と \\(j\\) は連結している（ \\(i \\leftrightarrow j\\) ）ので、 $$ \\sum_{k=1}&#94;{\\infty} u_{k} = P(\\exists n \\geq 0.\\ \\boldsymbol{x_{n}} = j | \\boldsymbol{x_{0}} =i) = 1 $$ （状態 \\(i\\) から始まり、 \\(j\\) へいつかは訪れる確率は \\(1\\) ）が成り立つ。一方 \\(p_{jj}&#94;{(n)}\\) は、 $$ \\begin{align} p_{jj}&#94;{(n)} &= P(\\boldsymbol{x_{n}} = j|\\boldsymbol{x_{0}}=j) \\\\ &= \\sum_{k=1}&#94;{n}P(\\boldsymbol{x_{n}}=j, T_{j} = k|\\boldsymbol{x_{0}}=j) \\quad (\\because 確率分布の周辺化) \\\\ &= \\sum_{k=1}&#94;{n}P(\\boldsymbol{x_{n}}=j|T_{j}=k, \\boldsymbol{x_{0}}=j)P(T_{j}=k|\\boldsymbol{x_{0}}=j) \\quad (\\because ベイズの定理) \\\\ &= \\sum_{k=1}&#94;{n}P(\\boldsymbol{x_{n}}=j|\\boldsymbol{x_{k}}=j, \\boldsymbol{x_{0}}=j)P(T_{j}=k|\\boldsymbol{x_{0}}=j) \\quad (\\because T_{j} = k \\implies \\boldsymbol{x_{k}} = j) \\\\ &= \\sum_{k=1}&#94;{n}P(\\boldsymbol{x_{n}}=j|\\boldsymbol{x_{k}}=j)P(T_{j}=k|\\boldsymbol{x_{0}}=j) \\quad (\\because マルコフ性) \\\\ &= \\sum_{k=1}&#94;{n}p_{jj}&#94;{(n-k)} u_{k} \\end{align} $$ と展開できる。数列 \\(p_{jj}&#94;{(n)}\\) の極限 \\(\\displaystyle\\lim_{n \\to \\infty} p_{jj}&#94;{(n)}\\) を求める為、ここでは数列の 母関数 を定義し、（片側）Z変換の最終値定理 24 を用いる。その為、今、 \\(\\displaystyle G(z) = \\sum_{n=0}&#94;{\\infty}p_{jj}&#94;{(n)}z&#94;{n},\\ U(z) = \\sum_{n=1}&#94;{\\infty}u_{n}z&#94;{n}\\) なる母関数を定義し、上式の両辺に \\(z&#94;{n}\\) を掛けて \\(n=1,2,\\dots\\) についての和を取ると、 $$ \\begin{align} （左辺）\\sum_{n=1}&#94;{\\infty} p_{jj}&#94;{(n)}z&#94;{n} &= \\sum_{n=1}&#94;{\\infty} p_{jj}&#94;{(n)}z&#94;{n} = \\sum_{n=0}&#94;{\\infty}p_{jj}&#94;{(n)}z&#94;{n} - p_{jj}&#94;{(0)} \\\\ &= G(z) - 1 \\\\ （右辺）\\sum_{n=1}&#94;{\\infty} \\sum_{k=1}&#94;{n} p_{jj}&#94;{(n-k)}u_{k}z&#94;{n} &= \\sum_{n=1}&#94;{\\infty} \\sum_{k=1}&#94;{n} p_{jj}&#94;{(n-k)}z&#94;{n-k}u_{k}z&#94;{k} \\\\ &= G(z)U(z) \\\\ \\therefore G(z) &= \\frac{1}{1-U(z)} \\end{align} $$ ここで、右辺式の最後の式変形には冪級数の積の公式 25 を用いている。最終値定理を適用する事を考えると、この場合は、 $$ \\lim_{n \\to \\infty} p_{jj}&#94;{(n)} = \\lim_{z \\to 1}(1-z)G(z) $$ が成立する 26 ので、 \\(\\displaystyle\\lim_{n \\to \\infty} p_{jj}&#94;{(n)}\\) の結果として、 $$ \\begin{align} \\lim_{n \\to \\infty} p_{jj}&#94;{(n)} &= \\lim_{z \\to 1}(1-z)G(z) = \\lim_{z \\to 1}\\frac{1-z}{1-U(z)} \\\\ &= \\lim_{z \\to 1}\\frac{\\frac{d(1-z)}{dz}}{\\frac{d(1-U(z))}{dz}} \\quad (\\because ロピタルの定理) \\\\ &= \\lim_{z \\to 1}\\frac{1}{\\frac{dU(z)}{dz}} = \\frac{1}{m_{j}} = \\pi_{j} \\\\ \\because \\lim_{z \\to 1} \\frac{dU(z)}{dz} &= \\lim_{z \\to 1}\\sum_{n=1}&#94;{\\infty}n u_{n} z&#94;{n-1} = \\lim_{z \\to 1}\\sum_{n=0}&#94;{\\infty} n u_{n} z&#94;{n} = \\sum_{n=0}&#94;{\\infty}n u_{n} = m_{j} \\end{align} $$ が得られる。さて、この結果より、任意の正数 \\(\\epsilon > 0\\) に対して \\(n \\geq N\\) なる全ての \\(n\\) が $$ |p_{jj}&#94;{(n)} - \\pi_{j}| \\leq \\frac{\\epsilon}{2} \\quad かつ \\quad \\sum_{k = N+1}&#94;{\\infty} u_{k} \\leq \\frac{\\epsilon}{2} $$ を同時に満たすような \\(N\\) を取ることができる。今、 \\(n \\geq 2N\\) に対し、 $$ \\begin{align} |p_{ij}&#94;{(n)} - \\pi_{j}| &= | \\sum_{k=1}&#94;{n} u_{k} p_{jj}&#94;{(n-k)} - \\pi_{j}| = | \\sum_{k=1}&#94;{n} u_{k} p_{jj}&#94;{(n-k)} - \\sum_{k=1}&#94;{\\infty}u_{k}\\pi_{j}| \\\\ &= |\\sum_{k=1}&#94;{n-N}u_{k}(p_{jj}&#94;{(n-k)}-\\pi_{j}) + \\sum_{k=n-N+1}&#94;{n} u_{k}(p_{jj}&#94;{(n-k)} - \\pi_{j}) -\\sum_{k=n+1}&#94;{\\infty}u_{k}\\pi_{j}| \\\\ &\\leq \\sum_{k=1}&#94;{n-N}u_{k}|p_{jj}&#94;{(n-k)}-\\pi_{j}| + \\sum_{k=n-N+1}&#94;{n} u_{k}|p_{jj}&#94;{(n-k)} - \\pi_{j}| + \\sum_{k=n+1}&#94;{\\infty}|u_{k}\\pi_{j}| \\\\ &\\leq \\sum_{k=1}&#94;{n-N}u_{k}\\frac{\\epsilon}{2} + \\sum_{k=n-N+1}&#94;{n} u_{k} + \\sum_{k=n+1}&#94;{\\infty}u_{k} = \\frac{\\epsilon}{2}\\sum_{k=1}&#94;{n-N}u_{k} + \\sum_{k=n-N+1}&#94;{\\infty} u_{k} \\\\ &\\leq \\frac{\\epsilon}{2} + \\frac{\\epsilon}{2} = \\epsilon \\end{align} $$ よって、 \\(\\displaystyle \\lim_{n \\to \\infty} p_{ij}&#94;{(n)} = \\pi_{j} = \\lim_{n \\to \\infty} p_{jj}&#94;{(n)}\\) 。 次に2. の \\(\\pi_{j}\\) の一意性を示す。まず、 \\(\\displaystyle \\sum_{j \\in X}p_{ij}&#94;{(n)} = 1\\) （どこかの状態には確率1で遷移している）より、この式で \\(n \\to \\infty\\) ならしめれば、1. により $$ \\sum_{j \\in X} \\pi_{j} = 1 $$ を得る。また、 \\(a_{j}(n) = P(\\boldsymbol{x_{n}} = j)\\) （時刻 \\(n\\) で状態 \\(j\\) を訪れる確率）とおくと、 $$ \\begin{align} a_{j}(n) &= \\sum_{i \\in X}P(\\boldsymbol{x_{0}}=i)P(\\boldsymbol{x_{n}}=j|\\boldsymbol{x_{0}}=i) = \\sum_{i \\in X}P(\\boldsymbol{x_{0}}=i)p_{ij}&#94;{(n)} \\\\ \\therefore \\lim_{n \\to \\infty} a_{j}(n) &= \\sum_{i \\in X}P(\\boldsymbol{x_{0}}=i) \\lim_{n \\to \\infty}p_{ij}&#94;{(n)} = \\pi_{j} \\sum_{i \\in X} P(\\boldsymbol{x_{0}} = i) = \\pi_{j} \\end{align} $$ が成立し、チャップマン−コルモゴロフ方程式により、 \\(n, m \\geq0\\) なる整数に対し、 $$ \\begin{align} a_{j}(m+n) &= \\sum_{r \\in X}P(\\boldsymbol{x_{0}}=r)P(\\boldsymbol{x_{m+n}}=j|\\boldsymbol{x_{0}}=r) = \\sum_{r \\in X} P(\\boldsymbol{x_{0}} = r) p_{rj}&#94;{(m+n)} \\\\ &= \\sum_{r \\in X} P(\\boldsymbol{x_{0}}=r) \\sum_{i \\in X} p_{ri}&#94;{(m)}p_{ij}&#94;{(n)} \\quad (\\because チャップマン−コルモゴロフ方程式を使用) \\\\ &= \\sum_{i \\in X}\\sum_{r \\in X}P(\\boldsymbol{x_{0}}=r)p_{ri}&#94;{(m)} p_{ij}&#94;{(n)} = \\sum_{i \\in X} a_{i}(m) p_{ij}&#94;{(n)} \\end{align} $$ この式の両辺を \\(m \\to \\infty\\) ならしめれば、極限と和の交換法則より、 $$ \\pi_{j} = \\sum_{i \\in X}\\pi_{i} p_{ij}&#94;{(n)} $$ を得る。特に \\(n=1\\) とすれば、 \\(\\displaystyle \\pi_{j} = \\sum_{i \\in X} \\pi_{j} p_{ij}\\) が得られる。 次に一意性を示す。今、 \\(\\pi_{i}&#94;{\\prime}\\ (i \\in X)\\) が、 $$ \\pi_{j}&#94;{\\prime} = \\sum_{i \\in X}\\pi_{i}&#94;{\\prime} p_{ij} \\quad かつ \\quad \\sum_{i \\in X} \\pi_{i}&#94;{\\prime} = 1 $$ を満たすとする。上述の議論により、全ての正整数 \\(n \\geq 0\\) に対し、 $$ \\pi_{j}&#94;{\\prime} = \\sum_{i \\in X}\\pi_{i}&#94;{\\prime} p_{ij}&#94;{(n)} $$ を得る。 \\(n \\to \\infty\\) とすると、 $$ \\pi_{j}&#94;{\\prime} = \\left(\\sum_{i \\in X}\\pi_{i}&#94;{\\prime}\\right) \\pi_{j} = \\pi_{j} $$ となって、一意性が示される。 詳細釣り合い条件の証明 最後に詳細釣り合い条件を示す。今、確率分布 \\(r\\) と遷移確率が $$ r_{i} p_{ij} = r_{j} p_{ji} $$ を満たしているとする。この時両辺ともに状態 \\(i\\) について和をとると、 $$ \\sum_{i \\in X} r_{i} p_{ij} = r_{j} \\sum_{i \\in X} p_{ji} = r_{j} $$ 2.により、 \\(r\\) は定常分布の解となっている事が分かる。 プログラミングに関係ない記事感じるんでしたよね？ 脚注 古澄英雄, 「21世紀の統計科学」第Ⅲ巻 第10章 マルコフ連鎖モンテカルロ法入門 ↩ 笠原正治, 確率過程論基礎 ↩ 中川裕志, マルコフ連鎖モンテカルロ法 ↩ 福島孝治, マルコフ連鎖モンテカルロ法の実践 ↩ tera monagi, マルコフ連鎖モンテカルロ法入門-1 ↩ 主に、確率分布の平均（期待値）、分散が対象となる ↩ 十分な回数の独立な試行を行った経験分布は理論的（真の）分布に一致する、という法則。例えばコイン投げをひたすら繰り返せば、表及び裏が出る 頻度の比率 はそれぞれ \\(1/2\\) に近づいていく。厳密には大数の法則は2種類（強、弱法則）あり、確率の応用において非常に非常に重要な法則であるが、ここでは説明をしない。 ↩ 確率変数のとる値が実数値でなくとも、事象が有限個存在（ \\(\\iff\\) 全事象が有限集合）する場合（例。サイコロとかコインを投げる試行）は議論で用いている分布を離散確率分布で考えれば良い。 ↩ 起こりえる全ての事象の集合。 ↩ 他の個人的に興味深い例：強化学習において \\(X\\) を選択した行動列の集合、 \\(h:X \\to \\mathbb{R}\\) を報酬関数とすれば、 \\(h(\\boldsymbol{x})\\) で行動列の報酬が計算でき、 \\(I\\) の計算結果は報酬の期待値となる。報酬の期待値が計算できることはエージェントの行動決定において大変有用である。 ↩ 一様分布や正規分布等のよく知られた分布は、サンプリングアルゴリズムも確立されている。一様分布はメルセンヌ・ツイスタ、正規分布にはボックス-ミューラー法といった具合である。 ↩ 空間の次元が増加すると、その空間の自由度が直感に反して 指数的 に増加すること。例えば、ユークリッド空間で一辺の長さが \\(a\\) の \\(n\\) 次元超立方体を占める直径 \\(a\\) の超球体の割合を計算してみると \\(\\frac{\\sqrt{(\\pi(a/2)&#94;{2})&#94;{n}}}{a&#94;{n} \\Gamma(\\frac{n}{2}+1)}\\) であり、 \\(n\\) を増加させると階乗オーダー（即ち、指数オーダーよりも早く）で減少する事が分かる。従って、一様乱数を用いていると、 \\(n\\) 次元空間で超球体の内部にサンプルが入る確率が階乗オーダーで小さくなる。 ↩ 厳密には、直前の1つのサンプルのみに依存するので1階マルコフ性と呼ばれる。 ↩ 詳細は 補足 で述べる。一般にエルゴード的とは、長時間に渡って観測した状態の平均（長時間平均）と、状態空間の平均（位相平均）が一致するという事を表す概念である。エルゴード理論がある様に、厳密な数学理論が展開されるが、ここではマルコフ連鎖以外については詳しくは説明しない（筆者がついていけてない）。 ↩ 連続な状態空間では、遷移確率行列の代わりに $$P(\\boldsymbol{x_{t+1}} \\in C|\\boldsymbol{x_{t}} = \\boldsymbol{e_{t}}) = \\int_{C} T(\\boldsymbol{e_{t}}, \\boldsymbol{y}) d \\boldsymbol{y} \\quad C \\subset X, \\boldsymbol{e_{t}} \\in X$$ となる様な条件付き確率分布 \\(T(\\boldsymbol{x}, \\boldsymbol{y})\\) （遷移核）を用いれば良い。 ↩ 形式的に書くと、状態 \\(j \\in X\\) の定常分布 \\(\\pi_{j}\\) は \\(\\pi_{j} = P(\\boldsymbol{x_{n}} = j)\\ n=0,1,\\dots\\) と表される。 ↩ 例えば、現在状態を中心とした正規分布からでの乱択でも3つの性質を満たし、マルコフ連鎖はエルゴード的となる。 ↩ これが詳細釣り合い条件を満たすことは、場合分けにより分かる: - \\(\\alpha(i \\to j) = 1\\) の時： \\(\\alpha(j \\to i) = \\frac{r_{i}q_{ij}}{r_{j}q_{ji}}\\) となるので、 $$ p_{ji} = q_{ji} \\alpha(j \\to i) = q_{ji} \\frac{r_{i}q_{ij}}{r_{j}q_{ji}} = \\frac{r_{i}}{r_{j}}q_{ij} = \\frac{r_{i}}{r_{j}} p_{ij} \\iff r_{i}p_{ij} = r_{j}p_{ji} $$ - \\(\\alpha(i \\to j) = \\frac{r_{j}q_{ji}}{r_{i}q_{ij}}\\) の時： \\(\\alpha(j \\to i) = 1\\) となるので、 $$ p_{ij} = q_{ij} \\alpha(i \\to j) = q_{ij} \\frac{r_{j}q_{ji}}{r_{i}q_{ij}} = \\frac{r_{j}}{r_{i}}q_{ji} = \\frac{r_{j}}{r_{i}} p_{ji} \\iff r_{i}p_{ij} = r_{j}p_{ji} $$ ↩ 温度パラメタの調節は非常に難しい事が知られている。実験結果を見て経験的に設定される事がほとんどである。 ↩ 分散パラメタの調節も非常に難しい。分散を大きくすると遷移幅（ステップサイズという）が大きくなって定常分布に落ち着くまでに時間が掛かり、分散を小さくし過ぎると遷移の動きが小さく、探索が十分に行われない危険性がある。一般に分散パラメタと温度パラメタにはトレードオフの関係がある。 ↩ \\(q_{ij} = q_{ji}\\) が成立する理由は、この場合 \\(j\\) は $$ j = i + \\varepsilon \\quad \\varepsilon \\sim {\\cal N}(\\boldsymbol{0}, \\sigma&#94;{2} \\boldsymbol{I}) $$ と書けるので、平均が \\(\\boldsymbol{0}\\) かつ正規分布の対称性により、 $$ i = j - \\varepsilon = j + \\varepsilon $$ よって \\(q_{ij} = {\\cal N}(i, \\sigma&#94;{2}\\boldsymbol{I}) = {\\cal N}(j, \\sigma&#94;{2}\\boldsymbol{I}) = q_{ji}\\) を満たす ↩ 機械学習では、ベイジアンネットワークやボルツマンマシン（深層学習の一部）等のモデル学習に使われる ↩ 毎回ランダムで選んでも、順番に全変数を1個ずつ選んでも良い ↩ 数列 \\(a_{n}\\) の母関数を \\(F(z) = \\displaystyle\\sum_{n=0}&#94;{\\infty}a_{n}z&#94;{n}\\) とする。今、複素数 \\(s \\in \\mathbb{C}\\) を用いて \\(z = \\exp(-s)\\) とおき、 \\(n\\) の和を \\(t\\) の積分に置き換えると、 $$ F(\\exp(-s)) = \\int_{0}&#94;{\\infty} a_{t}\\exp(-st) dt $$ これは数列 \\(a_{t}\\) のラプラス変換に他ならない。従ってラプラス変換の最終値定理を適用できる。離散の場合のラプラス変換を（片側）Z変換と呼ぶ。 ↩ 2つの冪級数を \\(\\displaystyle\\sum_{n=0}&#94;{\\infty}a_{n}z&#94;{n}, \\sum_{n=0}&#94;{\\infty}b_{n}z&#94;{n}\\) とし、積の結果を \\(\\displaystyle\\sum_{n=0}&#94;{\\infty}c_{n}z&#94;{n}\\) とする。等号を立てると、 $$\\begin{align} \\left(\\sum_{n=0}&#94;{\\infty}a_{n}z&#94;{n}\\right)\\left(\\sum_{n=0}&#94;{\\infty}b_{n}z&#94;{n} \\right) = a_{0}b_{0}z&#94;{0} + (a_{0}b_{1} + a_{1}b_{0})z&#94;{1} + (a_{0}b_{2}+a_{1}b_{1}+a_{2}b_{0})z&#94;{2} + \\dots \\\\ = \\sum_{n=0}&#94;{\\infty}c_{n}z&#94;{n} = c_{0}z&#94;{0} + c_{1}z&#94;{1} + c_{2}z&#94;{2} + \\dots \\end{align}$$ 係数比較により、 \\(c_{0} = a_{0}b_{0},\\ c_{1} = a_{0}b_{1} + a_{1}b_{0},\\ \\dots\\) が成立し、よって \\(c_{n} = \\displaystyle \\sum_{k=0}&#94;{n}a_{k}b_{n-k}\\) となる。ここの例では、 \\(a_{k} = u_{k}z&#94;{k},\\ b_{k} = p_{jj}&#94;{(k)}z&#94;{k}\\) とおけば良い。 ↩ （証明）母関数（Z変換）を \\(F(z) = \\displaystyle \\sum_{n=0}&#94;{\\infty}a_{n}z&#94;{n}\\) とおくと、 $$\\begin{align} \\lim_{z \\to 1} (1-z) F(z) = \\lim_{z \\to 1}(1-z) \\sum_{n=0}&#94;{\\infty} a_{n}z&#94;{n} = \\lim_{z \\to 1} \\sum_{n=0}&#94;{\\infty} a_{n} (z&#94;{n} - z&#94;{n+1}) = \\lim_{z \\to 1} \\lim_{n \\to \\infty} \\sum_{k=0}&#94;{n} a_{k} (z&#94;{k} - z&#94;{k+1}) \\\\ = \\lim_{z \\to 1} \\lim_{n \\to \\infty} \\sum_{k=0}&#94;{n} (a_{k} - a_{k-1}) z&#94;{k} \\quad (\\because a_{-1} = 0, また a_{0}(z&#94;{0}-z&#94;{1}) + a_{1}(z&#94;{1}-z&#94;{2}) +\\dots = a_{0}z&#94;{0} + (a_{0}-a_{1})z&#94;{1} + \\dots) \\\\ = \\lim_{n \\to \\infty} \\sum_{k=0}&#94;{n} (a_{k} - a_{k-1}) = \\lim_{n \\to \\infty} a_{n}\\end{align}$$ ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"記事","url":"/mcmcmarukohulian-suo-montekarurofa.html","loc":"/mcmcmarukohulian-suo-montekarurofa.html"},{"title":"LPC（Linear Predictive Coding, 線形予測符号化）","text":"（Q****にマジギレして移行） 線形予測分析等とも言及される。 英語版で決定的に簡単な資料は ここ で見れます。ここの解説はその日本語訳以下の何かです。英語が読める人はそっちを見たほうが絶対早いです。 ここよりも良い資料が有ります：（ 人工知能に関する断創録 ） アルゴリズムの導出 問題設定 時間について離散化した信号が \\(y_{0}, y_{1}, ..., y_{n}\\) として得られたとする。ここで、 \\(y_{n}\\) を直前の \\(y_{i}\\ (i=0,...,n-1)\\) によって予測する事を考える。 予測にあたって、線形予測では \\(k\\) 個の係数 \\(a_{1},...,a_{k}\\) を用いた単純な線形結合 $$ -a_{1}y_{n-1} - a_{2}y_{n-2} - ... - a_{k}y_{n-k} = - \\sum_{i=1}&#94;{k} a_{i} y_{n-i} $$ によって \\(y_{n}\\) を近似する： $$ y_{n} \\approx - \\sum_{i=1}&#94;{k} a_{i} y_{n-i} $$ （係数に負号 \\(-\\) が付いているのは、システムのフィードバック係数として捉えた時は負を付けるのが常識となっているからと考えられる。全ての係数の符号を反転させれば通常の和に戻るので、以下の導出にとって本質的な問題にならない。） 予測の 誤差 は、全ての \\(n\\) における 二乗誤差 の和 \\(E\\) によって測る： $$ \\begin{split} E &= \\sum_{n=-\\infty}&#94;{\\infty} \\left[ y_{n} - \\left\\{ -\\sum_{i=1}&#94;{k} a_{i} y_{n-i} \\right\\} \\right]&#94;{2} \\\\ &= \\sum_{n=-\\infty}&#94;{\\infty} \\left\\{ y_{n} + \\sum_{i=1}&#94;{k}a_{i}y_{n-i} \\right\\}&#94;{2} \\end{split} $$ ここで \\(a_{0} = 1\\) と定義すると、 $$ E = \\sum_{n=-\\infty}&#94;{\\infty} \\left\\{\\sum_{i=0}&#94;{k}a_{i}y_{n-i}\\right\\}&#94;{2} $$ とまとめられる。後は、この \\(E\\) を最小化するように係数 \\(a_{1},...,a_{k}\\) を定めれば良い。 誤差の最小化 偏微分 誤差の最小化を考える。常套手段ではあるが、 \\(E\\) を \\(a_{j} \\ (j=1,...,k)\\) によって偏微分し、その結果を \\(0\\) とおいて解くことを考える。まず、 \\(E\\) の偏微分は、 $$ \\begin{split} \\frac{\\partial E}{\\partial a_{j}} &= \\sum_{n=-\\infty}&#94;{\\infty} \\frac{\\partial}{\\partial a_{j}} \\left\\{\\sum_{i=0}&#94;{k}a_{i}y_{n-i} \\right\\}&#94;{2} \\\\ &= \\sum_{n=-\\infty}&#94;{\\infty} \\frac{\\partial}{\\partial a_{j}} \\left\\{ a_{0}y_{n} + ... + a_{j}y_{n-j} + ... + a_{k}y_{n-k} \\right\\}&#94;{2} \\\\ &= \\sum_{n=-\\infty}&#94;{\\infty} 2 y_{n-j} \\sum_{i=0}&#94;{k}a_{i}y_{n-i} \\\\ &= 2 \\sum_{i=0}&#94;{k}a_{i} \\sum_{n=-\\infty}&#94;{\\infty} y_{n-j} y_{n-i} \\quad (\\because \\text{和の順序交換}) \\\\ &= 2 \\sum_{i=0}&#94;{k}a_{i} \\sum_{n&#94;{\\prime}=-\\infty}&#94;{\\infty} y_{n&#94;{\\prime}} y_{n&#94;{\\prime}+j-i} \\quad (n&#94;{\\prime} = n-j \\ \\text{とおいた}) \\end{split} $$ ここで、 \\(R_{l}\\) を次の式で定義する： $$ R_{l} = \\sum_{n=-\\infty}&#94;{\\infty} y_{n} y_{n+l} $$ （ 自己相関 という。） \\(R_{l}\\) を用いることで、偏微分の結果は、 $$ \\frac{\\partial E}{\\partial a_{j}} = 2 \\sum_{i=0}&#94;{k} a_{i}R_{|j-i|} $$ と表せる。 次に、 \\(\\displaystyle\\frac{\\partial E}{\\partial a_{j}} = 0\\ (j=1,...,k)\\) とおいて解く事を考える。和の前に付いている係数 \\(2\\) は両辺 \\(2\\) で割ることで消すことが出来る。その上で \\(j=1,...,k\\) での式を並べてみると、 $$ \\begin{split} a_{0}R_{|0-1|} + a_{1}R_{|1-1|} + ... + a_{k}R_{|k-1|} &= 0 \\\\ a_{0}R_{|0-2|} + a_{1}R_{|1-2|} + ... + a_{k}R_{|k-2|} &= 0 \\\\ \\vdots \\\\ a_{0}R_{|0-k|} + a_{1}R_{|1-k|} + ... + a_{k}R_{|k-k|} &= 0 \\\\ \\end{split} $$ より、行列形式で $$ \\begin{bmatrix} R_{1} & R_{0} & R_{1} & ... & R_{k-1} \\\\ R_{2} & R_{1} & R_{0} & ... & R_{k-2} \\\\ \\vdots & & & \\ddots & \\vdots \\\\ R_{k} & R_{k-1} & R_{k-2} & ... & R_{0} \\end{bmatrix} \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\end{bmatrix} = \\vec{0} $$ と表せられる。以下、 $$ M = \\begin{bmatrix} R_{1} & R_{0} & ... & R_{k-1} \\\\ R_{2} & R_{1} & ... & R_{k-2} \\\\ \\vdots & & \\ddots & \\vdots \\\\ R_{k} & R_{k-1} & ... & R_{0} \\end{bmatrix} \\ , \\ \\vec{a}_{k} = \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\end{bmatrix} $$ として、 \\(M\\vec{a}_{k} = \\vec{0}\\) を解くことを考える。 Levinson-Durbin再帰（Levinson-Durbin recursion）へ 上までで求まった連立方程式 \\(M\\vec{a}\\_{k+1} = \\vec{0}\\) をもう少し整理していく。数値解法的には、 \\(M\\) は正方行列にしておくのが望ましい。そこで、 \\(M\\) の一番上の行に \\([R_{0} R_{1} ... R_{k}]\\) を追加すると、 $$ \\begin{split} M\\vec{a}_{k} &= \\begin{bmatrix} R_{1} & R_{0} & ... & R_{k-1} \\\\ R_{2} & R_{1} & ... & R_{k-2} \\\\ \\vdots & & \\ddots & \\vdots \\\\ R_{k} & R_{k-1} & ... & R_{0} \\end{bmatrix} \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\end{bmatrix} \\\\&= \\begin{bmatrix} R_{0} & R_{1} & ... & R_{k} \\\\ R_{1} & R_{0} & ... & R_{k-1} \\\\ \\vdots & & \\ddots & \\vdots \\\\ R_{k} & R_{k-1} & ... & R_{0} \\end{bmatrix} \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\end{bmatrix} -\\begin{bmatrix} \\sum_{i=0}&#94;{k}a_{i}R_{i} \\\\ 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} = \\vec{0} \\end{split} $$ と変形できる。よって、次の連立方程式を解くことに帰着できる： $$ \\begin{bmatrix} R_{0} & R_{1} & ... & R_{k} \\\\ R_{1} & R_{0} & ... & R_{k-1} \\\\ \\vdots & & \\ddots & \\vdots \\\\ R_{k} & R_{k-1} & ... & R_{0} \\end{bmatrix} \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\end{bmatrix} =\\begin{bmatrix} \\sum_{i=0}&#94;{k}a_{i}R_{i} \\\\ 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} $$ この連立方程式を高速に解くアルゴリズムが、Levinson-Durbin再帰法である。以下、 \\(e_{k} = \\sum_{i=0}&#94;{k} a_{i} R_{i}\\) とし、また行列 \\(N_{k}\\) を次で定義する： $$ N_{k} = \\begin{bmatrix} R_{0} & R_{1} & ... & R_{k} \\\\ R_{1} & R_{0} & ... & R_{k-1} \\\\ \\vdots & & \\ddots & \\vdots \\\\ R_{k} & R_{k-1} & ... & R_{0} \\end{bmatrix} $$ Levinson-Durbin再帰 このアルゴリズムは、数学的帰納法によく似ている： \\(k=1\\) の場合で係数を求める 一般の \\(k\\) で係数が求まったとし、その結果から \\(k+1\\) で係数を求める （ 参考資料 で筆者は、「Levinson-Durbin帰納法と言ったほうがいいんじゃないか」と書いてあった。）ここでは、1.および2.の場合の解をそれぞれ見ていく。 k=1の時 $$ \\vec{a}_{1}= \\begin{bmatrix} 1 \\\\ a_{1} \\end{bmatrix} ,\\ N_{1}\\vec{a}_{1}= \\begin{bmatrix} e_{1} \\\\ 0 \\end{bmatrix} ,\\ N_{1}= \\begin{bmatrix} R_{0} & R_{1} \\\\ R_{1} & R_{0} \\end{bmatrix} $$ より、実際に \\(N_{1}\\vec{a}_{1}\\) を計算してみると、 $$ N_{1}\\vec{a}_{1}= \\begin{bmatrix} R_{0} + R_{1}a_{1} \\\\ R_{1} + R_{0}a_{1} \\end{bmatrix}= \\begin{bmatrix} e_{1} \\\\ 0 \\end{bmatrix} $$ より、 \\(e_{1} = R_{0} + R_{1}a_{1}\\) 、及び \\(R_{1} + R_{0}a_{1} = 0\\) から \\(a_{1} = -\\displaystyle\\frac{R_{1}}{R_{0}}\\) と求められる。（ \\(R_{0} = \\displaystyle\\sum_{n=-\\infty}&#94;{\\infty}y_{n}&#94;{2} > 0\\) より、至る所ゼロ除算の心配はない） 一般のkの時 仮定として、 $$ N_{k}\\vec{a}_{k}= \\begin{bmatrix} R_{0} & R_{1} & ... & R_{k} \\\\ R_{1} & R_{0} & ... & R_{k-1} \\\\ \\vdots & & \\ddots & \\vdots \\\\ R_{k} & R_{k-1} & ... & R_{0} \\end{bmatrix} \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\end{bmatrix} =\\begin{bmatrix} e_{k} \\\\ 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} $$ が成立していたとする。 \\(k+1\\) の時、行列 \\(N_{k+1}\\) は $$ N_{k+1}= \\begin{bmatrix} R_{0} & R_{1} & ... & R_{k} & R_{k+1} \\\\ R_{1} & R_{0} & ... & R_{k-1} & R_{k} \\\\ \\vdots & & \\ddots & & \\vdots \\\\ R_{k} & R_{k-1} & ... & R_{0} & R_{1} \\\\ R_{k+1} & R_{k} & ... & R_{1} & R_{0} \\end{bmatrix}= \\left[ \\begin{array}{cccc|c} & & & & R_{k+1} \\\\ & N_{k} & & & R_{k} \\\\ & & & & \\vdots \\\\ & & & & R_{1} \\\\\\hline R_{k+1} & R_{k} & ... & R_{1} & R_{0} \\end{array} \\right] $$ となり、 \\(N_{k}\\) の行・列共に1つ増えた行列となる。 一方の \\(\\vec{a}_{k+1}\\) は未知である。そこで、技巧的ではあるが次 \\(\\vec{a}\\_{k}\\) を \\(0\\) を追加する事で拡張した次のベクトル \\(\\vec{u}\\_{k+1}, \\vec{v}\\_{k+1}\\) を用いる事を考える： $$ \\vec{u}_{k+1}= \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\\\ 0 \\end{bmatrix}\\ ,\\ \\vec{v}_{k+1}= \\begin{bmatrix} 0 \\\\ a_{k} \\\\ \\vdots \\\\ a_{2} \\\\ a_{1} \\\\ 1 \\end{bmatrix} $$ \\(\\vec{u}\\_{k+1}, \\vec{v}\\_{k+1}\\) は互いに要素を反転したベクトルである（互いに 一次独立 で有ることにも注目）。これら \\(\\vec{u}\\_{k+1}, \\vec{v}\\_{k+1}\\) を用いて \\(N\\_{k+1}\\vec{u}\\_{k+1}\\) と \\(N_{k+1}\\vec{v}\\_{k+1}\\) を計算すると、まず \\(N\\_{k+1}\\vec{u}\\_{k+1}\\) は $$ \\begin{split} N_{k+1}\\vec{u}_{k+1}&= \\left[ \\begin{array}{cccc|c} & & & & R_{k+1} \\\\ & N_{k} & & & R_{k} \\\\ & & & & \\vdots \\\\ & & & & R_{1} \\\\\\hline R_{k+1} & R_{k} & ... & R_{1} & R_{0} \\end{array} \\right] \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\\\ 0 \\end{bmatrix}\\\\ &= \\begin{bmatrix} \\\\ \\\\ N_{k}\\vec{a}_{k} \\\\ \\\\ \\\\ \\hline [R_{k+1} R_{k} ... R_{1}] \\vec{a}_{k} \\end{bmatrix}= \\begin{bmatrix} e_{k} \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ \\displaystyle\\sum_{j=0}&#94;{k} a_{j} R_{k+1-j} \\end{bmatrix} \\end{split} $$ であり、もう一方の \\(N\\_{k+1}\\vec{v}\\_{k+1}\\) は、 \\(N\\_{k+1}\\) が 対称行列 なので \\(N\\_{k+1}\\vec{u}\\_{k+1}\\) の結果を反転したベクトルとなる： $$ N_{k+1}\\vec{v}_{k+1}= \\begin{bmatrix} \\displaystyle\\sum_{j=0}&#94;{k} a_{j} R_{k+1-j} \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ e_{k} \\end{bmatrix} $$ そして、 \\(\\vec{a}\\_{k+1}\\) は \\(\\vec{u}\\_{k+1}\\) と \\(\\vec{v}\\_{k+1}\\) の線形結合で表現できる： $$ \\vec{a}_{k+1} = \\vec{u}_{k+1} + \\lambda \\vec{v}_{k+1} \\quad (\\lambda : 実数) $$ これは、実際に \\(N\\_{k+1}(\\vec{u}\\_{k+1} + \\lambda \\vec{v}\\_{k+1})\\) を計算することで確かめられる： $$ N_{k+1}(\\vec{u}_{k+1} + \\lambda \\vec{v}_{k+1}) = N_{k+1}\\vec{u}_{k+1} + N_{k+1}\\lambda \\vec{v}_{k+1}= \\begin{bmatrix} e_{k} + \\lambda \\displaystyle\\sum_{j=0}&#94;{k} a_{j} R_{k+1-j} \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ \\displaystyle\\sum_{j=0}&#94;{k} a_{j} R_{k+1-j} + \\lambda e_{k} \\end{bmatrix} $$ ここで \\(\\lambda = - \\displaystyle\\frac{\\sum_{j=0}&#94;{k} a_{j} R_{k+1-j}}{e_{k}}\\) とすれば、 $$ N_{k+1}(\\vec{u}_{k+1} + \\lambda \\vec{v}_{k+1}) = \\begin{bmatrix} e_{k} - \\lambda&#94;{2} e_{k} \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ \\displaystyle\\sum_{j=0}&#94;{k} a_{j} R_{k+1-j} - \\displaystyle\\sum_{j=0}&#94;{k} a_{j} R_{k+1-j} \\end{bmatrix}= \\begin{bmatrix} (1-\\lambda&#94;{2}) e_{k} \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} $$ となって \\(e\\_{k+1}\\) が求まる。同時に右辺の結果を与える \\(\\lambda\\) は唯一つしか存在しないので、この時の \\(\\vec{u}\\_{k+1} + \\lambda \\vec{v}\\_{k+1}\\) は \\(\\vec{a}\\_{k+1}\\) と一致する。 アルゴリズム 以上の導出結果をまとめると、 \\(k=1\\) の時： $$ a_{1} = - \\frac{R_{1}}{R_{0}} \\ , \\ e_{1} = R_{0} + R_{1}a_{1} $$ \\(k\\) が求まった時、 \\(k+1\\) は： $$ \\lambda = - \\displaystyle\\frac{\\sum_{j=0}&#94;{k}a_{j}R_{k+1-j}}{e_{k}} \\ , \\ e_{k+1} = (1-\\lambda&#94;{2})e_{k}\\ ,\\ \\vec{a}_{k+1} = \\vec{u}_{k+1} + \\lambda \\vec{v}_{k+1} $$ ここで、 $$ R_{l} = \\sum_{n=-\\infty}&#94;{\\infty} y_{n}y_{n+l}\\ ,\\ \\vec{u}_{k+1}= \\begin{bmatrix} 1 \\\\ a_{1} \\\\ \\vdots \\\\ a_{k} \\\\ 0 \\end{bmatrix}\\ ,\\ \\vec{v}_{k+1}= \\begin{bmatrix} 0 \\\\ a_{k} \\\\ \\vdots \\\\ a_{1} \\\\ 1 \\end{bmatrix} $$ となる。 自己相関 \\(R_{l}\\) は過去から未来までの無限の信号和になっているので現実の計算機では計算出来ない。実際には自己相関の代わりに次の 標本自己相関 \\(\\tilde{R}\\_{l}\\) を用いる： $$ \\tilde{R}_{l} = \\sum_{i=0}&#94;{n} y_{i}y_{i-l} \\quad (l = 0, ..., k) $$ 補足 周波数特性の導出 近似式は誤差項 \\(e_{n}\\) を用いて次の等式で書き表せる： $$ \\begin{split} y_{n} = - a_{1}y_{n-1} - a_{2}y_{n-2} - \\dots -a_{k}y_{n-k} + e_{n} \\\\ y_{n} = - \\sum_{i=1}&#94;{k} a_{i}y_{n-k} + e_{n} \\end{split} $$ この式を両辺z変換すると、次の伝達関数を得る： $$ \\begin{split} Y(z) = - \\sum_{i=1}&#94;{k} a_{i}z&#94;{-i}Y(z) + E(z) \\\\ \\iff \\frac{Y(z)}{E(z)} = \\frac{1}{1+ \\sum_{i=1}&#94;{k}a_{i}z&#94;{-i}} \\end{split} $$ この結果は、予測誤差を入力することで出力音声が得られるシステムを表している。人間の声帯から発せられた音声を \\(E(z)\\) とすれば、この伝達関数は声道の共鳴する特性をモデル化していると考えることができる。共鳴が発生する周波数では伝達関数のパワー（振幅、ゲイン）が高くなり、この結果からフォルマント分析を行うことができる。 伝達関数の周波数特性を求めるには、z変換の結果に \\(z=\\exp(j\\omega), (\\omega=2\\pi f:角周波数)\\) を代入する： $$ \\begin{split} \\frac{Y(z)}{E(z)} = \\frac{1}{1+ \\sum_{i=1}&#94;{k} a_{i} \\exp(-j i \\omega) } \\end{split} $$ 標本自己相関の計算 標本自己相関は自分自身との相関を計算するので \\(O(N&#94;{2})\\) の計算量があるが、ウィーナー・ヒンチンの定理（信号のパワースペクトラムは、その自己相関に等しい）を使って自己相関を計算すれば、実質FFTと同等の計算量 \\(O(N \\log N)\\) で抑えることもできる。但し、巡回畳み込みや、パワースペクトラムの平均処理を考慮する必要がある。 参考資料リスト LPCについて： 東京大学 音情報処理論 ウィーナー・ヒンチンの定理： 京都大学 工業数学 実装 実装はC言語です（リファレンスはLLで書くべきだった...） #include <stdio.h> #include <math.h> #include <stdlib.h> #include <string.h> #include <float.h> /* （標本）自己相関の計算 */ static int calc_auto_correlation ( double * auto_corr , const double * data , const size_t num_sample , const size_t max_order ); /* Levinson-Durbin再帰計算 */ static int levinson_durbin_recursion ( double * lpc_coef , const double * auto_corr , const size_t max_order ); int main ( void ) { int num_sample = 300 ; /* サンプル数 */ int max_delay = 10 ; /* LPC係数の数 */ int i_sample , i_delay ; double * data = ( double * ) malloc ( sizeof ( double ) * num_sample ); double * predict = ( double * ) malloc ( sizeof ( double ) * num_sample ); double * auto_cor = ( double * ) malloc ( sizeof ( double ) * ( max_delay + 1 )); double * coff = ( double * ) malloc ( sizeof ( double ) * ( max_delay + 1 )); double error ; /* 波形の生成 */ for ( i_sample = 0 ; i_sample < num_sample ; i_sample ++ ) { data [ i_sample ] = sin ( i_sample * 0.01 ) + 0.5 * cos ( 4.0f * sin ( i_sample * 0.05 )); } /* 自己相関・Levinson-Durbin再帰計算 */ calc_auto_correlation ( auto_cor , data , num_sample , max_delay + 1 ); levinson_durbin_recursion ( coff , auto_cor , max_delay ); /* 予測テスト */ for ( i_sample = 0 ; i_sample < num_sample ; i_sample ++ ) { if ( i_sample < max_delay ) { /* 最初のmax_delayステップ分は元信号を単純コピー */ predict [ i_sample ] = data [ i_sample ]; } else { /* 以降は予測 */ predict [ i_sample ] = 0.0f ; for ( i_delay = 1 ; i_delay <= max_delay ; i_delay ++ ) { predict [ i_sample ] -= ( coff [ i_delay ] * data [ i_sample - i_delay ]); } } } /* 誤差計算・結果表示 */ error = 0.0f ; for ( i_sample = 0 ; i_sample < num_sample ; i_sample ++ ) { error += pow ( predict [ i_sample ] - data [ i_sample ], 2 ); printf ( \"No:%d Data: %f Predict: %f \\n \" , i_sample , data [ i_sample ], predict [ i_sample ]); } printf ( \"Error : %f \\n \" , sqrt ( error / num_sample )); free ( data ); free ( predict ); free ( auto_cor ); free ( coff ); return 0 ; } static int levinson_durbin_recursion ( double * lpc_coef , const double * auto_corr , const size_t max_order ) { int delay , i_delay ; double lambda ; double * u_vec , * v_vec , * a_vec , * e_vec ; if ( lpc_coef == NULL || auto_corr == NULL ) { fprintf ( stderr , \"Data or result pointer point to NULL. \\n \" ); return - 1 ; } /* * 0次自己相関（信号の二乗和）が0に近い場合、入力信号は無音と判定 * => 予測誤差, LPC係数は全て0として無音出力システムを予測. */ if ( fabs ( auto_corr [ 0 ]) < FLT_EPSILON ) { for ( i_delay = 0 ; i_delay < max_order + 1 ; ++ i_delay ) { lpc_coef [ i_delay ] = 0.0f ; } return 0 ; } /* 初期化 */ a_vec = ( double * ) malloc ( sizeof ( double ) * ( max_order + 2 )); /* a_0, a_k+1を含めるとmax_order+2 */ e_vec = ( double * ) malloc ( sizeof ( double ) * ( max_order + 2 )); /* e_0, e_k+1を含めるとmax_order+2 */ u_vec = ( double * ) malloc ( sizeof ( double ) * ( max_order + 2 )); v_vec = ( double * ) malloc ( sizeof ( double ) * ( max_order + 2 )); for ( i_delay = 0 ; i_delay < max_order + 2 ; i_delay ++ ) { u_vec [ i_delay ] = v_vec [ i_delay ] = a_vec [ i_delay ] = 0.0f ; } /* 最初のステップの係数をセット */ a_vec [ 0 ] = 1.0f ; e_vec [ 0 ] = auto_corr [ 0 ]; a_vec [ 1 ] = - auto_corr [ 1 ] / auto_corr [ 0 ]; e_vec [ 1 ] = auto_corr [ 0 ] + auto_corr [ 1 ] * a_vec [ 1 ]; u_vec [ 0 ] = 1.0f ; u_vec [ 1 ] = 0.0f ; v_vec [ 0 ] = 0.0f ; v_vec [ 1 ] = 1.0f ; /* 再帰処理 */ for ( delay = 1 ; delay < max_order ; delay ++ ) { lambda = 0.0f ; for ( i_delay = 0 ; i_delay < delay + 1 ; i_delay ++ ) { lambda += a_vec [ i_delay ] * auto_corr [ delay + 1 - i_delay ]; } lambda /= ( - e_vec [ delay ]); e_vec [ delay + 1 ] = ( 1 - lambda * lambda ) * e_vec [ delay ]; /* u_vec, v_vecの更新 */ for ( i_delay = 0 ; i_delay < delay ; i_delay ++ ) { u_vec [ i_delay + 1 ] = v_vec [ delay - i_delay ] = a_vec [ i_delay + 1 ]; } u_vec [ 0 ] = 1.0f ; u_vec [ delay + 1 ] = 0.0f ; v_vec [ 0 ] = 0.0f ; v_vec [ delay + 1 ] = 1.0f ; /* resultの更新 */ for ( i_delay = 0 ; i_delay < delay + 2 ; i_delay ++ ) { a_vec [ i_delay ] = u_vec [ i_delay ] + lambda * v_vec [ i_delay ]; } } /* 結果の取得 */ memcpy ( lpc_coef , a_vec , sizeof ( double ) * ( max_order + 1 )); free ( u_vec ); free ( v_vec ); free ( a_vec ); free ( e_vec ); return 0 ; } static int calc_auto_correlation ( double * auto_corr , const double * data , const size_t num_sample , const size_t max_order ) { int i_sample , delay_time ; if ( max_order > num_sample ) { fprintf ( stderr , \"Max order(%zu) is larger than number of samples(%zu). \\n \" , max_order , num_sample ); return - 1 ; } if ( auto_corr == NULL || data == NULL ) { fprintf ( stderr , \"Data or result pointer point to NULL. \\n \" ); return - 2 ; } /* （標本）自己相関の計算 */ for ( delay_time = 0 ; delay_time < max_order ; delay_time ++ ) { auto_corr [ delay_time ] = 0.0f ; for ( i_sample = delay_time ; i_sample < num_sample ; i_sample ++ ) { auto_corr [ delay_time ] += data [ i_sample ] * data [ i_sample - delay_time ]; } } return 0 ; } 実験 実際に走らせた結果のグラフは以下。 原信号が簡単すぎたのか、係数は少なめでも十分に予測できている。しかし、適当な係数の数の取り方を決める手法がないと、実信号で使い物になりそうにない。とりあえず、自己相関を使いこなしたN. Wiener is GOD.（結言） if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"記事","url":"/lpclinear-predictive-coding-xian-xing-yu-ce-fu-hao-hua.html","loc":"/lpclinear-predictive-coding-xian-xing-yu-ce-fu-hao-hua.html"},{"title":"離散フーリエ変換（DFT）","text":"（Q****にマジギレして移行） 離散時間かつ離散周波数でのフーリエ変換を離散フーリエ変換という。 準備：時間領域で離散化すると、周波数領域では周期的になる \\(f(t)\\) を離散化した信号を \\(g(t)\\) とおく。離散化には、サンプリング周期 \\(t_{s}\\) の周期的デルタ関数 \\(\\delta_{t_{s}}(t)\\) を用いて $$ g(t) = f(t) \\delta_{t_s}(t) = \\sum_{n=-\\infty}&#94;{\\infty} f(t) \\delta(t - nt_{s}) $$ とする。デルタ関数 \\(\\delta(t)\\) は関数 \\(f(t)\\) に対して次が成り立つ（超）関数である： $$ \\int&#94;{\\infty}_{-\\infty} f(t) \\delta(t) dt = f(0) $$ \\(t_{s}\\) の逆数はサンプリングレート（ \\(f_{s} = 1/t_{s}\\) ）そのものである。また、周期的デルタ関数の（複素）フーリエ級数は、 $$ \\begin{aligned} \\delta_{t_{s}}(t) &= \\sum_{n=-\\infty}&#94;{\\infty} c_{n} \\exp(j\\omega_{s}t)dt \\\\ c_{n} &= \\frac{1}{t_{s}} \\int&#94;{t_{s}/2}_{-t_{s}/2} \\delta_{t_{s}}(t) \\exp(-jn\\omega_{s}t)dt \\end{aligned} $$ と表せる。ここで \\(\\omega_{s}=2\\pi/t_{s}\\) （サンプリング角周波数）である。 \\(c_{n}\\) の計算を考えると、積分範囲 \\([-t_{s}/2, t_{s}/2]\\) に唯一つのインパルスが存在する事に留意すれば、次の結果を得る： $$ c_{n} = \\frac{1}{t_{s}} \\int&#94;{t_{s}/2}_{-t_{s}/2} \\delta(t) \\exp(-jn\\omega_{s}t)dt = \\frac{1}{t_{s}}\\exp(0) = \\frac{1}{t_{s}} $$ よって、周期的デルタ関数の複素フーリエ級数は、 $$ \\delta_{t_s}(t) = \\frac{1}{t_{s}} \\sum_{n=-\\infty}&#94;{\\infty} \\exp(j n \\omega_{s} t) = \\frac{1}{t_{s}} \\sum_{n=-\\infty}&#94;{\\infty} \\exp(j 2\\pi n t) $$ であり、この結果を用いると、 \\(g(t)\\) のフーリエ変換 \\({\\cal F}[g(t)]\\) は、 $$ \\begin{split} {\\cal F}[g(t)] &= \\frac{1}{t_{s}} \\sum_{n=-\\infty}&#94;{\\infty} {\\cal F} \\left[ f(t) \\exp(j n \\omega_{s} t) \\right] \\\\ &= \\frac{1}{t_{s}} \\sum_{n=-\\infty}&#94;{\\infty} \\int_{-\\infty}&#94;{\\infty} f(t) \\exp[ -j (\\omega - n\\omega_{s}) t] dt \\\\ &= \\frac{1}{t_{s}} \\sum_{n=-\\infty}&#94;{\\infty} F(\\omega - n\\omega_{s}) \\end{split} $$ ここで、 \\(F(\\omega)\\) は \\(f(t)\\) をフーリエ変換した結果を表している。この結果は、離散化した信号のフーリエ変換は周波数領域で 周期 \\(\\omega_{s}\\) で \\(F(\\omega)\\) を繰り返す 事を示している。 離散フーリエ変換・離散フーリエ逆変換 離散化の仮定 時間領域で離散化した信号 \\(f[n]\\) を次の様に定義する： $$ f[n] = f(nt_{s}) \\quad n = 0,...,N-1 $$ ここで、 \\(N\\) はサンプリング個数である。重要な仮定として、 \\(f(t)\\) は \\(N\\) このサンプリング期間で周期的であるとする。即ち、 \\(f(t)\\) の周期を \\(T\\) とおくと、 $$ T = Nt_{s} $$ が成立する。更に、 周波数領域についても \\(\\omega_{s}\\) を \\(N\\) 分割 し、 $$ \\omega_{k} = \\frac{\\omega_{s}}{N} k = \\frac{2\\pi}{Nt_{s}}k \\quad k = 0,...,N-1 $$ として、周波数領域で離散化した信号 \\(F[k]\\) を次の様に定義する： $$ F[k] = F(\\omega_{k}) \\quad k = 0,...,N-1 $$ 分割の個数 \\(N\\) が時間領域と周波数領域で異なる場合、変換対が対称にならないので高速フーリエ変換の時に不都合が生じる。 離散フーリエ変換の導出 離散化の仮定のもとで、フーリエ変換は次の様に計算できる： $$ F[k] = \\int_{-\\infty}&#94;{\\infty} f(t) \\exp(-j\\omega_{k}t) dt = \\int_{-\\infty}&#94;{\\infty} f(t) \\exp\\left(-j\\frac{2\\pi k}{Nt_{s}} t \\right) dt $$ \\(f(t)\\) は周期 \\(T\\) で繰り返すので、積分範囲は1周期分とする（なぜ一周期か：フーリエ係数の仮定から。係数は1周期の積分で良い。三角関数の完全性を見よ）： $$ F[k] = \\int&#94;{T}_{0} f(t) \\exp \\left(-j \\frac{2\\pi k}{Nt_{s}} t \\right)dt $$ \\(t = nt_{s}\\) と変数変換すると（ \\(n\\) を積分変数とする）、 $$ F[k] = t_{s}\\int&#94;{N}_{0} f(nt_{s}) \\exp \\left(-j \\frac{2\\pi k}{N} n\\right)dn $$ この積分は、次の和で近似できる。 $$ F[k] \\approx t_{s}\\sum&#94;{N-1}_{n=0} f(nt_{s}) \\exp \\left(-j \\frac{2\\pi k}{N} n\\right) = t_{s} \\sum&#94;{N-1}_{n=0} f[n] \\exp \\left(-j \\frac{2\\pi nk}{N} \\right) $$ この式が離散フーリエ変換の式となる。逆変換については、複素フーリエ級数 $$ \\left\\{ \\begin{array}{l} f(nt_{s}) = \\displaystyle \\sum_{k=-\\infty}&#94;{\\infty} c_{n} \\exp(j\\omega_{k}kn t) \\\\ c_{n} = \\displaystyle \\frac{1}{T} \\int&#94;{T}_{0} f(t) \\exp(-j n\\omega_{k} t) dt \\end{array} \\right. $$ から、 \\(c_{n}\\) を消去すると、 $$ f(nt_{s}) = \\sum_{k=-\\infty}&#94;{\\infty} \\left\\{ \\frac{1}{T} \\int&#94;{T}_{0} f(t) \\exp\\left( -j \\frac{2\\pi kt}{T} \\right) dt \\right\\} \\exp\\left( \\frac{j2\\pi k}{T} nt_{s} \\right) \\\\ f(nt_{s}) = \\frac{\\omega_{s}}{2 \\pi N} \\sum_{k=-\\infty}&#94;{\\infty} F[k] \\exp\\left(j \\frac{2\\pi nk}{N} \\right) $$ \\(F[k]\\) の周期は \\(\\omega_{s}\\) なので、1周期分は \\(k = 0,...,N-1\\) となる。再び1周期分のみを考えると、 $$ f[n] = \\frac{\\omega_{s}}{2 \\pi N} \\sum_{k=0}&#94;{N-1} F[k] \\exp\\left(j \\frac{2\\pi nk}{N} \\right) $$ この式が離散フーリエ逆変換の式となる。変換の式をまとめると、 $$ \\left\\{ \\begin{array}{l} \\displaystyle F[k] = t_{s} \\sum&#94;{N-1}_{n=0} f[n] \\exp \\left(-j \\frac{2\\pi nk}{N} \\right) \\\\ \\displaystyle f[n] = \\frac{\\omega_{s}}{2 \\pi N} \\sum_{k=0}&#94;{N-1} F[k] \\exp\\left(j \\frac{2\\pi nk}{N} \\right) \\end{array} \\right. $$ これがフーリエ変換対となり、一方に他方を代入するとちゃんと逆に戻る事が確認できる： $$ \\begin{split} f[n] &= \\frac{\\omega_{s}}{2\\pi N}\\sum_{k=0}&#94;{N-1}F[k]\\exp\\left(j\\frac{2\\pi nk}{N}\\right) \\\\ &= \\frac{2\\pi t_{s}}{2\\pi t_{s}N}\\sum_{k=0}&#94;{N-1}\\left\\{ \\sum&#94;{N-1}_{n&#94;\\prime=0} f[n&#94;\\prime] \\exp \\left(-j \\frac{2\\pi n&#94;\\prime k}{N} \\right) \\right\\} \\exp\\left(j\\frac{2\\pi nk}{N}\\right) \\\\ &= \\frac{1}{N} \\sum_{n&#94;{\\prime}=0}&#94;{N-1} f[n&#94;\\prime] \\sum_{k=0}&#94;{N-1} \\exp\\left[ -j (n-n&#94;\\prime) \\frac{2\\pi k}{N} \\right] \\end{split} $$ \\(\\sum_{k=0}&#94;{N-1} \\exp\\left[ -j (n-n&#94;\\prime) \\frac{2\\pi k}{N} \\right]\\) の値ついては \\(k\\) の積分 $$ \\int&#94;{N}_{0} \\exp\\left[ -j (n-n&#94;\\prime) \\frac{2\\pi k}{N} \\right] dk $$ と考えれば、 \\(n=n&#94;\\prime\\) の時は明らかに \\(N\\) であり、残りの \\(n \\neq n&#94;\\prime\\) の時は $$ \\begin{split} \\int&#94;{N}_{0} \\exp\\left[ -j (n-n&#94;\\prime) \\frac{2\\pi k}{N} \\right] dk &= - \\frac{1}{j(n-n&#94;\\prime)\\frac{2\\pi}{N}} \\left[ \\exp\\left[ -j(n-n&#94;\\prime)\\frac{2\\pi k}{N} \\right] \\right]_{0}&#94;{N} \\\\ &= - \\frac{1}{j(n-n&#94;\\prime)\\frac{2\\pi}{N}} \\left\\{ \\exp[-j2(n-n&#94;\\prime)\\pi] - \\exp(0)\\right\\} \\\\ &= 0 \\end{split} $$ となるので、最終的に $$ \\frac{1}{N} \\sum_{n&#94;{\\prime}=0}&#94;{N-1} f[n&#94;\\prime] \\sum_{k=0}&#94;{N-1} \\exp\\left[ -j (n-n&#94;\\prime) \\frac{2\\pi k}{N} \\right] = \\frac{1}{N} f[n] N = f[n] $$ を得る。 また \\(t_{s}=1\\) とおくと、 \\(\\omega_{s} = 2\\pi\\) となって、DFTのよく見る変換式が得られる： $$ \\left\\{ \\begin{array}{l} \\displaystyle F[k] = \\sum&#94;{N-1}_{n=0} f[n] \\exp \\left(-j \\frac{2\\pi nk}{N} \\right) \\\\ \\displaystyle f[n] = \\frac{1}{N} \\sum_{k=0}&#94;{N-1} F[k] \\exp\\left(j \\frac{2\\pi nk}{N} \\right) \\end{array} \\right. $$ これらの式を実装するのは簡単である。じゃあ、実装しようか…（暗黒微笑） （デルタ関数から導く方法だと、どうしても正規化定数 \\(1/N\\) が出てこない。正規化定数は本質的では無いとかいうけど、計算上は無視できない。） if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"記事","url":"/li-san-huriebian-huan-dft.html","loc":"/li-san-huriebian-huan-dft.html"},{"title":"2020-04-22","text":"\\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\end{equation*} Signed-LMSの2階微分 その2 早速既存研究が無いか見ている。二乗誤差最小化のLMSでもヘッセ行列の逆行列の計算負荷が高いから使わん、という論調がほとんど。Signed-LMSについては今の所、微分してるところも見てない。 NEURAL NETWORK Widrow-Hoff Learning Adaline Hagan LMS 観測分散行列がヘッセ行列に一致することが書いてあった。 Stochastic error whitening algorithm for linear filter estimation with noisy data 評価関数として絶対値が入ったものを使っている。 The Least Mean Squares Algorithm 分かりやすめな解説。そうか、ウィーナーフィルタか。 行列 \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}}\\) が正則にならない件について、これ正則化すればいいんじゃねと思い立つ。要は \\(\\lambda\\) を正則化パラメータとして \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}} + \\lambda \\ve{I}\\) に対して逆行列を求めていく。 多分、係数側に正則項を追加することになるはず。 \\(\\min \\mathrm{E}[|\\varepsilon(n)|] + \\lambda ||\\ve{h}||_{2}\\) のような定式化か？ それでも逆行列 \\((\\ve{X}\\ve{X}&#94;{\\mathsf{T}} + \\lambda \\ve{I})&#94;{-1}\\) を求めるのは骨が折れそう。そこで、自然勾配学習で使っていた適応的自然勾配学習法（ Singularities Affect Dynamics of Learning in Neuromanifolds より）が使えそう。具体的には、次の式で自然勾配を適応的に求めていく。 \\begin{equation*} \\ve{G}_{t+1}&#94;{-1} = (1 + \\varepsilon_{t}) \\ve{G}_{t}&#94;{-1} - \\varepsilon_{t} \\ve{G}_{t}&#94;{-1} \\parfrac{J(\\ve{h})}{\\ve{h}} \\left( \\ve{G}_{t}&#94;{-1} \\parfrac{J(\\ve{h})}{\\ve{h}} \\right)&#94;{\\mathsf{T}} \\end{equation*} ここで \\(\\varepsilon_{t}\\) は小さな定数。『情報幾何の新展開』では、カルマンフィルタ由来らしい。うーん、もう試してみたいな。 （念の為） \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}} + \\lambda \\ve{I}\\) が正則行列になる理由 すぐに思い出せなくてヒヤッとしたのでここで示しておく。 \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}}\\) は対称行列だから、直交行列 \\(\\ve{P}\\) （ \\(\\ve{P}&#94;{-1} = \\ve{P}&#94;{\\mathsf{T}}\\) ）と固有値を並べた対角行列 \\(\\ve{\\Lambda}\\) を用いて、 \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}} = \\ve{P}&#94;{\\mathsf{T}} \\ve{\\Lambda} \\ve{P}\\) と対角化できる。よって、 \\(\\lambda > 0\\) なる定数を用いた時、 \\begin{align*} \\ve{X}\\ve{X}&#94;{\\mathsf{T}} + \\lambda \\ve{I} &= \\ve{P}&#94;{\\mathsf{T}} \\ve{\\Lambda} \\ve{P} + \\lambda \\ve{P}&#94;{\\mathsf{T}} \\ve{P} \\\\ &= \\ve{P}&#94;{\\mathsf{T}} \\ve{\\Lambda} \\ve{P} + \\ve{P}&#94;{\\mathsf{T}} \\lambda \\ve{I} \\ve{P} \\\\ &= \\ve{P}&#94;{\\mathsf{T}} (\\ve{\\Lambda} + \\lambda \\ve{I}) \\ve{P} \\end{align*} また、任意のベクトル \\(\\ve{v}\\) を使った時、 \\begin{align*} \\ve{v}&#94;{\\mathsf{T}} \\ve{X} \\ve{X}&#94;{\\mathsf{T}} \\ve{v} &= (\\ve{X}&#94;{\\mathsf{T}} \\ve{v})&#94;{\\mathsf{T}} \\ve{X}&#94;{\\mathsf{T}} \\ve{v} = ||\\ve{X}&#94;{\\mathsf{T}} \\ve{v} ||_{2}&#94;{2} \\\\ \\ve{v}&#94;{\\mathsf{T}} \\ve{X} \\ve{X}&#94;{\\mathsf{T}} \\ve{v} &= \\ve{v}&#94;{\\mathsf{T}} \\ve{P}&#94;{\\mathsf{T}} \\ve{\\Lambda} \\ve{P} \\ve{v} = \\sum_{i}&#94;{N} \\ve{\\Lambda}_{ii} (\\ve{Pv})_{i}&#94;{2} \\\\ \\Rightarrow ||\\ve{X}&#94;{\\mathsf{T}} \\ve{v} ||_{2}&#94;{2} &= \\sum_{i}&#94;{N} \\ve{\\Lambda}_{ii} (\\ve{Pv})_{i}&#94;{2} \\geq 0 \\end{align*} の関係式が成り立つ。最後の不等式が成り立つには、全ての \\(i\\) に対して \\(\\ve{\\Lambda}_{ii} \\geq 0\\) でなければならない。よって \\(\\ve{XX}&#94;{\\mathsf{T}}\\) の固有値は全て非負。 ここで \\(\\ve{P}&#94;{\\mathsf{T}} (\\ve{\\Lambda} + \\lambda \\ve{I}) \\ve{P}\\) に注目すると、全ての固有値に \\(\\lambda\\) が足されていることが分かる。 \\(\\lambda\\) は正だから、 \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}} + \\lambda \\ve{I}\\) の固有値は全て正になり正定値行列となる。正定値行列は正則だから、 \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}} + \\lambda \\ve{I}\\) は正則行列。 フィッシャー情報行列とヘッセ行列と分散行列の絡みについて 以下の記事が非常にわかりやすい。 Fisher Information Matrix Natural Gradient Descent 結論、ラプラス分布に従う残差を仮定した最尤推定において、観測分散行列はフィッシャー情報行列に一致し、その逆行列は自然勾配に該当するはず。つうかニュートン法の特殊ケースに見えるがどうなんでしょ。フィッシャー情報行列がヘッセ行列に見えるんだが、定義通り（対数尤度のヘッセ行列）そうだよな。指数族の最尤推定をニュートン法で解こうとしたら全部自然勾配学習法にならね？ TODO 評価のことを考えて行きたい。固定した信号（答えが分かっている信号。乱数固定。）を使ったときに、誤差平面と勾配はどうなっている？フィルタの次元は2ぐらいにして、フィルタを固定して各統計量がどうなっているかプロットする。まずは絶対値残差と勾配の観察が重要に思える（もちろん、2次の最小化ケースも重要）。 古いQiita記事を移行せねば… Jupiterええな。使ってみるか 評価がまとまったら結果共有に入りたい。 OMPを使う。 メッセージパッシング使えない？ 何らかの確率モデル化をせよ、というふうに受け取った。 AMP, Survay-Propagation（三村さん、樺島さん）がありえる。 → AMP, Survay-Propagationについて調査すべし。 いろんな論文で自然勾配をどうやって定義しているか要観察。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"雑記","url":"/2020-04-22.html","loc":"/2020-04-22.html"},{"title":"2020-04-21","text":"残差勾配 \\(\\mathrm{E}[\\varepsilon(n) x(n - m)]\\) の挙動観察 \\(m\\) が大きいときは無視できるのでは？ なお、長時間平均値は0に収束していることを見た。 \\(m\\) をずらした時の平均値の様子を見る。どこかで影響が小さくなって打ち切れるはず。 ガチャガチャ弄ってるってるけど示唆があんまりない。 低次（〜10）の係数は大きく変動する傾向。しかし、次に述べるピッチなどに影響しているのか、全てに当てはまる傾向ではない。 \\(\\mathrm{E}[\\varepsilon(n) x(n - m)]\\) は \\(m\\) を大きくすれば単調減少するわけではない。音源依存で傾向が異なる。ピッチ？か何かに反応して大きくなる場合がある。 同一発音区間では、フィルタ係数の符号は同一になる傾向が見られる。単一のsin波を等価させたときはわかりやすい。 440.0Hzのsin波に対する各タップの平均勾配変化 ボイス対する各タップの平均勾配変化 ピアノ演奏に対する各タップの平均勾配変化 Signed-LMSの目的関数の2階微分 勇気を出してやってみる。 \\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\end{equation*} 符号関数を \\(\\tanh(Tx)\\) で近似して微分してみる（ \\(T\\) は温度パラメータで、 \\(\\tanh(Tx)\\) を \\(T \\to \\infty\\) ならしめれば符号関数に近づく）と、 \\begin{equation*} \\frac{d}{dx} \\tanh(Tx) = T (\\tanh(Tx))&#94;{\\prime} = T(1 - \\tanh&#94;{2}(Tx)) \\end{equation*} さて、 \\(1 - \\tanh&#94;{2}(Tx)\\) に注目すると、 \\(T\\) の極限では \\(x = 0\\) を除き0を取るが、 \\(x = 0\\) において1を取る。よってこれはインパルス関数になる（極限と微分操作を交換したけどやかましいことは暗黙で...）。 符号関数を微分するとインパルス関数が出てくることについては 超関数的微分_δ関数関連（２） を見るのが早いかも。以下では、その話に従って、 \\(\\frac{d}{dx} \\mathrm{sign}(x) = 2\\delta(x)\\) とする。 さて、今一度評価関数 \\(\\mathrm{E}[|\\varepsilon(n)|]\\) の偏微分と2階の偏導関数を考える。 \\begin{align*} \\parfrac{}{h(m)} \\mathrm{E}[|\\varepsilon(n)|] &= \\mathrm{E}\\left[ \\parfrac{}{h(m)} |\\varepsilon(n)| \\right] \\\\ &= \\mathrm{E}\\left[ \\left\\{ \\parfrac{}{h(m)} \\varepsilon(n) \\right\\} \\mathrm{sign}[\\varepsilon(n)] \\right] \\\\ &= -\\mathrm{E}\\left[ \\mathrm{sign}[\\varepsilon(n)] x(n - m) \\right] \\\\ \\frac{\\partial&#94;{2}}{\\partial h(m) \\partial h(k)} \\mathrm{E}[|\\varepsilon(n)|] &= - \\parfrac{}{h(k)} \\mathrm{E}\\left[ \\mathrm{sign}[\\varepsilon(n)] x(n - m) \\right] \\\\ &= - \\mathrm{E}\\left[ \\left\\{ \\parfrac{}{h(k)} \\varepsilon(n) \\right\\} 2\\delta(\\varepsilon(n)) x(n - m) \\right] \\\\ &= 2\\mathrm{E}\\left[ \\delta(\\varepsilon(n)) x(n - m) x(n - k) \\right] \\end{align*} ここで \\(\\mathrm{E}\\left[ \\delta(\\varepsilon(n)) x(n - m) x(n - k) \\right]\\) に注目する。これは \\(\\varepsilon(n) = 0\\) のときだけ和を取る演算だ。 \\(\\sum\\) を用いると、 \\begin{equation*} \\mathrm{E}\\left[ \\delta(\\varepsilon(n)) x(n - m) x(n - k) \\right] = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n = 1, \\varepsilon(n) = 0}&#94;{N} x(n - m) x(n - k) \\end{equation*} という計算に該当する。厳密計算は \\(\\varepsilon(n) = 0\\) なる \\(n\\) を見つけたら足していく感じでいいと思うけど、今は \\(\\varepsilon(n)\\) はラプラス分布に従うと仮定している。だからラプラス分布に従って \\(P(\\varepsilon(n) = 0) = \\frac{1}{2\\lambda}\\) （分散 \\(2\\lambda&#94;{2}\\) ）の重み付けをして計算してしまって良いように見えるのだがどうなんだろう。なんか怪しくて考え続けている。 もし適応フィルタに組み込むなら、残差が0になったら上の式に従ってヘッセ行列を更新し、ニュートン法を使い続ける。これは試してみたい。問題はヘッセ行列が逆行列を持つかというところ…4-20で半正定値であることは確認したが正定値とは限らない。共役勾配法を検討する必要があるかも。 \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}}\\) は正則になるとは思えない…。（軽く試したけどすぐにだめな例が見つかった。） 他の頂いたアイディア 周波数領域に一旦飛ばすのはあり？ ありだけど計算量が高い。圧縮率が上がるのであれば大アリ。 確率的PCAとか使えない？辞書は小さくて済む。 線形ダイナミクスにより上手く定式化できない？ 優先度低 出す学会については HND 先生に聞くこと。 相談する機会はどこかで絶対に必要。 著作権処理済み音源データベースについて相談 → 自分で情報をまとめて、申し込んでいいかというところまで進めるべし。 RWC 研究用音楽データベース: 音楽ジャンルデータベースと楽器音データベース RWC研究用音楽データベース → 進めた。動けるようになったら書類をまとめていく。 Donohoさんなどが圧縮センシングの文脈で既にやりきってない？ ありえる。調査すべし。 → ライス大学では成果をすべて公開しているから見るだけ見たほうが良い。 → http://dsp.rice.edu/cs/ を見よ。 Compressed sensing block MAP-LMS adaptive filter for sparse channel estimation and a bayesian Cramer-Rao bound 残差はガウス分布としてるけどクラメル-ラオ下限との絡みを述べている。何か重要そう。 Bayesian Compressive Sensing Using Laplace Priors これもパラメータの事前分布にラプラス分布を導入してベイズ推定するもの。残差ではないはず。 「L1」, 「Laplace」, 「residual」, 「lossless」で検索したけどスパース解を求めるものばかり。今のところはセーフ？ → 継続して調査はする。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"雑記","url":"/2020-04-21.html","loc":"/2020-04-21.html"},{"title":"2020-04-20","text":"IRLSの更新式について MathJaxの環境を確認しつつ使用中。プリアンブルが無いけどページ内で一回 newcommand を行えばずっと使えるみたい。便利。 \\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\end{equation*} 逐次的更新の件について。IRLSでは以下の評価関数 \\(J(\\ve{\\beta})\\) の最小化を考える。 \\begin{equation*} J(\\ve{\\beta}) = \\sum&#94;{M}_{i = 1} w_{i} (y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}})&#94;{2} \\end{equation*} ここで \\(M\\) は観測数。これは二次式だから評価関数は凸関数になる。早速 \\(\\ve{\\beta}\\) で偏微分してみると、 \\begin{align*} \\parfrac{}{\\ve{\\beta}} J(\\ve{\\beta}) &= \\sum&#94;{M}_{i = 1} w_{i} 2 \\left(- \\frac{\\partial}{\\partial \\ve{\\beta}} \\innerp{\\ve{\\beta}}{\\ve{x}_{i}} \\right) (y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}}) \\\\ &= -2 \\sum&#94;{M}_{i = 1} w_{i} (y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}}) \\ve{x}_{i} \\end{align*} \\(\\parfrac{}{\\ve{\\beta}} J(\\ve{\\beta}) = 0\\) とおくと、 \\begin{align*} \\sum_{i = 1}&#94;{M} w_{i} \\innerp{\\ve{\\beta}}{\\ve{x}_{i}} \\ve{x}_{i} &= \\sum_{i = 1}&#94;{M} w_{i} y_{i} \\ve{x}_{i} \\\\ \\iff \\left[ \\ve{x}_{1} ... \\ve{x}_{M} \\right] \\left[ \\begin{array}{c} w_{1} \\innerp{\\ve{\\beta}}{\\ve{x}_{1}} \\\\ \\vdots \\\\ w_{M} \\innerp{\\ve{\\beta}}{\\ve{x}_{M}} \\end{array} \\right] &= \\left[ \\ve{x}_{1} ... \\ve{x}_{M} \\right] \\left[ \\begin{array}{c} w_{1}y_{1} \\\\ \\vdots \\\\ w_{M}y_{M} \\end{array} \\right] \\\\ \\iff \\left[ \\ve{x}_{1} ... \\ve{x}_{M} \\right] \\left[ \\begin{array}{ccc} w_{1} & \\dots & 0 \\\\ \\vdots & \\ddots & \\vdots \\\\ 0 & \\dots & w_{M} \\end{array} \\right] \\left[ \\begin{array}{c} \\innerp{\\ve{\\beta}}{\\ve{x}_{1}} \\\\ \\vdots \\\\ \\innerp{\\ve{\\beta}}{\\ve{x}_{M}} \\end{array} \\right] &= \\left[ \\ve{x}_{1} ... \\ve{x}_{M} \\right] \\left[ \\begin{array}{ccc} w_{1} & \\dots & 0 \\\\ \\vdots & \\ddots & \\vdots \\\\ 0 & \\dots & w_{M} \\end{array} \\right] \\left[ \\begin{array}{c} y_{1} \\\\ \\vdots \\\\ y_{M} \\end{array} \\right] \\\\ \\iff \\left[ \\ve{x}_{1} ... \\ve{x}_{M} \\right] \\left[ \\begin{array}{ccc} w_{1} & \\dots & 0 \\\\ \\vdots & \\ddots & \\vdots \\\\ 0 & \\dots & w_{M} \\end{array} \\right] \\left[ \\begin{array}{c} \\ve{x}_{1}&#94;{\\mathsf{T}} \\\\ \\vdots \\\\ \\ve{x}_{M}&#94;{\\mathsf{T}} \\end{array} \\right] \\ve{\\beta} &= \\left[ \\ve{x}_{1} ... \\ve{x}_{M} \\right] \\left[ \\begin{array}{ccc} w_{1} & \\dots & 0 \\\\ \\vdots & \\ddots & \\vdots \\\\ 0 & \\dots & w_{M} \\end{array} \\right] \\ve{y} \\\\ \\iff \\ve{X} \\ve{W} \\ve{X}&#94;{\\mathsf{T}} \\ve{\\beta} &= \\ve{X} \\ve{W} \\ve{y} \\end{align*} \\(\\ve{X}\\ve{W}\\ve{X}&#94;{\\mathsf{T}}\\) が正則（TODO: \\(\\ve{X}\\) が行フルランク、かつ \\(\\ve{W}\\) が正則なら行けそうに見えるけど本当か？）の場合は閉形式で係数が求まる: \\begin{equation*} \\ve{\\beta} = (\\ve{X} \\ve{W} \\ve{X}&#94;{\\mathsf{T}})&#94;{-1} \\ve{X} \\ve{W} \\ve{y} \\end{equation*} ここまでは一般論。さて、更新式に注目する。 \\(\\beta_{j}\\) だけで偏微分してみると、 \\begin{align*} \\parfrac{J(\\ve{\\beta})}{\\beta_{j}} &= \\sum_{i = 1}&#94;{M} \\parfrac{}{\\beta_{j}} w_{i} (y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}})&#94;{2} \\\\ &= -2 \\sum_{i = 1}&#94;{M} w_{i} (\\ve{x}_{i})_{j} (y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}}) \\end{align*} 残差のL1ノルム最小化を考えるときは \\(w_{i} = \\frac{1}{|y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}}|}\\) とおくので代入すると、 \\begin{equation*} \\parfrac{J(\\ve{\\beta})}{\\beta_{j}} = -2 \\sum_{i = 1}&#94;{M} (\\ve{x}_{i})_{j} \\mathrm{sign}(y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}}) \\end{equation*} 瞬間値（ \\(M=1\\) とする）を考えるとSigned-LMSの更新式そのものになっている。 和を取ると平均操作に近いから、LMSアルゴリズムと考えていることは同じ。 \\(\\parfrac{J(\\ve{\\beta})}{\\beta_{j}}\\) を更に \\(\\beta_{k}\\) で偏微分してみると、 \\begin{align*} \\frac{\\partial&#94;{2} J(\\ve{\\beta})}{\\partial \\beta_{j} \\partial \\beta_{k}} &= -2 \\sum_{i = 1}&#94;{M} w_{i} (\\ve{x}_{i})_{j} \\parfrac{}{\\beta_{k}} (y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}}) \\\\ &= 2 \\sum_{i = 1}&#94;{M} w_{i} (\\ve{x}_{i})_{j} (\\ve{x}_{i})_{k} \\\\ &= 2 \\left[ (\\ve{x}_{1})_{j} \\dots (\\ve{x}_{M})_{j} \\right] \\left[ \\begin{array}{c} w_{1} (\\ve{x}_{1})_{k} \\\\ \\vdots \\\\ w_{M} (\\ve{x}_{M})_{k} \\end{array} \\right] = 2 \\left[ (\\ve{x}_{1})_{j} \\dots (\\ve{x}_{M})_{j} \\right] \\ve{W} \\left[ \\begin{array}{c} (\\ve{x}_{1})_{k} \\\\ \\vdots \\\\ (\\ve{x}_{M})_{k} \\end{array} \\right] \\end{align*} 2次式が出てくるのがわかる（ \\(\\ve{W}\\) は計量だ）。そして \\((\\ve{H})_{jk} = \\frac{\\partial&#94;{2} J(\\ve{\\beta})}{\\partial \\beta_{j} \\partial \\beta_{k}}\\) なるヘッセ行列 \\(\\ve{H}\\) は以下: \\begin{equation*} \\ve{H} = 2 \\ve{X} \\ve{W} \\ve{X}&#94;{\\mathsf{T}} \\end{equation*} ヘッセ行列の性質により関数の最小値・最大値の存在がわかる。対称行列なのは間違いない（ \\((\\ve{X})_{ij} = (\\ve{X})_{ji}\\) は自明）。（固有値分解とは見れない。 \\(\\ve{H}\\) は \\(N \\times N\\) の行列であるのに対して、 \\(\\ve{X}\\) は \\(N \\times M\\) の行列。 \\(\\ve{X} \\ve{X}&#94;{\\mathsf{T}}\\) は平均化、除算を抜いた分散共分散行列になり半正定値行列。）また、任意のベクトル \\(\\ve{v}\\) に対して、 \\begin{align*} \\ve{v}&#94;{\\mathsf{T}} \\ve{X} \\ve{W} \\ve{X}&#94;{\\mathsf{T}} \\ve{v} &= \\ve{v}&#94;{\\mathsf{T}} \\ve{X} \\ve{W}&#94;{1/2} \\ve{W}&#94;{1/2} \\ve{X}&#94;{\\mathsf{T}} \\ve{v} \\\\ &= (\\ve{W}&#94;{1/2} \\ve{X}&#94;{\\mathsf{T}} \\ve{v})&#94;{\\mathsf{T}} \\ve{W}&#94;{1/2} \\ve{X}&#94;{\\mathsf{T}} \\ve{v} \\\\ &= || \\ve{W}&#94;{1/2} \\ve{X}&#94;{\\mathsf{T}} \\ve{v} ||_{2}&#94;{2} \\geq 0 \\end{align*} だから、 \\(\\ve{W}\\) が半正定値（ \\(\\iff\\) すべての重みが非負）ならばヘッセ行列は半正定値行列で、極小値が最小値になる。また、 \\(J(\\ve{\\beta})\\) は凸関数（半正定値だから狭義の凸関数ではない）。 もう少しヘッセ行列を見る。ヘッセ行列を上手く使えたらニュートン法で解けそうな気がして。 \\begin{equation*} (\\ve{H})_{jk} = 2 \\sum_{i = 1}&#94;{M} w_{i} (\\ve{x}_{i})_{j} (\\ve{x}_{i})_{k} \\end{equation*} より、スペクトル分解的に見ると、 \\begin{align*} \\frac{1}{2} \\ve{H} &= w_{1} \\left[ \\begin{array}{ccc} (\\ve{x}_{1})_{1}&#94;{2} & \\dots & (\\ve{x}_{1})_{1} (\\ve{x}_{1})_{N} \\\\ \\vdots & \\ddots & \\vdots \\\\ (\\ve{x}_{1})_{N} (\\ve{x}_{1})_{1} & \\dots & (\\ve{x}_{1})_{N}&#94;{2} \\\\ \\end{array} \\right] + \\dots + w_{M} \\left[ \\begin{array}{ccc} (\\ve{x}_{M})_{1}&#94;{2} & \\dots & (\\ve{x}_{M})_{1} (\\ve{x}_{M})_{N} \\\\ \\vdots & \\ddots & \\vdots \\\\ (\\ve{x}_{M})_{N} (\\ve{x}_{M})_{1} & \\dots & (\\ve{x}_{M})_{N}&#94;{2} \\\\ \\end{array} \\right] \\\\ &= w_{1} \\ve{x}_{1} \\ve{x}_{1}&#94;{\\mathsf{T}} + \\dots + w_{M} \\ve{x}_{M} \\ve{x}_{M}&#94;{\\mathsf{T}} \\\\ &= \\sum_{i = 1}&#94;{M} w_{i} \\ve{x}_{i} \\ve{x}_{i}&#94;{\\mathsf{T}} \\end{align*} 信号処理的には \\(\\ve{x}_{1}, \\ve{x}_{2}, \\dots \\ve{x}_{M}\\) は系列で現れる。 LMSフィルタでは \\(i = 1\\) の時だけを考えていたと考えられれる。 \\(i = 2,\\dots,M\\) のときの影響は少ないのではないかと思う。 FIRフィルタを考えるのならば、各 \\(\\ve{x}_{1}\\) は入ってきた1次元信号データを時系列順に並べたものだから、直前のベクトル \\(\\ve{x}_{2}\\) を使えそうな構造に見える。 上の仮定を使ってヘッセ行列の逆行列 \\(\\ve{H}&#94;{-1}\\) を逐次近似計算できない？ 分散共分散行列がほぼヘッセ行列になってるけどこれは何？ 金谷さんの解説 にそれとなく解説がある。フィッシャー情報行列との関連もある。。。クラメル・ラオの下限についてわかりやすい説明あり。 最尤法 にもそれとなく解説あり。 奥村さん もあり。観測からヘッセ行列を構成できる？ そして自然勾配のアイディアが出てくる。自然勾配を使ったLMSアルゴリズムは…あった… Normalized Natural Gradient Adaptive Filtering for Sparse and Nonsparse Systems 甘利先生による解説 で、LMSアルゴリズム含めて大まかなところはだいたい言ってる。 高知工科大学の博論 ワンチャンスL1残差最小化はやってないかも。 TODO: 前のMTGで言われたことの整理 分散行列、ヘッセ行列、フィッシャー情報行列、自然勾配の整理 Fisher Information Matrix OMPが気になる。試してみたい。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"雑記","url":"/2020-04-20.html","loc":"/2020-04-20.html"},{"title":"2020-04-19","text":"IRLS(Iteratively Reweighted Least Squares) その2 理論ばっかり追っていて悶々してきたので、IRLSでL1残差最小化が解けないか実験してみる。 第5章 厳密解から近似解へ に『スパースモデリング』5章のPython実装あり。 スパースモデリング：第3章 追跡アルゴリズム は『スパースモデリング』3章のPython実装。 IRLSの実装は カレル大学卒論 を参考に。Pythonで簡単にできた。 import numpy # IRLS法によりPhi @ x = yのスパース解を求める def irls_update ( Phi , x , y , order ): EPSILON = 10 ** ( - 8.0 ) # 重みの計算 weight = numpy . abs ( y - Phi @ x ) . flatten () # 小さくなりすぎた重みは打ち切る weight [ weight < EPSILON ] = EPSILON # 対角行列に展開 W = numpy . diag ( weight ** ( order - 2 )) # 更新後の係数: Phi.T @ W @ Phi @ x = Phi.T @ W @ y の解 return numpy . linalg . solve ( Phi . T @ W @ Phi , Phi . T @ W @ y ) if __name__ == \"__main__\" : DIMENSION = 2 NUM_SAMPLES = 100 NUM_ITERATION = 50 # 解ベクトル X_ANSWER = numpy . array ([ 0.5 , 0.5 ]) . reshape (( DIMENSION , 1 )) x = numpy . zeros (( DIMENSION , 1 )) xhistory = numpy . zeros (( DIMENSION , NUM_ITERATION )) # 観測を生成 Phi = numpy . random . rand ( NUM_SAMPLES , DIMENSION ) y = Phi @ X_ANSWER # 加法的雑音を重畳 # yrand = y + numpy.random.normal(0, 0.3, (NUM_SAMPLES, 1)) yrand = y + numpy . random . laplace ( 0 , 0.3 , ( NUM_SAMPLES , 1 )) error = numpy . zeros ( NUM_ITERATION ) emp_error = numpy . zeros ( NUM_ITERATION ) # IRLSを繰り返し適用 for count in range ( NUM_ITERATION ): x = irls_update ( Phi , x , yrand , 1 ) xhistory [:, count ] = x . reshape ( 2 ) error [ count ] = numpy . linalg . norm ( y - Phi @ x , ord = 1 ) / NUM_SAMPLES emp_error [ count ] = numpy . linalg . norm ( yrand - Phi @ x , ord = 1 ) / NUM_SAMPLES 実装は楽だったけど、誤差解析が沼。 誤差を重畳してみると、真の誤差と経験誤差が当然一致しない。 経験誤差的には局所解に入っている印象。 サンプル数が少ないと大域最小解に入らないケースあり（経験誤差曲面の最小値が真の誤差の曲面の最小値に不一致） 経験誤差の曲面は二次曲線に見える。（2次式の最小化を考えているから当然のはず。） 最小二乗解よりも誤差が悪い時がある。最小二乗解はorder=2とすれば良くて、その時重み行列Wは単位行列になり、普通の最小二乗法と一致。 思いつき: IRLSは評価関数の最小化を考える時閉形式で求まるので何も考えない。パラメータに関してもう一度微分できるのでニュートン法使えそう。 フィルタのときのように逐次的に求められない？ パラメータ全てではなく1こずつ。サンプルについても1こずつ。更新していく。評価関数の最小化は平均値の最小化に見受けられるので、逐次的に更新しても良いように見える。 今日は遅いのでもう寝る","tags":"雑記","url":"/2020-04-19.html","loc":"/2020-04-19.html"},{"title":"2020-04-18","text":"IRLS(Iteratively Reweighted Least Squares) LAD(Least Absolute Deviation)を近似的・逐次的に解く方法としてのIRLSについて調査。そういえば基本的な原理を抑えていなかった。 Iteratively Reweighted Least Squares についてサクッと。 文字通りサクッとしたまとめ。OMPを使って解いているというのがとても気になる Iterative Reweighted Least Squares 導入から解法まで。しかしなぜ解が求まるのかは不明。 Iterative Reweighted Least Squares バッファロー大の講義資料？これも何故解けるのかはちゃんと書いてない。 Iterative Reweighted Least Squares これが一番いいかも。なぜ解けるかもざっくり証明がある。 そこで出てきたsupergradient（優勾配？劣勾配に対応している？）がよくわからん。資料のすぐ下に解説があったけど。 Supergradients に定義はあったけど幾何学的イメージが欲しい。 Weiszfeld Algorithmsという幾何中央値を求めるアルゴリズムは Generalized Weiszfeld Algorithms for Lq Optimization に解説あり。しかしこの論文いいこと言ってる。「Generalized Weiszfeld Algorithms」は圧縮センシングとは異なりスパース表現を求めるわけではない。スパース性は担保されなくても、よりL1ノルムの意味で小さい解を求める。 なぜ、IRLSとLMSアルゴリズムを結びつける研究がないのか。IRLSの逐次適用によってもフィルタ係数を更新していけそうだけど。試してみるし、類似研究が無いか引き続き調べる。 『スパースモデリング』の5章にも記述はある。しかし残差のL1最小化ではない。","tags":"雑記","url":"/2020-04-18.html","loc":"/2020-04-18.html"},{"title":"2020-04-17","text":"LAD(Least Absolute Deviation) LAD(Least Absolute Deviation)を見ている。これは、残差をL1ノルムにした回帰問題一般のこと。 カレル大学卒論 が結構まとまっている。 最尤推定による近似的手法 は軽く読んだ。各傾きと切片を固定して逐次更新していく。更新時は中央値を拾ってくる。うーん中央値だと高速推定が厳しい。。。 ラプラス分布の最尤推定しようとしてもがく。対数尤度とって見てみても、単純な絶対値和が出て止まるし、反復スケーリング法を参考に、パラメータの増分を加えた時の対数尤度の下限を求めようとしたが上手く行かず。4時間飛ばす。 最尤推定の計算のあがき あがいて「A maximum likelihood approach to least absolute deviation regression」を引用している文献を漁ったら辞書学習をL1にしているやつが、やっぱりいた。 Online Robust Non-negative Dictionary Learning for Visual Tracking パーティクルフィルターを使っておる。 上の文献で使ってるHuber Loss結構すごくね？この誤差に基づくLMSアルゴリズムねえの？→「Robust Huber adaptive filter」だけど中身を読めず… また、 Convex Optimization and Modeling を読んでたらHuber損失はL1とL2の中間的な性質を示すようで、0に集中しなくなりそうな印象を受けた。","tags":"雑記","url":"/2020-04-17.html","loc":"/2020-04-17.html"},{"title":"2020-04-16","text":"LMSフィルターの挙動観察 \\(\\mathrm{E}[\\mathrm{sign}[e(n)]x(n-m)]\\) の挙動を追いたい。色々な信号に対して、 \\(m\\) が十分大きいとき、0に近づくかどうか を知りたい。もし0に近づくならば有効な過程として解法に使える。 しかしその前に、LMSフィルター自体の挙動を追いたい。 残差はどの様に減る？残差の時系列は？ ステップサイズにより収束の度合い（残差の分布）が違う... 当然、フィルタ次数でも収束の度合い（残差の分布）が違う 残差分布はどうなってる？Signed-LMSでラプラス分布に近づいてる？ これは本当のようで、Signed-LMSの方が裾が細い残差分布が得られている。 単純な正弦波に対してはLMSのほうが残差が小さくなるが、ボイスやピアノ音源に対しては圧倒的にSignLMSの方が性能が良い（残差のヒストグラムを見ると、裾が狭い） \\(\\mathrm{E}[\\mathrm{sign}[e(n)]x(n-m)]\\) , \\(\\mathrm{E}[e(n)x(n-m)]\\) は両方とも0。 逐次計算していったら、音源非依存で0に近づいていく 当然だよな…そもそもの過程として入力と雑音は無相関と仮定しているのだから。 仮定しているのだからは正しくなくて、無相関にするようにフィルタ係数を更新しているが正しい。 無相関になったときに勾配が0で最急勾配法が止まる。 なんか絶対値誤差最小化ってどっかで見たよな…と思っていたら、 https://en.wikipedia.org/wiki/Least_absolute_deviations 修士のときに一回戦っていた。 カレル大学卒論 が結構まとまっている。 \\(L_{1}\\) ノルム最小化を近接オペレータの繰り返し適用で解けんじゃね？と思っている 近接勾配法とproximal operator を読んだが、パラメータ正則化だけだな パラメータ正則化はあるけど、残差をスパースにするのがない。なんで？ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"雑記","url":"/2020-04-16.html","loc":"/2020-04-16.html"},{"title":"2020-04-10","text":"続・古いロスレス音声コーデックの調査 古いロスレス音声コーデックと理論の概要を取りまとめた雑誌の特集があった: Lossless Compression of Digital Audio 理論としてもその通りだし、雑誌発行時点(1998)からさしたるブレークスルーが無いように見える。 AudioPak, OggSquish, Philips, Sonarc, WAという謎のコーデック現る…。いったい何個あるんだ。","tags":"雑記","url":"/2020-04-10.html","loc":"/2020-04-10.html"},{"title":"2020-04-08","text":"古いロスレス音声コーデックの調査 ロスレス音声の歴史を探るために古いロスレス音声コーデックの情報を探っている。以下のサイトが Hydrogenaudioでの比較 よりも古い内容を扱っている。 Lossless Compression of Audio 見つけたロスレス音声コーデックを一覧する。というかほぼ Really Rare Wares 様へのリンク。 古めのロスレス音声コーデック RKAU(RK Audio) 古い比較において優秀な圧縮率を誇っていた。当時のMonkey's Audioよりも上。サイトを覗いたら exe と dll のみの配布だった。 RKAUのホームページ（魚拓） を見ても特に情報なし。 AudioZip これも圧縮率が比較的優秀。 AudioZipのホームページ（魚拓） を見てもこちらも特に情報なし。 WavArc こちらも最大圧縮率(-c5)を選択するとそれなりに優秀な結果を出していた。このページにexeとドキュメントをまとめたzipもあり。 WaveZip 圧縮率よりは速度重視のコーデックのようだ。MUSICompress というアルゴリズムの実装。 WaveZipのデータシート によると符号化にはLZ(Lampel-Ziv)を使用しているようだ。 WaveZipの概要 が比較サイトに掲載されていた。どうやら、入力波形を近似波形と誤差波形に分けて符号化するようだ。WaveZipではHu LPAC/LTAC LPACはMPEG4-ALSの前身。LPACの前身がLTAC。LPACの平均的な圧縮率は優秀なようだ。 LPAC（魚拓） に以前公開していたサイトあり。 LTAC(Lossless Transform Audio Compression)は名前の通り変換符号化に基づくロスレス音声圧縮コーデック、LPAC(Lossless Predictive Audio Compression)は予測に基づくロスレス音声圧縮コーデック。 LPACに ベルリン工科大学、Real Networks、NTT の改良が加わってMPEG4-ALSが出来上がり、それ以降LPACの開発は停止されている。この経緯については MPEG4-ALS（魚拓） に記述あり。 Shorten（魚拓） おそらくロスレス音声の最古参にして基礎。なんと執筆時点（2020-04-08）でも brew でインストールできた（ Shortenのmanページ もあるから各Linuxディストリビューションで使えるものと想像する）。エンコード速度はピカイチ。 Shortenの論文 （テクニカルレポート）もある。この論文で、今のロスレス音声につながる重要な事実に幾つか触れている。 音声信号は準定常（短い区間では定常とみなせる）だからブロックに分けてエンコード/デコードすべき。 音声のモデル化には線形予測(LPC, Linear Predictive Coding)が使える。 残差信号はガウス分布よりもラプラス分布に従っていると見える。その符号化にはライス符号を使うのが良い。 この時点で既にラプラス分布を仮定したパラメータ設定を行っているからかなりの慧眼。他のロスレス音声コーデックはShortenを発展させたものに過ぎないと見える。 所感 どうも2000年代前半までは各自でロスレス音声コーデックを作り、各自で最強を謳っていたらしい。 歴史を雑にまとめると、1994年にShortenの論文が出てから、それよりも圧縮率の良いもの、圧縮速度（展開速度）が早いものが開発されて混沌に突入し上記のコーデックが現れた。その後、Monkey's Audio, WavPack, FLAC, LPAC（MPEG4-ALS）が生き残り、2000年以降はLa（更新停止）, TAK, TTA, ALAC（更新停止）, WMAL(Windows Media Audio Lossless), 2010年以降はOptimFROGが出現しているようだ。 気になるのは比較サイトの Rice Coding, AKA Rice Packing, Elias Gamma codes and other approaches である。Rice符号よりも効率の良いとされるPod符号の紹介がある。要観察。 スパース適応フィルタ LPCの定式化をスパースにする試みは多くなされている。 Sparse Modeling for Lossless Audio Compression : Ghidoさん（OptimFROGの人）の試み 貪欲法によりスパース解を求めている。 スパース表現に基づく音声音響符号化 : NTTの試み 最小二乗解を求めるのではなくL1最小化に置き換えた定式化を行う。 でも、TTAがやっているような適応フィルタをスパース解に近づける手法はまだロスレス音声に対してやっていないように見える。 スパースな解を目指してフィルタ係数を更新する適応フィルタはスパース適応フィルタ(Sparse Adaptive Filters)というようで、2000年代以降に研究が進んでいるようだ。 最も基本的な適応フィルタであるLMS(Least Mean Square)フィルタは名前の通り二乗誤差最小化に立脚している。 スパース適応フィルタの主な用途はエコーキャンセル、ブラインド話者分離、複数話者特定ではあるが、やはり変換後の分布がスパースになるというのは大きい。 スパース適応フィルタの最近のサーベイ論文 を流し読みした。スパース適応フィルタは、変数更新のときに1部の変数だけ更新する方法と、スパース最適化に従って更新するやり方の2つがあった。PNLMS(Proportionate NLMS), IPNLMS(Improved PNLMS)が後者の定式化で興味あり。引き続き見ていく。 Regularized Least-Mean-Square Algorithms には正則化を入れたLMSアルゴリズムの解説あり。LASSOにモチベーションを受けた最適化アルゴリズムが ZA-LMS や APWL1 として提案されている。","tags":"雑記","url":"/2020-04-08.html","loc":"/2020-04-08.html"},{"title":"2020-04-02","text":"GitHub io + Pelican を使ってみた。しばらくこちらで日報を書きたい。 GitHub io + Pelicanは以下の記事を参考にしている。まだあんまり分かってない。 Python製静的HTMLジェネレータのPelicanでGitHub Pagesを公開する方法 GitHub Pagesで静的サイトを簡単に作る Python製 Pelican を使ってサクッとブログを公開する Pelicanのテーマ集 テーマ導入時にハマったので参考にしたissue comment 今日は（というか3月末）からSLAの高速化作業とまとめをしていた。 格子型フィルタ演算はどうしても1乗算型にできず。次数演算を4次数にしてSSE演算するのがやっと。 SSE化するときに、スカラー演算とベクトル演算が混じったときに処理負荷が大きく上がってハマった。 StackOverFlowの記事 では _mm_set_epi32 のコストが高い旨記述あり。 _mm_loadu_si128 の使用に置き換えた。 他の記事 で言及があってようやく分かった。全てをベクトル演算化したところ、処理負荷は4/5倍になった。あんまり早くなっていない。遺憾。 gccとVC にはgccとVisual Studioの挙動の差異について色々と書いてあった。","tags":"雑記","url":"/2020-04-02.html","loc":"/2020-04-02.html"}]};