var tipuesearch = {"pages":[{"title":"R&#94;-1の計算(4)","text":"引き続き sklearnのソース(Github) を見ながら、 依存関係にスパース性を入れる — グラフィカル lasso の話 ∗ の対応を見出そうとしているが、どうも一致しない。pythonのソース側が対応していると言っているのがFriedman Sparse inverse covariance estimation with the graphical lasso とあるので、それを参照したが、実装はFortran...（Rは呼び出しインターフェースだけ。。。） GLASSOの中身で <https://github.com/scikit-learn/scikit-learn/blob/0fb307bf39bbdacd6ed713c00724f8f871d60370/sklearn/covariance/_graph_lasso.py#L226> enet_coordinate_descent関数 を呼んでおり、数値最適化はLASSO(ElasticNetで片方の係数を0にしたもの)に任されている。 どうやら元論文の実装(LASSO最適化を行う)をそのまま落とし込んだようで、ソフトしきい値作用素は一切出てこない。。。 githubで探してみても同様の実装が多数。 簡単そうに見えるから実装してみるか。アルゴリズムを紙にまとめてみた。やってみよう。","tags":"雑記","url":"/r-1noji-suan-4.html","loc":"/r-1noji-suan-4.html"},{"title":"R&#94;-1の計算(3)","text":"要約すると、もうGraphical LASSO実装して試してみるべきかと思う。 sklearnのソース(Github) 数式との対応を追っていく。（しっかし昼は全く集中できない。。。） 気になるのはオプティマイザ（勾配法orLARS）の実装が他のモジュールでやってるところか。","tags":"雑記","url":"/r-1noji-suan-3.html","loc":"/r-1noji-suan-3.html"},{"title":"R&#94;-1の計算(2)","text":"今更ながら三重対角行列、かなり具合が良さそうに見える。 三重対角行列の特殊形の固有値は綺麗 三重対角行列の固有値と固有ベクトルを計算したい 三重対角化 - [物理のかぎしっぽ] 頭に入れときたいのは、「対称行列は直交行列との積（直交変換）で3重対角行列に変換できる」ということ。 Estimating sparse precision matrices スパース（三重対角）な精度行列（共分散行列の逆行列）を求める。これ、かなり近いのでは。 やはり、Graphical LASSOを遅くてもいいから試したくある。 GraphLassoによる変数間の関係のグラフ化 sklearnで実装されているから、逐次計算じゃなくても計算してみることはできる。次はsklearnによる結果と比較してみよう。","tags":"雑記","url":"/r-1noji-suan-2.html","loc":"/r-1noji-suan-2.html"},{"title":"R&#94;-1の計算(1)","text":"\\(R&#94;{-1}\\) の計算高速化を考えていく。 なにより対象を知るのが一番だと思うので、まずは確認コードと真値の計算とその確認を行っていく。","tags":"雑記","url":"/r-1noji-suan-1.html","loc":"/r-1noji-suan-1.html"},{"title":"論文書き(1)","text":"TODO: 図: 実データの結果、グレスケにすると手法の区別がつかない。移動平均サンプル数を多くする？ カラーeps → グレスケepsの裏技 移動平均サンプル数を増やした。グレスケ画像を作った。でもグレスケ置換はしない。白黒印刷で問題ないことがわかればOK｡ 概要: 短い背景があるだけ。研究の新規性が明確でない。研究の目的が述べられず。すぐにLMSとSAの説明に入ってしまう。 ラプラス分布がーがいるかも？→いや、うるさい。 残差をスパースにする必要がある。したがって、圧縮率改善のためには予測モデルの改善を模索する必要がある。SAは… 論理的なギャップに打ち勝つ新規性(novelty)をはっきりさせる。 主張を強めるための数量的な改善点を述べよ。（例: 5%良くなった）。行を追加していい。 実験結果から見れる研究の結論は何？結局コーデックに何が嬉しいの？ TODO: 背景の既存研究の論理的なギャップを要約。結論の言葉を要約。 背景と同じで論理的なギャップなんてなくて、「SAの収束改善」が大事で、これを強調する。To overcome... 結論の言葉、どうするか。（他のSAの論文見てると、実験結果よかった！で終わってて、おれもそうなってるんだが。）ロスレス音声に関するところだと、Future workを述べるか？ 定量的な結果…。実験結果から言えることがない。どうしよう。 導入: 関連する象徴的な(iconic)研究を載せるのを推奨→亀岡の研究のつもり。他にはOptimFROGか？→「A novel normalized sign algorithm for system identifica- tion under impulsive noise interference」を入れた。 新規性をもっと明確に喋れ。既存研究の論理的ギャップに対する改善点は何？現状の問題の解決策になっている？ 研究の背後に有る動機は？ TODO: 概要とかぶるが、既存研究の論理的なギャップは何か洗い出す。そして本研究が何を解決しているか（→適切な分布の仮定を満たす、収束の早い適応アルゴリズムが得られた。）整理。他に、関連する象徴的な研究を洗い出す。 論理的なギャップなんてなくて、「SAの収束改善」が大事で、これを強調する。 象徴的な研究としては「A novel normalized sign algorithm for system identification under impulsive noise interference」を入れた。新しめのまとまった、というかSAの方向性を述べた論文。もう一個くらい見繕っておくか。 ディスカッション: 制限を述べただけになってる。 他手法と比べて提案手法はどうなのか？得られた結果に対するコメントを述べるべし。 他手法はどうなのか？ 結果が意味するのはなにか？（最終段落で短く述べられてるだけになっている。もっと書くべし。） TODO: 他手法との比較を追加。結果の吟味を追加。 他と比べてよかった。はまず言う。 It is obvious that proposed algorithms show better convergence performance than that of the SA. RLSと似たパフォーマンスを出していたのも頷ける。The NNGSA had similar performances as RLS. しかし…負荷が…というつなぎ方に変える。On the other hand, however, 結論: コーデックや社会にどんな影響がある？ コーデックにどのように適用する？ 今後の展望（研究範囲）をもっと掘り下げるべし。 TODO: Future studyにロスレス音声予測モデルへの組み込みを検討する、とまず言う。そのために…をやる。という流れに。 ロスレス音声への組み込みを将来研究に組み込んだ。","tags":"雑記","url":"/lun-wen-shu-ki1.html","loc":"/lun-wen-shu-ki1.html"},{"title":"論文読み(4)","text":"論文読みのコメント: 「新板 情報幾何学の新展開」の15.7節（p190）にFisher情報行列の固有値の分布の議論が有る。なにか使えないか？ DCの件、自分の研究内容にフォーカスしすぎてて広がりが見えにくかったという指摘があった。来年早いうちに着手する。春休み入ってからとか。 筆者(Tianshu Quさん)に連絡してできたらソース貰う。","tags":"雑記","url":"/lun-wen-du-mi4.html","loc":"/lun-wen-du-mi4.html"},{"title":"論文読み(3)","text":"一気に追い込んで資料を作成。雑かも。 一点気になっていたのが \\(l&#94;{2}\\) と \\(L&#94;{2}\\) の違い。 Difference between l2 norm and L2 norm 実数列に対するノルムは \\(l\\) 、有界な定義域 \\(\\Omega\\) 上に定義されたルベーグ可測関数のノルムは \\(L\\) で良さそう。 クソ大雑把に言うと、列に対するノルムは \\(l\\) となり、関数に対するノルムは \\(L\\) と考えて良さそう。","tags":"雑記","url":"/lun-wen-du-mi3.html","loc":"/lun-wen-du-mi3.html"},{"title":"論文読み(2)","text":"今日でCBCの概要を掴んで、プロット、スライド作成に入りたい。 Context-dependent bitplane coding in China AVS Audio あった。読んでる。なんとなくつかめたので、説明を試みたい。","tags":"雑記","url":"/lun-wen-du-mi2.html","loc":"/lun-wen-du-mi2.html"},{"title":"論文読み(1)","text":"標準化されたロスレス音声規格IEEE 1857.2、くっそ怪しい。 リファレンスエンコーダが公開されてないっぽい。 一応概要みたいのは以下: LOSSLESS AUDIO COMPRESSION IN THE NEW IEEE STANDARD FOR ADVANCED AUDIO CODING さっと読んだ。工夫したのは、ブロック先頭で残差が大きくなるから、それをビットシフトして振幅を潰し、下位ビットの情報は別に送ること、算術符号はテンプレートとなる確率分布を使用すること、がメインである。うーん。かなり泥臭いと思う。モデルがすごいと言うよりは工夫メインな印象を受ける。また、他の論文でウェーブレットを使っているみたいな話があるけど、どうにもこちらも怪しい。 ロスレス音声でウェーブレット+BPを使う話。 AUDIO LOSSLESS CODING/DECODING METHOD USING BASIS PURSUIT ALGORITHM 音声圧縮でウェーブレットを使うのは筋が悪かったので、少なくとも自分には衝撃ではある。で、ちゃんと読んでみようと思ったのだが4pで概要しか示されてない。 肝となる部分でわからないのが、ウェーブレット辞書を結合して過完備な辞書を作るところ。基礎が抜けていることを疑って、Donohoを読む: Atomic Decomposition by Basis Pursuit そして論文ではliftingを使ったと行っているが、liftingを使った場合、どうなるのか？画像に対して試したのが下: IMAGE COMPRESSION BASED ON COMPRESSIVE SENSING USING WAVELET LIFTING SCHEME ロッシーなんだよなあ。 BPで辞書作るときって、基底をサンプリングして作るんだっけか？BPの動きを確認し始める。 Example: Basis pursuit (BP) ウェーブレットの場合の答えが以下にある。精読していく。 Multi-Scale Dictionary Learning using Wavelets Dictionary Learning Using Wavelets そもそもウェーブレット変換って行列表現できたっけ？と思ったら、余裕でできてた。これの高速算方が離散ウェーブレット変換(DWT)だったわ。 1次元ウェーブレット変換 論文が参照しているウェーブレット系のペーパーが重い。 Building Your Own Wavelets at Home 有名なペーパー。ウェーブレット自分自身で構築できるようだ（2nd Generation Wavelet）。その計算方法がLifting Schemeとなる。 Factoring Wavelet Transforms into Lifting Steps 1st Generation WaveletはLiftingの形式に持っていけると言っている 非常にボリュームが大きい。。。弱った。 INTEGER WAVELET TRANSFORM BASED LOSSLESS AUDIO COMPRESSION 古いけど、ウェーブレットを使ったロスレス音声圧縮がここに。 理論一切抜きで、計算法は分かった。しかし、BPによってどのように基底を選んでいるのかさっぱり分からん。ウェーブレットは固定辞書だから、L1正則化問題を解析的に解いてはいないはず。Basis Pursuitはアルゴリズムじゃなくて原理だと 原論文 で言っていたし: BP is an optimization principle, not an algorithm. Over the last 40 years, a tremendous amount of work has been done on the solution of linear programs. Until the 1980s, most work focused on variants of Dantzig's sim- plex algorithm, which many readers have no doubt studied. In the last ten years, some spectacular breakthroughs have been made by the use of so-called interior-point methods, which use an entirely different principle. うーん、妄想してみると、こんなかんじだろうか？ 辞書作成: Cohen-Daubechies-Feuveau(cdf) wavelet, Daubechies(db) wavelet, Symlets(sym) 等（\"等\"は謎。全部書いてくれよ...）から辞書を作る。ここでは、cdf,db,symの3つ使ったと考える。 ウェーブレット変換: cdf, db, symの3つで変換を行う。変換はLifting Schemeで行う。 基底選択: 最もL1ノルム（残差絶対値和）が小さかったウェーブレット基底を選び、出力を確定させる。 この操作を低域/高域成分の両方に対し、高解像度から低解像度に向かって行っていく。（高域/低域両方に対して分析をおこなうのをウェーブレットパケット解析というようだ。低域成分（画像で言うなら左上）だけに分析を続けるのはウェーブレット解析。ウェーブレットパケット解析は二分木をなす。） 最終的に得られた出力をエントロピー符号化する。 解像度の深さと、選んだ基底の情報はside informationとして渡す。 ウェーブレット理論と工学への応用 日本語でちゃんと書かれたリフティングの話。印刷して、読もう。 わからないのは後はエントロピー符号化(BCB)のはず。クローズっぽいんだよなあ…。 明日、プロットをまとめる。","tags":"雑記","url":"/lun-wen-du-mi1.html","loc":"/lun-wen-du-mi1.html"},{"title":"自由工作(10)","text":"黙々と進めた。残タスクは、 コマンドラインの整備:DONE 残差出力モードの追加(-e):DONE 統計情報出力モードの追加(-c):DONE テストケース追加:DONE 白色雑音入力(randで生成したものでよい):DONE リリース実行確認:DONE 先頭で一発空エンコードして適応を早める:DONE コード整理 エンコーダとデコーダを分ける: DONE ブロックデータエンコード/デコード関数が大きいので関数化: 小さくまとまったのでいいかな。 音質向上への工夫 MS処理の再興。MS処理のスイッチオプションを追加 もう一度試してみたらRMSEが悪化していることが分かった。（BGMとアイカツ音源で調べた） 実際に聞いてみるとパチパチ言ってる。不連続点が出ている。パチパチ言ってた記憶はないので、何かがおかしい。デバッグ。 デコード時にLRに戻す前にオーバーフローしていた。 バグや。ブロックヘッダにLRが入っているが、フィルタはMSで予測していた。そらパチパチ言うわ。 パチパチは直したが、得られた結果は微妙と言わざるを得ない。最大誤差は減ってるけど、平均誤差は増大した傾向。 オプションにしてもデフォルトでオフかなあ。 MSでうまく行かない例としては、振幅が大きい振動波で、side成分が割れている場合。（ピエトロの気絶の55秒付近）そこをADPCM化すると、エフェクターを通したように割れてしまう。 ロスレスではないから、エンコード時にsideも右シフトすることで、sideが割れる問題は緩和した。採用。しかしMSはオプションとする（デフォルトOFF）。 振幅がでかいときに誤差が大きくなる。じゃあ、入力を1bit右シフトして、出力時に1bit左シフトしていいんじゃない。 純粋に情報量が落ちそう。試してみるが。→うん、だめ。1bitぶん何かがわからなくなるのはつらい。 NG的なアイデア入らないか？ プリエンファシスを掛けたもので勾配計算する。重いか…？ 爆裂に精度悪化。とりやめ。時間切れ。 IIR的（出力）の適応: ダメだった。負荷も増えるし、やらん。 モーメンタムみたいに、前の勾配を使えないか？ やってみたが微妙。たいていRMSEが悪くなる。良くなっても劇的じゃない。 SLAのLogSignを強引に入れてみたけど良くない。 その他、残差と履歴をlog/sign化したけど芳しくなかった。 コードを2の補数にしたい。 上位ビットを埋めるのが帰って辛いように思えた。保留。 ノイズシェーピングが芳しくない。 ちょっと考えると、品質の低いフィルター突っ込んでんのと同じに思えた。実際外すとRMSEが向上した。 廃止の方向で検討。 負荷 instruments -t \"Time Profiler\" ./aad ... でいける。 今更だが、 資料1 , ffmpeg Macでinstrumentsが廃止されたようだ。 xcrun xctrace record --template 'Time Profiler' --target-stdout - --launch -- ./aad -e ManiMani.wav a.aad で計測を行っている。 感想・展望 うーん、性能が良くない。IMA-ADPCMに毛が生えた程度か。XMAみたく、ブロック区間の残差の最大振幅値を計測して割った方がええのかな。 4bitのときは、残差を max(-最小残差/8, 最大残差/7) で割れば、残差が4bit収まる。 3bitならば max(-最小残差/4, 最大残差/3), 2bitならば max(-最小残差/2, 最大残差/1) となるはず。 一般化すると max(-最小残差/(1 << (bits-1)), 最大残差/((1 << (bits-1)) - 1)) ブランチ切ってやってみたい...と思ったらできないことがすぐに分かった。量子化誤差が適応中にわからない。 LPCを使うのもありだな。係数の絶対値が1を超えるから係数のスケール情報を入れる必要があるが。 量子化誤差が適応的に出る（しかも、エンコード/デコードで全く同じ値が出る）から、これに応じてステップサイズ、もしくは符号化値を変えられないか。 複数回エンコードを回すの有効かも。少なくともファイル先頭では効いた。 単純に単一ブロックを繰り返しエンコードするのは効果が薄かった。 次（前）の区間と合わせてエンコードするのもいいかも。オーバーラップする形。これは効いたので取り入れた。 テーブルの見直し。急激に振幅がかわる（2〜3サンプルで-1から1に近づくときがある）ので、おそらく、テーブルの150以降の要素はもっと大きい値をとってもいいと思う。 ステップサイズを適応的に計算するyamaha形式を試してみたい。IMAではテーブルの256階調に限られるが、こちらはより柔軟に思える。 * ADPCMの仕組み#1 や rockbox や ffmpeg が参考になる。 * やっつけでやってみた。音圧の低い音源では少しよくなったが、りんごの木など音圧が大きい音源で軒並みRMSEが2割ほど悪化。取り下げていく。逆に考えると、低音圧音源で現在の実装があんまり良くないともいえる結果やな。 残差波形を見ているとピッチの残差立ち上がりが大きくて、また、それによって聞こえやすいノイズが発生している。周期は170サンプル=282Hz(@48k)とか。 ピッチを潰すのは有効かも。自己相関を計算して周期を解析して、その一点で潰しにかかる。 タイムオーバー。現実にもどりましょ。","tags":"雑記","url":"/zi-you-gong-zuo-10.html","loc":"/zi-you-gong-zuo-10.html"},{"title":"自由工作(9)","text":"AADのフォーマットを書いてく。デバッグ効率のため（データ到着順で見れるようにしたい）に、ビッグエンディアンで... ヘッダフォーマット 名前 サイズ[byte] 内容（補足） AADシグネチャ 4 'A', 'A', 'D', '0' フォーマットバージョン番号 4 1 チャンネル数 2 サンプル数 4 1チャンネルあたりの全サンプル数 サンプリングレート 4 サンプルあたりビット数 2 2, 3, 4のいずれか。1もいつかは対応したい。 ブロックサイズ 2 ブロックのヘッダと圧縮済みデータを含めたサイズ。末尾のブロックではこの値以下になる ブロックあたりサンプル数 4 末尾のブロックではこの値以下になる ブロックサイズは256の倍数にしたい。デフォルト1024で。 ブロックヘッダフォーマット 名前 サイズ[byte] 内容（補足） フィルタ係数 8 * チャンネル数 符号付き16bit整数の係数が4つ それがチャンネル数ぶん フィルタ入力履歴 8 * チャンネル数 符号付き16bit整数のサンプルが4つ（先頭4サンプル） それがチャンネル数ぶん テーブルインデックス 1 * チャンネル数 予約領域 1 * チャンネル数 偶数にするため。 ヘッダサイズは18 * チャンネル数[byte]。 しかしヘッダが大きすぎるかもしれない。入力履歴は毎回リセットすべきか？ SLAではブロックごとにフィルタ係数をリセットしていたけど、こっちではまずそう。ブロックあたりサンプル数が少なくて適応が遅くなる。 →ホールド（直前サンプルが続いている）でもOK。軽く試したけど、当然、誤差は増える。 まずは富豪的に、上のフォーマットで作る。 ブロックデータフォーマット サンプルあたりビット数で異なる。ビッグエンディアンで、上位bitから順に書いていく。 4bit: 2サンプル(=1byte)単位でインターリーブ。 3bit: 8サンプル(=3byte)単位でインターリーブ。 2bit: 4サンプル(=1byte)単位でインターリーブ。 1bit: 8サンプル(=1byte)単位でインターリーブ。 ブロックデータサイズは、(インターリーブの単位*チャンネル数)の倍数に設定する。 フォーマット ビッグエンディアンで記録する。 ヘッダフォーマット 名前 サイズ[byte] 内容（補足） AADシグネチャ 4 'A', 'A', 'D', '0' フォーマットバージョン番号 4 コーデックバージョン番号 4 チャンネル数 2 サンプル数 4 1チャンネルあたりの全サンプル数 サンプリングレート 4 サンプルあたりビット数 2 2, 3, 4のいずれか。1もいつかは対応したい。 ブロックサイズ 2 ブロックのヘッダと圧縮済みデータを含めたサイズ。末尾のブロックではこの値以下になる ブロックあたりサンプル数 4 末尾のブロックではこの値以下になる マルチチャンネル処理法 1 0:何もしていない、1:LR->MS処理（効果が薄いため、廃止予定） ブロックヘッダフォーマット 名前 サイズ[byte] 内容（補足） テーブルインデックス上位8bit 1 テーブルインデックス下位4bit / 係数シフト数 1 下位4bitは固定小数の小数部。 フィルタ係数 8 符号付き16bit整数の係数が4つ。係数シフト数分左シフトして使う。 フィルタ入力履歴 8 符号付き16bit整数のサンプルが4つ（先頭4サンプル） これがチャンネル数分並ぶ。ヘッダサイズは18 * チャンネル数[byte]。 ブロックデータフォーマット サンプルあたりビット数で異なる。ビッグエンディアンで、上位bitから順に書いていく。 4bit: 2サンプル(=1byte)単位でインターリーブ。 3bit: 8サンプル(=3byte)単位でインターリーブ。 2bit: 4サンプル(=1byte)単位でインターリーブ。 1bit: 8サンプル(=1byte)単位でインターリーブ。（未サポート。将来的にやりたい。）","tags":"雑記","url":"/zi-you-gong-zuo-9.html","loc":"/zi-you-gong-zuo-9.html"},{"title":"自由工作(8)","text":"ステップサイズテーブルの再設計。256エントリでいいはず。8bitの領域を使い切るべき。 * インデックス更新テーブルの吟味(特に3bit)。 LMSフィルタの吟味（プリエンファシスもやったところで再度SAを確かめてみたい。→かんたんにやってみたけど、低音圧でSA、高音圧でLMSの印象。一応SAにしておく。発散する場合がみられている。。。nibbleが2の補数になったらそれを残差として突っ込むという夢がある。） フォーマット再度策定。2,3,4bitの書き出し処理分割。 nibble（出力コード）は2の補数でいい。符号+絶対値だとエンコードデコードが複雑になる。 ここまでやってて色々弄ってたら、なーんか音質が悪化していることに気付く。デフォルトのADPCMの方がよくね？ 耳で聞くよりはRMSでがっちり評価していきたい。 プリエンファシスが悪そう。実装を整理してON/OFFできるようにして調査する。 インデックス更新値を持ち越して次サンプルで使う手法、あんまり美味しくない。 テーブルを256エントリに拡張したら、高音圧音源ではグッドだけど、低音圧音源でジャリジャリが目立つ。sin波で適応が遅い感じ。 2bitだとどうしても適応が遅い印象。 フィルタの学習も遅い印象も受ける。最初のブロックを何回か回して処理開始するとかどうでしょう。いいアイデアだけど、フィルタの状態をブロックヘッダに入れる実装がまだなので、それができてから。 さて、コーデックとして仕立てていくか。基本的なAPIはIMAADPCMと同じで良いとして、 命名規則の変更: IMAADPCM -> AAD (Ayashi Adaptive Differential pulse code modulation) 拡張子.aad フォーマット策定: ヘッダ, ブロックヘッダ, ブロック エンコードパラメータの整理 プリエンファシス、デエンファシスをプロセッサハンドルを介してできるように。","tags":"雑記","url":"/zi-you-gong-zuo-8.html","loc":"/zi-you-gong-zuo-8.html"},{"title":"自由工作(7)","text":"Inside IMA ADPCM こっちも同じ内容 Simple Time Domain Audio Coding MediaWikiの前身となる資料。時間領域符号化の包括的なまとめでもある。有益そう。 強引に3,2bit化してみた。なんとなくできてしまっているが、2bitは流石にジリジリいう。 なんでかな、と思ったらステップサイズが4bitむけのものになっていて、テーブル参照インデックスが0でも7になってしまい、確実に揺れてしまうのが問題であると想像している。テーブル自作を試みているが、なかなかに苦戦。 IMA-ADPCMのステップサイズが謎。どっから導出したんだろうか。 純粋な指数関数ではなさそう。とくに、最初の8要素は線形関数になってるのが奇特。（テーブルの情報量を増やしたいのかな？）しかし、後になると指数関数 \\(2&#94;{\\log_{2}(32767/7)/88 x + \\log_{2}(7)}\\) とほぼ一致。 自作のテーブルより、IMA-ADPCMのテーブルの方がいいRMSを出している。。。何故やろ・・・。 テーブルは一旦諦めて、モデルの改善を考えたが、あんまり良くない。 フィルタ次数を8にしたり、IIR（予測値をフィードバック）したり。 効果があったのが3つ。 ノイズシェーピング。残差を量子化するからその量子化誤差を1/16を掛けてフィードバックする（大きすぎると発散する）。残差わずかに減少。 LR->MS。ステレオ音源で残差減少。注意点としては、16bit幅を超えるからやるならPCMを32bit幅で持つべき。いまは破壊的な処理をしてる。 プリエンファシス。1サンプルエンコード/デコード処理でやりたいが、そうなってない（汚い実装になってる）。一回RMS減ったのは見たけど、本当かもう一度確かめたい。 これらはスイッチできるといいなあ。 2bitとなると音質クッソ厳しい（りんごの木、Mani Mani等音圧変化の激しい曲はかなりきびしい。声のみだけだったらいける。）けど、ここらで独立させてみるか。","tags":"雑記","url":"/zi-you-gong-zuo-7.html","loc":"/zi-you-gong-zuo-7.html"},{"title":"自由工作(6)","text":"群論再開させつつ。 mac update以降、コンパイル警告がうざったくてしょうがなくなっていた。どうやら /usr/include が消えたようで… export SDKROOT=\"$(xcrun --sdk macosx --show-sdk-path)\" で黙らせている。 4次の適応フィルタを予測に突っ込んでみた。平均的な平均絶対値誤差は前値予測よりもガッツリ減っているが、音質はあんまり替わってない印象。 カレンダーガールを突っ込んだら高域（20k〜）にガッツリノイズがついた。ナイキストレートの早さでノイスがのってる。 48k音源ではどうも共通して現れる特徴のようだ。 音質は、原音と変わんねえだろと思い続けている。ここがおかしいというのを具体的に指摘できないでいる。スペクトログラムを見て初めて分かる感じ。 ビット数減らしに行くのがよさそう。試すのであれば、残差は4bitで書き出すけど、内容は3bitまでしか持たないようにするという方策。 3,2bitに応じたテーブル作成が熱い。","tags":"雑記","url":"/zi-you-gong-zuo-6.html","loc":"/zi-you-gong-zuo-6.html"},{"title":"自由工作(5)","text":"ノイズ（差分の量子化誤差）はまさにi.i.d.なラプラスからサンプリングした感じ。全帯域にある。 人間の声のところは調波構造があるけど、それ以外、ピッチのない楽器などは単純な白色雑音といった印象。 ノイズシェーピングを試しているが…本当にいいのか疑問。 プリエンファシスみたく直前サンプルで引くと、たしかにノイズの低域は消える、けど高域はそのままだし、 ノイズのRMSはむしろ悪化している状態。 逆に直前サンプルで足すとノイズ高域は消えるけど、低域が残ってｺﾞｰという感じのノイズになる。目立つ。うーん。 ノイズシェーピングの基本は、ノイズ帯域を\"おいやる\"ことにあるようで、その後になにかしないとうまみがない？ （低域のノイズを消してノイズを高域に追いやってからローパスをかけるかんじ。） 適応フィルタチックなことも試してみたが、不安定になりがち。 残差の符号だけ使い、ステップサイズをクソ小さくしてなんとか安定するが、ノイズのRMSは何もしないものから悪化。 一旦ノイズシェーピングなしのやつをアップする。 自己流のやつを試してみたい気持ちがある。","tags":"雑記","url":"/zi-you-gong-zuo-5.html","loc":"/zi-you-gong-zuo-5.html"},{"title":"自由工作(4)","text":"エンコードもできた印象。まずは、量子化誤差の観察を開始している。 ラプラス分布っぽいので頻度を出してみる。→すごいラプラスだった。 gnuplotで頻度を出すには以下で行ける。素晴らしい。 :: plot \"foo.txt\" u 1 smooth frequency with boxes plot \"foo.txt\" u 1 smooth frequency with lines","tags":"雑記","url":"/zi-you-gong-zuo-4.html","loc":"/zi-you-gong-zuo-4.html"},{"title":"自由工作(3)","text":"しばらく夏休みしてた。作業再開。エンコード作成中。 ADPCMの音質改善にはノイズシェーピング（量子化ノイズ）をへらすのが有効らしい。特許に注意だけど切れてそう。 休んでいる間に色々リンク見つけたからまとめてからねる。 adpcm-xq WavPackの人のADPCM(IMA)の改良エンコーダ。いいアイデアが2つ。ノイズシェーピングと先読みエンコード。 A comparison of Internet audio compression formats 音質比較 What quality measurement is best for (A)DPCM? ADPCMの評価指標について G.726 ADPCMエンコーダの詳細 本と同じ内容だけど、こっちはいつでも見れる。 信号品質を保つディジタル化技術: ノイズシェーピング量子化—I ノイズシェーピングの基礎。Ⅵまである。丁寧。 ADPCM音質改善 重要。ノイズシェーピングの効果について書いてある。ソースもある。 ADCの動作原理 ADCとノイズシェーピングの必要性がわかりやすく書いてある。 AD変調器(2) こちらもADCとノイズシェーピングについて記述有り。 Bit Twiddling Hacks Hacker's Delightに掲載されてないのもある。","tags":"雑記","url":"/zi-you-gong-zuo-3.html","loc":"/zi-you-gong-zuo-3.html"},{"title":"自由工作(2)","text":"ADPCMのデコードはほぼできた。次はエンコード。 いろんなソース見とるが、予測時に分岐しまくるのやばくね？とおもってたらそのとおりで、ffmpeg実装は乗算を使ってる: ffmpegの実装（adpcm_ima_expand_nibble） ffmpegのエンコーダ実装(adpcm_ima_compress_sample) static inline int16_t adpcm_ima_expand_nibble ( ADPCMChannelStatus * c , int8_t nibble , int shift ) { int step_index ; int predictor ; int sign , delta , diff , step ; step = ff_adpcm_step_table [ c -> step_index ]; step_index = c -> step_index + ff_adpcm_index_table [( unsigned ) nibble ]; step_index = av_clip ( step_index , 0 , 88 ); sign = nibble & 8 ; delta = nibble & 7 ; /* perform direct multiplication instead of series of jumps proposed by * the reference ADPCM implementation since modern CPUs can do the mults * quickly enough */ diff = (( 2 * delta + 1 ) * step ) >> shift ; predictor = c -> predictor ; if ( sign ) predictor -= diff ; else predictor += diff ; c -> predictor = av_clip_int16 ( predictor ); c -> step_index = step_index ; return ( int16_t ) c -> predictor ; } static inline uint8_t adpcm_ima_compress_sample ( ADPCMChannelStatus * c , int16_t sample ) { int delta = sample - c -> prev_sample ; int nibble = FFMIN ( 7 , abs ( delta ) * 4 / ff_adpcm_step_table [ c -> step_index ]) + ( delta < 0 ) * 8 ; c -> prev_sample += (( ff_adpcm_step_table [ c -> step_index ] * ff_adpcm_yamaha_difflookup [ nibble ]) / 8 ); c -> prev_sample = av_clip_int16 ( c -> prev_sample ); c -> step_index = av_clip ( c -> step_index + ff_adpcm_index_table [ nibble ], 0 , 88 ); return nibble ; } nibbleってなんだよ・・・って思って調べたら1/2バイト(4bit)のことだった。 デコーダ作って安定させてたら、AudacityとffmpegのADPCM(IMA)のデコード結果が違うことに気付く。 原因は、Audacityを始めとした多くのコーデックでは分岐が多い近似実装になっているからだった。 こいつ が原因か。 一方、ffmpegは近頃のCPUは十分乗算が早いからと言う理由で厳密計算している。ということで自分も厳密計算を選ぶ。 もう一点、AudacityにADPCM(IMA)を突っ込むと末尾が伸びてしまう。これは末尾のブロックも同一サンプル数でデコードしているから…。 あきらかな不具合。PR送るか、送らざるべきか…。 Audacityは内部でlibsndfileを使ってるから、 こっち にPRを送るべき。","tags":"雑記","url":"/zi-you-gong-zuo-2.html","loc":"/zi-you-gong-zuo-2.html"},{"title":"自由工作(1)","text":"まずはIMA-ADPCM互換のデコーダ/エンコーダを作ってみますかね。かなり情報あるし。 FFMPEGで出力する方法は: ffmpeg -i <input.wav> -f wav -acodec adpcm_ima_wav <output.wav> Macで再生もできた。ほぼ1/4になる。理論的には1/4だけどwavに余計なチャンクが入っているから減っている？ ステレオ以上はどうなってるのか見ている。インターリーブしているようだ。 Microsoft IMA ADPCM 上記のサイト含めてフォーマットをまとめると（ 全て リトルエンディアン） 名前 サイズ[byte] 内容 RIFFチャンクID 4 'R', 'I', 'F', 'F' RIFFチャンクサイズ 4 ファイルサイズ - 8（これ以降の残りファイルサイズ） ファイルフォーマットタイプ 4 'W', 'A', 'V', 'E' FMTチャンクID 4 'f', 'm', 't', ' ' FMTチャンクサイズ 4 これ以降のFMTフィールドのサイズ WAVEフォーマットタイプ 2 IMA-ADPCMなら17 チャンネル数 2 IMA-ADPCMの場合は1（モノラル）か2（ステレオ）しかないっぽい サンプリングレート 4 データ速度（byte/sec） 4 = ブロックサイズ * サンプリングレート / ブロックあたりサンプル数 ブロックサイズ 2 ブロックのヘッダと圧縮済みデータを含めたサイズ サンプルあたりビット数 2 IMA-ADPCMなら4のはず エキストラサイズ 2 これ以降に続く追加データサイズ ブロックあたりサンプル数 2 FACTチャンクID 4 'f', 'a', 'c', 't' FACTチャンクサイズ 4 これ以降のFACTチャンクサイズ サンプル数 4 = DATAチャンクサイズ * ブロックあたりサンプル数 / ブロックサイズ DATAチャンクID 4 'd', 'a', 't', 'a' DATAチャンクサイズ 4 これ以降のDATAチャンクサイズ 圧縮済みデータ ※ ※ = DATAチャンクサイズ","tags":"雑記","url":"/zi-you-gong-zuo-1.html","loc":"/zi-you-gong-zuo-1.html"},{"title":"自由工作","text":"発表会終わり。発表準備と並行して群論やってた。 夏休みは自由工作（息抜き）としてADPCMエンコーダデコーダ作ろうかと思ってる。 もちろん、群論（リー群まで）と情報幾何（統計的応用まで、行間のまとめ）は進める。 ADPCMのフォーマットを見ている。 IMA ADPCM vs MS ADPCM Microsoft ADPCM IMA ADPCM CRI ADX ADPCM Recommended Practices for Enhancing Digital Audio Compatibility in Multimedia Systems IMA公式の推奨規格。実装も掲載されてて有益。 MS-ADPCMかIMA-ADPCMやなあ。IMA-ADPCMの方が説明が充実している。 そして、なんとなくステップ幅をテーブル引きするところにTAKとの類似点を感じる。 G.726もありだがテーブル引きを使ってない。説明は「音声&画像処理の常識」に書いてある。 研究としてはグラフィカルLASSOの導入忘れずに。もう一度張っとく。 依存関係にスパース性を入れる — グラフィカル lasso の話","tags":"雑記","url":"/zi-you-gong-zuo.html","loc":"/zi-you-gong-zuo.html"},{"title":"研究会に向けて - 執筆(5)","text":"自己相関行列の逆の推定、グラフィカルLASSOが有効ではというありがたい指摘あり。 依存関係にスパース性を入れる — グラフィカル lasso の話 他にも精度行列の推定を（スパース制約を入れて）高速にやるみたいな話がたくさん出てきている。参考にすべし。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete-zhi-bi-5.html","loc":"/yan-jiu-hui-nixiang-kete-zhi-bi-5.html"},{"title":"IGおべんきょ(4)","text":"しばらくIGをおべんきょしてた。行間メモは公開していきたい。 で、いまはChentsovの定理で絶賛ハマってる。(0,4)-テンソル場で定数倍にならない理由って何よ。 証明の1ステップと言ったらラベルに対する付替えで、 4次元以上で起こる特殊なこと…を調べていて、群論が関わってくるのでは。と。 ラベルの付替えは対称群に相当するはず。 交代群が非可換になること ガロア理論を理解しよう でももっと単純に考えるべきかも。 \\(F\\) は当然計算できる上で、 \\(\\~{F}\\) も不変性の要求を満たす。 でも \\(\\~{F}\\) は \\(F\\) の定数倍にならない、みたいな論法。","tags":"雑記","url":"/igobenkiyo4.html","loc":"/igobenkiyo4.html"},{"title":"IGおべんきょ(3)","text":"IGがだいぶ止まってたので、レビューが帰るまでのあいだ進める。 今日の合言葉：写像の微分は接ベクトルの写像。","tags":"雑記","url":"/igobenkiyo3.html","loc":"/igobenkiyo3.html"},{"title":"研究会に向けて - 執筆(4)","text":"引き続き執筆。今日あたりであらすじ書いてレビュー予定。 思ったのが、先にデータの自己相関行列の逆を計算して勾配計算用のデータを用意しちゃう発想はどうよ？という点。 もしくは、自己相関（の偏り）を打ち消すようなフィルタを先にかけてからフィルタ処理をおこなうのはどうか？演算誤差が気になるけど、ありえる発想。 これはもしかしたらプリエンファシスの一般化かもしれない。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete-zhi-bi-4.html","loc":"/yan-jiu-hui-nixiang-kete-zhi-bi-4.html"},{"title":"研究会に向けて - 執筆(3)","text":"土日は黙々と執筆してた。 1点気になったのが、自然勾配法を共役勾配法的にやれないかというところ。そうすれば逆行列を計算しなくて済む。 ここらへん誰かやってないのかな？誰でも思いつくと思うけど。 Adaptive Filters 適応フィルタの新しい良さげなまとめ。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete-zhi-bi-3.html","loc":"/yan-jiu-hui-nixiang-kete-zhi-bi-3.html"},{"title":"研究会に向けて - 執筆(2)","text":"\\begin{equation*} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\inprod[2]{\\langle #1,\\ #2 \\rangle} \\end{equation*} うーん、SAの原典を探ってるときに Adaptive Filtering: Algorithms and Practical Implementation が参照されてて、その中で Performance of LMS-Newton Adaptation Algorithms With Variable Convergence Factor in Nonstationary Environments が参照されてたけど、全く同じやん… どうも、Winner解を求める最適化問題のニュートン法を求めると、自己相関行列の逆が自然に出てくるみたい。そして、その適応ステップ版アルゴリズム（LMS Newton Algorithm, 初出はAdaptive Signal Processing(Widrow)）は上記論文と完全に同一。 LMS Newton Algorithmは、Adaptive Signal Processingのp142あたり（Chapter8冒頭）が詳しいが、残差の二乗を目的関数（Adaptive Filter Theory p105 2.38, 2.50に注目）としたときのニュートン法を近似して得られる。導出にあたり勾配を近似（確率降下）することでNewton法が成立している。 適応ステップサイズの設定法には他にもある。 準最適ステップゲインを用いたBlock LMS-Newtonアルゴリズム これはLMS Newton Algorithmに関する話だけど、ここで提案されているやり方をSAに持っていけないか？→ブロック単位で更新しているから話が違う？いや、もうちょっと読み込もう。 この論文で可変ステップサイズに関する議論が出てきている。最適係数から垂線を下ろしたところでステップサイズを決めるという方針。それにしたがってNGSAにおいても最適なステップサイズを求めたら今までのNNGSAと同一の結果が出た。 勾配 \\(\\ve{g}[n] = \\mathrm{sgn}(\\varepsilon[n])\\ve{x}[n]\\) に対して \\(\\inprod{\\ve{R}&#94;{-1}\\ve{g}[n]}{\\ve{h}_{\\rm opt} - (\\ve{h}[n] + \\mu[n] \\ve{R}&#94;{-1} \\ve{g}[n])}_{\\ve{R}} = 0\\) を満たす \\(\\mu[n]\\) こそ、勾配のなす方向に対して \\(\\ve{h}_{\\rm opt}\\) から垂線を降ろせているから最適になる。直交条件を展開すると、 \\(\\ve{g}[n]&#94;{\\mathsf{T}} \\ve{R}&#94;{-1} \\ve{R} (\\ve{h}_{opt} - \\ve{h}[n]) - \\mu[n] \\ve{g}[n]&#94;{\\mathsf{T}} \\ve{R}&#94;{-1} \\ve{R} \\ve{R}&#94;{-1} \\ve{g}[n] = 0\\) で、 \\(\\ve{g}[n] = \\mathrm{sgn}(\\varepsilon[n])\\ve{x}[n]\\) を突っ込むと \\(\\mathrm{sgn}(\\varepsilon[n]) \\ve{x}[n]&#94;{\\mathsf{T}} (\\ve{h}_{\\rm opt} - \\ve{h}[n]) - \\mu[n] \\ve{x}[n]&#94;{\\mathsf{T}} \\ve{R}&#94;{-1} \\ve{x}[n] = \\mathrm{sgn}(\\varepsilon[n]) \\varepsilon[n] + \\mathrm{sgn}(\\varepsilon[n]) v[n] - \\mu[n] \\ve{x}[n]&#94;{\\mathsf{T}} \\ve{R}&#94;{-1} \\ve{x}[n] = 0\\) より、 \\(v[n]=0\\) ならばいつものステップサイズが出てくる。論文間違ってると思う。。。 つまり、NNGSAはその意味でも最適。追記すべきかも。しかし、勾配 \\(\\ve{g}[n]\\) がLMSのときとの差異が気になる。 有益そうなのは、ブロックあたり1回だけ逆行列補題を使うだけでもよいという主張（問題ないことを示している）。つまり自己相関行列の更新を間引く。 Analysis of LMS-Newton Adaptive Filtering Algorithms with Variable Convergence Factor Academaから落とした。 Newton LMS AlgorithmはRLSと等価。 Optimal variable step size for the LMS/Newton algorithm with application to subband adaptive filtering これもAcademiaから でも、NNGSAまで至らないと上記の一致は指摘できない。また、こっちはFisher情報行列ベースで話を進めているから、射影の足がKLダイバージェンスに一致することを議論できる。 あ、でもNGSAは残差のsgnとってるだけだから、LMS Newton Algorithmのステップサイズを荒く量子化したやつに対応するのか。いや、それでも、ラプラス分布仮定時に最急勾配になってるはずなんや。最適値近傍で頑張って0に近づけるし、しかも遠いときはゆっくり近づいてロングテールな分布を作っているんや。 Adaptive filters: stable but divergent なんか適応フィルタのまとめ。時間があれば。 SAの収束性能解析論文がヒットし始めた Adaptive Filtering with Binary Reinforcement とても重要な論文。SAの限界について基本的な定理が述べられている。そして、SAはLMSより遅いという指摘あり。これが欲しかった。 CONVERGENCE ANALYSIS OF THE SIGN ALGORITHM FOR ADAPTIVE FILTERING","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete-zhi-bi-2.html","loc":"/yan-jiu-hui-nixiang-kete-zhi-bi-2.html"},{"title":"研究会に向けて - 執筆(1)","text":"今日から執筆していく。目標、7/27に第一般。 しかしまだ書き始めず、プロットを練る。プロットの構成はだいたい発表とおんなじだが、 イントロをしっかり書きたいから、既存のロスレス音声の論文の構成を参考にしていく。 Sparse modeling for lossless audio compression OptimFROGのひと。 オーディオ環境は高級化している。その中でロスレス圧縮は現実的である。プレーヤが使うから、デコーダは高速実装できるべきだ。今現在使われているいろんなコーデックがある。MP4-ALS, WMAL, ALAC, Monkey's Audio, FLAC, OptimFROG等。それぞれ異なる予測モデルと圧縮アルゴリズムを使用している。圧縮率、エンコード速度、デコード速度の3つの評価軸があるが、全てを最大にすることはできず、トレードオフの関係にある。例えば、予測次数を最大にすれば圧縮率は向上するが、エンコード/デコード速度が悪化する。 An Introduction to Super Audio CD and DVD-Audio Super Audio CD(SACD)なんてあったのか…すでに死んでるが…。OptimFROGでは高級なオーディオの規格として挙げていた。 A hierarchical lossless/lossy coding system for high quality audio up to 192 kHz sampling 24 bit format: 公開されてない... Lossless Compression of Speech and Audio Signals, and Its Application NTTの原田さんの博論。成果は符号化メイン。 SHORTEN: Simple lossless and near-lossless waveform compression シンプルで宜しい。うざったるい背景描写ほとんどなし。 デジタル化した音声ファイルをそのまま保存するとかなりの容量を食う。ZIP等の一般的な圧縮アルゴリズムは、音声の特徴を捉えていないからうまく圧縮できない。一般的な音声データは16bitで、サンプル間に相関がある。これらのファイルに対する圧縮ユーティリティは高速で、移植性があり、多くのデータを処理可能で素晴らしい圧縮率を達成する必要がある。 国際標準 MPEG-4 ALS による ハイレゾ音源ロスレス伝送 MPEG4-ALSの分かりやすい説明。飾り言葉がおおいので注意。（「コト」や「モノ」の下りは使えない） MPEG­4 ALS – The Standard for Lossless Audio Coding MPEG4-ALSのもうちょっと分かりやすい説明。厚すぎず手軽で良い。 ロッシー符号化は編集やアーカイビングに向かない。歪みを生む。MP3やAACを知覚符号化と言っていた。 予測誤差の Golomb-Rice 符号量を最小化する線形予測分析 これは遊びが無くて良いように見える。というかこれ引用するだろうし、しっかり参考にすべき。 やはりバックグラウンドにロスレス音声は使える。うまく話を作ろう。 「最小絶対値推定量がロバスト推定量で あることから線形予測分析に基づく音声分析の耐雑音 性能を向上する目的として応用されている」もよいアイデア。 Lossless compression of digital audio 今の発表につながる概観書。基礎は変わってない。 デジタル配信で重要な役割を果たす、ミキシングを高い忠実性を保てる。 Cascaded RLS–LMS Prediction in MPEG-4 Lossless Audio Coding MPEG4にカスケード接続したLMS+RLSを突っ込むと3%程圧縮率がよくなるという話。MPEG4-ALSも適応フィルタを使っているので、引用する必要はある。そらそうよ。負荷大丈夫か。 既存研究調査 \\begin{equation*} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\end{equation*} 1回ざっと目を通した論文 Natural Gradient Works Efficiently in Learning LMS界隈からの引用多数。 Adaptive algorithms for sparse echo cancellation 俯瞰した背景描写もある。 PNLMSに偏っているか。古い。 Review and Comparison of Variable Step-Size LMS Algorithms 適応ステップサイズ手法の比較。2015年。 比較について多くの手法を3つの応用例から見ている。結論はNLMSが最高ということだったけど、比較過程については要注目。 Proportionate Normalized Least-Mean-Squares Adaptation in Echo Cancelers 頻繁に参照されるPNLMS。係数の絶対値をその最大値で正規化した値を対角要素に持つ対角行列をフィッシャー情報行列の逆行列とする。 NLMSと比較。DSP実装して実ノイズで試してもいる。理論的解析（定常雑音に対する収束レート解析）もしている。 Normalized Natural Gradient Adaptive Filtering for Sparse and Nonsparse Systems フィッシャー情報行列を対角行列で与えている。 まさに自然勾配をがっつり使う論文。絶対参照すべき。対角行列を計量にしたINLMSを導入し、スパース係数（1つだけ1.0で他全部0）ではPNLMSに負けたけど、非スパース係数（全部1）ではPNLMSよりも結果が良いとか言ってる。 シミュレーション節が短すぎ。システム同定をやったらしいがよく分からん。 Full Proportionate Functional Link Adaptive Filters for Nonlinear Acoustic Echo Cancellation これも。謎のリーマン計量を作る。 比較データの生成が恣意的すぎるので無し。 New Sparse Adaptive Algorithms Based on the Natural Gradient and the l0-Norm これも謎のリーマン計量を使っている…。損失関数に計量が入っちゃってるけどいいのか？→大丈夫っぽい。損失関数の設計は自由。 応用が特殊すぎる。オレオレデータセットに対して有効性を示されても困る。 NATURAL GRADIENT-BASED ADAPTIVE ALGORITHMS FOR SPARSE UNDERWATER ACOUSTIC CHANNEL IDENTIFICATION L0ノルム最小化に自然勾配法をあわせた。とある。やけに性能が良い。 ↑と著者が同じ。データセットも同じ。 l0 Norm Constraint LMS Algorithm for Sparse System Identification 係数l0ノルム最小化。l0ノルムをexpで近似して解析的最小化。 この論文で相関のあるガウス雑音の作り方が明確に示されている。 ITU-Tのデータを使ってるのは参考になった、 が、スパースなデータの作り方が恣意的すぎる。。。 AN IMPROVED VARIABLE STEP-SIZE AFFINE PROJECTION SIGN ALGORITHM FOR ECHO CANCELLATION これが一番近いかも。 なんでここまできて自然勾配に至らないのか？こいつの引用を漁ったけど同一の研究なし。 謎の手順（ガウス雑音に1次のIIRフィルタを通して、しかもベルヌーイ試行で出力判定する）で入力を生成している。よくあるのか？？？ Variable Step-Size NLMS and Affine Projection Algorithms これもそれなりに近い。affine projection algorithm で情報行列の逆を使っている。 移動平均フィルタを理想フィルタにしている。ガウス雑音に謎の2次IIRフィルタを通したものをリファレンスとしている…。 System Identification Using Reweighted Zero Attracting Least Absolute Deviation Algorithms ZA-LADの原典。自分のやっている研究に近いかも。残差L1ノルム最小化はロバストだいう主張。 スパースなときに有利であることを言いたいらしい。 16タップの係数を使い、最初のXXXXイテレーションでは5番目のタップだけ1（他全部0）、次に奇数タップをすべて1にしてYYYYイテレーション、最後に偶数タップを-1にしてZZZZイテレーション。。。 ノイズとして非ガウス的（α-stableと言っていた）なものを使用。SNRはGeneralized SNRという尺度を使用。 他に、白色ガウス雑音に1次のフィルタを通して入力していた。出力に相関をもたせる意図か。 A Novel Family of Adaptive Filtering Algorithms Based on The Logarithmic Cost LLADの原典。 これのデータよい。採用。 単純明快。(理論ばっかりで分かりにくいと思っていたが） リファレンス信号 \\(d_{t} = \\ve{w}_{0}&#94;{\\mathsf{T}} \\ve{x}_{t} + n_{t}\\) で、 \\(\\ve{w}_{0}\\) はリファレンス係数（論文ではランダム選択にしていた。スパースじゃないならいいかも。）、 \\(\\ve{x}_{t}\\) は分散 \\(\\sigma_{x}&#94;{2} = 1\\) の i.i.d な平均0ガウス信号系列、 \\(n_{t}\\) はノイズ信号（分散0.01のガウス雑音と分散10000(偏差100)で一定確率(1,2,5%)で発生するインパルス雑音） 一定確率でインパルス雑音が発生するケースはロバスト性を示すために使われていた。LMSは全く等化できずにいた。 Sparse Least Logarithmic Absolute Difference Algorithm with Correntropy-Induced Metric Penalty 重みによくわからないペナルティを付加したSigned LMS。 これもしかしたら重要かもしれない。ちゃんと書けてる。 Convergence Analysis of Zero Attracting Natural Gradient Non-Parametric Maximum Likelihood Algorithm これ読めないんだけどAbstract読み限り相当やってそう。 以下、日本語論文 音響エコー経路の変動特性を反映させたRLS適応アルゴリズム 室内インパルス応答の統計的性質に基づく指数重み付けLMSフィルタ 実験としては微妙で、理論と一致しているかどうかの議論で終わっている。比較実験なし。 エコーキャンセラ向けのNormalizedLMSアルゴリズムの改良 社内発表資料？ 適応フィルタにおけるブロック形重み付けステップサイズの制御法 直交ECLMSアルゴリズムを用いたエコーキャンセラーの設計 ダブルトーク問題も入ってきちゃってる。 エコーキャンセラにおける適応アルゴリズムとダブルトーク検出の関係 これもダブルトーク問題。しっかしNLMSとの比較のみ。 比較対象にすべき手法 NLMS, Signed-LMS, RLS PNLMS IPNLMS(Improved PNLMS) APA(Affine Projection Algorithm) 比較対象にすべきデータ 発話音声（ソースがない...） 理想係数に入力として単位インパルス（雑音源よりもレベルの小さいノイズもあり）をXXXX回繰り返し入れ続け（途中で理想係数を急に変える）、同時にレベルを決めた雑音源を入力。 シードのみを変えて、XXX回独立した試行を行ってその平均を（残差トレンドの平均も）とる。 ITU G.168のエコーパスモデル 公式 から資料入手可能。 Annex Dに8つのエコーインパルスのデータが乗っかっている。5番目のインパルスがスパースだから良いらしい。 また、リファレンスの波形にフィルタを通して使うらしい。 ほぼ0で、ランダムに選んだいくつかの係数だけが1になっているリファレンスフィルタの出力 * 入力例1: ガウス雑音に1次（極が1つの）のIIRを通し、さらにベルヌーイ過程として、一定確率pでノイズ、1-pで0となる信号 * 入力例2: ガウス雑音に2次のIIRを通す 比較基準 2乗誤差(misalignmentとか行ったりする)[dB] 計算量（畳み込み、係数更新における乗算+加算回数） 定常状態での係数の分散 理想係数との誤差MSE（MSD(Mean Square Deviationとも言う。Simonの本から来てると思われる)。もし計算できるなら。正規化してdB表示する: \\(10 \\log_{10} ( ||h - \\hat{h}|| / ||h|| )\\) ） 定常状態でのMSE MSEの和（全実験での） 可変ステップサイズアルゴリズムの場合は、ステップサイズの変化 思ったこと ブロック線図を書くと良さそう？多くの論文が書いてる。エコーキャンセラーのアーキテクチャは示すべきか。 提案手法はウィーナー解に収束するか？ ロバスト適応同定手法によるエコーキャンセラの設計 ここにウィーナー解との関連がある 信号とシステム ここにもそれなりにある。 音響データベースがある... 6. RWCP 実環境音声・音響データベース (RWCP-SSD) Sign アルゴリズムの概観については、以下もどっかで見ておきたい。 再考・適応アルゴリズム 実は自然勾配法による適応アルゴリズムは非線形適応アルゴリズムになってる？ 非線形適応信号処理技術の新潮流 ──再生核の応用──","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete-zhi-bi-1.html","loc":"/yan-jiu-hui-nixiang-kete-zhi-bi-1.html"},{"title":"研究会に向けて(17) - 中間発表","text":"\\begin{equation*} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\end{equation*} 資料に追い込みを掛けていたので、あまり進捗なし。発表してもらったコメントで大きそうなのをメモる。 SA、実はヘブ則そのものでは？ 全くその通り。識別タスクにしたらまんまそれ。NN的に見ると〜はヘブ則と言ってもいいくらい。 グラフは正方形にすべし。 全くその通り。すぐに修正するべし。 尤度は独立な観測では不完全。独立同分布な(i.i.d.)な観測や NNGSAの最適化問題による定式化ってリッジ回帰に似てる。対角行列を計量にしてる。 \\(\\mathrm{E}\\left[ \\left\\{ \\frac{\\mathrm{sgn}(\\varepsilon[n])}{\\sigma} \\right\\}&#94;{2} \\ve{x}[n] \\ve{x}[n]&#94;{\\mathsf{T}} \\right] = \\frac{1}{\\sigma&#94;{2}} \\mathrm{E} \\left[ \\ve{x}[n] \\ve{x}[n]&#94;{\\mathsf{T}} \\right]\\) はほんまか？a.e.では？近似では？ \\(\\mathrm{E}\\) だから厳密？ やっぱり要審査。自分は期待値操作でルベーグ積分するから、測度0の点は抜いても大丈夫だと思っている。 厳密にいけそう。 \\(\\mathrm{sgn}(x) := \\frac{x}{|x|}\\) と定義すると、 \\((\\mathrm{sgn}(x))&#94;{2} = \\frac{x&#94;{2}}{|x|&#94;{2}} = 1\\) 。 \\(x=0\\) のときが怪しくなるが、これは、 \\(\\mathrm{sgn}(x) \\approx \\frac{x}{\\sqrt{x&#94;{2} + \\varepsilon}}\\) としてやって（ \\(\\varepsilon \\to 0\\) とすれば符号関数に一致）、 \\((\\mathrm{sgn}(x))&#94;{2} \\approx \\frac{x&#94;{2}}{x&#94;{2} + \\varepsilon}\\) で、 \\(\\varepsilon \\to 0\\) としてやれば恒等的に1になる。多分、近似を使ったやり方のほうが \\(x=0\\) でややこしくならないから筋がいい。 答えとしては、 \\(\\mathrm{sgn}(x) := \\lim_{\\varepsilon \\to 0} \\frac{x}{\\sqrt{x&#94;{2} + \\varepsilon}}\\) がいいかも。 いや、まだ怪しい… \\(\\mathrm{sgn}(0) = 0\\) という定義だから、絶対 \\((\\mathrm{sgn}(0))&#94;{2} = 0\\) になる。積分を絡めて考えないとだめか。至るところ1なんだけど、1点 \\(x=0\\) において \\(0\\) を取る関数の平均。。。 グラフのitaration → iteration \\(\\ve{R}&#94;{-1}\\) の計算について。 低ランク近似、とくに、 \\(n\\) 重対角行列で近似できん？→確かに。相関行列は端っこに近づくほど0になっていくから、有効かも。 DFTしてなだらかに変化する要素（つまり低域信号）のパワーは切り捨てる近似がオッケーだったりしないか。→まったくそのとおり、 \\(\\ve{R}\\) をDFTすると、ウィーナ・ヒンチンが顔を出しそう。 スレ―ビングというらしい。 （所感）残差がガウス分布に従うとしたLMS ←ちょっと突然すぎる。 LMS（残差がガウス分布に従う）は… ←こっちのほうがいい。むしろ、ガウス分布の話はいらない。 損失関数はReLuにしても良いのでは→あり。でもどうなるんだろう。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete17-zhong-jian-fa-biao.html","loc":"/yan-jiu-hui-nixiang-kete17-zhong-jian-fa-biao.html"},{"title":"研究会に向けて(16)","text":"引き続き資料を作っている。 昨日気になっていた NNGSAの収束する最適係数はWienner解で間違いないのか検証する必要あり。 は並行して確認中。直交原理（勾配が0になる解）を満たす解はWienner解に一致するのか？というところ。 怪しいかもしれない。適応ステップサイズがミソで、最適係数時、そいつを含めて平均をとったときにゼロになるとは思えない。 Natural Gradient A better gradient for gradient descent? 面白そうだけどちとタイミングが悪い。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete16.html","loc":"/yan-jiu-hui-nixiang-kete16.html"},{"title":"研究会に向けて(15)","text":"淡々と資料を作っている。 NNGSAの収束する最適係数はWienner解で間違いないのか検証する必要あり。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete15.html","loc":"/yan-jiu-hui-nixiang-kete15.html"},{"title":"研究会に向けて(14)","text":"\\begin{equation*} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand{\\parfrac}[2]{{\\frac{\\partial #1}{\\partial #2}}} \\end{equation*} 今日から発表資料作る。久々にBeamerでやろうかね。 資料作ってたら、ラグランジュ未定乗数法による定式化で \\((\\ve{h} - \\ve{h}&#94;{\\prime})&#94;{\\mathsf{T}}\\ve{R}(\\ve{h} - \\ve{h}&#94;{\\prime})\\) の最小化を考えたけど、これってレイリー商の下限すなわち最小固有値が答えでは。もうちょっと考えたくなってきた。 \\(\\mu(n)\\) は垂線の長さに対応するんだっけ？ アフィン写像アルゴリズムへの拡張は、NLMSの制約を増やしたものに過ぎない。ラグランジュの未定乗数法を使って、 \\begin{align*} \\mathcal{L} &= (\\ve{h} - \\ve{h}&#94;{\\prime})&#94;{\\mathsf{T}}\\ve{R}(\\ve{h} - \\ve{h}&#94;{\\prime}) + (\\ve{d} - \\ve{A}\\ve{h}&#94;{\\prime})&#94;{\\mathsf{T}} \\ve{\\lambda} \\\\ \\parfrac{\\mathcal{L}}{\\ve{h}&#94;{\\prime}} &= 2\\ve{R}(\\ve{h} - \\ve{h}&#94;{\\prime}) - \\parfrac{}{\\ve{h}&#94;{\\prime}} \\ve{h}&#94;{\\prime\\mathsf{T}} \\ve{A}&#94;{\\mathsf{T}} \\ve{\\lambda} \\\\ &= 2\\ve{R}(\\ve{h} - \\ve{h}&#94;{\\prime}) - \\ve{A}&#94;{\\mathsf{T}} \\ve{\\lambda} \\\\ \\implies \\ve{h}&#94;{\\prime} &= \\ve{h} + \\frac{1}{2} \\ve{R}&#94;{-1} \\ve{A}&#94;{\\mathsf{T}} \\ve{\\lambda} \\\\ \\implies \\ve{\\lambda} &= 2 (\\ve{A} \\ve{R}&#94;{-1} \\ve{A}&#94;{\\mathsf{T}})\\ve{e} \\end{align*} から、 \\begin{align*} \\ve{h}&#94;{\\prime} &= \\ve{h} + \\ve{R}&#94;{-1}\\ve{A}&#94;{\\mathsf{T}}(\\ve{A} \\ve{R}&#94;{-1} \\ve{A}&#94;{\\mathsf{T}})&#94;{-1} \\ve{e} \\\\ &= \\ve{h} + \\ve{R}&#94;{-1}\\ve{A}&#94;{\\mathsf{T}}(\\ve{A} \\ve{R}&#94;{-1} \\ve{A}&#94;{\\mathsf{T}})&#94;{-1}(\\ve{d} - \\ve{A} \\ve{h}) \\\\ &= \\left\\{ \\ve{I} - \\ve{R}&#94;{-1}\\ve{A}&#94;{\\mathsf{T}}(\\ve{A} \\ve{R}&#94;{-1} \\ve{A}&#94;{\\mathsf{T}})&#94;{-1}\\ve{A} \\right\\} \\ve{h} + \\ve{R}&#94;{-1}\\ve{A}&#94;{\\mathsf{T}}(\\ve{A} \\ve{R}&#94;{-1} \\ve{A}&#94;{\\mathsf{T}})\\ve{d} \\end{align*} \\(\\ve{P} = \\ve{R}&#94;{-1}\\ve{A}&#94;{\\mathsf{T}}(\\ve{A} \\ve{R}&#94;{-1} \\ve{A}&#94;{\\mathsf{T}})&#94;{-1}\\ve{A}\\) とすれば \\(\\ve{P}&#94;{2} = \\ve{P}\\) だから射影行列になっている。 アルゴリズムを導いたけどあんまりいい考察は出てこない、というか、煩雑。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete14.html","loc":"/yan-jiu-hui-nixiang-kete14.html"},{"title":"研究会に向けて(13)","text":"\\begin{equation*} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\end{equation*} 発表向けの脚本を書いてた。 正規化アルゴリズムに関して、まだしたりない考察がある。 射影先の超平面の曲率はもしかして \\(\\ve{R}\\) だったりしない？漠然とした超平面ではなく、何らかの性質がないか？ これは、制約が一次式だから絶対に超平面になる。 アフィン写像アルゴリズムへ拡張するべきでは？ やってみた。次の日へどうぞ。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete13.html","loc":"/yan-jiu-hui-nixiang-kete13.html"},{"title":"研究会に向けて(12)","text":"\\begin{equation*} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\end{equation*} 発表に向けてのプロットに集中したい。また、正規化自然勾配SAが事後残差最小化ではなくラグランジュから導いて同じ結論が得られるか見たい。（もしかしたら、別の更新式が出る可能性がある） ラグランジュの結果、かなり良い解釈が得られた。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete12.html","loc":"/yan-jiu-hui-nixiang-kete12.html"},{"title":"研究会に向けて(11)","text":"\\begin{equation*} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\end{equation*} 乗せるデータをまとめる。 自然勾配SA法の有効性を示す。 人口データに対する実験: SA(ステップサイズ=0.005,0.01,0.02)と比較して収束が速いことを示す。しかし係数適応は遅いことは同時に指摘。 正規化自然勾配SA法の有効性を示す。 人口データに対する実験: RLS(忘却係数=1,0.9,0.99)と比較。収束は遅い場合があるが、定常誤差は小さく、また係数変更時の適応が早い。忘却係数に依存せず安定した収束性能を示す。 自然勾配法の有効性を示す。 実データに対する実験: 音楽の一部データに対する比較。SA, RLS(忘却係数=0.99), 正規化自然勾配SA, 自然勾配SAで比較。 RMSを比較。RLSとほぼ同等の性能を達成している。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete11.html","loc":"/yan-jiu-hui-nixiang-kete11.html"},{"title":"研究会に向けて(10)","text":"\\begin{equation*} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\end{equation*} 今日あたりで目処を…というか、デフォルトの自然勾配法に対する言い訳を考えておきたい。 ガチャガチャいじっていると、LMSに \\(\\ve{R}&#94;{-1}\\) を掛けたのも強いということが分かってくる…。 \\begin{equation*} \\ve{h}&#94;{\\prime} \\leftarrow \\ve{h} + \\mu \\ve{R}&#94;{-1} \\varepsilon(n) \\ve{x}(n) \\end{equation*} 何度も見てきた通りだが、上式のステップサイズを（事後誤差最小化基準により）適応化すると正規化版の式に一致する。ちなみに、LMSに対してはフィッシャー情報行列が意味のある統計量に結びつかない。Signアルゴリズムの改良から話を初めて、ステップサイズ適応化してまでたどり着くと、初めてLMS版に対応する式が導かれる。 確かに上は性能が良いが、裏付けが薄く眉唾の感を逃れられない。疑似自然勾配LMSと名付けて実装しておく。名目としては、正規化の簡略版と見れるはず。収束議論もしておきたい。 と思ったら、疑似自然勾配LMSは実データですっ飛ぶ傾向あり。誤差が急上昇するところで係数が吹っ飛んでしまう。。トレードオフのようで、誤差の符号をとる（自然勾配SA）は適応が遅すぎて、残差をそのまま使う（疑似自然勾配LMS）は適応が敏感すぎてすっ飛ぶ傾向がある。正規化は本質的な働きをしているように見える。 まとめようか。 勾配を観察すれば分かることだけど、やっぱり自然勾配SAは勾配が平坦になりすぎるきらいがある。どんなに最適値との差があっても同一の勾配になりやすい。 実データでは十分なサンプルが取れて、しかも特性はのんびり変化するから性能が良くなる。 忘却係数は高く取れば定常誤差を小さくできるが、1.0にすると特性追従が遅くなるので、1にほど近い0.997等に設定する。ステップサイズは実験では1.0等大きめに、実データは0.1等にとる。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete10.html","loc":"/yan-jiu-hui-nixiang-kete10.html"},{"title":"研究会に向けて(9)","text":"トイデータに対する実験をやっているが、色々と悲しい。 自然勾配SignAlgorithmの性能が悪い。下手するとSignAlgorithmとどっこい 実データに対しては良い結果を出していた。 原因を調べていたら、係数の初期値が最適値の近くにあると収束が早いということが分かった。 トイデータ実験は[-1,1]から一様乱数選択していたので、それだと広すぎるらしく、収束が遅い。勾配が平坦に広がりすぎている可能性がある。 忘却係数を低く（ステップサイズを大きく）すると応答は良くなるけどオフセットが残る。 実データはサンプル数が多いのと、係数が大きな値を取りにくいことから性能が良かったものと想像。 正規化版は自己相関行列の逆行列の二次形式で割ってるから、自己相関の逆数で割ってる、即ち、自己相関を掛けてると見れる。じゃあ、簡易的に入力データのノルムの平均値を掛けてやればいいんじゃねと思ってやってみたらそれなりに安定してきた。 眉唾だから再度要検証。 RLSが強すぎる。忘却係数付きRLSが一番強い。 忘却係数はトレードオフという感じ。0.9まで下げると収束は早いけどオフセットが残る。0.99だと係数が変わったときに収束が遅くなる。1.0（普通のRLS）だと係数が変わったときにまったく収束していかない。 正規化自然勾配SignAlgorithmは忘却係数の値によらずほぼ同じ学習曲線になる。依存するのはステップサイズくらいか。そこは主張できるかも。 NLMSもMSD（係数誤差）の意味ではRLSと同程度まで下げられているが、正規化自然勾配SignAlgorithmは収束ははやいがそこまで誤差が下がらない。 実装ミスあり。係数更新がFinvの更新前に行われていた。 普通の自然勾配法は大きな影響あり。あれ？でも正規化自然勾配の方はあまり影響がない。 実装ミスなのか微妙。。負荷減らしのための方策だった（フィッシャー情報行列の逆との積を使い回せるから） 性能差が顕著なのでこれはよく考えたほうが良い。アルゴリズムの整合性的にもあやしい。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete9.html","loc":"/yan-jiu-hui-nixiang-kete9.html"},{"title":"研究会に向けて(8)","text":"昨日の結果を受けて、相関があるガウス雑音信号を実験の対象にしたいと思っている。（なぜなら、現実のデータは相関があるから。そして、NLMSは相関のあるデータに弱いから。）いろんな論文で構成法が乗っていたので再調査。 l0 Norm Constraint LMS Algorithm for Sparse System Identification に明確に記述あり。v[t]をi.i.dなガウス雑音として、1次の自己回帰(Auto Regressive)フィルタ x[t] = x[t-1] * 0.8 + v[t] で信号に相関をもたせたあとに、正規化（標準偏差で割る）して分散を1にしている。有色雑音と言っていた。 また、昨日の夜にモデルに係数を状態として持たせるか考えた。係数が途中で変わるケースの結果が取りにくいので。 でも、扱う側でうまく計算すればできそうなのでやめた。モデル側の実装が複雑になるのは避けたい。 実験ケースを分類しよう。 人口データ: 観測雑音: -40dBの白色ガウス雑音、MSD（Mean Square Deviations, 係数2乗誤差）とMSE（Mean Square Error, 二乗誤差）を比較 入力: i.i.d.ガウス雑音、係数: 一様乱数で選択 主張: NLMSと同程度、RLSは収束が早い 入力: 相関のあるi.i.d.ガウス雑音、係数: 一様乱数で選択 主張: NLMSよりは早い 入力: 相関のあるi.i.d.ガウス雑音、係数: 一様乱数で選択、XXXXサンプル後に係数を一様乱数で変更 主張: 係数変更後の適応でRLSより収束が早い 実データに対する等価実験: MSEを比較。 音源は著作権切れデータベースから10秒程度を切り出して使用。 この通りにコードをまとめていく。水曜日あたりで結果が出ると◎。 人口データについてはまとまったかな。火曜日で実データ選定と実験をやっていく。 「信号とシステム」にシステムを等価する際の図が描かれている。ロスレス音声ではどうなっているか、資料作りまでに要観察。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete8.html","loc":"/yan-jiu-hui-nixiang-kete8.html"},{"title":"研究会に向けて(7)","text":"トイデータ対象の実験スクリプトを作ってた。で、RLSが強いことが分かった。 定常的なガウス雑音（ラプラス雑音でも！）環境下では、指数レートよりも早く最適解に入っていく。 途中で最適係数を変えると収束は他よりも鈍くなる。そこを突くべきか。 （RLSの忘却係数を0.8くらいにしないと同等にならない。） また、正規化込みの自然勾配法はNLMSと同程度の収束レートだった。ていうか性能ほぼ同じ。 →入力に強い相関をもたせる（x[t] += x[t-1] * 0.97）とNLMSの性能が大幅悪化することを確認した。 入力に相関がない場合は（自己相関行列が等方的になるので）NLMSと同等になるようだ。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete7.html","loc":"/yan-jiu-hui-nixiang-kete7.html"},{"title":"研究会に向けて(6)","text":"Lecture 5: Variants of the LMS algorithm を見ていたらNLMSをラグランジュ未定乗数法で求める方法があった。今までは事後残差最小化で見ていたけど、これは本質かもしれない。持ち帰って再度計算してみるべきかも。 Lecture 4: Stochastic gradient based adaptation: Least Mean Square (LMS) Algorithm にHeykinの簡易まとめあり。有益。 t-wadaさんのプレゼンテーションで情熱を持って話しているか？をチェックポイントにしている。 ここ 。 全くそのとおりだと思うので思い出しておく。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete6.html","loc":"/yan-jiu-hui-nixiang-kete6.html"},{"title":"研究会に向けて(5)","text":"\\begin{equation*} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\end{equation*} 引き続き周辺を見るが、そろそろRLSとPNLMSの実装に入ろうかな。 トイデータの実験条件も整理したい。 A Novel Family of Adaptive Filtering Algorithms Based on The Logarithmic Cost のデータの作り方を参考にしようと思う。 リファレンス信号 \\(d_{t} = \\ve{w}_{0}&#94;{\\mathsf{T}} \\ve{x}_{t} + n_{t}\\) で、 \\(\\ve{w}_{0}\\) はリファレンス係数（論文ではランダム選択にしていた。スパースじゃないならいいかも。）、 \\(\\ve{x}_{t}\\) は分散 \\(\\sigma_{x}&#94;{2} = 1\\) の i.i.d な平均0ガウス信号系列、 \\(n_{t}\\) はノイズ信号（分散0.01のガウス雑音と分散10000(偏差100)で一定確率(1,2,5%)で発生するインパルス雑音） 一定確率でインパルス雑音が発生するケースはロバスト性を示すために使われていた。LMSは全く等化できずにいた。 念の為Simon, Heykinを見てから方針を固める。 5.7節(p285)あたりから実験の記述あり。図5.19(p287)は必要になるはず。しかし、入力はベルヌーイ列、フィルタ係数は偶対称。。。 p297あたりに誤差曲面が書いてあった。遅いケースが有るということを、たしかに自分も確認している。 RLSを実装し、トイデータ向けの実験フレームワークを作ってしまうべきか。 その後にPNLMSを追加できれば良い。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete5.html","loc":"/yan-jiu-hui-nixiang-kete5.html"},{"title":"研究会に向けて(4)","text":"外出したのであんまり進捗なし。周辺調査してるけど、よい（コンセンサスのとれた）比較方法ないなあ… 実音声でやるのは確定として、トイデータはどうしようか。再考・適応アルゴリズムにあるように、完全に人工のインパルス応答（指数敵減衰信号）でもいいかも。係数をスパースにするのが目的ではないし。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete4.html","loc":"/yan-jiu-hui-nixiang-kete4.html"},{"title":"研究会に向けて(3)","text":"今日は予定を立てよう。ちょうど良いタイミングでゼミ発表も入った。 Tomoki Kawahira Courses 東工大の教授の数学の資料集 多様体の基礎のキソ ルベーグ積分の基礎のキソ 係数をスパースにするLMSって、そういえば更新をたまにしか行わない手法もあったな。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete3.html","loc":"/yan-jiu-hui-nixiang-kete3.html"},{"title":"IGおべんきょ(2)","text":"学会までには3-4章が手一杯に見える。しっかし先に進みたい。Fisher情報行列の意味付けをしないといかん。 ヘルシンキ大の幾何学講義ノート？ アフィン接続について - p79の座標変換則を満たすことを証明するときの切り口として参考になった","tags":"雑記","url":"/igobenkiyo2.html","loc":"/igobenkiyo2.html"},{"title":"FCMの係数更新式の導出","text":"\\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\newcommand\\mean[2]{\\mathrm{E}_{#1} \\left[ #2 \\right]} \\newcommand\\KL[2]{\\mathrm{KL} \\left[ #1 \\ \\middle| \\middle| \\ #2 \\right]} \\end{equation*} FCMの目的関数: \\begin{equation*} J = \\sum_{i = 1}&#94;{N} \\sum_{j = 1}&#94;{c} \\mu_{ij}&#94;{m} D_{ij}&#94;{2} \\end{equation*} ここで、 \\(N,c\\) はそれぞれデータ数とクラスタ数、 \\(\\mu_{ij}\\) はファジイ係数で \\(i\\) 番目のデータがクラスタ \\(j\\) に持つ重みを示す。 \\(m \\in [1, \\infty)\\) はファジイ度合いを決める係数で大きく取ればよりファジイ（曖昧さを許す）になる。 \\(m = 1\\) のときはハードなクラスタリングになる（らしい） 。 \\(D_{ij}\\) は \\(i\\) 番目のデータと \\(j\\) 番目のクラスタの中心との距離。 各データの重みの総和は1になるように制約を課す。式で書くと \\begin{equation*} \\sum_{j = 1}&#94;{c} \\mu_{ij} = 1 \\quad i = 1, ..., N \\end{equation*} この制約条件下でのラグランジュ関数（ラグランジアン） \\(L\\) は、 \\begin{equation*} L = \\sum_{i = 1}&#94;{N} \\sum_{j = 1}&#94;{c} \\mu_{ij}&#94;{m} D_{ij}&#94;{2} + \\sum_{i = 1}&#94;{N} \\lambda_{i} \\left[ 1 - \\sum_{j = 1}&#94;{c} \\mu_{ij} \\right] \\end{equation*} となる。偏微分して0とおき、最適条件を求めることを考える。 \\begin{align*} \\parfrac{L}{\\mu_{ij}} &= m \\mu_{ij}&#94;{m-1} D_{ij}&#94;{2} - \\lambda_{j} = 0 \\tag{1} \\\\ \\parfrac{L}{\\lambda_{i}} &= 1 - \\sum_{j = 1}&#94;{c} \\mu_{ij} = 0 \\tag{2} \\end{align*} より、まず(1)式から \\(\\mu_{ij}\\) について解くと、 \\begin{equation*} \\mu_{ij} = \\left( \\frac{\\lambda_{i}}{mD_{ij}&#94;{2}} \\right)&#94;{\\frac{1}{m-1}} = \\lambda_{i}&#94;{\\frac{1}{m-1}} \\left( \\frac{1}{mD_{ij}&#94;{2}} \\right)&#94;{\\frac{1}{m-1}} \\tag{3} \\end{equation*} これを(2)式に代入すると、 \\begin{align*} 1 &= \\sum_{j=1}&#94;{c} \\mu_{ij} = \\sum_{j=1}&#94;{c} \\left( \\frac{\\lambda_{i}}{mD_{ij}&#94;{2}} \\right)&#94;{\\frac{1}{m-1}} \\\\ &= \\lambda_{i}&#94;{\\frac{1}{m-1}} \\sum_{j=1}&#94;{c} \\left( \\frac{1}{mD_{ij}&#94;{2}} \\right)&#94;{\\frac{1}{m-1}} \\\\ \\implies \\lambda_{i}&#94;{\\frac{1}{m-1}} &= \\frac{1}{\\sum_{j=1}&#94;{c} \\left( \\frac{1}{mD_{ij}&#94;{2}} \\right)&#94;{\\frac{1}{m-1}}} \\end{align*} これを(3)式に代入すれば、 \\begin{align*} \\mu_{ij} &= \\lambda_{i}&#94;{\\frac{1}{m-1}} \\left( \\frac{1}{mD_{ij}&#94;{2}} \\right)&#94;{\\frac{1}{m-1}} = \\frac{1}{\\sum_{k=1}&#94;{c} \\left( \\frac{1}{mD_{ik}&#94;{2}} \\right)&#94;{\\frac{1}{m-1}}} \\left( \\frac{1}{mD_{ij}&#94;{2}} \\right)&#94;{\\frac{1}{m-1}} \\\\ &= \\frac{1}{\\sum_{k=1}&#94;{c} \\left( \\frac{1}{mD_{ik}&#94;{2}} \\right)&#94;{\\frac{1}{m-1}} \\left( \\frac{1}{mD_{ij}&#94;{2}} \\right)&#94;{-\\frac{1}{m-1}}} = \\frac{1}{\\sum_{k=1}&#94;{c} \\left( \\frac{mD_{ij}&#94;{2}}{mD_{ik}&#94;{2}} \\right)&#94;{\\frac{1}{m-1}}} \\\\ &= \\frac{1}{\\sum_{k=1}&#94;{c} \\left( \\frac{D_{ij}}{D_{ik}} \\right)&#94;{\\frac{2}{m-1}}} \\end{align*} 最後が気持ちよかった（小並感） 参考文献 Fuzzy Systems Fuzzy Clustering 1 4 FUZZY CLUSTERING","tags":"雑記","url":"/fcmnoxi-shu-geng-xin-shi-nodao-chu.html","loc":"/fcmnoxi-shu-geng-xin-shi-nodao-chu.html"},{"title":"IGおべんきょ(1)","text":"月内は情報幾何重視で行こう。 英文校正サービス よさそう。研究会向け原稿もOverleaf上でやるべく整理するか。","tags":"雑記","url":"/igobenkiyo1.html","loc":"/igobenkiyo1.html"},{"title":"研究会に向けて(2)","text":"AdaBoostのリスクがexpなのはリスクの上界を与えているから。また、更新式は学習理論p64など以下で。 AdaBoost AdaBoost はじめてのパターン認識 第11章 boosting A decision-theoretic generalication of on-line learning and application to boosting 情報幾何本読み進め中。 美しい結果（曲線上に平行移動はすごいと思った）が次々出てくるが、リーマン曲率テンソルのテンソル性を示すのに手間取ってる。 研究会に向けては、実験計画を立てておきたい。 既存研究調査を引き続きやっていき、比較対象の手法をまとめる。また、比較対象手法と、対象のデータを纏めていく。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete2.html","loc":"/yan-jiu-hui-nixiang-kete2.html"},{"title":"研究会に向けて(1)","text":"今週前半は休んでいた。流石にイベント中止が連打されて精神的に余裕がなくなった。 イベントレポートをこっちに移動しようか考えている。 研究の方は、研究会への申込みに着手した。 正則化はタイムアップ。将来の課題に回す。研究会の準備をしていく。 他にも、事故相関行列の計算高速化が色々試せそう。例えば、クロネッカ積に分解したり。","tags":"雑記","url":"/yan-jiu-hui-nixiang-kete1.html","loc":"/yan-jiu-hui-nixiang-kete1.html"},{"title":"逆写像定理までの整理(3)","text":"記事に起こしてたら誤りなども見つかって1週間かかってしまった。。 これでようやく情報幾何学に入門できそう。","tags":"雑記","url":"/ni-xie-xiang-ding-li-madenozheng-li-3.html","loc":"/ni-xie-xiang-ding-li-madenozheng-li-3.html"},{"title":"逆写像定理までの整理(2)","text":"ついでにラグランジュ未定乗数法とKKT条件まで行ってしまった。欲張った。 予定より断然時間かかってしまったけど、だいたい落ち着いたかも。記事に起こす。","tags":"雑記","url":"/ni-xie-xiang-ding-li-madenozheng-li-2.html","loc":"/ni-xie-xiang-ding-li-madenozheng-li-2.html"},{"title":"陰関数定理とその応用","text":"\\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\newcommand\\dfrac[2]{\\frac{\\mathrm{d} #1}{\\mathrm{d} #2}} \\newcommand\\mean[2]{\\mathrm{E}_{#1} \\left[ #2 \\right]} \\newcommand\\KL[2]{\\mathrm{KL} \\left[ #1 \\ \\middle| \\middle| \\ #2 \\right]} \\end{equation*} 逆写像定理をちゃんと振り返ろうとしたら、ついでに色々出てきてまとめる必要があるなと感じた。 記述は笠原皓司「微分積分学」を大幅に参考にしている。 準備 多変数関数の微分と偏微分 偏導関数の連続性による微分可能性の条件 写像の微分と偏微分 積分公式 連続関数の集合の完備性 不動点定理 陰関数定理 多変数の場合 陰関数定理の応用 逆写像定理 多変数の場合 制約付き極値問題 ラグランジュの未定乗数法 KKT条件 準備 多変数関数の微分と偏微分 1変数関数のグラフは一般に曲線で、それに接線が引けるときに関数は微分可能と言った。2変数以上を持つ関数のグラフは一般に曲面になる。この関数が微分可能というときは、接平面が構築できれば良い。これを数学的にもう少し詳しく述べると次のようになる。 2変数関数 \\(z = f(x, y)\\) のグラフの一点 \\(\\ve{x}_{0} = (x_{0}, y_{0})\\) における \\(f({x}_{0}, y_{0})\\) の接平面を考える。今、接平面ができたとしてその方程式を考えると、定数 \\(\\alpha, \\beta\\) を用いて \\begin{equation*} z - f(x_{0}, y_{0}) = \\alpha (x - x_{0}) + \\beta (y - y_{0}) \\end{equation*} と表せる。点 \\(\\ve{x}_{0}\\) とその近傍の点 \\(\\ve{x} = (x, y)\\) において、この平面上の \\(z\\) の値と \\(f(x, y)\\) の誤差は、 \\begin{equation*} g(x, y) = f(x, y) - z = f(x, y) - \\left\\{ f(x_{0}, y_{0}) + \\alpha (x - x_{0}) + \\beta (y - y_{0}) \\right\\} \\end{equation*} となる。接平面であるときには、この誤差 \\(g(x, y)\\) が \\(|\\ve{x} - \\ve{x}_{0}| = \\sqrt{(x - x_{0})&#94;{2} + (y - y_{0})&#94;{2}}\\) に対して無視できる程小さいことが必要である。即ち、 \\begin{equation*} \\lim_{\\ve{x} \\to \\ve{x}_{0}} \\frac{g(x, y)}{|\\ve{x} - \\ve{x}_{0}|} = 0 \\end{equation*} を満たせば良い。このとき、 \\(f(x, y)\\) は点 \\(\\ve{x}_{0}\\) において微分可能という。 2変数関数の微分 \\(z = f(x, y)\\) が点 \\(\\ve{x}_{0} = (x_{0}, y_{0})\\) で微分可能とは、ある定数 \\(\\alpha, \\beta\\) があって \\begin{equation*} \\begin{cases} f(x, y) = f(x_{0}, y_{0}) + \\alpha (x - x_{0}) + \\beta (y - y_{0}) + g(x, y) \\\\ \\displaystyle \\lim_{\\ve{x} \\to \\ve{x}_{0}} \\frac{g(x, y)}{|\\ve{x} - \\ve{x}_{0}|} = 0 \\quad (\\ve{x} \\neq \\ve{x}_{0}) \\end{cases} \\end{equation*} と表せることである。 2変数関数の偏導関数 \\(f(x, y)\\) が \\(\\ve{x}_{0} = (x_{0}, y_{0})\\) で微分可能なら、 \\(\\alpha, \\beta\\) はそれぞれ以下の式で求まる。 \\begin{align*} \\alpha = \\lim_{x \\to x_{0}} \\frac{f(x, y_{0}) - f(x_{0}, y_{0})}{x - x_{0}} \\\\ \\beta = \\lim_{y \\to y_{0}} \\frac{f(x_{0}, y) - f(x_{0}, y_{0})}{y - y_{0}} \\end{align*} （証明） \\begin{equation*} \\begin{cases} f(x, y) = f(x_{0}, y_{0}) + \\alpha (x - x_{0}) + \\beta (y - y_{0}) + g(x, y) \\\\ \\displaystyle \\lim_{\\ve{x} \\to \\ve{x}_{0}} \\frac{g(x, y)}{|\\ve{x} - \\ve{x}_{0}|} = 0 \\quad (\\ve{x} \\neq \\ve{x}_{0}) \\end{cases} \\end{equation*} だから、 \\(y = y_{0}\\) とすると、 \\begin{equation*} f(x, y_{0}) = f(x_{0}, y_{0}) + \\alpha (x - x_{0}) + g(x, y_{0}) \\end{equation*} これは、 \\(y = y_{0}\\) と固定したときに、 \\(f(x, y_{0})\\) が \\(x\\) で微分可能であることを示している。また、 \\(\\alpha\\) について解くと、 \\begin{align*} \\alpha &= \\frac{f(x, y_{0}) - f(x_{0}, y_{0})}{x - x_{0}} + \\frac{g(x, y_{0})}{x - x_{0}} \\\\ \\implies \\lim_{x \\to x_{0}} \\alpha &= \\alpha = \\lim_{x \\to x_{0}} \\frac{f(x, y_{0}) - f(x_{0}, y_{0})}{x - x_{0}} \\end{align*} \\(\\beta\\) についても同様に \\(x = x_{0}\\) として求められる。（証明終） この \\(\\alpha, \\beta\\) を偏微分係数といい、 \\begin{align*} \\alpha = \\parfrac{f}{x}(x_{0}, y_{0}) = f_{x}(x_{0}, y_{0}) \\\\ \\beta = \\parfrac{f}{y}(x_{0}, y_{0}) = f_{y}(x_{0}, y_{0}) \\end{align*} と書く。2変数以上の場合も全く同様の考えにより微分が定義できる。冗長だが述べると、 多変数関数の微分 \\(z = f(\\ve{x}) = f(x_{1}, ..., x_{n})\\) が点 \\(\\ve{x}_{0} = (x_{1}&#94;{0}, ..., x_{n}&#94;{0})\\) で微分可能であるとは、ある定数 \\(\\alpha_{1}, ..., \\alpha_{n}\\) が存在して、 \\begin{equation*} \\begin{cases} \\displaystyle f(\\ve{x}) = f(\\ve{x}_{0}) + \\sum_{i = 1}&#94;{n} \\alpha_{i} (x_{i} - x_{i}&#94;{0}) + g(\\ve{x}) \\\\ \\displaystyle \\lim_{\\ve{x} \\to \\ve{x}_{0}} \\frac{g(\\ve{x})}{|\\ve{x} - \\ve{x}_{0}|} = 0 \\quad (\\ve{x} \\neq \\ve{x}_{0}) \\end{cases} \\end{equation*} と表せることである。 多変数関数の偏導関数 \\(f(\\ve{x})\\) が点 \\(\\ve{x}_{0}\\) で微分可能なら、 \\(\\alpha_{i}\\ (i = 1,...,n)\\) はそれぞれ以下の式で求められる。 \\begin{equation*} \\alpha_{i} = \\lim_{x_{i} \\to x_{i}&#94;{0}} \\frac{f(x_{1}&#94;{0}, ..., x_{i}, ..., x_{n}&#94;{0}) - f(\\ve{x}_{0})}{x_{i} - x_{i}&#94;{0}} \\end{equation*} （証明）微分可能性の定義式において \\(x_{j} = x_{j}&#94;{0}\\ (j \\neq i)\\) とおくと、 \\begin{align*} f(x_{1}&#94;{0}, ..., x_{i}, ..., x_{n}&#94;{0}) &= f(\\ve{x}_{0}) + \\alpha_{i}(x_{i} - x_{i}&#94;{0}) + g(x_{1}&#94;{0}, ..., x_{i}, ..., x_{n}&#94;{0}) \\\\ \\implies \\alpha_{i} &= \\frac{f(x_{1}&#94;{0}, ..., x_{i}, ..., x_{n}&#94;{0}) - f(\\ve{x}_{0})}{x_{i} - x_{i}&#94;{0}} + \\frac{g(x_{1}&#94;{0}, ..., x_{i}, ..., x_{n}&#94;{0})}{x_{i} - x_{i}&#94;{0}} \\\\ \\implies \\lim_{x_{i} \\to x_{i}&#94;{0}} \\alpha_{i} = \\alpha_{i} &= \\lim_{x_{i} \\to x_{i}&#94;{0}} \\frac{f(x_{1}&#94;{0}, ..., x_{i}, ..., x_{n}&#94;{0}) - f(\\ve{x}_{0})}{x_{i} - x_{i}&#94;{0}} \\end{align*} （証明終） やはり、この \\(\\alpha_{i}\\ (i = 1,...,n)\\) を偏微分係数と呼び、 \\begin{equation*} \\alpha_{i} = \\parfrac{f}{x_{i}}(\\ve{x}_{0}) \\end{equation*} と書く。 偏導関数の連続性による微分可能性の条件 \\(f(x, y)\\) が \\(\\ve{x}_{0} = (x_{0}, y_{0})\\) において微分可能であれば、 \\(x, y\\) によって偏微分可能であるが、その逆（偏微分可能ならば微分可能）は成り立たない。しかし、以下の定理により、偏導関数に連続性を付与すれば、微分可能であることが示せる。 偏導関数の連続性による微分可能性の条件 \\(f(x, y)\\) が点 \\(\\ve{x}_{0} = (x_{0}, y_{0})\\) で偏微分可能であり、かつ、 \\(x, y\\) どちらかの偏導関数が \\(\\ve{x}_{0}\\) で連続であるならば、 \\(f(x, y)\\) は \\(\\ve{x}_{0}\\) で微分可能である。 （証明） \\(\\parfrac{f}{y}(x,y)\\) が \\(\\ve{x}_{0}\\) の近傍で存在し、かつ \\(\\ve{x}_{0}\\) で連続と仮定して証明する（ \\(\\parfrac{f}{x}\\) が \\(\\ve{x}_{0}\\) で連続としても同様に示せる）。 \\(f\\) は \\(x\\) について偏微分可能だから、 \\begin{align*} \\parfrac{f}{x}(x_{0}, y_{0}) &= \\frac{f(x, y_{0}) - f(x_{0}, y_{0})}{x - x_{0}} + \\frac{g(x)}{x - x_{0}} \\\\ \\implies f(x, y_{0}) &= f(x_{0}, y_{0}) + \\parfrac{f}{x}(x_{0}, y_{0})(x - x_{0}) + g(x) \\tag{1} \\\\ \\lim_{x \\to x_{0}} \\frac{g(x)}{x - x_{0}} &= 0 \\end{align*} なる \\(g(x)\\) が存在する。一方、 \\(\\ve{x}_{0}\\) の近傍で \\(f\\) は \\(y\\) について偏微分可能だから、平均（中間）値の定理により、 \\begin{equation*} f(x, y) - f(x, y_{0}) = \\parfrac{f}{y}(x, \\eta)(y - y_{0}) \\end{equation*} を満たす \\(\\eta\\) が \\(y_{0}\\) と \\(y\\) の間に存在する。上式を(1)に代入すると、 \\begin{align*} f(x, y) &= f(x_{0}, y_{0}) + \\parfrac{f}{x}(x_{0}, y_{0})(x - x_{0}) + \\parfrac{f}{y}(x, \\eta)(y - y_{0}) + g(x) \\\\ &= f(x_{0}, y_{0}) + \\parfrac{f}{x}(x_{0}, y_{0})(x - x_{0}) + \\parfrac{f}{y}(x_{0}, y_{0})(y - y_{0}) + \\left\\{ \\parfrac{f}{y}(x, \\eta) - \\parfrac{f}{y}(x_{0}, y_{0}) \\right\\} (y - y_{0}) + g(x) \\\\ &= f(x_{0}, y_{0}) + \\parfrac{f}{x}(x_{0}, y_{0})(x - x_{0}) + \\parfrac{f}{y}(x_{0}, y_{0})(y - y_{0}) + h(x, y) \\end{align*} ここで、 \\begin{equation*} h(x, y) = \\left\\{ \\parfrac{f}{y}(x, \\eta) - \\parfrac{f}{y}(x_{0}, y_{0}) \\right\\} (y - y_{0}) + g(x) \\end{equation*} とおいている。そして \\(h(x, y)\\) は、 \\begin{equation*} \\frac{h(x, y)}{|\\ve{x} - \\ve{x}_{0}|} = \\left\\{ \\parfrac{f}{y}(x, \\eta) - \\parfrac{f}{y}(x_{0}, y_{0}) \\right\\} \\frac{y - y_{0}}{|\\ve{x} - \\ve{x}_{0}|} + \\frac{x - x_{0}}{|\\ve{x} - \\ve{x}_{0}|} \\frac{g(x)}{x - x_{0}} \\end{equation*} と変形でき、 \\(|\\ve{x} - \\ve{x}_{0}| = \\sqrt{(x - x_{0})&#94;{2} + (y - y_{0})&#94;{2}}\\) より \\(\\frac{y - y_{0}}{|\\ve{x} - \\ve{x}_{0}|} \\leq \\frac{|y - y_{0}|}{|\\ve{x} - \\ve{x}_{0}|} \\leq 1\\) と \\(\\frac{x - x_{0}}{|\\ve{x} - \\ve{x}_{0}|} \\leq \\frac{|x - x_{0}|}{|\\ve{x} - \\ve{x}_{0}|} \\leq 1\\) が成り立つ。また、 \\(\\ve{x} \\to \\ve{x}_{0}\\) のとき \\((x, \\eta) \\to (x_{0}, y_{0})\\) となるが、仮定より \\(\\parfrac{f}{y}(x, y)\\) は \\(\\ve{x}_{0}\\) で連続だから、 \\(\\parfrac{f}{y}(x, \\eta) - \\parfrac{f}{y}(x_{0}, y_{0}) \\to 0\\) となる。従って、 \\begin{equation*} \\lim_{\\ve{x} \\to \\ve{x}_{0}} \\frac{h(x, y)}{|\\ve{x} - \\ve{x}_{0}|} = 0 \\end{equation*} これは \\(f(x, y)\\) が \\(\\ve{x}_{0}\\) で微分可能であることを示している。（証明終） 上記は最も単純な2変数の場合の証明だが、一般の多変数においても同様の定理が成り立つ。 偏導関数の連続性による微分可能性の条件（多変数） \\(\\ve{x} = (x_{1}, ..., x_{p}),\\ \\ve{y} = (y_{1}, ..., y_{n})\\) とするとき、 \\(p + n\\) 変数の関数 \\(f(\\ve{X}) = f(\\ve{x}, \\ve{y}) = f(x_{1}, ..., x_{p}, y_{1}, ..., y_{n})\\) が点 \\(\\ve{X}_{0} = (\\ve{x}_{0}, \\ve{y}_{0}) = (x_{1}&#94;{0}, ..., x_{p}&#94;{0}, y_{1}&#94;{0}, ..., y_{n}&#94;{0})\\) で \\(\\ve{x}\\) に関して微分可能であり、かつ \\(\\ve{y}\\) に関する偏導関数が \\(\\ve{X}_{0}\\) の近傍で存在し、しかも偏導関数が \\(\\ve{X}_{0}\\) で連続ならば、 \\(f(\\ve{x}, \\ve{y})\\) は \\((\\ve{x}_{0}, \\ve{y}_{0})\\) で微分可能である。 （証明）2変数の場合とほぼ同様。 \\(f\\) は \\(\\ve{x}\\) について微分可能だから、 \\begin{equation*} \\begin{cases} \\displaystyle f(\\ve{x}, \\ve{y}_{0}) = f(\\ve{x}_{0}, \\ve{y}_{0}) + \\sum_{i = 1}&#94;{p} \\parfrac{f}{x_{i}}(\\ve{x}_{0}, \\ve{y}_{0})(x_{i} - x_{i}&#94;{0}) + g(\\ve{x}) \\tag{2} \\\\ \\displaystyle \\lim_{\\ve{x} \\to \\ve{x}_{0}} \\frac{g(\\ve{x})}{|\\ve{x} - \\ve{x}_{0}|} = 0 \\end{cases} \\end{equation*} 一方、 \\((\\ve{x}_{0}, \\ve{y}_{0})\\) において、 \\(f\\) は \\(\\ve{y}\\) について偏微分可能だから、平均値の定理より \\begin{equation*} f(\\ve{x}, \\ve{y}) - f(\\ve{x}, \\ve{y}_{0}) = \\sum_{i = 0}&#94;{n} \\parfrac{f}{y_{i}} (\\ve{x}, \\ve{\\eta}) (y_{i} - y_{i}&#94;{0}) \\end{equation*} を満たす \\(\\ve{\\eta}\\) が \\(\\ve{y}_{0}\\) と \\(\\ve{y}\\) の間に存在する。(2)へ代入すると、 \\begin{align*} f(\\ve{x}, \\ve{y}) &= f(\\ve{x}_{0}, \\ve{y}_{0}) + \\sum_{i = 1}&#94;{p} \\parfrac{f}{x_{i}}(\\ve{x}_{0}, \\ve{y}_{0})(x_{i} - x_{i}&#94;{0}) + \\sum_{i = 1}&#94;{n} \\parfrac{f}{y_{i}}(\\ve{x}, \\ve{\\eta})(y_{i} - y_{i}&#94;{0}) + g(\\ve{x}) \\\\ &= f(\\ve{x}_{0}, \\ve{y}_{0}) + \\sum_{i = 1}&#94;{p} \\parfrac{f}{x_{i}}(\\ve{x}_{0}, \\ve{y}_{0})(x_{i} - x_{i}&#94;{0}) + \\sum_{i = 1}&#94;{n} \\parfrac{f}{y_{i}}(\\ve{x}_{0}, \\ve{y}_{0})(y_{i} - y_{i}&#94;{0}) + \\sum_{i = 1}&#94;{n} \\left\\{ \\parfrac{f}{y_{i}}(\\ve{x}, \\ve{\\eta}) - \\parfrac{f}{y_{i}}(\\ve{x}_{0}, \\ve{y}_{0}) \\right\\}(y_{i} - y_{i}&#94;{0}) + g(\\ve{x}) \\\\ &= f(\\ve{x}_{0}, \\ve{y}_{0}) + \\sum_{i = 1}&#94;{p} \\parfrac{f}{x_{i}}(\\ve{x}_{0}, \\ve{y}_{0})(x_{i} - x_{i}&#94;{0}) + \\sum_{i = 1}&#94;{n} \\parfrac{f}{y_{i}}(\\ve{x}_{0}, \\ve{y}_{0})(y_{i} - y_{i}&#94;{0}) + h(\\ve{x}, \\ve{y}) \\end{align*} \\(h(\\ve{x}, \\ve{y})\\) を \\(|\\ve{X} - \\ve{X}_{0}| = \\sqrt{ \\sum_{i = 1}&#94;{p} (x_{i} - x_{i}&#94;{0})&#94;{2} + \\sum_{i = 1}&#94;{n} (y_{i} - y_{i}&#94;{0})&#94;{2} }\\) で割ると、 \\begin{equation*} \\frac{h(\\ve{x}, \\ve{y})}{|\\ve{X} - \\ve{X}_{0}|} = \\sum_{i = 1}&#94;{n} \\left\\{ \\parfrac{f}{y_{i}}(\\ve{x}, \\ve{\\eta}) - \\parfrac{f}{y_{i}}(\\ve{x}_{0}, \\ve{y}_{0}) \\right\\} \\frac{y_{i} - y_{i}&#94;{0}}{|\\ve{X} - \\ve{X}_{0}|} + \\frac{|\\ve{x} - \\ve{x}_{0}|}{|\\ve{X} - \\ve{X}_{0}|}\\frac{g(\\ve{x})}{|\\ve{x} - \\ve{x}_{0}|} \\end{equation*} となる。やはり \\(\\ve{X} \\to \\ve{X}_{0}\\) のとき \\(\\lim_{\\ve{X} \\to \\ve{X}_{0}} \\frac{h(\\ve{x}, \\ve{y})}{|\\ve{X} - \\ve{X}_{0}|} = 0\\) だから、 \\(f\\) は \\((\\ve{x}_{0}, \\ve{y}_{0})\\) において微分可能である。（証明終） 写像の微分と偏微分 \\(\\mathbb{R}&#94;{n}\\) の領域 \\(\\Omega\\) から \\(\\mathbb{R}&#94;{m}\\) への写像 \\(\\ve{f}\\) を考える。 \\(\\ve{x} = [x_{1}, ..., x_{n}]&#94;{\\mathsf{T}} \\in \\Omega\\) に対して \\(\\ve{f}(\\ve{x}) = [ f_{1}(\\ve{x}), ..., f_{m}(\\ve{x}) ]&#94;{\\mathsf{T}} \\in \\mathbb{R}&#94;{m}\\) と書けるから、 \\(f_{1}(\\ve{x}), ..., f_{m}(\\ve{x})\\) が \\(\\ve{x}_{0} = [ x_{1}&#94;{0}, ..., x_{n}&#94;{0} ]&#94;{\\mathsf{T}}\\) で連続な時、 \\begin{equation*} \\left\\{ \\begin{array}{ll} \\displaystyle f_{1}(\\ve{x}) = f_{1}(\\ve{x}_{0}) + \\sum_{i = 1}&#94;{n} \\parfrac{f_{1}}{x_{i}} (x_{i} - x_{i}&#94;{0}) + g_{1}(\\ve{x}) & \\\\ \\displaystyle f_{2}(\\ve{x}) = f_{2}(\\ve{x}_{0}) + \\sum_{i = 1}&#94;{n} \\parfrac{f_{2}}{x_{i}} (x_{i} - x_{i}&#94;{0}) + g_{2}(\\ve{x}) & \\\\ \\vdots & \\\\ \\displaystyle f_{m}(\\ve{x}) = f_{m}(\\ve{x}_{0}) + \\sum_{i = 1}&#94;{n} \\parfrac{f_{m}}{x_{i}} (x_{i} - x_{i}&#94;{0}) + g_{m}(\\ve{x}) & \\\\ \\displaystyle \\lim_{\\ve{x} \\to \\ve{x}_{0}} \\frac{g_{i}(\\ve{x})}{|\\ve{x} - \\ve{x}_{0}|} = 0 & (i = 1, ..., m) \\end{array} \\right. \\end{equation*} が成り立つ。ここで、次の ヤコビ行列（関数行列） \\begin{equation*} \\ve{M}(\\ve{x}_{0}) = \\parfrac{\\ve{f}}{\\ve{x}}(\\ve{x}_{0}) = \\left[ \\begin{array}{cccc} \\parfrac{f_{1}}{x_{1}}(\\ve{x}_{0}) & \\parfrac{f_{1}}{x_{2}}(\\ve{x}_{0}) & \\dots & \\parfrac{f_{1}}{x_{n}}(\\ve{x}_{0}) \\\\ \\parfrac{f_{2}}{x_{1}}(\\ve{x}_{0}) & \\parfrac{f_{2}}{x_{2}}(\\ve{x}_{0}) & \\dots & \\parfrac{f_{2}}{x_{n}}(\\ve{x}_{0}) \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\parfrac{f_{m}}{x_{n}}(\\ve{x}_{0}) & \\parfrac{f_{m}}{x_{n}}(\\ve{x}_{0}) & \\dots & \\parfrac{f_{m}}{x_{n}}(\\ve{x}_{0}) \\\\ \\end{array} \\right] \\end{equation*} を使えば、次のようにまとめられる。 \\begin{equation*} \\begin{cases} \\ve{f}(\\ve{x}) = \\ve{f}(\\ve{x}_{0}) + \\ve{M}(\\ve{x}_{0}) (\\ve{x} - \\ve{x}_{0}) + \\ve{g}(\\ve{x}) \\\\ \\displaystyle \\lim_{\\ve{x} \\to \\ve{x}_{0}} \\frac{\\ve{g}(\\ve{x})}{|\\ve{x} - \\ve{x}_{0}|} = \\ve{0} \\end{cases} \\end{equation*} ここで、 \\(\\ve{g}(\\ve{x}) = [ g_{1}(\\ve{x}), ..., g_{m}(\\ve{x}) ]&#94;{\\mathsf{T}}\\) である。そして行列 \\(\\ve{M}(\\ve{x}_{0})\\) が存在するとき、写像 \\(\\ve{f}\\) は \\(\\ve{x}_{0}\\) で微分可能であるという。 写像の微分可能性の必要十分条件 写像 \\(\\ve{f}\\) が \\(\\ve{x}_{0}\\) で微分可能であるための必要十分条件は、 \\(\\ve{x}_{0}\\) の近傍で定義され、かつ \\(\\ve{x}_{0}\\) で連続な関数を要素とする行列 \\(\\ve{M}(\\ve{x})\\) があって、 \\begin{equation*} \\ve{f}(\\ve{x}) = \\ve{f}(\\ve{x}_{0}) + \\ve{M}(\\ve{x})(\\ve{x} - \\ve{x}_{0}) \\tag{3} \\end{equation*} を満たすことである。また、このとき \\(\\parfrac{\\ve{f}}{\\ve{x}}(\\ve{x}_{0}) = \\ve{M}(\\ve{x}_{0})\\) 。 （ \\(\\Rightarrow\\) の証明） \\(\\ve{f}\\) が \\(\\ve{x}_{0}\\) で微分可能とする。 \\begin{align*} \\ve{f}(\\ve{x}) &= \\ve{f}(\\ve{x}_{0}) + \\parfrac{\\ve{f}}{\\ve{x}}(\\ve{x}_{0})(\\ve{x} - \\ve{x}_{0}) + \\ve{g}(\\ve{x}) \\\\ &= \\ve{f}(\\ve{x}_{0}) + \\left\\{ \\parfrac{\\ve{f}}{\\ve{x}}(\\ve{x}_{0}) + \\frac{\\ve{g}(\\ve{x})}{|\\ve{x} - \\ve{x}_{0}|&#94;{2}} (\\ve{x} - \\ve{x}_{0})&#94;{\\mathsf{T}} \\right\\} (\\ve{x} - \\ve{x}_{0}) \\end{align*} の観察から、 \\begin{equation*} \\ve{M}(\\ve{x}) = \\left\\{ \\begin{array}{ll} \\parfrac{\\ve{f}}{\\ve{x}}(\\ve{x}_{0}) + \\frac{\\ve{g}(\\ve{x})}{|\\ve{x} - \\ve{x}_{0}|&#94;{2}} (\\ve{x} - \\ve{x}_{0})&#94;{\\mathsf{T}} & (\\ve{x} \\neq \\ve{x}_{0}) \\\\ \\parfrac{\\ve{f}}{\\ve{x}}(\\ve{x}_{0}) & (\\ve{x} = \\ve{x}_{0}) \\end{array} \\right. \\end{equation*} とおけば、この \\(\\ve{M}(\\ve{x})\\) は \\(\\ve{x}_{0}\\) で連続であり、(3) 式が得られることがわかる。（ \\(\\Rightarrow\\) の証明終） （ \\(\\Leftarrow\\) の証明） (3) 式から、 \\begin{align*} \\ve{f}(\\ve{x}) &= \\ve{f}(\\ve{x}_{0}) + \\ve{M}(\\ve{x})(\\ve{x} - \\ve{x}_{0}) \\\\ &= \\ve{f}(\\ve{x}_{0}) + \\ve{M}(\\ve{x}_{0})(\\ve{x} - \\ve{x}_{0}) + \\left\\{ \\ve{M}(\\ve{x}) - \\ve{M}(\\ve{x}_{0}) \\right\\} (\\ve{x} - \\ve{x}_{0}) \\end{align*} となり、今、 \\begin{equation*} \\ve{g}(\\ve{x}) = \\left\\{ \\ve{M}(\\ve{x}) - \\ve{M}(\\ve{x}_{0}) \\right\\} (\\ve{x} - \\ve{x}_{0}) \\end{equation*} とおくと、 \\(\\ve{M}(\\ve{x})\\) の \\(\\ve{x}_{0}\\) における連続性から \\(\\frac{|\\ve{g}(\\ve{x})|}{|\\ve{x} - \\ve{x}_{0}|} = |\\ve{M}(\\ve{x}) - \\ve{M}(\\ve{x}_{0})| \\to 0\\ (\\ve{x} \\to \\ve{x}_{0})\\) より \\(\\lim_{\\ve{x} \\to \\ve{x}_{0}} \\frac{\\ve{g}(\\ve{x})}{|\\ve{x} - \\ve{x}_{0}|} = \\ve{0}\\) が成立する。よって \\(\\ve{f}\\) は \\(\\ve{x}_{0}\\) において微分可能。（ \\(\\Leftarrow\\) の証明終） 上記の必要十分条件を用いることで、合成写像に対する微分公式が簡単に得られる。 合成写像の微分 \\(\\ve{y} = \\ve{f}(\\ve{x})\\) は \\(\\mathbb{R}&#94;{n}\\) から \\(\\mathbb{R}&#94;{m}\\) への写像、 \\(\\ve{z} = \\ve{g}(\\ve{y})\\) は \\(\\mathbb{R}&#94;{m}\\) から \\(\\mathbb{R}&#94;{l}\\) への写像で、 \\(\\ve{f}\\) が \\(\\ve{x}_{0}\\) で、 \\(\\ve{g}\\) が \\(\\ve{y}_{0} = \\ve{f}(\\ve{x}_{0})\\) でそれぞれ微分可能なら、 \\(\\ve{g}(\\ve{f}(\\ve{x}))\\) は \\(\\ve{x}_{0}\\) で微分可能で、 \\begin{equation*} \\parfrac{\\ve{z}}{\\ve{x}}(\\ve{x}_{0}) = \\parfrac{\\ve{z}}{\\ve{y}} (\\ve{y}_{0}) \\parfrac{\\ve{y}}{\\ve{x}}(\\ve{x}_{0}) \\end{equation*} （証明） \\begin{equation*} \\begin{cases} \\ve{f}(\\ve{x}) = \\ve{f}(\\ve{x}_{0}) + \\ve{M}(\\ve{x})(\\ve{x} - \\ve{x}_{0}) \\\\ \\ve{g}(\\ve{y}) = \\ve{g}(\\ve{y}_{0}) + \\ve{N}(\\ve{y})(\\ve{y} - \\ve{y}_{0}) \\end{cases} \\end{equation*} と書けるから、 \\begin{align*} \\ve{z} = \\ve{g}(\\ve{f}(\\ve{x})) &= \\ve{g}(\\ve{f}(\\ve{x}_{0}) + \\ve{M}(\\ve{x})(\\ve{x} - \\ve{x}_{0})) \\\\ &= \\ve{g}(\\ve{y}_{0}) + \\ve{N}(\\ve{f}(\\ve{x})) \\left\\{ \\ve{f}(\\ve{x}_{0}) + \\ve{M}(\\ve{x})(\\ve{x} - \\ve{x}_{0}) - \\ve{y}_{0} \\right\\} \\\\ &= \\ve{g}(\\ve{y}_{0}) + \\ve{N}(\\ve{f}(\\ve{x})) \\ve{M}(\\ve{x})(\\ve{x} - \\ve{x}_{0}) \\end{align*} ここで \\(\\ve{N}(\\ve{f}(\\ve{x}))\\ve{M}(\\ve{x})\\) は \\(\\ve{x}_{0}\\) で連続だから、 \\(\\ve{g}(\\ve{f}(\\ve{x}))\\) は \\(\\ve{x}_{0}\\) で微分可能で、 \\begin{equation*} \\parfrac{\\ve{z}}{\\ve{x}}(\\ve{x}_{0}) = \\ve{N}(\\ve{f}(\\ve{x}_{0})) \\ve{M}(\\ve{x}_{0}) = \\parfrac{\\ve{z}}{\\ve{y}}(\\ve{y}_{0}) \\parfrac{\\ve{y}}{\\ve{x}}(\\ve{x}_{0}) \\end{equation*} （証明終） 積分公式 平均値の定理を応用した便利な公式。以下の証明で頻繁に使用するため証明を与える。 積分公式 \\(\\ve{f}\\) を \\(\\mathbb{R}&#94;{n}\\) の領域 \\(\\Omega\\) から \\(\\mathbb{R}&#94;{n}\\) への \\(C&#94;{1}\\) 級写像とする。 \\(\\ve{x}_{0}, \\ve{x} \\in \\Omega\\) とこの2点を結ぶ線分が \\(\\Omega\\) に属するとき、 \\begin{equation*} \\ve{f}(\\ve{x}) - \\ve{f}(\\ve{x}_{0}) = \\left\\{ \\int_{0}&#94;{1} \\parfrac{\\ve{f}}{\\ve{x}} (\\ve{x}_{0} + t (\\ve{x} - \\ve{x}_{0})) \\mathrm{d}t \\right\\} (\\ve{x} - \\ve{x}_{0}) \\end{equation*} ここで、 \\(\\{ \\}\\) の中身は \\(n \\times n\\) の行列になっていることに注意。 （証明） \\(\\ve{\\varphi}(t) = \\ve{f}(\\ve{x}_{0} + t (\\ve{x} - \\ve{x}_{0}))\\) とおくと、 \\begin{align*} \\ve{f}(\\ve{x}) - \\ve{f}(\\ve{x}_{0}) &= \\ve{\\varphi}(1) - \\ve{\\varphi}(0) = \\int_{0}&#94;{1} \\dfrac{\\ve{\\varphi}(t)}{t} \\mathrm{d}t \\\\ &= \\int_{0}&#94;{1} \\parfrac{\\ve{f}}{\\ve{x}} (\\ve{x}_{0} + t (\\ve{x} - \\ve{x}_{0})) \\dfrac{}{t} \\left\\{ \\ve{x}_{0} + t (\\ve{x} - \\ve{x}_{0}) \\right\\} \\mathrm{d}t \\quad (\\because \\text{合成関数の微分}) \\\\ &= \\int_{0}&#94;{1} \\parfrac{\\ve{f}}{\\ve{x}} (\\ve{x}_{0} + t (\\ve{x} - \\ve{x}_{0})) (\\ve{x} - \\ve{x}_{0}) \\mathrm{d}t \\\\ &= \\left\\{ \\int_{0}&#94;{1} \\parfrac{\\ve{f}}{\\ve{x}} (\\ve{x}_{0} + t (\\ve{x} - \\ve{x}_{0})) \\mathrm{d}t \\right\\} (\\ve{x} - \\ve{x}_{0}) \\end{align*} （証明終） 連続関数の集合の完備性 かなり基礎的だが、以下の証明に必要なため書く。区間 \\(I\\) で連続な関数の集合を \\(C&#94;{0}(I)\\) と書く。 \\(f \\in C&#94;{0}(I)\\) に対して、関数の \"大きさ\" を次のノルムとして定義する。 関数のノルム \\(|| f ||_{0} = \\sup_{x \\in I} |f(x)|\\) を関数 \\(f\\) のノルムという。 ノルムは一般に次の3つの満たしている。 \\(|| f ||_{0} \\geq 0\\) （等号成立は \\(f(x) = 0\\ (x \\in I)\\) に限る） \\(|| \\lambda f ||_{0} = |\\lambda| || f ||_{0}\\) （ \\(\\lambda\\) は定数） \\(|| f + g ||_{0} \\leq || f ||_{0} + || g ||_{0}\\) （ 三角不等式 と呼ぶ） 関数のノルムにより、 \\(C&#94;{0}(I)\\) 上の関数列 \\(\\{ f_{n}(x) \\}\\) が \\(I\\) において \\(f(x)\\) に一様収束することを \\begin{equation*} || f_{n} - f ||_{0} \\to 0 \\quad (n \\to \\infty) \\end{equation*} と表せる。 次に、連続関数のノルムについて一様収束列とコーシー列が同値であることを見ていく。 連続関数の一様収束列とコーシー列 \\(C&#94;{0}(I)\\) の関数列 \\(\\{ f_{n}(x) \\}\\) が一様収束列であるための必要十分条件は、 \\(\\{ f_{n}(x) \\}\\) がノルムに関してコーシー列であることである。ここで、ノルムに関するコーシー列とは、任意の \\(\\varepsilon > 0\\) に対して自然数 \\(N\\) を適当に選べば、 \\(p, q \\geq N\\) に対して、 \\begin{equation*} || f_{p} - f_{q} ||_{0} < \\varepsilon \\end{equation*} が成立することを言う。 （ \\(\\Rightarrow\\) の証明） \\(\\{ f_{n}(x) \\}\\) が \\(f \\in C&#94;{0}(I)\\) に一様収束すれば、任意の \\(\\varepsilon > 0\\) に対して自然数 \\(N\\) を適当に大きく選んで \\(|| f_{n} - f ||_{0} < \\varepsilon / 2\\ (n \\geq N)\\) とできるから、 \\(p, q \\geq N\\) なる \\(p, q\\) について \\begin{align*} || f_{p} - f_{q} ||_{0} &= || f_{p} - f - ( f_{q} - f ) ||_{0} \\\\ &\\leq || f_{p} - f ||_{0} + || -( f_{q} - f ) ||_{0} \\quad (\\because \\text{三角不等式}) \\\\ &= || f_{p} - f ||_{0} + || f_{q} - f ||_{0} \\\\ &< \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} = \\varepsilon \\end{align*} これは \\(\\{ f_{n}(x) \\}\\) がコーシー列をなしていることを示している。（ \\(\\Rightarrow\\) の証明終） （ \\(\\Leftarrow\\) の証明） コーシー列は収束列（本稿では省略！！）だから、極限値があり、それを \\(f\\) とおく。任意の \\(\\varepsilon > 0\\) に対して、自然数 \\(N\\) を適当に大きく選び、 \\begin{equation*} |f_{p}(x) - f_{q}(x)| \\leq || f_{p} - f_{q} ||_{0} < \\varepsilon \\quad (p,q \\geq N, \\ x \\in I) \\end{equation*} とできる。ここで、 \\(q \\to \\infty\\) とすると、 \\(\\lim_{q \\to \\infty} f_{q}(x) = f(x)\\) だから、 \\begin{equation*} |f_{p}(x) - f(x)| \\leq || f_{p} - f || < \\varepsilon \\quad (p \\geq N) \\end{equation*} となる。これは、 \\(\\{ f_{n}(x) \\}\\) が \\(f(x)\\) への一様収束列であることを示している。 最後に \\(f \\in C&#94;{0}(I)\\) 、即ち \\(f\\) が \\(I\\) で連続であることを示す。任意の点 \\(x_{0} \\in I\\) に対して、収束列の元 \\(f_{n}\\) を使うと、 \\begin{align*} |f(x) - f(x_{0})| &= |f(x) - f_{n}(x) + f_{n}(x) - f_{n}(x_{0}) + f_{n}(x_{0}) - f(x_{0}) | \\\\ &\\leq |f(x) - f_{n}(x)| + |f_{n}(x) - f_{n}(x_{0})| + |f_{n}(x_{0}) - f(x)| \\\\ &\\leq || f_{n} - f ||_{0} + |f_{n}(x) - f_{n}(x_{0})| + || f_{n} - f ||_{0} \\end{align*} まず、 \\(\\{ f_{n}(x) \\}\\) の一様収束性により、任意の \\(\\varepsilon > 0\\) に対して \\(n\\) を十分大きく取れば \\(|| f_{n} - f ||_{0} < \\varepsilon / 3\\) とできる。また、 \\(f_{n}\\) は \\(I\\) で連続だから、ある \\(\\delta > 0\\) があって \\(|f_{n}(x) - f_{n}(x_{0})| < \\varepsilon / 3\\ (|x - x_{0}| < \\delta)\\) とできる。まとめると、任意の \\(\\varepsilon > 0\\) と \\(x_{0} \\in I\\) に対して、 ある \\(\\delta > 0\\) があって、任意の \\(x \\in I\\) で \\begin{equation*} |f(x) - f(x_{0})| < \\frac{\\varepsilon}{3} + \\frac{\\varepsilon}{3} + \\frac{\\varepsilon}{3} = \\varepsilon \\quad (|x - x_{0}| < \\delta) \\end{equation*} が成立している。これは、 \\(f(x)\\) が \\(I\\) で連続であることを示しており、 \\(f \\in C&#94;{0}(I)\\) が言える。（ \\(\\Leftarrow\\) の証明終） 一般に、コーシー列が必ず収束列になるとき、その集合を 完備 であるという。直感的には、集合上にコーシー列を構成したときに、極限値がその集合から飛び出ることがないことを指す。 \\(C&#94;{0}(I)\\) はノルムに関して完備な集合である。 不動点定理 本稿では（「微分積分学」を参考に）陰関数の存在を示すために不動点定理を使用する。本節では不動点定理について説明する。 縮小写像 関数集合 \\(\\mathcal{F}\\) から \\(\\mathcal{F}\\) への写像 \\(\\Phi(f)\\) がノルム \\(||f||_{0} = \\sup_{\\ve{x}} |f(\\ve{x})|\\) に関して 縮小写像 であるとは、ある定数 \\(\\rho \\in [0, 1)\\) があって、 \\begin{equation*} ||\\Phi(f) - \\Phi(g)||_{0} \\leq \\rho ||f - g||_{0} \\end{equation*} が任意の \\(f, g \\in \\mathcal{F}\\) について成立することを言う。 縮小写像 \\(\\Phi\\) によって写像した関数間の距離は、写像する前よりも小さくなることを言っている。この縮小写像を繰り返し適用することで、ある関数（極限関数）に一様収束するとき、それを不動点という。定理の形で述べると次のようになる。 不動点定理 \\(\\Phi(f)\\) を \\(\\mathcal{F}\\) から \\(\\mathcal{F}\\) への縮小写像とし、 \\(\\mathcal{F}\\) は \\(C&#94;{0}(\\Omega)\\) （定義域 \\(\\Omega\\) の \\(C&#94;{0}\\) 級すなわち連続関数の集合）において完備な集合とする。このとき、 \\begin{equation*} f = \\Phi(f) \\end{equation*} を満たす関数 \\(f \\in \\mathcal{F}\\) が唯一つ存在する。この様な \\(f\\) を \\(\\mathcal{F}\\) における \\(\\Phi\\) の不動点という。 （証明） \\(f_{0} \\in \\mathcal{F}\\) を任意に一つ取って、 \\begin{equation*} f_{n} = \\Phi(f_{n-1}) \\quad n = 1, 2, ... \\end{equation*} によって関数列 \\(\\{ f_{n} \\}\\) を作り、これがノルム \\(||\\cdot||_{0}\\) に関してコーシー列を作っていることを確かめる。 \\(\\Phi\\) は縮小写像だから、 \\begin{align*} || f_{n + 1} - f_{n} ||_{0} &= || \\Phi(f_{n}) - \\Phi(f_{n-1}) ||_{0} \\\\ &\\leq \\rho || f_{n} - f_{n-1} ||_{0} = \\rho || \\Phi(f_{n-1}) - \\Phi(f_{n-2}) ||_{0} \\\\ &\\leq \\rho&#94;{2} || f_{n-1} - f_{n-2} ||_{0} = \\rho&#94;{2} || \\Phi(f_{n-2}) - \\Phi(f_{n-1}) ||_{0} \\\\ &\\vdots \\\\ &\\leq \\rho&#94;{n} || f_{1} - f_{0} ||_{0} \\end{align*} 従って、 \\(p \\leq q\\) を満たす任意の添字について、 \\begin{align*} || f_{p} - f_{q} ||_{0} &= || f_{p} - f_{p+1} + f_{p+1} - f_{p+2} + f_{p+2} + ... + f_{q-1} + f_{q} ||_{0} \\\\ &\\leq || f_{p} - f_{p+1} ||_{0} + || f_{p+1} - f_{p+2} ||_{0} + ... + || f_{q-1} + f_{q} ||_{0} \\quad (\\because \\text{三角不等式}) \\\\ &\\leq \\rho&#94;{p} || f_{1} - f_{0} ||_{0} + \\rho&#94;{p+1} || f_{1} - f_{0} ||_{0} + ... + \\rho&#94;{q-1} || f_{1} - f_{0} ||_{0} \\\\ &= \\rho&#94;{p}(1 + \\rho + ... + \\rho&#94;{q-1-p}) || f_{1} - f_{0} ||_{0} \\\\ &= \\frac{\\rho&#94;{p}(1 - \\rho&#94;{q-1-p})}{1 - \\rho} || f_{1} - f_{0} ||_{0} \\quad (\\because \\text{等比級数の和の公式}) \\\\ &\\leq \\frac{\\rho&#94;{p}}{1 - \\rho} || f_{1} - f_{0} ||_{0} \\end{align*} 最後の式は \\(p\\) を大きくしていくといくらでも小さくなる。従って、 \\(\\{ f_{n} \\}\\) はコーシー列である。更に、 \\(\\mathcal{F}\\) は完備な集合だから \\(\\{ f_{n} \\}\\) は収束列であり、ある \\(f \\in \\mathcal{F}\\) があって、 \\(f_{n}\\) は 領域 \\(\\Omega\\) において \\(f\\) に一様収束する（ \\(\\because\\) コーシーの収束定理）。 従って、 \\(f_{n} = \\Phi(f_{n-1})\\) の \\(n\\) を大きくしていくと、極限において \\begin{equation*} f = \\Phi(f) \\end{equation*} が成立する。従って、 \\(f\\) は \\(\\Phi\\) の不動点である。 次に唯一性を示す。仮に不動点が2つあったとして、それらを \\(f, g\\) を書くと、 \\begin{equation*} || f - g ||_{0} = || \\Phi(f) - \\Phi(g) ||_{0} \\leq \\rho || f - g ||_{0} < || f - g ||_{0} \\end{equation*} となるが、これは \\(|| f - g ||_{0} > 0\\) である限り \\(|| f - g ||_{0} < || f - g ||_{0}\\) となって矛盾。従って \\(|| f - g ||_{0} = 0\\) でなければならず、これは \\(f\\) と \\(g\\) が同一の不動点であることを意味する。（証明終） 陰関数定理 まずは2変数 \\(x, y\\) で考えてみる。 \\(x&#94;{2} + y&#94;{2} - 2 = 0\\) のように \\(y = f(x)\\) が陽に分からない場合がある。この2変数関数 \\(F(x, y)\\) による等式 \\(F(x, y) = 0\\) を陰関数表示という。 \\(F(x, y) = 0\\) に対して、何らかの関数 \\(y = f(x)\\) （もしくは \\(x = h(y)\\) ）の存在を保証するのが陰関数定理である。 陰関数定理（2変数） \\(\\mathbb{R}&#94;{2}\\) のある領域（開部分集合） \\(\\Omega\\) で \\(F(x, y)\\) は連続とし、 \\(\\Omega\\) の1点 \\((x_{0}, y_{0})\\) の近傍 \\(U\\) で \\(y\\) について偏微分可能かつ \\(F_{y}(x, y) = \\parfrac{F}{y}(x, y)\\) は \\(U\\) で連続とする。このとき、次の 1 - 4 が成り立つ。 もし、 \\(F(x_{0}, y_{0}) = 0,\\ F_{y}(x_{0}, y_{0}) \\neq 0\\) ならば、 \\((x_{0}, y_{0})\\) の十分小さい近傍 \\(V\\) において \\begin{equation*} y_{0} = f(x_{0}), \\ F(x, f(x)) = 0 \\end{equation*} を満たす連続関数 \\(y = f(x)\\ ((x, y) \\in V)\\) が唯一つ存在する。（ \\(x\\) と \\(y\\) の関係を入れ替えても成立する。即ち \\(F(x_{0}, y_{0}) = 0,\\ F_{x}(x_{0}, y_{0}) \\neq 0\\) ならば、 \\((x_{0}, y_{0})\\) の近傍で \\(x_{0} = h(y_{0}), \\ F(h(y), y) = 0\\) を満たす連続関数 \\(h\\) が存在する）。 1が成り立つとき、 \\(F\\) が \\((x_{0}, y_{0})\\) において \\(x\\) について偏微分可能なら、 \\(f(x)\\) は \\(x_{0}\\) において微分可能で、 \\begin{equation*} \\dfrac{f}{x}(x_{0}) = - \\frac{F_{x}(x_{0}, y_{0})}{F_{y}(x_{0}, y_{0})} \\end{equation*} 2が成り立つとき、 \\(F\\) が \\(U\\) 上で \\(C&#94;{1}\\) 級なら、 \\(f(x)\\) も \\(C&#94;{1}\\) 級で、 \\begin{equation*} \\dfrac{f}{x}(x) = - \\frac{F_{x}(x, y)}{F_{y}(x, y)} \\quad (x, f(x)) \\in V \\end{equation*} 3が成り立つとき、 \\(F\\) が \\(U\\) 上で \\(C&#94;{m}\\) 級なら、 \\(f(x)\\) も \\(C&#94;{m}\\) 級。 （1.の証明） \\(x_{0}\\) の近傍 \\(U_{1}\\) と \\(y_{0}\\) の近傍 \\(U_{2}\\) を適当に選んで \\(U_{1} \\times U_{2} \\subset U\\) となるようにしておく。 \\(M = F_{y}(x_{0}, y_{0})\\) とおく。 \\(F_{y}\\) は仮定より連続だから、 \\(\\rho \\in (0, 1)\\) なる \\(\\rho\\) を1つ取り、これに応じて \\(U_{1}, U_{2}\\) を小さく取り直して \\begin{equation*} |M - F_{y}(x, y)| < \\rho |M| \\quad (x \\in U_{1}, y \\in U_{2}) \\end{equation*} とできる。更に、 \\(F\\) は連続だから、 \\(U_{2} = [ y_{0} - \\delta, y_{0} + \\delta ]\\) と閉区間を取ったとき、 \\(\\delta\\) に応じて \\(U_{1}\\) を小さく取り直し、 \\begin{equation*} |F(x, y_{0}) - F(x_{0}, y_{0})| = |F(x, y_{0})| < (1 - \\rho)|M|\\delta \\quad (x \\in U_{1}) \\end{equation*} とできる。次に、関数の集合 \\(\\mathcal{F}\\) として、 \\(U_{1}\\) 上で連続で、 \\(y_{0} = \\varphi(x_{0})\\) となり、かつ \\(x \\in U_{1}\\) において \\(\\varphi(x) \\in U_{2}\\) となるような関数 \\(\\varphi\\) の全体をとる。 \\(U_{1}\\) 上で連続な関数の集合を \\(C&#94;{0}(U_{1})\\) とかくと、 \\(\\mathcal{F} \\subset C&#94;{0}(U_{1})\\) が成立する。今、写像 \\(\\Phi(\\varphi)\\) として、 \\begin{equation*} \\Phi(\\varphi)(x) = \\varphi(x) - \\frac{1}{M} F(x, \\varphi(x)) \\end{equation*} とおいた時、これが \\(\\mathcal{F}\\) から \\(\\mathcal{F}\\) への縮小写像であって、かつ \\(\\mathcal{F}\\) が完備であることを示す。まず、 \\(\\varphi \\in \\mathcal{F}\\) を任意に取ったときに、 \\(\\Phi(\\varphi) \\in \\mathcal{F}\\) となることを示す。平均値の定理により、 \\(\\varphi(x)\\) と \\(y_{0}\\) の間に \\(\\xi_{1}(x)\\) を適当に選び、 \\begin{equation*} F(x, \\varphi(x)) = F(x, y_{0}) + F_{y}(x, \\xi_{1}(x))(\\varphi(x) - y_{0}) \\end{equation*} とできるから、 \\begin{align*} |\\Phi(\\varphi)(x) - y_{0}| &= |\\varphi(x) - \\frac{1}{M}F(x, \\varphi(x)) - y_{0}| \\\\ &= |\\varphi(x) - y_{0} - \\frac{1}{M}F(x, y_{0}) - \\frac{1}{M}F(x, \\xi_{1}(x))(\\varphi(x) - y_{0})| \\\\ &= \\left| \\left\\{ \\varphi(x) - y_{0} \\right\\} \\left\\{ 1 - \\frac{1}{M}F(x, \\xi_{1}(x)) \\right\\} - \\frac{1}{M}F(x, \\varphi(x)) \\right| \\\\ &\\leq |\\varphi(x) - y_{0}|\\left| 1 - \\frac{1}{M}F(x, \\xi_{1}(x)) \\right| + \\left| \\frac{1}{M}F(x, \\varphi(x)) \\right| \\quad (\\because \\text{三角不等式}) \\\\ &< \\rho |\\varphi(x) - y_{0}| + (1 - \\rho)\\delta \\\\ &\\leq \\rho \\delta + (1 - \\rho)\\delta \\quad (\\because \\varphi(x) \\in U_{2} = [y_{0} - \\delta, y_{0} + \\delta]) \\\\ &= \\delta \\end{align*} よって、 \\(\\Phi(\\varphi)(x) \\in U_{2}\\) だから、 \\(\\Phi(\\varphi) \\in \\mathcal{F}\\) 。次に、 \\(\\varphi, \\psi \\in \\mathcal{F}\\) をとると、 \\begin{align*} \\Phi(\\varphi)(x) - \\Phi(\\psi)(x) &= \\varphi(x) - \\frac{1}{M} F(x, \\varphi(x)) - \\left\\{ \\psi(x) - \\frac{1}{M} F(x, \\psi(x)) \\right\\} \\\\ &= \\varphi(x) - \\psi(x) - \\frac{1}{M} \\left\\{ F(x, \\varphi(x)) - F(x, \\psi(x)) \\right\\} \\end{align*} 再び平均値の定理より、 \\(\\varphi(x)\\) と \\(\\psi(x)\\) の間に \\(\\xi_{2}(x)\\) を適当に選び、 \\begin{equation*} F(x, \\varphi(x)) = F(x, \\psi(x)) + F_{y}(x, \\xi_{2}(x))(\\varphi(x) - \\psi(x)) \\end{equation*} とできるから、 \\begin{align*} \\Phi(\\varphi)(x) - \\Phi(\\psi)(x) &= \\varphi(x) - \\psi(x) - \\frac{1}{M} \\left\\{ F_{y}(x, \\xi_{2}(x))(\\varphi(x) - \\psi(x)) \\right\\} \\\\ &= \\left\\{ 1 - \\frac{1}{M} F_{y} (x, \\xi_{2}(x)) \\right\\} (\\varphi(x) - \\psi(x)) \\end{align*} となる。 \\(\\xi_{2}(x) \\in U_{2}\\) だから、 \\(|M - F_{y}(x, \\xi_{2}(x))| < \\rho |M|\\) が成り立ち、 \\begin{equation*} |\\Phi(\\varphi)(x) - \\Phi(\\psi)(x)| < \\rho |\\varphi(x) - \\psi(x)| \\leq \\rho || \\varphi - \\psi ||_{0} \\end{equation*} これが任意の \\(x \\in U_{1}\\) で成り立つから、 \\(\\rho || \\varphi - \\psi ||_{0}\\) は \\(|\\Phi(\\varphi)(\\ve{x}) - \\Phi(\\psi)(\\ve{x})|\\) の上限を与えており、 \\(|| \\Phi(\\varphi) - \\Phi(\\psi) ||_{0} \\leq \\rho || \\varphi - \\psi ||_{0}\\) が言える。従って \\(\\Phi\\) は縮小写像である。 次に、 \\(\\mathcal{F}\\) が完備であることを示す。 \\(\\mathcal{F} \\subset C&#94;{0}(U_{1})\\) で \\(C&#94;{0}(U_{1})\\) は完備だから、 \\(\\mathcal{F}\\) の中のコーシー列は \\(C&#94;{0}(U_{1})\\) の中での収束列である。写像 \\(\\Phi\\) による極限関数 \\(f\\) は、 \\(\\Phi\\) の作り方により、 \\(U_{1}\\) 上で連続で、 \\(y_{0} = f(x_{0})\\) を満たす。また、各点収束として考えると（コーシー列は一様収束性を述べているので可能）、極限関数 \\(f(x)\\) は閉区間 \\(U_{2}\\) に属するから、 \\(f \\in \\mathcal{F}\\) である。即ち \\(\\mathcal{F}\\) は完備。 以上より不動点定理が使える。即ち、 \\begin{equation*} f(x) = \\Phi(f)(x) \\quad (x \\in U_{1}) \\end{equation*} を満たす関数が \\(\\mathcal{F}\\) の中に唯一存在する。これは、 \\begin{equation*} \\Phi(f)(x) = f(x) - \\frac{1}{M} F(x, f(x)) \\end{equation*} と合わせると、 \\begin{equation*} F(x, f(x)) = 0 \\quad (x \\in U_{1}) \\end{equation*} が得られるから、定理1が示された。（1.の証明終） （2.の証明） \\(F\\) は \\((x_{0}, y_{0})\\) で偏微分可能で \\(F_{y}(x, y)\\) は \\(U\\) で連続だから、 \\(F(x, y)\\) は全微分可能である（ \\(\\because\\) 準備）。従って \\(U\\) において、 \\begin{equation*} F(x, y) = F(x_{0}, y_{0}) + \\alpha(x, y)(x - x_{0}) + \\beta(x, y)(y - y_{0}) \\end{equation*} とかける（ \\(\\alpha, \\beta\\) は \\((x_{0}, y_{0})\\) で連続な関数で、かつ \\(\\alpha(x_{0}, y_{0}) = F_{x}(x_{0}, y_{0}), \\beta(x_{0},\\ y_{0}) = F_{y}(x_{0}, y_{0}) \\neq 0\\) ）。 \\(x \\in V\\) に対して \\(y = f(x)\\) を代入すると、 \\begin{align*} F(x, f(x)) = 0 &= F(x_{0}, f(x_{0})) + \\alpha(x, f(x))(x - x_{0}) + \\beta(x, f(x))(f(x) - y_{0}) \\\\ &= \\alpha(x, f(x))(x - x_{0}) + \\beta(x, f(x))(f(x) - y_{0}) \\\\ \\implies f(x) &= y_{0} - \\frac{\\alpha(x, f(x))}{\\beta(x, f(x))}(x - x_{0}) \\end{align*} 両辺を \\(x - x_{0}\\) で割ってから \\(x \\to x_{0}\\) としてみると、 \\(-\\alpha(x, f(x)) / \\beta(x, f(x))\\) は \\(x_{0}\\) において（連続関数の商になっているので）連続だから極限値をもつ。即ち \\(f(x)\\) は \\(x_{0}\\) で微分可能で、 \\begin{equation*} \\dfrac{f}{x}(x_{0}) = - \\frac{\\alpha(x_{0}, f(x_{0}))}{\\beta(x_{0}, f(x_{0}))} = - \\frac{F_{x}(x_{0}, y_{0})}{F_{y}(x_{0}, y_{0})} \\tag{4} \\end{equation*} （2.の証明終） （3.の証明） \\(F\\) が \\(C&#94;{1}\\) 級ならば (4) の右辺は \\((x_{0}, y_{0})\\) で連続だから、 \\(y_{0} = f(x_{0})\\) を代入したものも \\(x_{0}\\) で連続である。即ち、 \\(\\dfrac{f}{x}(x)\\) は連続関数（ \\(C&#94;{0}\\) 級）だから、 \\(f(x)\\) は \\(C&#94;{1}\\) 級。（3.の証明終） （4.の証明） \\(F\\) が \\(C&#94;{m}\\) 級ならば \\(f(x)\\) も \\(C&#94;{m}\\) 級であることを示す。 \\(m = 1\\) の場合は 3. より成立する。 \\(m - 1\\) の場合に成立すると仮定して、もし、 \\(F\\) が \\(C&#94;{m}\\) 級ならば、同時に \\(F\\) は \\(C&#94;{m-1}\\) 級だから、 仮定より \\(f(x)\\) も \\(C&#94;{m-1}\\) 級である。従って、 \\begin{equation*} \\dfrac{f}{x}(x) = - \\frac{F_{x}(x, f(x))}{F_{y}(x, f(x))} \\end{equation*} の右辺は \\(C&#94;{m-1}\\) 級の関数 \\(F_{x}, F_{y}\\) に \\(C&#94;{m-1}\\) 級の関数 \\(f(x)\\) を代入したもので、合成関数の微分法から右辺は \\(C&#94;{m-1}\\) 級である。 \\(\\dfrac{f}{x}(x)\\) が \\(C&#94;{m-1}\\) 級だから、 \\(f(x)\\) は \\(C&#94;{m}\\) 級。（4.の証明終） 多変数の場合 3変数 \\(x, y, z\\) による連立陰関数 \\begin{equation*} \\begin{cases} F(x, y, z) = 0 \\\\ G(x, y, z) = 0 \\end{cases} \\end{equation*} を満たす連続関数 \\(y=f(x),\\ z = g(x)\\) を求める問題を考える。 \\(F(x_{0}, y_{0}, z_{0}) = 0,\\ F_{y}(x_{0}, y_{0}, z_{0}) \\neq 0\\) とすると、陰関数定理により、 \\((x_{0}, y_{0}, z_{0})\\) の近傍で \\(y = Y(x, z)\\) という陰関数が存在する。これを \\(G\\) に代入すると、 \\begin{equation*} G(x, Y(x, z), z) = H(x, z) = 0 \\end{equation*} となるが、もし、 \\(G(x_{0}, y_{0}, z_{0}) = 0,\\ H_{z}(x_{0}, z_{0}) \\neq 0\\) ならば、これから \\(z = g(x)\\) という陰関数が存在する。これを \\(y = Y(x, z)\\) に代入して、 \\begin{equation*} y = f(x) = Y(x, g(x)) \\end{equation*} とおけば、2つの陰関数が求められる。今、 \\begin{align*} H_{z}(x, z) &= G_{z}(x, Y(x, z), z) \\\\ &= \\parfrac{G}{z} + \\parfrac{G}{y} \\dfrac{Y}{z} \\quad (\\because \\text{合成関数の微分}) \\\\ &= G_{z} - G_{y}\\frac{F_{z}}{F_{y}} \\quad (\\because \\text{陰関数定理}) \\\\ &= \\frac{1}{F_{y}} \\det \\left[ \\begin{array}{cc} F_{y} & F_{z} \\\\ G_{y} & G_{z} \\end{array} \\right] \\end{align*} だから、 \\(H_{z}(x_{0}, z_{0}) \\neq 0\\) は、行列 \\begin{equation*} \\parfrac{F}{\\ve{y}} = \\left[ \\begin{array}{cc} F_{y} & F_{z} \\\\ G_{y} & G_{z} \\end{array} \\right] \\quad \\left( \\ve{F} = \\left[ \\begin{array}{c} F \\\\ G \\end{array} \\right],\\ \\ve{y} = \\left[ \\begin{array}{c} y \\\\ z \\end{array} \\right] \\right) \\end{equation*} が \\((x_{0}, y_{0}, z_{0})\\) で正則という条件と同値になる。従って、 \\(\\parfrac{F}{\\ve{y}}\\) が正則であれば陰関数を持つことが分かる（ \\(\\parfrac{F}{\\ve{y}}\\) が正則ならば、 \\(F_{y}, F_{z}\\) のいずれかは \\(0\\) ではないから、 \\(F_{y}(x_{0}, y_{0}, z_{0}) \\neq 0\\) という条件をおいても良い）。これを一般化した定理を以下に示す。 陰関数定理（多変数） \\(\\mathbb{R}&#94;{p} \\times \\mathbb{R}&#94;{n}\\) の領域 \\(\\Omega\\) で、 \\(n\\) 次元写像 \\begin{equation*} \\ve{F}(\\ve{x}, \\ve{y}) = \\left[ \\begin{array}{c} F_{1}(x_{1}, ..., x_{p}, y_{1}, ..., y_{n}) \\\\ F_{2}(x_{1}, ..., x_{p}, y_{1}, ..., y_{n}) \\\\ \\vdots \\\\ F_{n}(x_{1}, ..., x_{p}, y_{1}, ..., y_{n}) \\end{array} \\right] \\end{equation*} は連続として、1点 \\((\\ve{x}_{0}, \\ve{y}_{0})&#94;{\\mathsf{T}} = (x_{1}&#94;{0}, ..., x_{p}&#94;{0}, y_{1}&#94;{0}, ..., y_{n}&#94;{0})&#94;{\\mathsf{T}}\\) の近傍 \\(U\\) でサイズ \\(n \\times n\\) の正方行列関数 \\begin{equation*} \\parfrac{\\ve{F}}{\\ve{y}}(\\ve{x}, \\ve{y}) = \\left[ \\begin{array}{cccc} \\parfrac{F_{1}}{y_{1}} & \\parfrac{F_{1}}{y_{2}} & \\dots & \\parfrac{F_{1}}{y_{n}} \\\\ \\parfrac{F_{2}}{y_{1}} & \\parfrac{F_{2}}{y_{2}} & \\dots & \\parfrac{F_{2}}{y_{n}} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\parfrac{F_{n}}{y_{1}} & \\parfrac{F_{n}}{y_{2}} & \\dots & \\parfrac{F_{n}}{y_{n}} \\end{array} \\right] \\end{equation*} は連続な正則行列とする。とのとき、次の 1 - 4 が成り立つ。 もし \\(\\ve{F}(\\ve{x}_{0}, \\ve{y}_{0}) = \\ve{0}\\) ならば、 \\((\\ve{x}_{0}, \\ve{y}_{0})\\) の十分小さい近傍 \\(V\\) があって \\begin{equation*} \\ve{y}_{0} = \\ve{f}(\\ve{x}_{0}), \\ \\ve{F}(\\ve{x}, \\ve{f}(\\ve{x})) = \\ve{0} \\quad (\\ve{x}, \\ve{f}(\\ve{x})) \\in V \\end{equation*} を満たす \\(n\\) 次元ベクトル値連続関数 \\(\\ve{f}(\\ve{x})\\) が唯一存在する。 1が成り立つとき、 \\(\\ve{F}\\) が \\((\\ve{x}_{0}, \\ve{y}_{0})\\) において \\(\\ve{x}\\) について微分可能なら、 \\(\\ve{f}(\\ve{x})\\) は \\(\\ve{x}_{0}\\) において微分可能で、 \\begin{equation*} \\parfrac{\\ve{f}}{\\ve{x}}(\\ve{x}_{0}) = - \\left[ \\parfrac{\\ve{F}}{\\ve{y}}(\\ve{x}_{0}, \\ve{y}_{0}) \\right]&#94;{-1} \\parfrac{\\ve{F}}{\\ve{x}}(\\ve{x}_{0}, \\ve{y}_{0}) \\end{equation*} 2が成り立つとき、 \\(\\ve{F}\\) が \\(U\\) 上で \\(C&#94;{1}\\) 級なら、 \\(\\ve{f}(\\ve{x})\\) も \\(C&#94;{1}\\) 級で、 \\begin{equation*} \\parfrac{\\ve{f}}{\\ve{x}}(\\ve{x}) = - \\left[ \\parfrac{\\ve{F}}{\\ve{y}}(\\ve{x}, \\ve{y}) \\right]&#94;{-1} \\parfrac{\\ve{F}}{\\ve{x}}(\\ve{x}, \\ve{y}) \\end{equation*} 3が成り立つとき、 \\(\\ve{F}\\) が \\(U\\) 上で \\(C&#94;{m}\\) 級なら、 \\(\\ve{f}(\\ve{x})\\) も \\(C&#94;{m}\\) 級である。 証明については2変数と同様に考える。 （1.の証明） \\(\\ve{x}_{0}\\) の近傍 \\(U_{1}\\) と \\(\\ve{y}_{0}\\) の近傍 \\(U_{2}\\) を適当に選んで \\(U_{1} \\times U_{2} \\subset U\\) となるようにしておく。次に、行列 \\(\\ve{M}\\) として \\begin{equation*} \\ve{M} = \\parfrac{\\ve{F}}{\\ve{y}}(\\ve{x}_{0}, \\ve{y}_{0}) \\end{equation*} とおく。 \\(\\ve{M}\\) は仮定より正則行列である。 \\(\\rho \\in (0, 1)\\) なる \\(\\rho\\) を1つ取り、これに応じて \\(U_{1}, U_{2}\\) を小さく取り直して \\begin{equation*} \\left| \\ve{M} - \\parfrac{\\ve{F}}{\\ve{y}}(\\ve{x}, \\ve{y}) \\right| < \\frac{\\rho}{|\\ve{M}&#94;{-1}|} \\quad (\\ve{x}, \\ve{y}) \\in U_{1} \\times U_{2} \\end{equation*} となる様にしておく（ \\(|\\ve{M}| = \\sup_{|\\ve{x}| = 1} |\\ve{M}\\ve{x}|\\) : 行列ノルム）。 \\(U_{2}\\) は、 \\begin{equation*} U_{2} = \\left\\{ \\ve{y} | |\\ve{y} - \\ve{y}_{0}| \\leq \\delta \\right\\} \\end{equation*} と閉集合にとり、この \\(\\delta\\) に応じて \\(U_{1}\\) を更に小さく取り直し、 \\begin{equation*} |\\ve{F}(\\ve{x}, \\ve{y}_{0})| < (1 - \\rho)\\frac{\\delta}{|\\ve{M}&#94;{-1}|} \\quad \\ve{x} \\in U_{1} \\end{equation*} が成り立つようにしておく（これは、 \\(\\ve{F}(\\ve{x}_{0}, \\ve{y}_{0}) = \\ve{0}\\) かつ \\(\\ve{F}\\) の連続性により可能）。 \\(\\ve{x}\\) の関数の集合 \\(\\mathcal{F}\\) として、 \\(U_{1}\\) 上で連続で、 \\(\\ve{y}_{0} = \\ve{\\varphi}(\\ve{x}_{0})\\) となり、かつ、 \\begin{equation*} \\ve{\\varphi}(\\ve{x}) \\in U_{2} \\quad \\ve{x} \\in U_{1} \\end{equation*} となるような写像 \\(\\ve{\\varphi}(\\ve{x})\\) の全体をとる。そして写像 \\(\\ve{\\Phi}(\\ve{\\varphi})\\) として、 \\begin{equation*} \\ve{\\Phi}(\\ve{\\varphi})(\\ve{x}) = \\ve{\\varphi}(\\ve{x}) - \\ve{M}&#94;{-1} \\ve{F}(\\ve{x}, \\ve{\\varphi}(\\ve{x})) \\end{equation*} とおく。上で述べた積分公式より、 \\begin{equation*} \\ve{F}(\\ve{x}, \\ve{\\varphi}(\\ve{x})) = \\ve{F}(\\ve{x}, \\ve{y}_{0}) + \\int_{0}&#94;{1} \\parfrac{\\ve{F}}{\\ve{y}} (\\ve{x}, \\ve{y}_{0} + t (\\ve{\\varphi}(\\ve{x}) - \\ve{y}_{0})) \\mathrm{d} t (\\ve{\\varphi}(\\ve{x}) - \\ve{y}_{0}) \\end{equation*} だから、 \\begin{align*} \\ve{\\Phi}(\\ve{\\varphi})(\\ve{x}) - \\ve{y}_{0} &= \\ve{\\varphi}(\\ve{x}) - \\ve{y}_{0} - \\ve{M}&#94;{-1} \\ve{F}(\\ve{x}, \\ve{\\varphi}(\\ve{x})) \\\\ &= \\ve{\\varphi}(\\ve{x}) - \\ve{y}_{0} - \\ve{M}&#94;{-1} \\ve{F}(\\ve{x}, \\ve{y}_{0}) - \\ve{M}&#94;{-1} \\int_{0}&#94;{1} \\parfrac{\\ve{F}}{\\ve{y}} (\\ve{x}, \\ve{y}_{0} + t (\\ve{\\varphi}(\\ve{x}) - \\ve{y}_{0})) \\mathrm{d} t (\\ve{\\varphi}(\\ve{x}) - \\ve{y}_{0}) \\\\ &= \\left\\{ \\ve{I} - \\ve{M}&#94;{-1} \\int_{0}&#94;{1} \\parfrac{\\ve{F}}{\\ve{y}} (\\ve{x}, \\ve{y}_{0} + t (\\ve{\\varphi}(\\ve{x}) - \\ve{y}_{0})) \\mathrm{d} t \\right\\} \\left\\{ \\ve{\\varphi}(\\ve{x}) - \\ve{y}_{0} \\right\\} - \\ve{M}&#94;{-1}\\ve{F}(\\ve{x}, \\ve{y}_{0}) \\\\ \\implies |\\ve{\\Phi}(\\ve{\\varphi})(\\ve{x}) - \\ve{y}_{0}| &\\leq \\left| \\ve{I} - \\ve{M}&#94;{-1} \\int_{0}&#94;{1} \\parfrac{\\ve{F}}{\\ve{y}} (\\ve{x}, \\ve{y}_{0} + t (\\ve{\\varphi}(\\ve{x}) - \\ve{y}_{0})) \\mathrm{d} t \\right||\\ve{\\varphi}(\\ve{x}) - \\ve{y}_{0}| + |\\ve{M}&#94;{-1}\\ve{F}(\\ve{x}, \\ve{y}_{0})| \\end{align*} となる。ここで、 \\begin{align*} \\left| \\ve{I} - \\ve{M}&#94;{-1} \\int_{0}&#94;{1} \\parfrac{\\ve{F}}{\\ve{y}} \\mathrm{d} t \\right| &= \\left| \\ve{M}&#94;{-1}\\left( \\ve{M} - \\int_{0}&#94;{1} \\parfrac{\\ve{F}}{\\ve{y}} \\mathrm{d} t \\right) \\right| \\\\ &\\leq |\\ve{M}&#94;{-1}| \\int_{0}&#94;{1} \\left| \\ve{M} - \\parfrac{\\ve{F}}{\\ve{y}} \\right| \\mathrm{d} t \\\\ &< |\\ve{M}&#94;{-1}| \\int_{0}&#94;{1} \\frac{\\rho}{|\\ve{M}&#94;{-1}|} \\mathrm{d} t = \\rho \\end{align*} が成り立つ。更に、 \\(\\ve{\\varphi}(\\ve{x}) \\in U_{2}\\) より、 \\(|\\ve{\\varphi}(\\ve{x}) - \\ve{y}_{0}| \\leq \\delta\\) 。しかも、 \\begin{equation*} |\\ve{M}&#94;{-1}\\ve{F}(\\ve{x}, \\ve{y}_{0})| \\leq |\\ve{M}&#94;{-1}||\\ve{F}(\\ve{x}, \\ve{y}_{0})| < (1 - \\rho) \\delta \\end{equation*} だから、 \\begin{equation*} |\\ve{\\Phi}(\\ve{\\varphi})(\\ve{x}) - \\ve{y}_{0}| < \\rho \\delta + (1 - \\rho) \\delta = \\delta \\end{equation*} 従って \\(\\ve{\\Phi}(\\ve{\\varphi}) \\in \\mathcal{F}\\) である。 次に、 \\(\\ve{\\varphi}, \\ve{\\psi} \\in \\mathcal{F}\\) に対し、 \\begin{equation*} \\ve{\\Phi}(\\ve{\\varphi})(\\ve{x}) - \\ve{\\Phi}(\\ve{\\psi})(\\ve{x}) = \\ve{\\varphi}(\\ve{x}) - \\ve{\\psi}(\\ve{x}) - \\ve{M}&#94;{-1} ( \\ve{F}(\\ve{x}, \\ve{\\varphi}(\\ve{x})) - \\ve{F}(\\ve{x}, \\ve{\\psi}(\\ve{x})) ) \\end{equation*} が成立するが、ここで積分公式 \\begin{equation*} \\ve{F}(\\ve{x}, \\ve{\\varphi}(\\ve{x})) - \\ve{F}(\\ve{x}, \\ve{\\psi}(\\ve{x})) = \\int_{0}&#94;{1} \\parfrac{\\ve{F}}{\\ve{y}} (\\ve{x}, \\ve{y}_{0} + t (\\ve{\\varphi}(\\ve{x}) - \\ve{\\psi}(\\ve{x}))) \\mathrm{d} t (\\ve{\\varphi}(\\ve{x}) - \\ve{\\psi}(\\ve{x})) \\end{equation*} を用いると、 \\begin{align*} \\ve{\\Phi}(\\ve{\\varphi})(\\ve{x}) - \\ve{\\Phi}(\\ve{\\psi})(\\ve{x}) &= \\ve{\\varphi}(\\ve{x}) - \\ve{\\psi}(\\ve{x}) - \\ve{M}&#94;{-1} \\int_{0}&#94;{1} \\parfrac{\\ve{F}}{\\ve{y}} (\\ve{x}, \\ve{\\varphi}(\\ve{x}) + t (\\ve{\\varphi}(\\ve{x}) - \\ve{\\psi}(\\ve{x}))) \\mathrm{d} t (\\ve{\\varphi}(\\ve{x}) - \\ve{\\psi}(\\ve{x})) \\\\ &= \\left\\{ \\ve{I} - \\ve{M}&#94;{-1} \\int_{0}&#94;{1} \\parfrac{\\ve{F}}{\\ve{y}} (\\ve{x}, \\ve{\\varphi}(\\ve{x}) + t (\\ve{\\varphi}(\\ve{x}) - \\ve{\\psi}(\\ve{x}))) \\mathrm{d} t \\right\\} (\\ve{\\varphi}(\\ve{x}) - \\ve{\\psi}(\\ve{x})) \\\\ \\implies |\\ve{\\Phi}(\\ve{\\varphi})(\\ve{x}) - \\ve{\\Phi}(\\ve{\\psi})(\\ve{x})| &= \\left| \\ve{I} - \\ve{M}&#94;{-1} \\int_{0}&#94;{1} \\parfrac{\\ve{F}}{\\ve{y}} (\\ve{x}, \\ve{\\varphi}(\\ve{x}) + t (\\ve{\\varphi}(\\ve{x}) - \\ve{\\psi}(\\ve{x}))) \\mathrm{d} t \\right| |\\ve{\\varphi}(\\ve{x}) - \\ve{\\psi}(\\ve{x})| \\\\ &< \\rho |\\ve{\\varphi}(\\ve{x}) - \\ve{\\psi}(\\ve{x})| \\leq \\rho ||\\ve{\\varphi}(\\ve{x}) - \\ve{\\psi}(\\ve{x})||_{0} \\end{align*} が任意の \\(\\ve{x} \\in U_{1}\\) で成り立つから、 \\begin{equation*} ||\\ve{\\Phi}(\\ve{\\varphi})(\\ve{x}) - \\ve{\\Phi}(\\ve{\\psi})(\\ve{x})||_{0} \\leq \\rho ||\\ve{\\varphi}(\\ve{x}) - \\ve{\\psi}(\\ve{x})||_{0} \\end{equation*} よって \\(\\ve{\\Phi}\\) は縮小写像。 次に \\(\\mathcal{F}\\) が完備であることを示す。まず、 \\(\\mathcal{F} \\subset C&#94;{0}(U_{1})\\) で \\(C&#94;{0}(U_{1})\\) は完備だから、 \\(\\mathcal{F}\\) の中で作ったコーシー列は \\(C&#94;{0}(U_{1})\\) の中で収束列となる。極限関数 \\(\\ve{f} = \\lim_{n \\to \\infty} \\ve{\\Phi}(\\ve{f}_{n})\\) が \\(\\mathcal{F}\\) に属することを示す。 \\(\\ve{\\Phi}\\) の定義より、 \\(\\ve{f}\\) は \\(U_{1}\\) 上で連続で、 \\(\\ve{y}_{0} = \\ve{f}(\\ve{x}_{0})\\) を満たす。各点収束としてみると、 \\(\\ve{f}(\\ve{x})\\) は 区間 \\(U_{1}\\) で閉区間 \\(U_{2}\\) に属するから、 \\(\\ve{f} \\in \\mathcal{F}\\) である。即ち \\(\\mathcal{F}\\) は完備。 不動点定理により、 \\(\\ve{f}(\\ve{x}) = \\ve{\\Phi}(\\ve{f})(\\ve{x})\\) を満たす \\(\\ve{f}(\\ve{x}) \\in \\mathcal{F}\\) が唯一存在する。この写像 \\(\\ve{f}\\) は \\(\\ve{f}(\\ve{x}) = \\ve{\\Phi}(\\ve{f})(\\ve{x}) = \\ve{f}(\\ve{x}) - \\ve{M}&#94;{-1}\\ve{F}(\\ve{x}, \\ve{f}(\\ve{x}))\\) を満たすので、 \\(\\ve{F}(\\ve{x}, \\ve{f}(\\ve{x})) = \\ve{0}\\) が成り立っている。（1. の証明終） （2.の証明） \\(\\ve{F}\\) は \\((\\ve{x}_{0}, \\ve{y}_{0})\\) で偏微分可能で、しかも連続だから微分可能で（ \\(\\because\\) 上述）であり、 \\begin{equation*} \\ve{F}(\\ve{x}, \\ve{y}) = \\ve{F}(\\ve{x}_{0}, \\ve{y}_{0}) + \\ve{A}(\\ve{x}, \\ve{y})(\\ve{x} - \\ve{x}_{0}) + \\ve{B}(\\ve{x}, \\ve{y})(\\ve{y} - \\ve{y}_{0}) \\end{equation*} と書ける（ \\(\\ve{A}, \\ve{B}\\) は \\((\\ve{x}_{0}, \\ve{y}_{0})\\) で連続な行列関数で、 \\(\\ve{A}(\\ve{x}_{0}, \\ve{y}_{0}) = \\parfrac{\\ve{F}}{\\ve{x}}(\\ve{x}_{0}, \\ve{y}_{0}),\\ \\ve{B}(\\ve{x}_{0}, \\ve{y}_{0}) = \\parfrac{\\ve{F}}{\\ve{y}}(\\ve{x}_{0}, \\ve{y}_{0})\\) ）。この式に \\(\\ve{y} = \\ve{f}(\\ve{x})\\) を代入すると、 \\begin{align*} \\ve{F}(\\ve{x}, \\ve{f}(\\ve{x})) = \\ve{0} &= \\ve{F}(\\ve{x}_{0}, \\ve{f}(\\ve{x}_{0})) + \\ve{A}(\\ve{x}, \\ve{f}(\\ve{x}))(\\ve{x} - \\ve{x}_{0}) + \\ve{B}(\\ve{x}, \\ve{f}(\\ve{x}))(\\ve{f}(\\ve{x}) - \\ve{f}(\\ve{x}_{0})) \\\\ \\implies \\ve{B}(\\ve{x}, \\ve{f}(\\ve{x})) \\ve{f}(\\ve{x}) &= \\ve{B}(\\ve{x}, \\ve{f}(\\ve{x})) \\ve{f}(\\ve{x}_{0}) - \\ve{A}(\\ve{x}, \\ve{f}(\\ve{x}))(\\ve{x} - \\ve{x}_{0}) \\\\ \\implies \\ve{f}(\\ve{x}) &= \\ve{f}(\\ve{x}_{0}) - \\ve{B}(\\ve{x}, \\ve{f}(\\ve{x}))&#94;{-1} \\ve{A}(\\ve{x}, \\ve{f}(\\ve{x}))(\\ve{x} - \\ve{x}_{0}) \\quad (\\because \\parfrac{\\ve{F}}{\\ve{y}} \\text{は正則}) \\end{align*} 行列 \\(\\ve{B}(\\ve{x}, \\ve{f}(\\ve{x}))&#94;{-1} \\ve{A}(\\ve{x}, \\ve{f}(\\ve{x}))\\) は \\(\\ve{x}_{0}\\) において連続だから、 \\(\\ve{f}\\) は \\(\\ve{x}_{0}\\) において微分可能で、 \\begin{equation*} \\parfrac{\\ve{f}}{\\ve{x}}(\\ve{x}_{0}) = \\ve{B}(\\ve{x}_{0}, \\ve{f}(\\ve{x}_{0}))&#94;{-1} \\ve{A}(\\ve{x}_{0}, \\ve{f}(\\ve{x}_{0})) = -\\left[ \\parfrac{\\ve{F}}{\\ve{y}} (\\ve{x}_{0}, \\ve{y}_{0}) \\right]&#94;{-1} \\parfrac{\\ve{F}}{\\ve{x}} (\\ve{x}_{0}, \\ve{y}_{0}) \\tag{5} \\end{equation*} （2.の証明終） （3.の証明） \\(\\ve{F}\\) が \\(C&#94;{1}\\) 級ならば(5)式の右辺は \\((\\ve{x}_{0}, \\ve{y}_{0})\\) で連続だから、 \\(\\ve{y}_{0} = \\ve{f}(\\ve{x}_{0})\\) を代入したものも \\(\\ve{x}_{0}\\) で連続である。即ち、 \\(\\parfrac{\\ve{f}}{\\ve{x}}(\\ve{x})\\) は \\(U\\) で連続であり、 \\(\\ve{f}\\) は \\(C&#94;{1}\\) 級。（3.の証明終） （4.の証明） \\(\\ve{F}\\) が \\(C&#94;{m}\\) 級ならば、 \\(\\ve{f}\\) も \\(C&#94;{m}\\) 級であることを示す。 \\(m = 1\\) の場合は、3.により成立する。 \\(m-1\\) の場合に成立するとして、もし、 \\(\\ve{F}\\) が \\(C&#94;{m}\\) 級ならば、同時に \\(\\ve{F}\\) は \\(C&#94;{m-1}\\) 級だから、仮定より \\(\\ve{f}\\) も \\(C&#94;{m-1}\\) 級である。よって、 \\begin{equation*} \\parfrac{\\ve{f}}{\\ve{x}}(\\ve{x}) = \\ve{B}(\\ve{x}, \\ve{f}(\\ve{x}))&#94;{-1} \\ve{A}(\\ve{x}, \\ve{f}(\\ve{x})) = -\\left[ \\parfrac{\\ve{F}}{\\ve{y}} (\\ve{x}, \\ve{y}) \\right]&#94;{-1} \\parfrac{\\ve{F}}{\\ve{x}} (\\ve{x}, \\ve{y}) \\end{equation*} の右辺は \\(C&#94;{m-1}\\) 級の写像 \\(\\parfrac{\\ve{F}}{\\ve{y}},\\ \\parfrac{\\ve{F}}{\\ve{x}}\\) に \\(C&#94;{m-1}\\) 級の写像 \\(\\ve{f}\\) を代入したものだから、合成関数の微分法により、右辺は \\(C&#94;{m-1}\\) 級になる。 \\(\\parfrac{f}{x}(\\ve{x})\\) が \\(C&#94;{m-1}\\) 級だから、 \\(\\ve{f}(\\ve{x})\\) は \\(C&#94;{m}\\) 級。（4.の証明終） 陰関数定理の応用 逆写像定理 2変数を例に取って考える。 \\(\\mathbb{R}&#94;{2}\\) から \\(\\mathbb{R}&#94;{2}\\) への写像 \\begin{equation*} \\begin{cases} x = f(s, t) \\\\ y = g(s, t) \\end{cases} \\end{equation*} が与えられたとき、その逆写像が存在するかどうかを考える。今、 \\begin{equation*} \\begin{cases} F(x, y, s, t) = f(s, t) - x \\\\ G(x, y, s, t) = g(s, t) - y \\end{cases} \\end{equation*} とおくと、 \\begin{equation*} F(x, y, s, t) = G(x, y, s, t) = 0 \\end{equation*} から陰関数 \\(s = h(x, y),\\ t = k(x, y)\\) が決まるか？という問題に帰着できる。 この問題は陰関数定理より解決できる。すなわち、行列 \\begin{equation*} \\left[ \\begin{array}{cc} \\parfrac{F}{s} & \\parfrac{F}{t} \\\\ \\parfrac{G}{s} & \\parfrac{G}{t} \\end{array} \\right] \\end{equation*} がある点 \\((x_{0}, y_{0}, s_{0}, t_{0})\\) の近傍で連続かつ正則であればよい。また、 \\begin{equation*} \\parfrac{F}{s} = \\parfrac{f}{s},\\ \\parfrac{F}{t} = \\parfrac{f}{t},\\ \\parfrac{G}{s} = \\parfrac{g}{s},\\ \\parfrac{G}{t} = \\parfrac{g}{t} \\end{equation*} だから、上の条件は写像 \\((f(s, t), g(s, t))&#94;{\\mathsf{T}}\\) のヤコビ行列 \\begin{equation*} \\left[ \\begin{array}{cc} \\parfrac{f}{s} & \\parfrac{f}{t} \\\\ \\parfrac{g}{s} & \\parfrac{g}{t} \\end{array} \\right] \\end{equation*} が \\((s_{0}, t_{0})\\) の近傍で連続かつ正則であることを示している。 多変数の場合 上記の議論を一般の \\(n\\) 変数に拡張したのが次の 逆写像定理 である。 逆写像定理 \\(\\mathbb{R}&#94;{n}\\) の領域 \\(\\Omega\\) から \\(\\mathbb{R}&#94;{n}\\) への写像 \\(\\ve{y} = \\ve{f}(\\ve{x})\\) が \\(\\Omega\\) の1点 \\(\\ve{x}_{0}\\) の近傍で \\(C&#94;{1}\\) 級かつヤコビ行列 \\(\\parfrac{\\ve{f}}{\\ve{x}}(\\ve{x})\\) が正則ならば、逆写像 \\(\\ve{x} = \\ve{h}(\\ve{y})\\) が \\(\\ve{y}_{0} = \\ve{f}(\\ve{x}_{0})\\) の十分小さい近傍で存在し \\(C&#94;{1}\\) 級である。その導関数は、 \\begin{equation*} \\parfrac{\\ve{h}}{\\ve{y}}(\\ve{y}) = \\left[ \\parfrac{\\ve{f}}{\\ve{x}}(\\ve{h}(\\ve{y})) \\right]&#94;{-1} \\end{equation*} である。また、 \\(\\ve{f}\\) が \\(C&#94;{m}\\) 級ならば \\(\\ve{h}\\) も \\(C&#94;{m}\\) 級である。 （証明）陰関数定理を \\(\\ve{F}(\\ve{x}, \\ve{y}) = \\ve{f}(\\ve{x}) - \\ve{y}\\) に適用すれば良い。 \\(\\ve{F}(\\ve{x}, \\ve{y})\\) は連続で、 \\(\\parfrac{\\ve{F}}{\\ve{x}} = \\parfrac{\\ve{f}}{\\ve{x}}\\) は \\(\\ve{x}_{0}\\) の近傍で連続な正則関数だから、陰関数定理により \\(\\ve{y}_{0}\\) の近傍で \\(\\ve{x}_{0} = \\ve{h}(\\ve{y}_{0}),\\ \\ve{F}(\\ve{h}(\\ve{y}), \\ve{y}) = \\ve{0}\\) を満たす連続な写像 \\(\\ve{h}\\) が唯一存在する。 \\(\\ve{h}(\\ve{y})\\) の導関数は、 \\begin{align*} \\parfrac{\\ve{h}}{\\ve{y}}(\\ve{y}) &= - \\left[ \\parfrac{\\ve{F}}{\\ve{x}} (\\ve{x}, \\ve{y}) \\right]&#94;{-1} \\parfrac{\\ve{F}}{\\ve{y}}(\\ve{x}, \\ve{y}) \\\\ &= - \\left[ \\parfrac{\\ve{f}}{\\ve{x}} (\\ve{x}, \\ve{y}) \\right]&#94;{-1} (- \\ve{I}) \\\\ &= \\left[ \\parfrac{\\ve{f}}{\\ve{x}}(\\ve{h}(\\ve{y})) \\right]&#94;{-1} \\end{align*} また、 \\(\\ve{f}\\) が \\(C&#94;{m}\\) 級であれば、 \\(\\ve{F}\\) も \\(C&#94;{m}\\) 級であり、陰関数定理の4.より \\(\\ve{h}\\) も \\(C&#94;{m}\\) 級となる。（証明終） 制約付き極値問題 ラグランジュの未定乗数法 ラグランジュの未定乗数法も、勾配の図を用いた直感に頼るのではなく陰関数定理により説明が可能である。 やはり例として2変数 \\(x, y\\) で考える。 \\(\\mathbb{R}&#94;{2}\\) のある領域 \\(\\Omega\\) 上で、2つの2変数関数 \\(f(x, y),\\ g(x, y)\\) が与えたられたとき、 \\(g(x, y) = 0\\) という条件下で \\(f(x, y)\\) の極値を求めることを考える。 \\(g(x, y) = 0\\) と交わる \\(f(x, y) = a\\) の交点が極値をとるならば、その点で \\(f(x, y) = a\\) と \\(g(x, y) = 0\\) のグラフは接しなければならない。その様な点では、法線ベクトル \\(\\parfrac{f}{\\ve{x}}, \\parfrac{f}{\\ve{x}}\\) は同じ方向を向いているから、 \\begin{equation*} \\parfrac{f}{\\ve{x}} = \\lambda \\parfrac{f}{\\ve{x}} \\iff \\parfrac{f}{x} - \\lambda \\parfrac{g}{x} = 0,\\ \\parfrac{f}{y} - \\lambda \\parfrac{g}{y} = 0,\\ g(x, y) = 0 \\end{equation*} を満たす定数 \\(\\lambda\\) が存在する。この式は形式上、 \\begin{equation*} F(x, y, \\lambda) = f(x, y) - \\lambda g(x, y) \\end{equation*} の3変数関数の極値問題と同様の形をしている。より詳しい証明は以下。 ラグランジュの未定乗数法 領域 \\(\\Omega\\) 上で2つの関数 \\(f(x, y),\\ g(x, y)\\) は \\(C&#94;{1}\\) 級とし、曲線 \\(g(x, y) = 0\\) 上で \\(\\parfrac{g}{\\ve{x}} \\neq \\ve{0}\\) とする。 \\(g(x, y) = 0\\) 上の点 \\(\\ve{x}_{0} = (x_{0}, y_{0})\\) が条件付き極値問題における極値点ならば、ある定数 \\(\\lambda\\) が存在して、 \\begin{equation*} \\parfrac{f}{\\ve{x}}(\\ve{x}_{0}) = \\lambda \\parfrac{g}{\\ve{x}}(\\ve{x}_{0}) \\end{equation*} （証明） 仮定の \\(\\parfrac{g}{\\ve{x}} \\neq \\ve{0}\\) より \\(\\parfrac{g}{y}(\\ve{x}_{0}) \\neq 0\\) が成立している。 \\(g(x, y) = 0\\) を陰関数表示だと思うと、陰関数定理により、 \\(\\ve{x}_{0} = (x_{0}, y_{0})\\) の近傍において \\(y_{0} = \\varphi(x_{0}),\\ \\dfrac{\\varphi}{x}(x) = -g_{x}(x, \\varphi(x)) / g_{y}(x, \\varphi(x))\\) を満たす \\(C&#94;{1}\\) 級の関数 \\(y = \\varphi(x)\\) が存在する。 \\(z = f(x, \\varphi(x))\\) の導関数を考えると、 \\begin{align*} \\dfrac{z}{x} &= \\parfrac{f}{x} (x, \\varphi(x)) + \\parfrac{f}{y}(x, \\varphi(x)) \\dfrac{\\varphi}{x}(x) \\quad (\\because \\text{合成関数の微分}) \\\\ &= f_{x}(x, \\varphi(x)) + f_{y}(x, \\varphi(x)) \\left\\{ - \\frac{g_{x}(x, \\varphi(x))}{g_{y}(x, \\varphi(x))} \\right\\} \\\\ &= \\frac{1}{g_{y}} (f_{x} g_{y} - f_{y} g_{x}) \\end{align*} 点 \\(\\ve{x}_{0}\\) においてこれが \\(0\\) になるから、 \\(f_{x}g_{y} - f_{y}g_{x} = 0\\) 。従って \\(f_{x}/g_{x} = f_{y}/g_{y} = \\lambda\\) とおくと、 \\(f_{x} = \\lambda g_{x},\\ f_{y} = \\lambda g_{y}\\) が得られ、まとめると \\(\\parfrac{f}{\\ve{x}}(\\ve{x}_{0}) = \\lambda \\parfrac{g}{\\ve{x}}(\\ve{x}_{0})\\) が得られる。（証明終） 制約条件が \\(g_{i}(\\ve{x}) = 0\\ (i = 1, ..., m)\\) と増えた場合も同様に考えられる。 ラグランジュの未定乗数法（複数制約） \\(\\mathbb{R}&#94;{n}\\) の領域 \\(\\Omega\\) 上で \\(C&#94;{1}\\) 級の関数 \\(f(\\ve{x}),\\ g_{i}(\\ve{x})\\ (i = 1, ..., m)\\) が与えられ、 \\(n-m\\) 次元曲面 \\(S = \\{ \\ve{x} | g_{i}(\\ve{x}) = 0, \\ i = 1,...,m \\}\\) 上で行列 \\(\\parfrac{\\ve{g}}{\\ve{x}} = \\left( \\parfrac{g_{i}}{x_{j}} \\right)\\) の階数（行列ランク）は常に \\(m\\) であるとする。 \\(S\\) 上の点 \\(\\ve{x}_{0}\\) が \\(f(\\ve{x})\\) の \\(S\\) の極値点ならば、 \\(m\\) 個の定数 \\(\\lambda_{1}, ..., \\lambda_{m}\\) があって、 \\begin{equation*} \\parfrac{f}{\\ve{x}}(\\ve{x}_{0}) = \\sum_{i = 1}&#94;{m} \\lambda_{i} \\parfrac{g_{i}}{\\ve{x}}(\\ve{x}_{0}) \\end{equation*} （証明） \\(\\parfrac{\\ve{g}}{\\ve{x}}\\) の階数は \\(m\\) だから、 \\(\\ve{x}&#94;{\\prime} = [x_{1}, ..., x_{n - m}],\\ \\ve{x}&#94;{\\prime\\prime} = [x_{n - m + 1}, ..., x_{n}]\\) として、 \\begin{equation*} \\parfrac{\\ve{g}}{\\ve{x}&#94;{\\prime\\prime}} = \\left[ \\begin{array}{cccc} \\parfrac{g_{1}}{x_{n-m+1}} & \\parfrac{g_{1}}{x_{n-m+2}} & \\dots & \\parfrac{g_{1}}{x_{n}} \\\\ \\parfrac{g_{2}}{x_{n-m+1}} & \\parfrac{g_{2}}{x_{n-m+2}} & \\dots & \\parfrac{g_{2}}{x_{n}} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\parfrac{g_{m}}{x_{n-m+1}} & \\parfrac{g_{m}}{x_{n-m+2}} & \\dots & \\parfrac{g_{m}}{x_{n}} \\\\ \\end{array} \\right] \\end{equation*} は正則であると仮定して良い（正則になるように \\(\\ve{x}&#94;{\\prime\\prime}\\) を選べば良い）。 \\(\\ve{g}(\\ve{x}) = \\ve{0}\\) を陰関数表示と見ると、陰関数定理により \\(x_{n-m+1} = \\varphi_{1}(\\ve{x}&#94;{\\prime}), ..., x_{n} = \\varphi_{m}(\\ve{x}&#94;{\\prime})\\) 、即ち \\(\\ve{x}&#94;{\\prime\\prime} = \\ve{\\varphi}(\\ve{x}&#94;{\\prime})\\) を満たす \\(C&#94;{1}\\) 級の写像 \\(\\ve{\\varphi} = [\\varphi_{1}, ..., \\varphi_{m}]\\) が存在し、また、 \\(\\parfrac{\\ve{\\varphi}}{\\ve{x}&#94;{\\prime}} = -\\left(\\parfrac{\\ve{g}}{\\ve{x}&#94;{\\prime\\prime}}\\right)&#94;{-1}\\left(\\parfrac{\\ve{g}}{\\ve{x}&#94;{\\prime}}\\right)\\) が成り立つ。 \\(\\ve{\\varphi}\\) を \\(y = f(\\ve{x}) = f(\\ve{x}&#94;{\\prime}, \\ve{x}&#94;{\\prime\\prime})\\) に代入すると、 \\begin{equation*} y = F(\\ve{x}&#94;{\\prime}) = f(\\ve{x}&#94;{\\prime}, \\ve{\\varphi}(\\ve{x}&#94;{\\prime})) \\end{equation*} が得られる。上記 \\(y\\) についての極値問題を考える。 \\(\\ve{x}_{0}\\) において、 \\begin{align*} \\parfrac{F}{\\ve{x}&#94;{\\prime}} &= \\parfrac{f}{\\ve{x}&#94;{\\prime}} + \\parfrac{f}{\\ve{x}&#94;{\\prime\\prime}} \\parfrac{\\ve{\\varphi}}{\\ve{x}&#94;{\\prime}} \\quad (\\because \\text{連鎖律}) \\\\ &= \\parfrac{f}{\\ve{x}&#94;{\\prime}} - \\parfrac{f}{\\ve{x}&#94;{\\prime\\prime}} \\left(\\parfrac{\\ve{g}}{\\ve{x}&#94;{\\prime\\prime}}\\right)&#94;{-1} \\parfrac{\\ve{g}}{\\ve{x}&#94;{\\prime}} = \\ve{0} \\end{align*} が極値となるための必要条件だから、今、 \\begin{equation*} [\\lambda_{1}, ..., \\lambda_{m}] = \\parfrac{f}{\\ve{x}&#94;{\\prime\\prime}} \\left(\\parfrac{\\ve{g}}{\\ve{x}&#94;{\\prime\\prime}}\\right)&#94;{-1} \\end{equation*} とおけば、 \\begin{equation*} \\parfrac{f}{\\ve{x}&#94;{\\prime\\prime}}(\\ve{x}_{0}) = [\\lambda_{1}, ..., \\lambda_{m}] \\parfrac{\\ve{g}}{\\ve{x}&#94;{\\prime\\prime}}(\\ve{x}_{0}),\\ \\parfrac{f}{\\ve{x}&#94;{\\prime}}(\\ve{x}_{0}) = [\\lambda_{1}, ..., \\lambda_{m}] \\parfrac{\\ve{g}}{\\ve{x}&#94;{\\prime}}(\\ve{x}_{0}) \\end{equation*} が成立しているから、まとめると、 \\begin{equation*} \\parfrac{f}{\\ve{x}}(\\ve{x}_{0}) = [\\lambda_{1}, ..., \\lambda_{m}] \\parfrac{\\ve{g}}{\\ve{x}}(\\ve{x}_{0}) = \\sum_{i = 1}&#94;{m} \\lambda_{i} \\parfrac{g_{i}}{\\ve{x}}(\\ve{x}_{0}) \\end{equation*} が得られる。（証明終） KKT条件 不等式制約 \\(g(x, y) \\geq 0\\) の条件下で \\(f(x, y)\\) の極値を見つける問題を考える。 簡単な例: \\(g(x, y) = y \\geq 0\\) \\(y \\geq 0\\) の領域の内部であれば、極大点の候補は \\(\\parfrac{f}{x} = \\parfrac{f}{y} = 0\\) で求められる。一方、境界上（ \\(y = 0\\) ）では、 \\begin{equation*} \\parfrac{f}{x}(x_{0}, 0) = 0,\\ \\parfrac{f}{y}(x_{0}, 0) \\leq 0 \\end{equation*} を満たす \\(x_{0}\\) が候補となる（ \\(\\parfrac{f}{y}(x_{0}, 0) > 0\\) とすると、それは \\(y\\) を正方向に増やしたときに \\(f\\) が更に増加することを意味するから、その点は極大点ではない）。これらの条件をまとめると、極点 \\((x_{0}, y_{0})\\) は次の条件を満たす必要がある。 \\begin{equation*} \\parfrac{f}{x}(x_{0}, y_{0}) = 0,\\ \\parfrac{f}{y}(x_{0}, y_{0}) \\leq 0,\\ y_{0} \\parfrac{f}{y}(x_{0}, y_{0}) = 0 \\end{equation*} 最後の条件は、 \\(y_{0} = 0\\) あるいは \\(\\parfrac{f}{y}(x_{0}, y_{0}) = 0\\) を要請している。 次に一般の条件式 \\(g(x, y) \\leq 0\\) を考える。今、新しい変数 \\(z\\) として \\begin{equation*} g(x, y) = z,\\ z \\geq 0 \\end{equation*} をおけば、元の問題を \\(z \\geq 0\\) における等式制約の条件付き極値問題に変換できる。よって、ラグランジュの未定乗数法により、 \\begin{equation*} F(x, y, z, \\lambda) = f(x, y) - \\lambda (g(x, y) - z) \\end{equation*} の \\(z \\geq 0\\) における極値を求めれば良い。これは、簡単な例の観察を元に、 \\begin{equation*} \\parfrac{F}{x} = 0,\\ \\parfrac{F}{y} = 0,\\ \\parfrac{F}{\\lambda} = 0,\\ \\parfrac{F}{z} \\leq 0,\\ z\\parfrac{F}{z} = 0,\\ z \\geq 0 \\end{equation*} を満たす \\((x, y, z, \\lambda)\\) を求める問題になる。偏微分を行うと、 \\begin{equation*} \\parfrac{f}{x} = \\lambda \\parfrac{g}{x},\\ \\parfrac{f}{y} = \\lambda \\parfrac{g}{y},\\ g(x, y) = z,\\ \\lambda \\leq 0,\\ \\lambda z = 0,\\ z \\geq 0 \\end{equation*} となり、後ろの4条件をまとめると、以下の条件が得られる。 \\begin{equation*} \\parfrac{f}{x} = \\lambda \\parfrac{g}{x},\\ \\parfrac{f}{y} = \\lambda \\parfrac{g}{y},\\ g(x, y) \\geq 0,\\ \\lambda \\leq 0,\\ \\lambda g(x, y) = 0 \\end{equation*} とまとめられる。極小値を求める場合は、 \\(-f(x, y)\\) の極大値を求めれば良い。この場合の条件は、 \\begin{equation*} \\parfrac{f}{x} = -\\lambda \\parfrac{g}{x},\\ \\parfrac{f}{y} = -\\lambda \\parfrac{g}{y},\\ g(x, y) = z,\\ \\lambda \\leq 0,\\ \\lambda z = 0,\\ z \\geq 0 \\end{equation*} となり、 \\(-\\lambda\\) を \\(\\lambda\\) に置き換えることで必要条件が得られる。 \\begin{equation*} \\parfrac{f}{x} = \\lambda \\parfrac{g}{x},\\ \\parfrac{f}{y} = \\lambda \\parfrac{g}{y},\\ g(x, y) \\geq 0,\\ \\lambda \\geq 0,\\ \\lambda g(x, y) = 0 \\end{equation*} 制約条件が増えても同様に考えれば良いから、次の定理が成立する。これを一般にKKT条件（Karush-Kuhn-Tucker condition）と呼ぶ。 KKT条件 \\(f(\\ve{x}), g_{i}(\\ve{x})\\ (i = 1, ..., m)\\) は \\(C&#94;{1}\\) 級とする。 \\(g_{i}(\\ve{x}) \\geq 0\\ (i = 1,...,m)\\) という条件の下で、 \\(f(\\ve{x})\\) の極大点 \\(\\ve{x}_{0}\\) は次の条件を満たさなければならない: ある定数 \\(\\lambda_{1}, ..., \\lambda_{m}\\) があって、 \\(\\ve{x}_{0}\\) において \\begin{equation*} \\begin{cases} \\displaystyle \\parfrac{f}{\\ve{x}}(\\ve{x}_{0}) = \\sum_{i = 1}&#94;{m} \\lambda_{i} \\parfrac{g_{i}}{\\ve{x}}(\\ve{x}_{0}) \\\\ \\lambda_{i} g_{i}(\\ve{x}_{0}) = 0,\\ g_{i}(\\ve{x}_{0}) \\geq 0,\\ \\lambda_{i} \\leq 0 \\quad (i = 1, ..., m) \\end{cases} \\end{equation*} （証明）変数 \\(z_{i}\\ (i = 1, ..., m)\\) を用いて \\begin{equation*} g_{i}(\\ve{x}) = z_{i},\\ z_{i} \\geq 0 \\quad (i = 1,...,m) \\end{equation*} とおく。定数を \\(\\lambda_{1}, ..., \\lambda_{m}\\) としてラグランジュの未定乗数法を適用すると、 \\begin{equation*} F(\\ve{x}, \\ve{z}, \\ve{\\lambda}) = f(\\ve{x}) - \\sum_{i = 1}&#94;{m} \\lambda_{i} \\left\\{ g_{i}(\\ve{x}) - z_{i} \\right\\} \\end{equation*} であり、極値条件は、 \\begin{equation*} \\left\\{ \\begin{array}{ll} \\displaystyle \\parfrac{F}{\\ve{x}}(\\ve{x}_{0}, \\ve{z}, \\ve{\\lambda}) = \\parfrac{f}{\\ve{x}}(\\ve{x}_{0}) - \\sum_{i = 1}&#94;{m} \\lambda_{i} \\parfrac{g_{i}}{\\ve{x}}(\\ve{x}_{0}) = \\ve{0} & \\\\ \\displaystyle \\parfrac{F}{z_{i}}(\\ve{x}_{0}, \\ve{z}, \\ve{\\lambda}) = \\lambda_{i} \\leq 0 & (i = 1,...,m) \\\\ \\displaystyle \\parfrac{F}{\\lambda_{i}}(\\ve{x}_{0}, \\ve{z}, \\ve{\\lambda}) = -g_{i}(\\ve{x}_{0}) + z_{i} = 0 & (i = 1,...,m) \\\\ \\displaystyle z_{i} \\parfrac{F}{z_{i}}(\\ve{x}_{0}, \\ve{z}, \\ve{\\lambda}) = z_{i}\\lambda_{i} = 0 & (i = 1,...,m) \\\\ z_{i} \\geq 0 & (i = 1,...,m) \\end{array} \\right. \\end{equation*} \\(z_{i} = g_{i}(\\ve{x})\\) を元に条件をまとめ直すと、 \\begin{equation*} \\begin{cases} \\displaystyle \\parfrac{f}{\\ve{x}}(\\ve{x}_{0}) = \\sum_{i = 1}&#94;{m} \\lambda_{i} \\parfrac{g_{i}}{\\ve{x}}(\\ve{x}_{0}) \\\\ \\lambda_{i} g_{i}(\\ve{x}_{0}) = 0,\\ g_{i}(\\ve{x}_{0}) \\geq 0,\\ \\lambda_{i} \\leq 0 \\quad (i = 1, ..., m) \\end{cases} \\end{equation*} （証明終）","tags":"記事","url":"/yin-guan-shu-ding-li-tosonoying-yong.html","loc":"/yin-guan-shu-ding-li-tosonoying-yong.html"},{"title":"逆写像定理までの整理","text":"評価を待つ間逆写像定理までを写経中。だいたい飲み込めてるが、やっぱ基礎の抜けがある…。 陰関数定理はだいたいOK。ついでにラグランジュ未定乗数法の厳密な証明を与えたい。（いままでなんとなくで済ませていたので止めを刺す。）","tags":"雑記","url":"/ni-xie-xiang-ding-li-madenozheng-li.html","loc":"/ni-xie-xiang-ding-li-madenozheng-li.html"},{"title":"正則化(8)","text":"\\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\newcommand\\mean[2]{\\mathrm{E}_{#1} \\left[ #2 \\right]} \\newcommand\\KL[2]{\\mathrm{KL} \\left[ #1 \\ \\middle| \\middle| \\ #2 \\right]} \\end{equation*} 前日思い立った内容って既に試していて、だめなところまで見えてた。すなわち直接 \\(\\mathrm{E}[(\\ve{x} + \\ve{a})(\\ve{x} + \\ve{a})&#94;{\\mathsf{T}}]\\) を計算する方針は試行済み。 色々探しているうちに、K-FACという自然勾配学習法の近似手法を見つける。クロネッカ積を使ってフィッシャー情報行列を分解しようというアイデアだ。 K-FACとは？ 大規模深層学習のための二次最適化の実現 これはすごい。少し前にクロネッカ積で計算できるんじゃないの？とは指摘もらってたけど、普通にメジャーな手法だ。 自然勾配近似法を起点としたバッチ正規化の数理的理解 に近似手法が挙げられている。 THREE MECHANISMS OF WEIGHT DECAY REGULARIZATION でWeight Decayの文脈でL2正則化学習則が示されている。 Preconditioned Stochastic Gradient Descent Precondition行列で勾配を更新する方法。ちょっと待て、自然勾配とちょっと違う。 Adaptive Natural Gradient Method for Learning of Stochastic Neural Networks in Mini-Batch Mode ではMatrix cookbookの(191)を使って行列に対する正則化を行っている。 \\((\\ve{Q} + \\sigma&#94;{2}\\ve{M})&#94;{-1} \\approx \\ve{Q}&#94;{-1} - \\sigma&#94;{2}\\ve{Q}&#94;{-1}\\ve{M}\\ve{Q}&#94;{-1}\\ (\\sigma\\text{ is small})\\) という近似。 逆写像定理までをおべんきょ中。まだ陰関数定理の途中。","tags":"雑記","url":"/zheng-ze-hua-8.html","loc":"/zheng-ze-hua-8.html"},{"title":"正則化(7)","text":"\\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\newcommand\\mean[2]{\\mathrm{E}_{#1} \\left[ #2 \\right]} \\newcommand\\KL[2]{\\mathrm{KL} \\left[ #1 \\ \\middle| \\middle| \\ #2 \\right]} \\end{equation*} Matrix cookbook を眺めていたら有益そうな等式を見つける。 \\(E[\\ve{x}] = \\ve{m}\\) として、 \\begin{align*} \\mathrm{E}[(\\ve{x} + \\ve{a})(\\ve{x} + \\ve{a})&#94;{\\mathsf{T}}] &= \\mathrm{E}[\\ve{x}\\ve{x}&#94;{\\mathsf{T}} + \\ve{x}\\ve{a}&#94;{\\mathsf{T}} + \\ve{a}\\ve{x}&#94;{\\mathsf{T}} + \\ve{a}\\ve{a}&#94;{\\mathsf{T}}] \\\\ &= \\mathrm{E}[\\ve{x}\\ve{x}&#94;{\\mathsf{T}} - \\ve{x}\\ve{m}&#94;{\\mathsf{T}} - \\ve{m}\\ve{x}&#94;{\\mathsf{T}} + \\ve{m}\\ve{m}&#94;{\\mathsf{T}} + \\ve{x}\\ve{m}&#94;{\\mathsf{T}} + \\ve{m}\\ve{x}&#94;{\\mathsf{T}} - \\ve{m}\\ve{m}&#94;{\\mathsf{T}} + \\ve{x}\\ve{a}&#94;{\\mathsf{T}} + \\ve{a}\\ve{x}&#94;{\\mathsf{T}} + \\ve{a}\\ve{a}&#94;{\\mathsf{T}}] \\\\ &= \\mathrm{E}[\\ve{x}\\ve{x}&#94;{\\mathsf{T}} - \\ve{x}\\ve{m}&#94;{\\mathsf{T}} - \\ve{m}\\ve{x}&#94;{\\mathsf{T}} + \\ve{m}\\ve{m}&#94;{\\mathsf{T}}] + \\ve{m}\\ve{m}&#94;{\\mathsf{T}} + \\ve{m}\\ve{m}&#94;{\\mathsf{T}} - \\ve{m}\\ve{m}&#94;{\\mathsf{T}} + \\ve{m}\\ve{a}&#94;{\\mathsf{T}} + \\ve{a}\\ve{m}&#94;{\\mathsf{T}} + \\ve{a}\\ve{a}&#94;{\\mathsf{T}} \\\\ &= \\mathrm{E}[(\\ve{x} - \\ve{m})(\\ve{x} - \\ve{m})&#94;{\\mathsf{T}}] + \\ve{m}\\ve{m}&#94;{\\mathsf{T}} + \\ve{m}\\ve{a}&#94;{\\mathsf{T}} + \\ve{a}\\ve{m}&#94;{\\mathsf{T}} + \\ve{a}\\ve{a}&#94;{\\mathsf{T}} \\\\ &= \\mathrm{E}[(\\ve{x} - \\ve{m})(\\ve{x} - \\ve{m})&#94;{\\mathsf{T}}] + (\\ve{m} + \\ve{a})(\\ve{m} + \\ve{a})&#94;{\\mathsf{T}} \\\\ &= \\mathrm{E}[\\ve{x}\\ve{x}&#94;{\\mathsf{T}}] - \\ve{m}\\ve{m}&#94;{\\mathsf{T}} + (\\ve{m} + \\ve{a})(\\ve{m} + \\ve{a})&#94;{\\mathsf{T}} \\end{align*} が成立する。 \\(\\ve{a}\\) を正則化で出てくるベクトルとすると、割と有益に見える。しかも \\(\\ve{m} = \\ve{0}\\) とできるならばもっとさっぱりする。 早速手元のデータで \\(\\ve{m} = \\ve{0}\\) とならないか、つまり、勾配 \\(\\mathrm{sign}[\\varepsilon(n)]\\ve{x}(n)\\) の平均が \\(\\ve{0}\\) にならないか観察したけど、成り立っていなそう。。。長時間平均をとっても収束している感じはしない。（自然勾配は、当然 \\(\\ve{0}\\) に漸近する傾向あり。学習が進んでいるから当然。） 平均 \\(\\ve{m}\\) を逐次推定すれば良さそうで、試してみたい。しかし今は情報幾何もやるのだ。明日やる。","tags":"雑記","url":"/zheng-ze-hua-7.html","loc":"/zheng-ze-hua-7.html"},{"title":"正則化(6)","text":"残った課題をやってたら土日が飛ぶ。ついでにカサゴ本を読み切る。 6月からは英語のおべんきょうをしようかと思っている。同時に情報幾何も進める。 早いところ進捗を見てもらいたいが、まだ無理っぽい。。。 テンソル テンソルの定義。分かりやすい説明。","tags":"雑記","url":"/zheng-ze-hua-6.html","loc":"/zheng-ze-hua-6.html"},{"title":"正則化(5)","text":"課題やってたら木金が飛んだ。。。 古い資料を漁ってたら、SPSA（Simultaneous perturbation stochastic approximation）が掘り返された。たしかシステム同定で使ったよな。なんか面白いかも知んない。","tags":"雑記","url":"/zheng-ze-hua-5.html","loc":"/zheng-ze-hua-5.html"},{"title":"正則化(4)","text":"\\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\newcommand\\mean[2]{\\mathrm{E}_{#1} \\left[ #2 \\right]} \\newcommand\\KL[2]{\\mathrm{KL} \\left[ #1 \\ \\middle| \\middle| \\ #2 \\right]} \\end{equation*} 引き続きMAP推定における自然勾配を調査する。 Noisy Natural Gradient as Variational Inference の式(5)からスタートするも…はっきりしたことを言ってないように見える。 Adaptive natural gradient learning algorithms for various stochastic models これの式(5)も参考になりそう。 Natural Gradients in Practice: Non-Conjugate Variational Inference in Gaussian Process Models 指数族の事後確率最大化を考える。フィッシャー情報行列を計算するための平均のとり方が妙。もうちょっと読みたい。","tags":"雑記","url":"/zheng-ze-hua-4.html","loc":"/zheng-ze-hua-4.html"},{"title":"正則化(3)","text":"実装の整理できて、正則化込で動かしているけど芳しくない。 正則化入れたらRMSが悪化。しかも、正則化係数を十分小さく取らないと誤差が大きくなる。 タップ数が多い場合は多少の効果あり。 タップ数が少ない（〜16個）のときは旨味が無いように思える。係数がスパースじゃないのでは。 試しに128個とかにしたら少しの改善が見られた。けど適応が遅くて正則化なしでもRMSが悪い。 フィッシャー情報行列固定で、勾配だけ正則化かける方は発散していく。 ついでにLMSでも自然勾配法試してみたけど、SignedLMSの自然勾配よりもRMSが悪い。 もう一度適応的自然勾配学習法を試したけど、十分に係数を小さく取らないと発散するし、小さくとっても性能が悪い。フィッシャー情報行列はちゃんと更新するべし。 なんで正則化したら性能落ちるのか？をもっと考えていたら、パラメータの事前分布を入れた瞬間に計量がさらに歪んでいそう（単純な残差の分散ではダメそう）。 Noisy Natural Gradient as Variational Inference の式(5)。 Robust Estimation of Natural Gradient in Optimization by Regularized Linear Regression 線形回帰における正則化に触れている。 Rprop Using the Natural Gradient パラメータの正則化ではない。フィッシャー情報行列に正則化パラメータを乗じた単位行列を足して逆行列を求めている。なんでも、正則化パラメータが大きければ普通の勾配法に近づくとのこと。そのとおりだが、一体どういう発想なんだろう。 Online Natural Gradient as a Kalman Filter ドンピシャであった（Proposition 4）けどだいぶ複雑。しかも、自然勾配法とカルマンフィルタの関係性を示している。カルマンフィルタのノイズの事前分布を取り入れている。 あがいてたら適応的自然勾配の近似計算があった。計算負荷削減に有益そう。 Topmoumoute online natural gradient algorithm","tags":"雑記","url":"/zheng-ze-hua-3.html","loc":"/zheng-ze-hua-3.html"},{"title":"正則化(2)","text":"\\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\newcommand\\mean[2]{\\mathrm{E}_{#1} \\left[ #2 \\right]} \\newcommand\\KL[2]{\\mathrm{KL} \\left[ #1 \\ \\middle| \\middle| \\ #2 \\right]} \\end{equation*} まだ悩んでいる。今は \\(\\ve{R}&#94;{-1}\\) を直接計算してるので、正則化込みの結果（ \\((\\ve{R} + \\lambda\\ve{I})&#94;{-1}\\) ）になっていない。この式を近似でもいいから計算できないか？ なんかうまくいきそうなんだけど、定式化にあたって一つ疑問が： 自然勾配って一般の損失関数にも使えるのか？ 対数尤度を損失関数に使った場合は、無論自然勾配になるけど、一般の損失関数の場合、フィッシャー情報行列と損失関数の勾配が噛み合わない気がする。 Fisher Information and Natural Gradient Learning of Random Deep Networks 甘利先生の論文だけど一般の損失に適用しているように見える Why Natural Gradient? →大丈夫っぽい。ちゃんと読もう。 簡単な例（極座標系）で示している。普通の勾配はユークリッド空間上になるけど、極座標の逆行列を乗じて自然勾配を得ている。 とは言っても目的関数の構造を適切に表していないと、性能が悪そうに見える。対数尤度以外でどういうときに有効なんだ？ 試してみるしかない？つまり、勾配分散を毎回求める必要があるのか、それとも、一つの計量を複数の損失関数で使い回せるかやってみる。 もう少し考えた。やっぱり正則化項を入れると損失関数の勾配は歪んでくると思う。だから、正則化項も含めてフィッシャー情報行列を計算しなければいかんと思う。ていうか、もはやフィッシャー情報行列は勾配の分散でしか無いように見えてきた。やり方としては、パラメータの事前分布にガウスorラプラス分布を入れて、そいつの対数尤度をとって最適化問題を考える。フィッシャー情報行列の式変形が難しくなるけど、そんなことは無視して（考察の余地はあるけど）逆行列補題でストレートにフィッシャー情報行列の逆行列を計算できる。 ようはMAP推定。 \\(\\max p(\\ve{x} | \\ve{\\theta}) p(\\ve{\\theta})\\) で、 \\(p(\\ve{x} | \\ve{\\theta})\\) は誤差分布、 \\(p(\\ve{\\theta})\\) はパラメータ事前分布。 \\(p(\\ve{\\theta}) = \\exp(-\\beta ||\\ve{\\theta}||_{2}), \\exp(-\\beta ||\\ve{\\theta}||_{1})\\) なり何でもあり。対数とって勾配の分散をとればフィッシャー情報行列が求まる。 試すこともできると思うのでやってみたい。","tags":"雑記","url":"/zheng-ze-hua-2.html","loc":"/zheng-ze-hua-2.html"},{"title":"正則化(1)","text":"\\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\newcommand\\mean[2]{\\mathrm{E}_{#1} \\left[ #2 \\right]} \\newcommand\\KL[2]{\\mathrm{KL} \\left[ #1 \\ \\middle| \\middle| \\ #2 \\right]} \\end{equation*} 逆行列補題を使えば、どんな自然勾配法でも上手く動きそうな気がしてきた…。 勾配の分散行列を逐次的に求められるから相当強い。 自己相関行列であることはそんなに重要でもないかも。。。。でも評価待ちましょう。。。 一方で今日から正則化をどうすればいいか考えている。答えはフィッシャー情報行列に \\(\\lambda \\ve{I}\\) を足すだけなんだが、意味づけというか解釈が上手くできない。どういう損失関数ならばフィッシャー情報行列に単位行列を足す形になるのか。。。 SignedLMSで試したけど難航中。どうしても \\(\\mathrm{sign}[\\varepsilon(n)]\\ve{x}(n)\\) との積をとる項が出てきて、その平均がどうなるかわからない。。。 実験的に勾配に係数ベクトルを足すなり係数の符号ベクトルを足すなりしてるけど、 正則化パラメータをめちゃくちゃ小さく取らないと結果が発散する…。","tags":"雑記","url":"/zheng-ze-hua-1.html","loc":"/zheng-ze-hua-1.html"},{"title":"自然勾配法の概観","text":"\\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\newcommand\\mean[2]{\\mathrm{E}_{#1} \\left[ #2 \\right]} \\newcommand\\KL[2]{\\mathrm{KL} \\left[ #1 \\ \\middle| \\middle| \\ #2 \\right]} \\end{equation*} 自然勾配法の概略。だいたい Fisher Information Matrix と Natural Gradient Descent から持ってきている。 パラメタベクトル \\(\\ve{\\theta}\\) を持つ確率密度関数 \\(p(\\ve{x}|\\ve{\\theta})\\) を考える。対数尤度関数 \\(\\log p(\\ve{x}|\\ve{\\theta})\\) の \\(\\ve{\\theta}\\) におけるへッシアン \\(\\ve{H}_{\\ve{\\theta}}\\) は、 \\begin{align*} \\ve{H}_{\\ve{\\theta}} \\log p(\\ve{x} | \\ve{\\theta}) &= \\left(\\parfrac{}{\\ve{\\theta}} \\right) \\left(\\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} \\log p(\\ve{x} | \\ve{\\theta}) \\\\ &= \\left(\\parfrac{}{\\ve{\\theta}} \\right) \\frac{\\left(\\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} p(\\ve{x} | \\ve{\\theta})}{p(\\ve{x} | \\ve{\\theta})} \\\\ &= \\frac{\\left\\{ \\left(\\parfrac{}{\\ve{\\theta}} \\right) \\left(\\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} p(\\ve{x} | \\ve{\\theta}) \\right\\} p(\\ve{x} | \\ve{\\theta}) - \\left(\\parfrac{}{\\ve{\\theta}} \\right) p(\\ve{x} | \\ve{\\theta}) \\left(\\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} p(\\ve{x} | \\ve{\\theta}) }{p(\\ve{x} | \\ve{\\theta})&#94;{2}} \\\\ &= \\frac{\\ve{H}_{\\ve{\\theta}} p(\\ve{x} | \\ve{\\theta})}{p(\\ve{x} | \\ve{\\theta})} - \\left\\{ \\frac{\\left(\\parfrac{}{\\ve{\\theta}} \\right) p(\\ve{x} | \\ve{\\theta})}{p(\\ve{x} | \\ve{\\theta})} \\right\\} \\left\\{ \\frac{\\left(\\parfrac{}{\\ve{\\theta}} \\right) p(\\ve{x} | \\ve{\\theta})}{p(\\ve{x} | \\ve{\\theta})} \\right\\}&#94;{\\mathsf{T}} \\\\ &= \\frac{\\ve{H}_{\\ve{\\theta}} p(\\ve{x} | \\ve{\\theta})}{p(\\ve{x} | \\ve{\\theta})} - \\left( \\parfrac{}{\\ve{\\theta}} \\log p(\\ve{x} | \\ve{\\theta}) \\right) \\left( \\parfrac{}{\\ve{\\theta}} \\log p(\\ve{x} | \\ve{\\theta}) \\right)&#94;{\\mathsf{T}} \\end{align*} 両辺分布 \\(p(\\ve{x}|\\ve{\\theta})\\) について平均をとる。このとき右辺第二項はスコア関数の分散になりフィッシャー情報行列 \\(\\ve{F}\\) そのものになることに注意すると、 \\begin{align*} \\mean{p(\\ve{x}|\\ve{\\theta})}{\\ve{H}_{\\ve{\\theta}} \\log p(\\ve{x} | \\ve{\\theta})} &= \\mean{p(\\ve{x}|\\ve{\\theta})}{\\frac{\\ve{H}_{\\ve{\\theta}} p(\\ve{x} | \\ve{\\theta})}{p(\\ve{x} | \\ve{\\theta})}} - \\mean{p(\\ve{x}|\\ve{\\theta})}{\\left( \\parfrac{}{\\ve{\\theta}} \\log p(\\ve{x} | \\ve{\\theta}) \\right) \\left( \\parfrac{}{\\ve{\\theta}} \\log p(\\ve{x} | \\ve{\\theta}) \\right)&#94;{\\mathsf{T}}} \\\\ &= \\mean{p(\\ve{x}|\\ve{\\theta})}{\\frac{\\ve{H}_{\\ve{\\theta}} p(\\ve{x} | \\ve{\\theta})}{p(\\ve{x} | \\ve{\\theta})}} - \\ve{F} \\\\ &= \\int p(\\ve{x}|\\ve{\\theta}) \\frac{\\ve{H}_{\\ve{\\theta}} p(\\ve{x} | \\ve{\\theta})}{p(\\ve{x} | \\ve{\\theta})} \\mathrm{d}\\ve{x} - \\ve{F} = \\int \\ve{H}_{\\ve{\\theta}} p(\\ve{x} | \\ve{\\theta}) \\mathrm{d}\\ve{x} - \\ve{F} \\\\ &= \\ve{H}_{\\ve{\\theta}} \\int p(\\ve{x} | \\ve{\\theta}) \\mathrm{d}\\ve{x} - \\ve{F} \\quad(\\because \\text{微分と積分の入れ替えを可能（正則条件）とする}) \\\\ &= \\ve{H}_{\\ve{\\theta}} 1 - \\ve{F} \\\\ &= - \\ve{F} \\end{align*} 従って、 対数尤度関数のへッシアンの平均に負号をつけるとフィッシャー情報行列に一致する。 つぎに、異なるパラメタ \\(\\ve{\\theta}, \\ve{\\theta}&#94;{\\prime}\\) をもつ確率分布 \\(p(\\ve{x}|\\ve{\\theta}), p(\\ve{x}|\\ve{\\theta}&#94;{\\prime})\\) 間の違いを測るダイバージェンスとしてKLダイバージェンスを使ったとき、 \\begin{align*} \\KL{p(\\ve{x}|\\ve{\\theta})}{p(\\ve{x}|\\ve{\\theta}&#94;{\\prime})} &= \\int p(\\ve{x}|\\ve{\\theta}) \\log \\left( \\frac{p(\\ve{x}|\\ve{\\theta})}{p(\\ve{x}|\\ve{\\theta}&#94;{\\prime})} \\right) \\mathrm{d}\\ve{x} \\\\ &= \\mean{p(\\ve{x}|\\ve{\\theta})}{\\log p(\\ve{x}|\\ve{\\theta})} - \\mean{p(\\ve{x}|\\ve{\\theta})}{\\log p(\\ve{x}|\\ve{\\theta}&#94;{\\prime})} \\end{align*} となる。 \\(\\ve{\\theta}\\) を固定し、パラメタ \\(\\ve{\\theta}&#94;{\\prime}\\) に関するへッシアン \\(\\ve{H}_{\\ve{\\theta}&#94;{\\prime}}\\) を求めると、 \\begin{align*} \\ve{H}_{\\ve{\\theta}&#94;{\\prime}} \\KL{p(\\ve{x}|\\ve{\\theta})}{p(\\ve{x}|\\ve{\\theta}&#94;{\\prime})} &= \\left( \\parfrac{}{\\ve{\\theta}&#94;{\\prime}} \\right) \\left( \\parfrac{}{\\ve{\\theta}&#94;{\\prime}} \\right)&#94;{\\mathsf{T}} \\KL{p(\\ve{x}|\\ve{\\theta})}{p(\\ve{x}|\\ve{\\theta}&#94;{\\prime})} \\\\ &= \\left( \\parfrac{}{\\ve{\\theta}&#94;{\\prime}} \\right) \\left\\{ \\left( \\parfrac{}{\\ve{\\theta}&#94;{\\prime}} \\right)&#94;{\\mathsf{T}} \\mean{p(\\ve{x}|\\ve{\\theta})}{\\log p(\\ve{x}|\\ve{\\theta})} - \\left( \\parfrac{}{\\ve{\\theta}&#94;{\\prime}} \\right)&#94;{\\mathsf{T}} \\mean{p(\\ve{x}|\\ve{\\theta})}{\\log p(\\ve{x}|\\ve{\\theta}&#94;{\\prime})}\\right\\} \\\\ &= - \\left( \\parfrac{}{\\ve{\\theta}&#94;{\\prime}} \\right) \\mean{p(\\ve{x}|\\ve{\\theta})}{\\left( \\parfrac{}{\\ve{\\theta}&#94;{\\prime}} \\right)&#94;{\\mathsf{T}} \\log p(\\ve{x}|\\ve{\\theta}&#94;{\\prime})} = - \\mean{p(\\ve{x}|\\ve{\\theta})}{\\left( \\parfrac{}{\\ve{\\theta}&#94;{\\prime}} \\right)\\left( \\parfrac{}{\\ve{\\theta}&#94;{\\prime}} \\right)&#94;{\\mathsf{T}} \\log p(\\ve{x}|\\ve{\\theta}&#94;{\\prime})} \\\\ &= -\\mean{p(\\ve{x}|\\ve{\\theta})}{\\ve{H}_{\\ve{\\theta}&#94;{\\prime}} \\log p(\\ve{x}|\\ve{\\theta}&#94;{\\prime})} \\end{align*} ここで \\(\\ve{\\theta}&#94;{\\prime} \\to \\ve{\\theta}\\) と近づけていくと、最後の式はフィッシャー情報行列 \\(\\ve{F}\\) にいくらでも近づく。よって、 \\begin{equation*} \\lim_{\\ve{\\theta}&#94;{\\prime} \\to \\ve{\\theta}} \\ve{H}_{\\ve{\\theta}&#94;{\\prime}} \\KL{p(\\ve{x}|\\ve{\\theta})}{p(\\ve{x}|\\ve{\\theta}&#94;{\\prime})} = \\ve{F} \\end{equation*} 次に、 \\(\\ve{\\theta}\\) 近傍での対数尤度関数の挙動を見ていく。 \\(\\ve{h}\\) を微小なベクトルとして、 \\(\\log p(\\ve{x}|\\ve{\\theta} + \\ve{h})\\) を2次の項までテイラー展開すると、 \\begin{align*} \\log p(\\ve{x}|\\ve{\\theta} + \\ve{h}) &\\approx \\log p(\\ve{x} | \\ve{\\theta}) + \\left( \\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} \\log p(\\ve{x} | \\ve{\\theta}) \\ve{h} + \\frac{1}{2} \\ve{h}&#94;{\\mathsf{T}} \\left( \\parfrac{}{\\ve{\\theta}} \\right) \\left( \\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} \\log p(\\ve{x} | \\ve{\\theta}) \\ve{h} \\\\ \\Rightarrow \\log p(\\ve{x}|\\ve{\\theta} + \\ve{h}) - \\log p(\\ve{x} | \\ve{\\theta}) &\\approx \\left( \\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} \\log p(\\ve{x} | \\ve{\\theta}) \\ve{h} + \\frac{1}{2} \\ve{h}&#94;{\\mathsf{T}} \\left( \\parfrac{}{\\ve{\\theta}} \\right) \\left( \\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} \\log p(\\ve{x} | \\ve{\\theta}) \\ve{h} \\\\ &= \\left( \\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} \\log p(\\ve{x} | \\ve{\\theta}) \\ve{h} + \\frac{1}{2} \\ve{h}&#94;{\\mathsf{T}} \\ve{H}_{\\ve{\\theta}} \\log p(\\ve{x} | \\ve{\\theta}) \\ve{h} \\end{align*} 両辺 \\(p(\\ve{x}|\\ve{\\theta})\\) について平均をとると、 \\begin{align*} \\mean{p(\\ve{x}|\\ve{\\theta})}{\\log p(\\ve{x}|\\ve{\\theta} + \\ve{h}) - \\log p(\\ve{x} | \\ve{\\theta})} &= \\mean{p(\\ve{x}|\\ve{\\theta})}{\\log\\left( \\frac{p(\\ve{x}|\\ve{\\theta} + \\ve{h})}{p(\\ve{x} | \\ve{\\theta})} \\right)} \\\\ &= \\int p(\\ve{x}|\\ve{\\theta}) \\log\\left[ \\frac{p(\\ve{x}|\\ve{\\theta} + \\ve{h})}{p(\\ve{x} | \\ve{\\theta})} \\right] \\mathrm{d}\\ve{x} = -\\int p(\\ve{x}|\\ve{\\theta}) \\log\\left[ \\frac{p(\\ve{x} | \\ve{\\theta})}{p(\\ve{x}|\\ve{\\theta} + \\ve{h})} \\right] \\mathrm{d}\\ve{x} \\\\ &= -\\KL{p(\\ve{x}|\\ve{\\theta})}{p(\\ve{x}|\\ve{\\theta} + \\ve{h})} \\\\ \\mean{p(\\ve{x}|\\ve{\\theta})}{\\left( \\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} \\log p(\\ve{x} | \\ve{\\theta}) \\ve{h}} &= \\int p(\\ve{x}|\\ve{\\theta}) \\frac{\\left( \\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} p(\\ve{x}|\\ve{\\theta})}{p(\\ve{x}|\\ve{\\theta})} \\mathrm{d}\\ve{x}\\ \\ve{h} \\\\ &= \\int \\left( \\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} p(\\ve{x}|\\ve{\\theta}) \\mathrm{d}\\ve{x}\\ \\ve{h} = \\left( \\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} \\int p(\\ve{x}|\\ve{\\theta}) \\mathrm{d}\\ve{x}\\ \\ve{h} \\quad (\\because \\text{正則条件}) \\\\ &= \\left( \\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} 1 \\ve{h} \\\\ &= 0 \\\\ \\mean{p(\\ve{x}|\\ve{\\theta})}{\\frac{1}{2} \\ve{h}&#94;{\\mathsf{T}} \\ve{H}_{\\ve{\\theta}} \\log p(\\ve{x} | \\ve{\\theta}) \\ve{h}} &= \\frac{1}{2} \\ve{h}&#94;{\\mathsf{T}} \\mean{p(\\ve{x}|\\ve{\\theta})}{\\ve{H}_{\\ve{\\theta}} \\log p(\\ve{x} | \\ve{\\theta})} \\ve{h} \\\\ &= -\\frac{1}{2} \\ve{h}&#94;{\\mathsf{T}} \\ve{F} \\ve{h} \\end{align*} よって、 \\begin{equation*} \\KL{p(\\ve{x}|\\ve{\\theta})}{p(\\ve{x}|\\ve{\\theta} + \\ve{h})} \\approx \\frac{1}{2} \\ve{h}&#94;{\\mathsf{T}} \\ve{F} \\ve{h} \\end{equation*} \\(\\ve{\\theta}\\) の近傍においてはフィッシャー情報行列が支配的になっていることがわかる。また、これにより確率分布のなす多様体のリーマン計量はフィッシャー情報行列であることがわかり、ここから情報幾何学が始まっていく。 以上の議論を基に、確率分布間の違いをKLダイバージェンスで測ったとき、損失関数 \\(l(\\ve{\\theta})\\) を最も減らす方向を考える。それは次の方向 \\(\\ve{h}&#94;{\\ast}\\) を見つけることに等しい： \\begin{equation*} \\ve{h}&#94;{\\ast} = \\underset{\\ve{h}\\ \\mathrm{s.t.} \\KL{p(\\ve{x}|\\ve{\\theta})}{p(\\ve{x}|\\ve{\\theta} + \\ve{h})} = c}{\\mathrm{argmin}} l(\\ve{\\theta} + \\ve{h}) \\end{equation*} 式の気持ちとしては、「KLダイバージェンスが定数 \\(c\\) を取る中で、最も \\(l(\\ve{\\theta})\\) を減らすベクトル \\(\\ve{h}\\) 」 である。これは制約付き最適化問題だから、ラグランジェの未定定数法により解くことを考える。ラグランジアン \\(\\mathcal{L}\\) は、 \\begin{align*} \\mathcal{L} &= l(\\ve{\\theta} + \\ve{h}) + \\lambda \\left\\{ \\KL{p(\\ve{x}|\\ve{\\theta})}{p(\\ve{x}|\\ve{\\theta} + \\ve{h})} - c \\right\\} \\\\ &\\approx l(\\ve{\\theta}) + \\left( \\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} l(\\ve{\\theta}) \\ve{h} + \\lambda \\left\\{ \\KL{p(\\ve{x}|\\ve{\\theta})}{p(\\ve{x}|\\ve{\\theta} + \\ve{h})} - c \\right\\} \\quad \\text{（1次の項までテイラー展開）} \\\\ &\\approx l(\\ve{\\theta}) + \\left( \\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} l(\\ve{\\theta}) \\ve{h} + \\lambda \\left\\{ \\frac{1}{2} \\ve{h}&#94;{\\mathsf{T}} \\ve{F} \\ve{h} - c \\right\\} \\end{align*} \\(\\mathcal{L}\\) を \\(\\ve{h}\\) で偏微分すると、 \\begin{align*} \\parfrac{}{\\ve{h}} \\mathcal{L} &\\approx \\parfrac{}{\\ve{h}} l(\\ve{\\theta}) + \\parfrac{}{\\ve{h}} \\left( \\parfrac{}{\\ve{\\theta}} \\right)&#94;{\\mathsf{T}} l(\\ve{\\theta}) \\ve{h} + \\lambda \\left\\{ \\parfrac{}{\\ve{h}} \\frac{1}{2} \\ve{h}&#94;{\\mathsf{T}} \\ve{F} \\ve{h} - \\parfrac{}{\\ve{h}} c \\right\\} \\\\ &= \\parfrac{}{\\ve{\\theta}} l(\\ve{\\theta}) + \\lambda \\ve{F} \\ve{h} \\end{align*} \\(\\parfrac{}{\\ve{h}} \\mathcal{L} = \\ve{0}\\) とおいて \\(\\ve{h}\\) について解くと、 \\begin{equation*} \\ve{h}&#94;{\\ast} = - \\frac{1}{\\lambda} \\ve{F}&#94;{-1} \\parfrac{}{\\ve{\\theta}} l(\\ve{\\theta}) \\end{equation*} が得られる。 \\(\\lambda\\) はスカラーだからベクトルの方向を変えない。よって、 \\(\\ve{F}&#94;{-1} \\parfrac{}{\\ve{\\theta}} l(\\ve{\\theta})\\) が最急勾配であることが分かる。この勾配を 自然勾配(Natural Gradient) という。 ニュートン法と何が違うのか？ 「 Adaptive Method of Realizing Natural Gradient Learning for Multilayer Perceptrons 」によると、 ニュートン法は教師信号を明示的に含んだ損失関数のへッシアンを使うが、自然勾配法は近似対象の標的関数とは独立した確率分布の空間Sの計量を使っているところが違うらしい。しかし一方で、対数尤度を損失関数、かつモデルが最適パラメタによって生成された教師信号yを生成するときはフィッシャー情報行列はヘッセ行列に一致する。このため、最適点において自然勾配法はニュートン法に一致する。とある。 自分なりの解釈として線形回帰問題を考える。 誤差が◯◯分布に従って発生すると考えた瞬間に確率分布の空間が定まり、この空間の計量たるフィッシャー情報行列に従って学習するのが自然勾配学習法。一方、各点の損失関数のヘッセ行列（2階微分）を求めて最適化を進めるのがニュートン法。でいいのか？ 恐らく、各点の損失関数を計算できるのならばニュートン法の方が優れている。 発想としても差異があって、ニュートン法は損失関数の2次のテイラー展開から最適な勾配を求めるのに対し、自然勾配法はKLダイバージェンスが一定という制約のもとで最適な勾配を求めている（自然勾配法を導出するとき、損失関数の1次の項までしかテイラー展開していないのがミソ。2次まで展開すると損失関数のへッシアンが出てきてニュートン法と変わらない）。","tags":"記事","url":"/zi-ran-gou-pei-fa-nogai-guan.html","loc":"/zi-ran-gou-pei-fa-nogai-guan.html"},{"title":"成果まとめ中(5)  / 自然勾配法の概観","text":"昨日まで苦悩しつつ収束条件をまとめた（運良く見つけることができた。同時にNLMSの収束条件も掴んだ。） でも、同時に新規性が無い気がしてきた。発見となるのは、SignedLMSのフィッシャー情報行列が自己相関行列になっているくらいか？ 適応ステップサイズ導出後は、普通のフィッシャー情報行列込みのNLMSと全く同じだし。","tags":"雑記","url":"/cheng-guo-matomezhong-5-zi-ran-gou-pei-fa-nogai-guan.html","loc":"/cheng-guo-matomezhong-5-zi-ran-gou-pei-fa-nogai-guan.html"},{"title":"成果まとめ中(4)","text":"AdaptiveFilterの本見てNLMSの議論を色々見てる。が、いい結果が出てこない。 本の内容も掴みかねてる。NLMSは係数誤差ベクトルのL2ノルムが指数的に減少するようだが本当か…？ LMSの収束条件が分かっていないことに気づく。 「Adaptive Filter Theory」では式4.22に、「Adaptive Signal Processing」では式4.45で示されているので確認中。","tags":"雑記","url":"/cheng-guo-matomezhong-4.html","loc":"/cheng-guo-matomezhong-4.html"},{"title":"成果まとめ中(3)","text":"SGD（確率的最急勾配法）の収束レートが少し気になったのちょっと観察。 機械学習における確率的最適化 もっと初等的な説明があると良いなあ。確率1で極値に収束したような気がしている…。 \\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\end{equation*} 適応ステップサイズの分母の \\(\\ve{x}(n)&#94;{\\mathsf{T}}\\ve{R}&#94;{-1}\\ve{x}(n)\\) がめちゃくちゃ気になって止まる。学習理論に「例えばパラメタ空間上のベクトル \\(x(\\theta)\\) の内積 \\(\\innerp{x}{x}\\) は、座標変換により不変な量として定義するならば \\(x&#94;{\\prime}(g_{ij}(\\theta))&#94;{-1}x\\) となる。」（なるべく原文ママ）と言ってて、まさにこの不変な量を指していると思っている。 これどういうこと？と思って探し始めたら沼。相対性理論にぶつかる。わかりやすかったのは下くらいか？ 内積が不変という意味 (6)ベクトル内積の座標変換不変性の確認 情報幾何の観点からすると、幾何的に微小線素は座標変換によって値を全く変えないことが重要らしい。 \\(\\ve{x}(n)\\) をパラメタ空間上のベクトルと捉えると、 \\(\\ve{R}&#94;{-1}\\) はパラメタ空間上の計量（元の空間の計量は:math: ve{R} ）を定め、 \\(\\ve{x}(n)&#94;{\\mathsf{T}}\\ve{R}&#94;{-1}\\ve{x}(n)\\) はパラメタ空間上のノルムを計算していて、ノルムだから不変でしょっていう議論になる？まだピンとこない。 あと、AdaptiveFilterの本見てNLMSの議論を色々見てる。","tags":"雑記","url":"/cheng-guo-matomezhong-3.html","loc":"/cheng-guo-matomezhong-3.html"},{"title":"成果まとめ中(2)","text":"ディジタル信号処理 第 10 回 適応信号処理 少し詳しく書いてある。やはり適応フィルタの原典を当たりたい。","tags":"雑記","url":"/cheng-guo-matomezhong-2.html","loc":"/cheng-guo-matomezhong-2.html"},{"title":"書類整理終わり、復帰 / 成果まとめ中(1)","text":"諸々の提出書類で実験できず。1週間空けて復帰。 報告書類を書いていたら、やっぱりフィッシャー情報行列とヘッセ行列の違いがよくわからなくなってきた。 対数尤度のヘッセ行列とフィッシャー情報行列に何かしらの共通点があるはず。 Notes on the Limitations of the Empirical Fisher Approximation 経験フィッシャー行列の性能限界について。 ヘッセ行列のくだりから自然勾配の導出まで、紙に証明をまとめた。明日辺りに記事に起こす。","tags":"雑記","url":"/shu-lei-zheng-li-zhong-wari-fu-gui-cheng-guo-matomezhong-1.html","loc":"/shu-lei-zheng-li-zhong-wari-fu-gui-cheng-guo-matomezhong-1.html"},{"title":"LMS Filterの挙動観察中(10)","text":"\\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\end{equation*} Normalizeするやつの意味付けを追っている。非常にRLS(Recursive Least Square)に近い、下手するとRLSそのものかも知れない。","tags":"雑記","url":"/lms-filternoju-dong-guan-cha-zhong-10.html","loc":"/lms-filternoju-dong-guan-cha-zhong-10.html"},{"title":"書類整理中","text":"色々と書類整理しているためあんまり実験が進んでいない。でも、既存研究がありそうでヒヤヒヤする毎日。 Normalized Natural Gradient Adaptive Filtering for Sparse and Nonsparse Systems かなり近い。が、LMSベースの計量を自ら設計している。コスト関数に、2乗誤差項に何か変換のL2ノルムを加算しており、それに対しての自然勾配を求めている。そうか、コスト関数の自然勾配を考えればいいのか。 Proportionate Normalized Least-Mean-Squares Adaptation in Echo Cancelers 自然勾配の発想に近づいていたPNLMSの実装 SPARSE LMS FOR SYSTEM IDENTIFICATION スパースLMS(ZA-LMS)の最初の論文。定式化が明確。","tags":"雑記","url":"/shu-lei-zheng-li-zhong.html","loc":"/shu-lei-zheng-li-zhong.html"},{"title":"LMS Filterの挙動観察中(9)","text":"\\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\end{equation*} 実装誤りを見直しながらもう一度。 やはり、自然勾配法が何故うまくいくのか、更新式の導出までやったほうが宜しい。実装間違いするから。適応的自然勾配の更新式は微小量の近似を使っている。微小量の近似は今まで何度も避けてきたが、この際おさらいする。ようはテイラー展開して2次以降の項を打ち切れば良し。高校数学レベルの話。 近似式 1/(1-x)のマクローリン展開 実験が落ち着いたら書いていきたい。 →実験OK。ステップサイズの設定が難しかったけど、ナイーブなものよりは性能がよいはず。 また、軽く見た感じでも自然勾配学習法は発散しやすい。以下の記事にあるように、正則化を掛けたほうが良さそう。 What is the empirical Fisher ? ヘッセ行列の計算は少し回り道になったが、理論的最適値との比較において議論できそう。 逆行列補題を使っていて、最早カルマンフィルタやRLSに近いんでないかと思えてきた。 信号とシステム 第6章 適応フィルタ Recursive Least Squares Estimation にLMSからRLSまで記述あり。 上の「信号とシステム」を眺めていたら、NLMSにおける適応的ステップサイズ決定則が使えそうな印象。NLMSは事後誤差 \\(e&#94;{+}(k)\\) を0にするように適応的なステップサイズ \\(\\alpha(k)\\) を定める。普通のSigned-LMSでは、リファレンス信号 \\(d(k)\\) , フィルタ係数 \\(\\ve{h}(k)\\) , 入力データ \\(\\ve{x}(k)\\) に対し、事後誤差は次のように展開できる。 \\begin{align*} e&#94;{+}(k) &= d(k) - \\innerp{\\ve{h}(k+1)}{\\ve{x}(k)} \\\\ &= d(k) - \\innerp{\\ve{h}(k) + \\alpha(k) \\mathrm{sign}[e(k)] \\ve{x}(k)}{\\ve{x}(k)} \\\\ &= d(k) - \\innerp{\\ve{h}(k)}{\\ve{x}(k)} - \\alpha(k) \\mathrm{sign}[e(k)] \\innerp{\\ve{x}(k)}{\\ve{x}(k)} \\\\ &= e(k) - \\alpha(k) \\mathrm{sign}[e(k)] ||\\ve{x}(k)||_{2}&#94;{2} \\end{align*} \\(e&#94;{+}(k) = 0\\) となるように \\(\\alpha(k)\\) を選ぶと、 \\begin{equation*} \\alpha(k) = \\frac{e(k)}{\\mathrm{sign}[e(k)] ||\\ve{x}(k)||_{2}&#94;{2}} = \\frac{|e(k)|}{||\\ve{x}(k)||_{2}&#94;{2}} \\end{equation*} として、事後誤差を最小にするステップサイズが求まった。（Signed-LMSでこういう議論があんまり見られないのはなぜだ？ この \\(\\alpha(k)\\) をSigned-LMSの更新則に突っ込むとNLMSになる ） 自然勾配を使った場合が有益（ステップサイズ設定つらい）なので、求めてみると、 \\begin{align*} e&#94;{+}(k) &= d(k) - \\innerp{\\ve{h}(k+1)}{\\ve{x}(k)} \\\\ &= d(k) - \\innerp{\\ve{h}(k) + \\alpha(k) \\mathrm{sign}[e(k)] \\ve{F}(k)&#94;{-1} \\ve{x}(k)}{\\ve{x}(k)} \\\\ &= d(k) - \\innerp{\\ve{h}(k)}{\\ve{x}(k)} - \\alpha(k) \\mathrm{sign}[e(k)] \\innerp{\\ve{F}(k)&#94;{-1}\\ve{x}(k)}{\\ve{x}(k)} \\\\ &= e(k) - \\alpha(k) \\mathrm{sign}[e(k)] \\innerp{\\ve{x}(k)}{\\ve{F}(k)&#94;{-1}\\ve{x}(k)} \\end{align*} よって、 \\begin{equation*} \\alpha(k) = \\frac{e(k)}{\\mathrm{sign}[e(k)] \\innerp{\\ve{x}}{\\ve{F}(k)&#94;{-1}\\ve{x}(k)}} = \\frac{|e(k)|}{\\innerp{\\ve{x}(k)}{\\ve{F}(k)&#94;{-1}\\ve{x}(k)}} \\end{equation*} が得られる。これは計量としてフィッシャー情報行列の逆行列を使った時の \\(\\ve{x}(k)\\) のノルムによる正規化に対応する。すると残差の絶対値が外れる。NLMSとかなり近いけど計量が入っているところが違う。 実装してみたら実験でも音源に依存せず安定している印象（注意！ノイズのない正弦波で発散した！おそらく、情報行列の要素が全て同一で特異になっている。）。 結果の意味付けが非常に大事な気がする。資料35pあたりの議論を当てはまると、何か幾何的な解釈が出てくるはずだ。改めて、ここらへんの議論って誰かやっていないか、気になる。明日はそこを考えてみる。改めて既存研究が無いか見て、報告に移そうか。 TODO: Normalizeするやつの結果の意味付け 忘却係数として捉えれば式が簡単にならんか？ \\((\\lambda \\ve{F} + \\ve{x}\\ve{x}&#94;{\\mathsf{T}})&#94;{-1}\\) で \\(0 < \\lambda < 1\\) は1に近い係数。 自然勾配法がなんでうまくいくのか Natural Gradient Descent を訳しながら理解していく。 New insights and perspectives on the natural gradient method も参考になりそう。 RLS(Recursive Least Square)の更新式の誤差に符号関数を被せたものが、自分が導いているものかも知れないと思い立つ。確認。","tags":"雑記","url":"/lms-filternoju-dong-guan-cha-zhong-9.html","loc":"/lms-filternoju-dong-guan-cha-zhong-9.html"},{"title":"LMS Filterの挙動観察中(8)","text":"まだ粘る。GW終わるまでには何らかのアウトプットがほしい。 指数移動平均のαを増やすと性能（誤差、エントロピー）が悪化する傾向あり。特に0.5以上（瞬間値の重みを大きく）すると、悪化が顕著。 分散行列の逆行列を見てみると、非常に大きい値を取っていることが分かる。これは特異にかなり近いのではないかと予測している。 また、指数移動平均で求めた分散行列の対角要素は経験分散に漸近するはずで、対角要素は時間遅延が加わった自分自身との2乗和で、全てが同じ値になることを期待していたが、なっていなかった。これは、指数移動平均は入力の順序により最終結果が異なるという状態が現れていると思う。（例：1,1,1,0 という系列と 0,1,1,1 という系列では指数移動平均の結果が異なる。） 学習率の設定も音源依存でだいぶ変わってしまう印象。ボイスでは 0.0001 が、ピアノでは 0.00001、50Hzサイン波では発散した（恐らくこれはほぼ定常な信号になっているからと思われる。定常な信号では全ての分散と共分散が同じ値になって、行列が特異になる。正則化（分散行列に定数を掛けた単位行列を加算）を行ったら安定した...） 行き詰まりを感じ、適応的自然勾配の更新式を逆行列補題（Woodburyの恒等式）から導いていた。 逆行列の補助定理（Woodburyの恒等式） 逆行列の公式 そのときに、論文では勾配ベクトルの分散行列を求めていることに気づく。そして自分が間違っている事がわかった。 情報行列は勾配ベクトルの分散行列だった。（データベクトルの分散行列ではない...） いままで入力データの分散行列を計算していたので、これは明確な誤り。 フィッシャー情報行列はスコア関数（対数尤度関数の勾配）の分散行列で定義される。よって、情報行列とデータの分散行列は一般に一致しない。 もう一つ自然勾配とフィッシャー情報行列に関する有益な情報源あり: What is the empirical Fisher ? 今一度Jupyterから出戻りしてみる。 思ったけど、今考えているのは絶対値誤差最小化のためにSigned-LMSだけど、データ側を符号とするLMSや、Sign-SignLMSの解析もありじゃないかと思ってきた。データ側を符号とするLMSは何を最小化しているのか？などが気になる。","tags":"雑記","url":"/lms-filternoju-dong-guan-cha-zhong-8.html","loc":"/lms-filternoju-dong-guan-cha-zhong-8.html"},{"title":"LMS Filterの挙動観察中(7)","text":"実データ適用で、どうも上手く行かない。やっぱり分散行列の逆行列が発散している。 適応的自然勾配をやめて、真面目に（毎サンプル平均を求めて）計算するようにしているけども結果がよろしくない。分散行列を標本平均ではなくて指数移動平均（α=0.1）に置き換えたらそれなりの性能が出ることを確認。しかし、ラプラス分布の計量を取り入れていない...。","tags":"雑記","url":"/lms-filternoju-dong-guan-cha-zhong-7.html","loc":"/lms-filternoju-dong-guan-cha-zhong-7.html"},{"title":"LMS Filterの挙動観察中(6)","text":"今日は実装整理して実データへ適用してみる。気になってるのが適応的自然勾配の更新式。 確率の重み付けは正規化しないと使えそうにないということ。 確率の重み付けをしても問題ないか？ 実データ適用、うーん性能が良くない！発散する！実装を確認しながら進行中。情報行列の逆行列を正規化すると発散はしないけど、逆行列がほぼ単位行列とほぼ同一で、元のSignedLMSと性能が同等。。。 まずは、適応的自然勾配じゃなくて負荷でかいけど真面目に計算する方針で行ってみる。 また、フィルタ処理をfor文でやるよりnumpyの演算にした方が格段に早かった。numpy大事。","tags":"雑記","url":"/lms-filternoju-dong-guan-cha-zhong-6.html","loc":"/lms-filternoju-dong-guan-cha-zhong-6.html"},{"title":"LMS Filterの挙動観察中(5)","text":"\\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\end{equation*} 別のことをしているときに、ふと適応的自然勾配学習法を弄ってて、なんとなくIRLSに応用できそうな印象が。 以下のような式でヘッセ行列（というか、重み付きの分散行列）を更新する。 \\begin{equation*} \\ve{H} \\leftarrow \\ve{H} + \\frac{1}{|y_{i} - \\ve{\\beta}&#94;{\\mathsf{T}} \\ve{x}|} \\ve{x} \\ve{x}&#94;{\\mathsf{T}} \\end{equation*} 他にも、ICA（独立成分分析）の尖度最大化（優ガウス分布化）の学習がなんか使えないかと考えつつある。でもこれはICAによるノイズ除去にだいぶ近い話になりそう。 分散行列と自己相関行列、だいぶ定義が近いな…間違ってないかなと思って再確認。分散行列と言ってるものはもしかしたら自己相関行列の誤りかもしれない。 相関行列の定義と分散共分散行列との関係 初学者のための無線通信信号処理入門 に明確に定義されてる。 平均0化していたら分散行列と自己相関行列は同一になりそうな雰囲気。雰囲気じゃだめでちゃんと確認すべき。 寄り道しすぎたので、改めて結果をまとめていく。","tags":"雑記","url":"/lms-filternoju-dong-guan-cha-zhong-5.html","loc":"/lms-filternoju-dong-guan-cha-zhong-5.html"},{"title":"LMS Filterの挙動観察中(4)","text":"本日も引き続き発散の原因を追う。 →ステップサイズを小さくしたら発散しなくなった…。職人芸じゃないかこんなの。NLMSみたく発散しない条件がほしいな。 本当に既存研究がないか、再度調査。 自然勾配を適応的に計算する方法を試している。無論、定義式通りに計算するのは問題ないことは確かめているが、計算量が気になるのです。 パラメータを色々といじりつつ、論文も参照してそれなりのパラメータを見つける。 パラメータについては Adaptive Natural Gradient Method for Learning of Stochastic Neural Networks in Mini-Batch Mode を皮切りに調査開始。 Adaptive Method of Realizing Natural Gradient Learning for Multilayer Perceptrons が甘利先生。（福水先生もいるぞ） この論文で適応的更新式の導出が述べられる。 Adaptive natural gradient learning algorithms for various stochastic models も甘利先生。（福水先生もいるぞ） A Simplified Natural Gradient Learning Algorithm 更にシンプルにしたもの。2011年。 Toy-problemとして中央値の逐次推定とかアリではと、少しだけ思った。","tags":"雑記","url":"/lms-filternoju-dong-guan-cha-zhong-4.html","loc":"/lms-filternoju-dong-guan-cha-zhong-4.html"},{"title":"LMS Filterの挙動観察中(3)","text":"LMSはヘッセ行列の逆行列込みの学習ができているが、Signed-LMSは上手く行かない。分散行列が特異になったり、要素が大きくなりすぎて発散してしまう。。。","tags":"雑記","url":"/lms-filternoju-dong-guan-cha-zhong-3.html","loc":"/lms-filternoju-dong-guan-cha-zhong-3.html"},{"title":"LMS Filterの挙動観察中(2)","text":"つまるところ、以下の計算をどうやるか？に尽きる。 \\begin{equation*} \\mathrm{E}\\left[ \\delta(\\varepsilon(n)) x(n - m) x(n - k) \\right] = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n = 1, \\varepsilon(n) = 0}&#94;{N} x(n - m) x(n - k) \\end{equation*} \\(\\varepsilon(n)\\) はi.i.d.（独立に同一の分布）から発生しているので、 \\(x(n-m), x(n-k)\\) には依存しない（予測係数にも依らず）で勝手に揺れると考える。 でもそんな計算は見たことがない。そもそもLADの文脈でこの話は出ているはずで、「Laplace Distribution linear regression」で検索掛けていたら、 Robust Mean Change-Point Detecting through Laplace Linear Regression Using EM Algorithm を見つけた。 イントロで「 ラプラス分布は正規分布の混合で表せる 」と「 混合を前提にしたEMアルゴリズムが存在する 」というのを見つけて、論文探しが改めて動く。混合ガウス分布をEMアルゴリズムで学習する話はよく聞くから、本質的なのは正規分布の混合で表せていることか。 ROBUST MIXTURE REGRESSION MODEL FITTING BY LAPLACE DISTRIBUTION は2013年の論文。印象的なのは、 IRLSはEMアルゴリズムの一種だということ。 ラプラス確率的フロンティアモデルのベイズ推定 は日本語でラプラス分布の混合について述べた論文 The Bayesian Lasso はLASSOを、パラメータの事前分布をラプラス分布としたものとして定式化している。ラプラス分布は直接扱わず、混合を考えている。 実験で試している、勾配ベクトルに分散行列（ヘッセ行列）の逆行列を掛ける行為は、ウィーナーフィルタに等しい。しかしウィーナーフィルタは観測分散行列 \\(\\ve{XX}&#94;{\\mathsf{T}}\\) が正則でないと計算できない。そこで、観測分散行列の低ランク近似を行ってその擬似逆行列を使ってフィルタ係数を更新していく手法がある。それを Reduced rank adaptive filters というらしい。 A New Approach to Adaptive Signal Processing で触れていた。この論文は適応フィルタを広汎的に見ており、有益。 Reduced-Rank Adaptive Filtering Based on Joint Iterative Optimization of Adaptive Filters ではReduced rank adaptive filtersのフィルタバンク版 邪念が動いて、パーティクルフィルター（粒子フィルター）でパラメータ決められんか考えてる。でも、LMSは状態空間モデルの範疇に入るのだろうか？（カルマンフィルタの一部だから当てはまったはず）。また、一般の状態空間モデルと違って状態は常に観測できるよな。またパーティクルフィルターもシミュレーションベースなので負荷が高そう。 パーティクル・フィルタをやさしく解説 が確かに優しい。 粒子フィルタの基礎と応用: フィルタ・平滑化・パラメータ推定 \\(\\mathrm{E}\\left[ \\delta(\\varepsilon(n)) x(n - m) x(n - k) \\right]\\) の解釈 結局 \\(\\mathrm{E}\\left[ \\delta(\\varepsilon(n)) x(n - m) x(n - k) \\right]\\) の解釈から逃げている...。もう少し考えていたら、残差 \\(\\varepsilon\\) は入力ベクトル \\(x\\) と独立であることを思い出した。ここから、次が言える。 \\begin{equation*} \\mathrm{E} \\left[\\delta(\\varepsilon(n)) x(n - m) x(n - k) \\right] = \\mathrm{E} \\left[ \\delta(\\varepsilon(n)) \\right] \\mathrm{E} \\left[ x(n - m) x(n - k) \\right] \\end{equation*} ここで、 \\(\\mathrm{E} \\left[ \\delta(\\varepsilon(n)) \\right]\\) はお察しの通りで、以下の通りに、やはり残差が0となる確率が出てくる。 \\begin{align*} \\mathrm{E} \\left[ \\delta(\\varepsilon(n)) \\right] &= \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n = 1}&#94;{N} \\delta(\\varepsilon(n)) = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n = 1, \\varepsilon(n) = 0}&#94;{N} 1 \\\\ &= P(\\varepsilon = 0) \\end{align*} よって、 \\begin{equation*} \\mathrm{E} \\left[\\delta(\\varepsilon(n)) x(n - m) x(n - k) \\right] = P(\\varepsilon = 0) \\mathrm{E} \\left[ x(n - m) x(n - k) \\right] \\end{equation*} \\(P(\\varepsilon = 0)\\) を考える。まず注意したいのは、連続型確率分布においては一点0をとる確率は0ということ（測度0だから）。近似するしかなく、方針としては、 残差の閾値を定めて、それ以下の数値を残差0とみなして確率を求める 離散型確率分布で考える ラプラス分布の基本的なことをおさらいすると、確率密度関数 \\(f(x, \\mu, \\sigma)\\) は、 \\begin{equation*} f(x, \\mu, \\sigma) = \\frac{1}{2 \\sigma} \\exp\\left( - \\frac{|x - \\mu|}{\\sigma} \\right) \\end{equation*} で、観測 \\(x_{1}, ..., x_{N}\\) が得られた時の尤度関数 \\(L(\\mu, \\sigma)\\) と対数尤度関数は、 \\begin{align*} L(\\mu, \\sigma) &= \\prod_{i = 1}&#94;{N} \\frac{1}{2 \\sigma} \\exp\\left( - \\frac{|x_{i} - \\mu|}{\\sigma} \\right) = \\frac{1}{(2 \\sigma)&#94;{N}} \\prod_{i = 1}&#94;{N} \\exp\\left( - \\frac{|x_{i} - \\mu|}{\\sigma} \\right) \\\\ \\log L(\\mu, \\sigma) &= -N\\log(2\\sigma) -\\sum_{i = 1}&#94;{N} \\frac{|x_{i} - \\mu|}{\\sigma} = -N\\log(2\\sigma) - \\frac{1}{\\sigma}\\sum_{i = 1}&#94;{N} |x_{i} - \\mu| \\end{align*} \\(\\mu\\) の最尤推定量は標本中央値となる。 \\(\\mu\\) が求まったとして、次は \\(\\sigma\\) の最尤推定値を考える。対数尤度関数を \\(\\sigma\\) で偏微分すると、 \\begin{equation*} \\frac{\\partial}{\\partial \\sigma} \\log L(\\mu, \\sigma) = -2 \\frac{N}{2\\sigma} + \\frac{1}{\\sigma&#94;{2}} \\sum_{i = 1}&#94;{N} |x_{i} - \\mu| = -\\frac{N}{\\sigma} + \\frac{1}{\\sigma&#94;{2}} \\sum_{i = 1}&#94;{N} |x_{i} - \\mu| \\end{equation*} \\(\\frac{\\partial}{\\partial \\sigma} \\log L(\\mu, \\sigma) = 0\\) とおいて \\(\\sigma\\) について解くと、 \\begin{equation*} \\frac{N}{\\sigma} = \\frac{1}{\\sigma&#94;{2}} \\sum_{i = 1}&#94;{N} |x_{i} - \\mu| \\Rightarrow \\sigma = \\frac{1}{N} \\sum_{i = 1}&#94;{N} |x_{i} - \\mu| \\end{equation*} \\(\\sigma\\) の最尤推定値は偏差の絶対値の標本平均となる。次に離散ラプラス分布を考える（ ここ を参考にしている）。離散ラプラス分布は次の確率（質量）関数 \\(P\\) を持つ: \\begin{align*} P(X = k) &= \\frac{f(k, 0, \\sigma)}{\\sum_{j = -\\infty}&#94;{\\infty} f(j, 0, \\sigma)} = \\frac{\\exp\\left( -\\frac{|k|}{\\sigma} \\right)}{\\sum_{j = -\\infty}&#94;{\\infty} \\exp\\left( -\\frac{|j|}{\\sigma} \\right)} \\\\ &= \\frac{\\exp\\left( -\\frac{|k|}{\\sigma} \\right)}{1 + 2 \\sum_{j = 1}&#94;{\\infty} \\exp\\left( -\\frac{j}{\\sigma} \\right)} \\end{align*} ここで、 \\begin{equation*} \\sum_{j = 1}&#94;{\\infty} \\exp\\left( -\\frac{j}{\\sigma} \\right) = \\lim_{n \\to \\infty} \\frac{\\exp(-1/\\sigma)(1 - \\exp(-n/\\sigma))}{1 - \\exp(-1/\\sigma)} = \\frac{\\exp(-1/\\sigma)}{1 - \\exp(-1/\\sigma)} \\end{equation*} よって、 \\begin{align*} P(X = k) &= \\frac{\\exp\\left( -\\frac{|k|}{\\sigma} \\right)}{1 + 2 \\frac{\\exp(-1/\\sigma)}{1 - \\exp(-1/\\sigma)}} = \\frac{1 - \\exp(-1/\\sigma)}{1 + \\exp(-1/\\sigma)} \\exp\\left(-\\frac{|k|}{\\sigma}\\right) \\\\ &= \\frac{1 - p}{1 + p} p&#94;{|k|}, \\quad p = \\exp(-1/\\sigma) \\end{align*} これは離散型確率分布であることに注意。 連続版かつ \\(\\mu=0\\) で、 \\(|x|\\) がある閾値 \\(\\delta > 0\\) 以下となる確率は次のように計算できる: \\begin{align*} P(|x| \\leq \\delta) &= \\int&#94;{\\delta}_{-\\delta} f(x, \\mu, \\sigma) dx = \\frac{1}{2 \\sigma} \\int&#94;{\\delta}_{-\\delta} \\exp\\left(-\\frac{|x|}{\\sigma} \\right) dx \\\\ &= \\frac{2}{2\\sigma} \\int&#94;{\\delta}_{0} \\exp\\left(-\\frac{x}{\\sigma} \\right) dx = \\frac{1}{\\sigma} (-\\sigma) \\int&#94;{\\delta}_{0} \\left\\{ \\exp\\left(-\\frac{x}{\\sigma} \\right) \\right\\}&#94;{\\prime} dx \\\\ &= -\\left[ \\exp\\left(-\\frac{x}{\\sigma} \\right) \\right]&#94;{\\delta}_{0} = \\exp(0) - \\exp\\left( - \\frac{\\delta}{\\sigma} \\right) \\\\ &= 1 - \\exp\\left( - \\frac{\\delta}{\\sigma} \\right) \\end{align*} この式により分散行列にかける係数を決めることを考えると、次が考察される。 \\(\\delta\\) が大きい（分散 \\(\\sigma\\) が小さい）と確率が1に近づき、分散行列はLMSのそれと近くなる。 逆に \\(\\delta\\) が小さい（分散 \\(\\sigma\\) が大きい）と分散行列に小さいスカラーを乗じる。分散行列の逆行列をとると、大きいスカラーを乗じることになり、勾配ベクトルのノルムが大きくなりそう。 ノイズレベル（ \\(\\approx\\) 分散）が小さいときは勾配が小さくなり極値付近を精密に調べ、大きい場合は勾配が大きくなりダイナミックに探索空間を動き回りそう。 LMSの性能解析に関する文献 色々さまよっているうちに出てきた。 Adaptive Filter Theory and Applications にLMSのステップサイズのとり方に関する記述あり。証明に有益。 Convergence Issues in the LMS Adaptive Filter も結構有益。 TODO 評価を続ける。評価がまとまったら結果共有に入りたい。 LMSの適応動作は、単層パーセプトロンの学習にも該当する。NNの観点からも引き続き論文調査を行うべし。 OMPを使う。 メッセージパッシング使えない？ 何らかの確率モデル化をせよ、というふうに受け取った。 AMP, Survay-Propagation（三村さん、樺島さん）がありえる。 → AMP, Survay-Propagationについて調査すべし。 いろんな論文で自然勾配をどうやって定義しているか要観察。 優先度低 パーティクルフィルター使えない？ 今日検討した結果、ちょっと今は保留。大量のサンプルが必要そうに見える。計算負荷を気にした結果、優先度を低くした。","tags":"雑記","url":"/lms-filternoju-dong-guan-cha-zhong-2.html","loc":"/lms-filternoju-dong-guan-cha-zhong-2.html"},{"title":"LMS Filterの挙動観察中(1)","text":"引き続き観察中。勾配の計算ミスがあったりして厳しかった。 問題は、やはりというかSignLMSでのヘッセ行列。 \\(\\mathrm{E}[\\varepsilon((n))x(n-m)x(n-k)]\\) の計算でインパルス応答の扱いをどうするのか...連続信号では厳密に0を取る確率は0だ。だからといって離散的に考えていいのか？ 誤差の絶対値を取って閾値以下ならば分散行列に加算する処理を入れたが、分散行列が特異になること多し。 デジタル的に考えれば、残差が0になる確率で重み付けしていいのでは無いかと思う。 またデジタル的に考えた時 残差が0になる確率は、離散ラプラス分布（ 参考資料 ）を元にサンプリング/もしくは重み付けで求める。（サンプリングの場合は[0,1]乱数を発生させて残差が0になる確率よりも小さければ採択する。まじのMC。というか、サンプリングしても重み付けしても同じでは？）分散パラメータは観測分散で求める。 一旦残差0の重み付けで実験を進めているが、まだ残差0確率が怪しい感じ。（0.93とかいう現実離れした数値。実際の音声では約0.09とかそんなん） 見やすいようにパラメータを2つにしている。2つにした時でも同じ出力を与える組み合わせがあり、それが直線上に並んでいる事がわかっている。","tags":"雑記","url":"/lms-filternoju-dong-guan-cha-zhong-1.html","loc":"/lms-filternoju-dong-guan-cha-zhong-1.html"},{"title":"LMS, Signed-LMSの挙動観察","text":"LMS, SIgned-LMSの挙動観察 入力信号を固定し、各フィルタ係数において、残差、残差勾配はどうなっているのか？ まずはいつもどおりのLMSフィルターからはじめ、Signed-LMSの解析を行ってみる。 In [1]: import sys import math import numpy as np import matplotlib.pyplot as plt # 固定した係数によるLMSフィルター処理 def lms_fixcoef ( data , coef ): num_samples = data . size filter_order = coef . size pred = np . zeros ( num_samples ) for smpl in range ( filter_order , num_samples , 1 ): pred [ smpl ] = np . dot ( coef , data [ smpl - filter_order : smpl ]) return pred In [2]: # xtics, ytics で係数を生成してLMSフィルター処理を実行 # 各点における残差と残差勾配を出力 def lms_experience ( data , xtics , ytics ): zerror = np . zeros (( xtics . size , ytics . size )) zerrorgrad = np . zeros (( xtics . size , ytics . size , 2 )) for x in range ( xtics . size ): for y in range ( ytics . size ): coef = np . array ([ xtics [ x ], ytics [ y ]]) pred = lms_fixcoef ( data , coef ) error = data - pred zerror [ x , y ] = np . sqrt ( np . mean ( error ** 2 )) zerrorgrad [ x , y , 0 ] = - 2 * np . mean ( error [ 1 :] * data [ 0 : - 1 ]) zerrorgrad [ x , y , 1 ] = - 2 * np . mean ( error [ 2 :] * data [ 0 : - 2 ]) return zerror , zerrorgrad def ploterror ( label , xtics , ytics , zmesh ): xmesh , ymesh = np . meshgrid ( xtics , ytics ) # plt.pcolormesh(xmesh, ymesh, zmesh, label=label, cmap='Blues') plt . contour ( xmesh , ymesh , zmesh , levels = np . linspace ( 0.0 , 1.5 , 10 ) . tolist ()) plt . colorbar () plt . xlabel ( 'x0' ) plt . ylabel ( 'x1' ) def plotgradient ( label , xtics , ytics , zmeshvec ): xmesh , ymesh = np . meshgrid ( xtics , ytics ) plt . quiver ( xmesh , ymesh , zmeshvec [:,:, 0 ], zmeshvec [:,:, 1 ], label = label ) plt . xlabel ( 'x0' ) plt . ylabel ( 'x1' ) # 実験用入力データの作成 NUM_SAMPLES = 1024 lineardata = np . ones ( NUM_SAMPLES ) sindata = np . ones ( NUM_SAMPLES ) for i in range ( NUM_SAMPLES ): sindata [ i ] = math . sin ( 2 * math . pi * 440 * i / 48000.0 ) np . random . seed ( 0 ) gaussnoise = np . random . normal ( 0 , 0.1 , NUM_SAMPLES ) np . random . seed ( 0 ) laplacenoise = np . random . laplace ( 0 , 0.1 , NUM_SAMPLES ) # x,yの解析範囲 xtics = np . linspace ( - 2 , 3 , 20 ) ytics = np . linspace ( - 2 , 3 , 20 ) plt . plot ( lineardata ) plt . show () plt . plot ( sindata ) plt . show () plt . plot ( gaussnoise ) plt . show () plt . plot ( laplacenoise ) plt . show () plt . plot ( sindata + gaussnoise ) plt . show () plt . plot ( sindata + laplacenoise ) plt . show () In [3]: zerror , zerrorgrad = lms_experience ( lineardata , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Error Gradient' , xtics , ytics , zerrorgrad ) plt . title ( 'Error and Error Gradient' ) plt . show () In [4]: zerror , zerrorgrad = lms_experience ( sindata , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Error Gradient' , xtics , ytics , zerrorgrad ) plt . title ( 'Error and Error Gradient' ) plt . show () In [5]: data = lineardata + gaussnoise zerror , zerrorgrad = lms_experience ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Error Gradient' , xtics , ytics , zerrorgrad ) plt . title ( 'Error and Error Gradient' ) plt . show () In [6]: data = sindata + gaussnoise zerror , zerrorgrad = lms_experience ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Error Gradient' , xtics , ytics , zerrorgrad ) plt . title ( 'Error and Error Gradient' ) plt . show () In [7]: data = lineardata + laplacenoise zerror , zerrorgrad = lms_experience ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Error Gradient' , xtics , ytics , zerrorgrad ) plt . title ( 'Error and Error Gradient' ) plt . show () In [8]: data = sindata + laplacenoise zerror , zerrorgrad = lms_experience ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Error Gradient' , xtics , ytics , zerrorgrad ) plt . title ( 'Error and Error Gradient' ) plt . show () ここまでの考察 どんな波形を突っ込んでも同じ残差分布になる（直線x0+x1=1上に解があるように見える）... 音声特有の相関の強みが出ている。ほぼ、x0+x1=1が理想的になる。x1（2個前データの係数）=1とするよりもx0（直前データの係数）=1の方が残差が小さい。これは、直前の信号により相関しているから。x0 = x1 = 0.5はその平均になり、これも残差は小さい。 勾配は正しく計算できてそう。 雑音を付加すると残差分布が楕円状に変わる 雑音が加わると、個々のサンプルの値よりも、サンプルの平均を取ったときに残差が小さくなる。 つまり、x0 = x1 = 0.5が理想に近い。 正規（ガウス）雑音、ラプラス分布雑音でほぼ同じ傾向。しかしラプラスの方がやや裾が広い？ ふつーのLMSはガウス雑音前提でやってるので注意。 勾配の向きが怪しい。グラフ左上、右下が残差勾配を下っている（=悪化している）様に見える。 →実装不具合のようだ。予測時のフィルタ係数を内積と一致させる（coef[0] data[smpl - 2] + coef[1] data[smpl - 1] とさせ）ないと座標軸と一致しない（反転してしまう。） → 次はSigned-LMSで解析してみる。 In [9]: # xtics, ytics で係数を生成してSigned-LMSフィルター処理を実行 # 各点における残差と残差勾配を出力 def signedlms_experience ( data , xtics , ytics ): zerror = np . zeros (( xtics . size , ytics . size )) zerrorgrad = np . zeros (( xtics . size , ytics . size , 2 )) for x in range ( xtics . size ): for y in range ( ytics . size ): coef = np . array ([ xtics [ x ], ytics [ y ]]) pred = lms_fixcoef ( data , coef ) error = data - pred zerror [ x , y ] = np . mean ( np . abs ( error )) zerrorgrad [ x , y , 0 ] = - np . mean ( np . sign ( error [ 1 :]) * data [ 0 : - 1 ]) zerrorgrad [ x , y , 1 ] = - np . mean ( np . sign ( error [ 2 :]) * data [ 0 : - 2 ]) return zerror , zerrorgrad data = lineardata zerror , zerrorgrad = signedlms_experience ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Error Gradient' , xtics , ytics , zerrorgrad ) plt . title ( 'Error and Error Gradient' ) plt . show () In [10]: data = sindata zerror , zerrorgrad = signedlms_experience ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Error Gradient' , xtics , ytics , zerrorgrad ) plt . title ( 'Error and Error Gradient' ) plt . show () In [11]: data = lineardata + gaussnoise zerror , zerrorgrad = signedlms_experience ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Error Gradient' , xtics , ytics , zerrorgrad ) plt . title ( 'Error and Error Gradient' ) plt . show () In [12]: data = sindata + gaussnoise zerror , zerrorgrad = signedlms_experience ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Error Gradient' , xtics , ytics , zerrorgrad ) plt . title ( 'Error and Error Gradient' ) plt . show () In [13]: data = lineardata + laplacenoise zerror , zerrorgrad = signedlms_experience ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Error Gradient' , xtics , ytics , zerrorgrad ) plt . title ( 'Error and Error Gradient' ) plt . show () In [14]: data = sindata + laplacenoise zerror , zerrorgrad = signedlms_experience ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Error Gradient' , xtics , ytics , zerrorgrad ) plt . title ( 'Error and Error Gradient' ) plt . show () Signed-LMSの観察 雑音がない時、どれだけ解から離れていても勾配が同一 稜線が直線になった谷になっていると想像。 普通のLMSでは解から離れると2乗則？で勾配が大きくなる 逆に、どんなに近くても勾配が同一（LMSでは解の近傍で勾配が急激に消える） 残差の裾野がLMSに比べて広い。 雑音がある時でも、解の近傍で勾配が消失しにくい。 解から離れると雑音がない時の勾配に近づく。 それでも尾根方向は勾配が消えている。 やっぱ山の稜線に沿った勾配（左上から右下）の向きが気になる。。。これ学習しようとすると思いっきり悪い方向に進むよな。 勾配の向きが怪しいのは、勾配法では必ずしも解の稜線に沿った向きに動かないから？→実装バグだった。 ここ あたりが参考になるかも？勾配は必ずしも極値点を向いてない。 →引き続き、LMSの勾配に観測分散行列（ヘッセ行列）の逆行列を掛けたらどうなるか見ていく In [15]: # xtics, ytics で係数を生成してLMSフィルター処理を実行 # 各点における残差と残差勾配を出力 def lms_experience_hessian ( data , xtics , ytics ): zerror = np . zeros (( xtics . size , ytics . size )) zerrorgrad = np . zeros (( xtics . size , ytics . size , 2 )) zerrorgradhessian = np . zeros (( xtics . size , ytics . size , 2 )) H = np . zeros (( 2 , 2 )) for smpl in range ( 2 , data . size , 1 ): xvec = data [ smpl - 2 : smpl ] . reshape (( 2 , 1 )) H += xvec @ xvec . T H /= data . size Hinv = np . linalg . inv ( H ) for x in range ( xtics . size ): for y in range ( ytics . size ): coef = np . array ([ xtics [ x ], ytics [ y ]]) pred = lms_fixcoef ( data , coef ) error = data - pred zerror [ x , y ] = np . sqrt ( np . mean ( error ** 2 )) grad = - 2 * np . array ([ np . mean ( error [ 1 :] * data [ 0 : - 1 ]), np . mean ( error [ 2 :] * data [ 0 : - 2 ])]) zerrorgrad [ x , y , :] = grad zerrorgradhessian [ x , y , :] = ( Hinv @ grad . reshape (( 2 , 1 ))) . reshape ( 2 ) return zerror , zerrorgrad , zerrorgradhessian , Hinv xtics = np . linspace ( - 2 , 3 , 20 ) ytics = np . linspace ( - 2 , 3 , 20 ) # data = lineardata # 特異になる！ data = sindata # あやしい。なぜか(2,-1)付近に集まっとる zerror , zerrorgrad , zerrorgradhessian , Hinv = lms_experience_hessian ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [16]: data = lineardata + gaussnoise zerror , zerrorgrad , zerrorgradhessian , Hinv = lms_experience_hessian ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [17]: data = sindata + gaussnoise zerror , zerrorgrad , zerrorgradhessian , Hinv = lms_experience_hessian ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [18]: data = lineardata + laplacenoise zerror , zerrorgrad , zerrorgradhessian , Hinv = lms_experience_hessian ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [19]: data = sindata + laplacenoise zerror , zerrorgrad , zerrorgradhessian , Hinv = lms_experience_hessian ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () ヘッセ行列を使った時の観察 ノイズがない場合、逆行列が計算できない場合がある。 分散行列が特異になる。見たところ分散行列の全ての要素が同一。 理論的には確かに半正定値までしか保証されていないから、正則ではないのはありえる。 雑音を入れた場合は今の所逆行列が計算できてる。でも、理論上は半正定値なので常に計算できるとは限らず。 サイン波ではノイズなしで逆行列を計算できたけど勾配が(2, -1)付近を向いてる。 ノイズがある場合、全ての勾配が極値点(0.5, 0.5)付近を向いている。 勾配の尾根方向における勾配消失が見られず、純粋に極値からの距離で勾配が決まっている印象がある。 これは最適化で有利に働きそう。 →引き続き、Signed-LMSに対して実験してみる 定義式通りインパルス関数を入れたらどうなってしまうんだろうか…（緊張） In [20]: # 平均0分散varのラプラス分布のP(|x| <= delta)を計算 def laplace_distribution_underdelta ( var , delta ): return 1 - math . exp ( - delta / var ) # ラプラス分布の0とみなす閾値 DELTA = 0.01 # xtics, ytics で係数を生成してLMSフィルター処理を実行 # 各点における残差と残差勾配を出力 def signedlms_experience_hessian ( data , xtics , ytics ): zerror = np . zeros (( xtics . size , ytics . size )) zerrorgrad = np . zeros (( xtics . size , ytics . size , 2 )) zerrorgradhessian = np . zeros (( xtics . size , ytics . size , 2 )) for x in range ( xtics . size ): for y in range ( ytics . size ): coef = np . array ([ xtics [ x ], ytics [ y ]]) pred = lms_fixcoef ( data , coef ) error = data - pred H = np . zeros (( 2 , 2 )) count = 0 for smpl in range ( 2 , data . size , 1 ): xvec = data [ smpl - 2 : smpl ] . reshape (( 2 , 1 )) H += xvec @ xvec . T var = np . mean ( np . abs ( error )) H = H * laplace_distribution_underdelta ( var , DELTA ) / data . size Hinv = np . linalg . inv ( H ) zerror [ x , y ] = np . sqrt ( np . mean ( error ** 2 )) grad = - np . array ([ np . mean ( np . sign ( error [ 1 :]) * data [ 0 : - 1 ]), np . mean ( np . sign ( error [ 2 :]) * data [ 0 : - 2 ])]) zerrorgrad [ x , y , :] = grad zerrorgradhessian [ x , y , :] = ( Hinv @ grad . reshape (( 2 , 1 ))) . reshape ( 2 ) return zerror , zerrorgrad , zerrorgradhessian # data = lineardata # 特異になる！ data = sindata zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [21]: data = lineardata + gaussnoise zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [22]: data = sindata + gaussnoise zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [23]: data = lineardata + laplacenoise zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [24]: data = sindata + laplacenoise zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () SignedLMS・ヘッセ行列を使った時の観察 怪しいけど、残差0のときに和を取るのをやめて、残差0を取る確率で重み付けして分散行列を計算した。 尾根の平坦なところ（画面左上、右下）で大きい勾配が出るようになった。 反面、左下と右上で勾配が小さくなったように見える（大きさは変わってないけど、相対的に小さくなった？） 分散パラメータ0.3は小さすぎる気がする。（残差が0になる確率が0.93と大きすぎる。）離散のスケールにそぐわないような気がする。 はじめから離散スケールで実験を行うべきかも。信号の振幅は[-32768, 32767]とする。 いや、[-1,1]のスケールで、残差0確率が10%になるように分散を設定するのが正しいか。 →連続型確率分布で、残差の絶対値が閾値delta以下になる確率を計算するようにした →実際に学習をシュミレーションしてみる 初期値を色々変えたときにどこに行くか。 ヘッセ行列を使った時に最適値に達する回数は？ In [25]: # LMSフィルター処理 def lms ( data , initcoef , stepsize ): num_samples = data . size filter_order = initcoef . size pred = np . zeros ( num_samples ) error = np . zeros ( num_samples ) coef = initcoef coefhistory = np . zeros (( filter_order , num_samples - filter_order )) for smpl in range ( filter_order , num_samples , 1 ): # 係数保存 coefhistory [:, smpl - filter_order ] = coef # 予測 pred [ smpl ] = np . dot ( coef , data [ smpl - filter_order : smpl ]) # 残差計算 error [ smpl ] = data [ smpl ] - pred [ smpl ] # 係数更新 coef += stepsize * error [ smpl ] * data [ smpl - filter_order : smpl ] return pred , coefhistory def lms_coefhistory_experience ( data , initcoef_list , stepsize ): filter_order = initcoef_list [ 0 ] . size listsize = len ( initcoef_list ) coefhistory = np . zeros (( listsize , filter_order , data . size - filter_order )) predhistory = np . zeros (( listsize , data . size )) for i in range ( listsize ): predhistory [ i ,:], coefhistory [ i ,:,:] = lms ( data , initcoef_list [ i ] . copy (), stepsize ) return predhistory , coefhistory # 係数の軌跡をプロット def plotcoefhistory ( coefhistory ): # plt.plot(coefhistory[0,:], coefhistory[1,:],marker='o') plt . plot ( coefhistory [ 0 ,:], coefhistory [ 1 ,:]) STEPSIZE = 0.05 initcoef_list = [ np . array ([ - 1.5 , - 1.5 ]), np . array ([ 0.5 , - 1.5 ]), np . array ([ 2.5 , - 1.5 ]), np . array ([ 2.5 , 0.5 ]), np . array ([ 2.5 , 2.5 ]), np . array ([ 0.5 , 2.5 ]), np . array ([ - 1.5 , 2.5 ]), np . array ([ - 1.5 , 0.5 ]), ] data = lineardata predhistory , coefhistory = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) zerror , zerrorgrad = lms_experience ( data , xtics , ytics ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgrad ) plt . show () In [26]: data = sindata _ , coefhistory = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) zerror , zerrorgrad = lms_experience ( data , xtics , ytics ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgrad ) plt . show () In [27]: data = lineardata + gaussnoise _ , coefhistory = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) zerror , zerrorgrad = lms_experience ( data , xtics , ytics ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgrad ) plt . show () In [28]: data = sindata + gaussnoise _ , coefhistory = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) zerror , zerrorgrad = lms_experience ( data , xtics , ytics ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgrad ) plt . show () In [29]: data = lineardata + laplacenoise _ , coefhistory = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) zerror , zerrorgrad = lms_experience ( data , xtics , ytics ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgrad ) plt . show () In [30]: data = sindata + laplacenoise _ , coefhistory = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) zerror , zerrorgrad = lms_experience ( data , xtics , ytics ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgrad ) plt . show () In [31]: # Sined-LMSフィルター処理 def signedlms ( data , initcoef , stepsize ): num_samples = data . size filter_order = initcoef . size pred = np . zeros ( num_samples ) error = np . zeros ( num_samples ) coef = initcoef coefhistory = np . zeros (( filter_order , num_samples - filter_order )) for smpl in range ( filter_order , num_samples , 1 ): # 係数保存 coefhistory [:, smpl - filter_order ] = coef # 予測 pred [ smpl ] = np . dot ( coef , data [ smpl - filter_order : smpl ]) # 残差計算 error [ smpl ] = data [ smpl ] - pred [ smpl ] # 係数更新 coef += stepsize * np . sign ( error [ smpl ]) * data [ smpl - filter_order : smpl ] return pred , coefhistory def signedlms_coefhistory_experience ( data , initcoef_list , stepsize ): filter_order = initcoef_list [ 0 ] . size listsize = len ( initcoef_list ) coefhistory = np . zeros (( listsize , filter_order , data . size - filter_order )) predhistory = np . zeros (( listsize , data . size )) for i in range ( listsize ): predhistory [ i ,:], coefhistory [ i ,:,:] = signedlms ( data , initcoef_list [ i ] . copy (), stepsize ) return predhistory , coefhistory SIGNEDLMS_STEPSIZE = 0.1 data = lineardata _ , coefhistory = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) zerror , zerrorgrad = signedlms_experience ( data , xtics , ytics ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgrad ) plt . show () In [32]: data = sindata _ , coefhistory = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) zerror , zerrorgrad = signedlms_experience ( data , xtics , ytics ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgrad ) plt . show () In [33]: data = lineardata + gaussnoise _ , coefhistory = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) zerror , zerrorgrad = signedlms_experience ( data , xtics , ytics ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgrad ) plt . show () In [34]: data = sindata + gaussnoise _ , coefhistory = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) zerror , zerrorgrad = signedlms_experience ( data , xtics , ytics ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgrad ) plt . show () In [35]: data = lineardata + laplacenoise _ , coefhistory = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) zerror , zerrorgrad = signedlms_experience ( data , xtics , ytics ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgrad ) plt . show () In [36]: data = sindata + laplacenoise _ , coefhistory = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) zerror , zerrorgrad = signedlms_experience ( data , xtics , ytics ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgrad ) plt . show () 最急降下法による学習の観察 （もう色んな所でしてるけど、改めて） 一旦裾野が広い方に行ってから、極値を目指しているように見える。 Sign-LMSはLMSと同一のステップサイズでも振動しがち。 Sign-LMSの方は極値付近でふらつく（LMSは極値付近では動かない） Sign-LMSは勾配が消えにくいから。 →次はヘッセ行列の逆行列で勾配を修正した場合の挙動を見る In [37]: # Hessian-LMSフィルター処理 def hessianlms ( data , initcoef , stepsize ): num_samples = data . size filter_order = initcoef . size pred = np . zeros ( num_samples ) error = np . zeros ( num_samples ) coef = initcoef coefhistory = np . zeros (( filter_order , num_samples - filter_order )) S = np . eye ( 2 ) for smpl in range ( filter_order , num_samples , 1 ): # 係数保存 coefhistory [:, smpl - filter_order ] = coef # 予測 pred [ smpl ] = np . dot ( coef , data [ smpl - filter_order : smpl ]) # 残差計算 error [ smpl ] = data [ smpl ] - pred [ smpl ] # 観測データのベクトル化 vdata = data [ smpl - filter_order : smpl ] . reshape (( filter_order , 1 )) # 勾配 grad = error [ smpl ] * vdata # 分散（情報）行列 S += vdata @ vdata . T # ヘッセ行列の逆行列を更新 Hinv = np . linalg . inv ( S / ( smpl - filter_order + 1 )) # 係数更新 coef += stepsize * ( Hinv @ grad ) . flatten () return pred , coefhistory def hessianlms_coefhistory_experience ( data , initcoef_list , stepsize ): filter_order = initcoef_list [ 0 ] . size listsize = len ( initcoef_list ) coefhistory = np . zeros (( listsize , filter_order , data . size - filter_order )) predhistory = np . zeros (( listsize , data . size )) for i in range ( listsize ): predhistory [ i ,:], coefhistory [ i ,:,:] = hessianlms ( data , initcoef_list [ i ] . copy (), stepsize ) return predhistory , coefhistory data = sindata hessian_predhistory , coefhistory = hessianlms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian , _ = lms_experience_hessian ( data , xtics , ytics ) predhistory , _ = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [38]: data = lineardata + gaussnoise hessian_predhistory , coefhistory = hessianlms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian , _ = lms_experience_hessian ( data , xtics , ytics ) predhistory , _ = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [39]: data = sindata + gaussnoise hessian_predhistory , coefhistory = hessianlms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian , _ = lms_experience_hessian ( data , xtics , ytics ) predhistory , _ = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [40]: data = lineardata + laplacenoise hessian_predhistory , coefhistory = hessianlms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian , _ = lms_experience_hessian ( data , xtics , ytics ) predhistory , _ = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [41]: data = sindata + laplacenoise hessian_predhistory , coefhistory = hessianlms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian , _ = lms_experience_hessian ( data , xtics , ytics ) predhistory , _ = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [:])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [:])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () ヘッセ行列込みのLMSで気付いたこと 解の軌跡が収束している。 雑音で揺れているものの、尾根に引っかからず、極小点(0.5, 0.5)にまっすぐ向かっているように見える。 こころなしか収束が早い（まだ要観察。数回の試行の平均軌跡を見れば良い？） 定式化の再確認 入力データに雑音が乗ってる。 本来の定式化では、雑音は入力と独立に乗るはず。 <今、上で実験しているもの> 雑音------- ↓ 入力 --> + --> <システム> --> 観測出力 <雑音が後で入るもの> 雑音------------------------- ↓ 入力 --> <システム> --> + --> 観測出力 意図したものにならないと、システムは雑音に対しても係数を畳み込んでしまうから雑音と相関を持つのでは？ →下で実験までしたけど、雑音が後に入るのは間違っていそう。観測できる入力には雑音が乗っている。観測とフィルタを畳みこむ必要がある。 In [42]: # LMSフィルター処理（リファレンス出力に対する等化） def lmsref ( reference , data , initcoef , stepsize ): num_samples = data . size filter_order = initcoef . size pred = np . zeros ( num_samples ) error = np . zeros ( num_samples ) coef = initcoef coefhistory = np . zeros (( filter_order , num_samples - filter_order )) for smpl in range ( filter_order , num_samples , 1 ): # 係数保存 coefhistory [:, smpl - filter_order ] = coef # 予測 pred [ smpl ] = np . dot ( coef , data [ smpl - filter_order : smpl ]) # 残差計算 error [ smpl ] = reference [ smpl ] - pred [ smpl ] # 係数更新 coef += stepsize * error [ smpl ] * data [ smpl - filter_order : smpl ] return pred , coefhistory def lmsref_coefhistory_experience ( reference , data , initcoef_list , stepsize ): filter_order = initcoef_list [ 0 ] . size listsize = len ( initcoef_list ) coefhistory = np . zeros (( listsize , filter_order , data . size - filter_order )) predhistory = np . zeros (( listsize , data . size )) for i in range ( listsize ): predhistory [ i ,:], coefhistory [ i ,:,:] = lmsref ( reference , data , initcoef_list [ i ] . copy (), stepsize ) return predhistory , coefhistory data = lineardata reference = data predhistory , coefhistory = lmsref_coefhistory_experience ( reference , data , initcoef_list , STEPSIZE ) zerror , zerrorgrad = lms_experience ( data , xtics , ytics ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgrad ) plt . show () 雑音をフィルタ出力に入れた場合の考察 入力に雑音が入らないので、最適解が(0.5, 0.5)ではなくなった。 Wikipedia 読んだら雑音をあとに入れるのはカンニングに当たる事がわかった。（つまり、実装は正しくない。ただし、等価器を事前学習する場合は話が別。） →雑音はフィルタ入力に加えるようにして、引き続きSignedLMSの実験。 In [43]: # Hessian-SignedLMSフィルター処理 def hessiansignedlms ( data , initcoef , stepsize ): num_samples = data . size filter_order = initcoef . size pred = np . zeros ( num_samples ) error = np . zeros ( num_samples ) coef = initcoef coefhistory = np . zeros (( filter_order , num_samples - filter_order )) S = np . eye ( 2 ) Hinv = np . eye ( 2 ) for smpl in range ( filter_order , num_samples , 1 ): # 係数保存 coefhistory [:, smpl - filter_order ] = coef # 予測 pred [ smpl ] = np . dot ( coef , data [ smpl - filter_order : smpl ]) # 残差計算 error [ smpl ] = data [ smpl ] - pred [ smpl ] # 観測データのベクトル化 vdata = data [ smpl - filter_order : smpl ] . reshape (( filter_order , 1 )) # 勾配 grad = np . sign ( error [ smpl ]) * vdata # 確率で重み付けした情報行列の計算 errvar = np . abs ( error [ smpl ]) # ヘッセ行列の逆行列を更新 hgrad = Hinv @ grad tau = np . max ([ 1 / ( smpl - filter_order + 1 ), 0.01 ]) Hinv += tau * ( Hinv - ( hgrad @ hgrad . T ) * laplace_distribution_underdelta ( errvar , DELTA )) coef += stepsize * hgrad . flatten () # S += (vdata @ vdata.T) * laplace_distribution_underdelta(errvar, DELTA) # Hinv = np.linalg.inv(S / (smpl - filter_order + 1)) # 係数更新 # coef += stepsize * (Hinv @ grad).flatten() return pred , coefhistory def hessiansignedlms_coefhistory_experience ( data , initcoef_list , stepsize ): filter_order = initcoef_list [ 0 ] . size listsize = len ( initcoef_list ) coefhistory = np . zeros (( listsize , filter_order , data . size - filter_order )) predhistory = np . zeros (( listsize , data . size )) for i in range ( listsize ): predhistory [ i ,:], coefhistory [ i ,:,:] = hessiansignedlms ( data , initcoef_list [ i ] . copy (), stepsize ) return predhistory , coefhistory HESSIANSIGNEDLMS_STEPSIZE = SIGNEDLMS_STEPSIZE / 50 data = sindata hessian_predhistory , coefhistory = hessiansignedlms_coefhistory_experience ( data , initcoef_list , HESSIANSIGNEDLMS_STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) predhistory , _ = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () ステップサイズを小さく取ったら発散しなくなった。 NLMSみたくステップサイズの収束が保証されている範囲を知りたい。 In [44]: data = lineardata + gaussnoise hessian_predhistory , coefhistory = hessiansignedlms_coefhistory_experience ( data , initcoef_list , HESSIANSIGNEDLMS_STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) predhistory , _ = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [45]: data = sindata + gaussnoise hessian_predhistory , coefhistory = hessiansignedlms_coefhistory_experience ( data , initcoef_list , HESSIANSIGNEDLMS_STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) predhistory , _ = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [46]: data = lineardata + laplacenoise hessian_predhistory , coefhistory = hessiansignedlms_coefhistory_experience ( data , initcoef_list , HESSIANSIGNEDLMS_STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) predhistory , _ = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [47]: data = sindata + laplacenoise hessian_predhistory , coefhistory = hessiansignedlms_coefhistory_experience ( data , initcoef_list , HESSIANSIGNEDLMS_STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) predhistory , _ = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [:])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [:])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () 所感 ふらつきが無くなったけど、収束は普通のSigned-LMSよりもおそいように見える。 おおむねええ感じ。さて、本当にこれが既存でないのか確かめるべきでは？ 有効性にあたり気になるところ LMSのヘッセ行列（確率による重み付けをしない）でいいんじゃないの？→軽く試したら全く収束しない。要精査。 エントロピーや誤差はLMSより良いの？ 情報行列の逆行列を誤っていたので再計算 データベクトルの分散行列を計算していた。これは間違いで、勾配ベクトルの分散行列が正しい。 In [48]: # xtics, ytics で係数を生成してLMSフィルター処理を実行 # 各点における残差と残差勾配を出力 def lms_experience_hessian_fix ( data , xtics , ytics ): zerror = np . zeros (( xtics . size , ytics . size )) zerrorgrad = np . zeros (( xtics . size , ytics . size , 2 )) zerrorgradhessian = np . zeros (( xtics . size , ytics . size , 2 )) H = np . zeros (( 2 , 2 )) for x in range ( xtics . size ): for y in range ( ytics . size ): coef = np . array ([ xtics [ x ], ytics [ y ]]) pred = lms_fixcoef ( data , coef ) error = data - pred for smpl in range ( 2 , data . size , 1 ): grad = error [ smpl ] * data [ smpl - 2 : smpl ] . reshape (( 2 , 1 )) H += grad @ grad . T H /= data . size Hinv = np . linalg . inv ( H ) zerror [ x , y ] = np . sqrt ( np . mean ( error ** 2 )) grad = - 2 * np . array ([ np . mean ( error [ 1 :] * data [ 0 : - 1 ]), np . mean ( error [ 2 :] * data [ 0 : - 2 ])]) zerrorgrad [ x , y , :] = grad zerrorgradhessian [ x , y , :] = ( Hinv @ grad . reshape (( 2 , 1 ))) . reshape ( 2 ) return zerror , zerrorgrad , zerrorgradhessian xtics = np . linspace ( - 2 , 3 , 20 ) ytics = np . linspace ( - 2 , 3 , 20 ) # data = lineardata # 特異になる！ data = sindata # あやしい。なぜか(2,-1)付近に集まっとる zerror , zerrorgrad , zerrorgradhessian = lms_experience_hessian_fix ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [49]: data = lineardata + gaussnoise zerror , zerrorgrad , zerrorgradhessian = lms_experience_hessian_fix ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [50]: data = sindata + gaussnoise zerror , zerrorgrad , zerrorgradhessian = lms_experience_hessian_fix ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [51]: data = lineardata + laplacenoise zerror , zerrorgrad , zerrorgradhessian = lms_experience_hessian_fix ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [52]: data = sindata + laplacenoise zerror , zerrorgrad , zerrorgradhessian = lms_experience_hessian_fix ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () 所感 平らなところで急激な勾配を示すようになった。 もともと急激な勾配があるところの勾配が消滅。 このままSigned-LMSの検算も行っていくが、おそらく同一の結果になると思われる。 なぜなら、Singned-LMSの勾配はsign(err) dataだからで、(勾配 勾配転置)を計算すると、それはデータの分散行列を求めているのと全くおなじになる。理論はともあれもう一度検算。 In [53]: # xtics, ytics で係数を生成してSignedLMSフィルター処理を実行 # 各点における残差と残差勾配を出力 def signedlms_experience_hessian_fix ( data , xtics , ytics ): zerror = np . zeros (( xtics . size , ytics . size )) zerrorgrad = np . zeros (( xtics . size , ytics . size , 2 )) zerrorgradhessian = np . zeros (( xtics . size , ytics . size , 2 )) H = np . zeros (( 2 , 2 )) for x in range ( xtics . size ): for y in range ( ytics . size ): coef = np . array ([ xtics [ x ], ytics [ y ]]) pred = lms_fixcoef ( data , coef ) error = data - pred for smpl in range ( 2 , data . size , 1 ): grad = np . sign ( error [ smpl ]) * data [ smpl - 2 : smpl ] . reshape (( 2 , 1 )) H += grad @ grad . T H /= data . size Hinv = np . linalg . inv ( H ) zerror [ x , y ] = np . sqrt ( np . mean ( error ** 2 )) grad = - 2 * np . array ([ np . mean ( error [ 1 :] * data [ 0 : - 1 ]), np . mean ( error [ 2 :] * data [ 0 : - 2 ])]) zerrorgrad [ x , y , :] = grad zerrorgradhessian [ x , y , :] = ( Hinv @ grad . reshape (( 2 , 1 ))) . reshape ( 2 ) return zerror , zerrorgrad , zerrorgradhessian xtics = np . linspace ( - 2 , 3 , 20 ) ytics = np . linspace ( - 2 , 3 , 20 ) # data = lineardata # 特異になる！ data = sindata # あやしい。なぜか(2,-1)付近に集まっとる zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian_fix ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [54]: data = lineardata + gaussnoise zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian_fix ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [55]: data = sindata + gaussnoise zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian_fix ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [56]: data = lineardata + laplacenoise zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian_fix ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () In [57]: data = sindata + laplacenoise zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian_fix ( data , xtics , ytics ) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Hessian Gradient' , xtics , ytics , zerrorgradhessian ) plt . title ( 'Error and Hessian Error Gradient' ) plt . show () 自然勾配を使ったLMSアルゴリズムに誤りを見つけたので修正して実験し直し。 In [58]: # Hessian-LMSフィルター処理 def hessianlms_fix ( data , initcoef , stepsize ): num_samples = data . size filter_order = initcoef . size pred = np . zeros ( num_samples ) error = np . zeros ( num_samples ) coef = initcoef coefhistory = np . zeros (( filter_order , num_samples - filter_order )) S = np . eye ( 2 ) for smpl in range ( filter_order , num_samples , 1 ): # 係数保存 coefhistory [:, smpl - filter_order ] = coef # 予測 pred [ smpl ] = np . dot ( coef , data [ smpl - filter_order : smpl ]) # 残差計算 error [ smpl ] = data [ smpl ] - pred [ smpl ] # 観測データのベクトル化 vdata = data [ smpl - filter_order : smpl ] . reshape (( filter_order , 1 )) # 勾配 grad = error [ smpl ] * vdata # 経験フィッシャー情報行列に加算 S += grad @ grad . T # 経験フィッシャー情報行列の逆行列を更新 Hinv = np . linalg . inv ( S / ( smpl - filter_order + 1 )) # 係数更新 coef += stepsize * ( Hinv @ grad ) . flatten () return pred , coefhistory def hessianlms_coefhistory_experience_fix ( data , initcoef_list , stepsize ): filter_order = initcoef_list [ 0 ] . size listsize = len ( initcoef_list ) coefhistory = np . zeros (( listsize , filter_order , data . size - filter_order )) predhistory = np . zeros (( listsize , data . size )) for i in range ( listsize ): predhistory [ i ,:], coefhistory [ i ,:,:] = hessianlms_fix ( data , initcoef_list [ i ] . copy (), stepsize ) return predhistory , coefhistory data = sindata hessian_predhistory , coefhistory = hessianlms_coefhistory_experience_fix ( data , initcoef_list , 0.05 ) zerror , zerrorgrad , zerrorgradhessian = lms_experience_hessian_fix ( data , xtics , ytics ) predhistory , _ = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [59]: data = lineardata + gaussnoise hessian_predhistory , coefhistory = hessianlms_coefhistory_experience_fix ( data , initcoef_list , 0.05 ) zerror , zerrorgrad , zerrorgradhessian = lms_experience_hessian_fix ( data , xtics , ytics ) predhistory , _ = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [60]: data = sindata + gaussnoise hessian_predhistory , coefhistory = hessianlms_coefhistory_experience_fix ( data , initcoef_list , 0.03 ) zerror , zerrorgrad , zerrorgradhessian = lms_experience_hessian_fix ( data , xtics , ytics ) predhistory , _ = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [61]: data = lineardata + laplacenoise hessian_predhistory , coefhistory = hessianlms_coefhistory_experience_fix ( data , initcoef_list , 0.02 ) zerror , zerrorgrad , zerrorgradhessian = lms_experience_hessian_fix ( data , xtics , ytics ) predhistory , _ = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [62]: data = sindata + laplacenoise hessian_predhistory , coefhistory = hessianlms_coefhistory_experience_fix ( data , initcoef_list , 0.02 ) zerror , zerrorgrad , zerrorgradhessian = lms_experience_hessian_fix ( data , xtics , ytics ) predhistory , _ = lms_coefhistory_experience ( data , initcoef_list , STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () 修正版実装の所感 勾配が小さい領域（左下と右上）が初期値だと学習が遅い。 逆に、裾野が広い領域では学習が早く進む。（早すぎて極値付近で振動しているように見える） 続いて、SignedLMSの自然勾配を試す。 In [63]: # Hessian-SignedLMSフィルター処理 def hessiansignedlms_fix ( data , initcoef , stepsize ): num_samples = data . size filter_order = initcoef . size pred = np . zeros ( num_samples ) error = np . zeros ( num_samples ) coef = initcoef coefhistory = np . zeros (( filter_order , num_samples - filter_order )) S = np . eye ( 2 ) Hinv = np . eye ( 2 ) for smpl in range ( filter_order , num_samples , 1 ): # 係数保存 coefhistory [:, smpl - filter_order ] = coef # 予測 pred [ smpl ] = np . dot ( coef , data [ smpl - filter_order : smpl ]) # 残差計算 error [ smpl ] = data [ smpl ] - pred [ smpl ] # 観測データのベクトル化 vdata = data [ smpl - filter_order : smpl ] . reshape (( filter_order , 1 )) # 勾配 grad = np . sign ( error [ smpl ]) * vdata # 確率で重み付けした情報行列の計算 # errvar = np.abs(error[smpl]) # ヘッセ行列の逆行列を更新 # hgrad = Hinv @ grad # tau = np.max([1 / (smpl - filter_order + 1), 0.01]) # Hinv += tau * (Hinv - (hgrad @ hgrad.T) * laplace_distribution_underdelta(errvar, DELTA)) # coef += stepsize * hgrad.flatten() S += vdata @ vdata . T Hinv = np . linalg . inv ( S / ( smpl - filter_order + 1 )) # 係数更新 coef += stepsize * ( Hinv @ grad ) . flatten () return pred , coefhistory def hessiansignedlms_coefhistory_experience ( data , initcoef_list , stepsize ): filter_order = initcoef_list [ 0 ] . size listsize = len ( initcoef_list ) coefhistory = np . zeros (( listsize , filter_order , data . size - filter_order )) predhistory = np . zeros (( listsize , data . size )) for i in range ( listsize ): predhistory [ i ,:], coefhistory [ i ,:,:] = hessiansignedlms ( data , initcoef_list [ i ] . copy (), stepsize ) return predhistory , coefhistory HESSIANSIGNEDLMS_STEPSIZE = SIGNEDLMS_STEPSIZE / 50 data = sindata hessian_predhistory , coefhistory = hessiansignedlms_coefhistory_experience ( data , initcoef_list , HESSIANSIGNEDLMS_STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) predhistory , _ = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [64]: data = lineardata + gaussnoise hessian_predhistory , coefhistory = hessiansignedlms_coefhistory_experience ( data , initcoef_list , HESSIANSIGNEDLMS_STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) predhistory , _ = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [65]: data = sindata + gaussnoise hessian_predhistory , coefhistory = hessiansignedlms_coefhistory_experience ( data , initcoef_list , HESSIANSIGNEDLMS_STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) predhistory , _ = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [66]: data = lineardata + laplacenoise hessian_predhistory , coefhistory = hessiansignedlms_coefhistory_experience ( data , initcoef_list , HESSIANSIGNEDLMS_STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) predhistory , _ = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () In [67]: data = sindata + laplacenoise hessian_predhistory , coefhistory = hessiansignedlms_coefhistory_experience ( data , initcoef_list , HESSIANSIGNEDLMS_STEPSIZE ) zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian ( data , xtics , ytics ) predhistory , _ = signedlms_coefhistory_experience ( data , initcoef_list , SIGNEDLMS_STEPSIZE ) for i in range ( len ( initcoef_list )): plotcoefhistory ( coefhistory [ i ]) ploterror ( 'Error' , xtics , ytics , zerror ) plotgradient ( 'Gradient' , xtics , ytics , zerrorgradhessian ) plt . show () for i in range ( len ( initcoef_list )): error = predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () for i in range ( len ( initcoef_list )): error = hessian_predhistory [ i ,:] - data plt . plot ( np . abs ( error [: 400 ])) plt . show () plt . hist (( predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . hist (( hessian_predhistory - data ) . flatten (), bins = 500 , histtype = 'step' ) plt . show () 所感 残差の分布としてはいい感じ。ナイーブなSignedLMSよりは良い。 左下と右上のように、最初の収束が遅い場合がある。 学習率を大きめにすると発散するケース多数。 正則化（分散行列に係数*単位行列を加算）かけたほうがいいかもしれない。 しかしそうした場合の更新式がどうなるか…。 情報共有用のデータプロット In [103]: data = sindata + laplacenoise zerror , zerrorgrad , zerrorgradhessian = signedlms_experience_hessian_fix ( data , xtics , ytics ) plt . plot ( data ) plt . title ( 'Input data' ) plt . savefig ( 'sin_laplace_input.png' ) plt . show () xmesh , ymesh = np . meshgrid ( xtics , ytics ) plt . figure ( figsize = ( 10 , 6 )) plt . contour ( xmesh , ymesh , zerror , levels = np . linspace ( 0.0 , 3.0 , 10 ) . tolist (), linestyles = 'dashed' ) plt . colorbar ( label = 'Error' ) plt . quiver ( xmesh , ymesh , zerrorgrad [:,:, 0 ], zerrorgrad [:,:, 1 ], label = 'SignedLMS Gradient' , color = 'black' ) plt . xlabel ( 'h0' ) plt . ylabel ( 'h1' ) plt . legend () plt . title ( 'Error and Gradient' ) plt . savefig ( 'error_and_gradient.png' ) plt . show () plt . figure ( figsize = ( 10 , 6 )) plt . contour ( xmesh , ymesh , zerror , levels = np . linspace ( 0.0 , 3.0 , 10 ) . tolist (), linestyles = 'dashed' ) plt . colorbar ( label = 'Error' ) plt . quiver ( xmesh , ymesh , zerrorgrad [:,:, 0 ], zerrorgrad [:,:, 1 ], label = 'SignedLMS Gradient' , color = 'black' ) plt . quiver ( xmesh , ymesh , zerrorgradhessian [:,:, 0 ], zerrorgradhessian [:,:, 1 ], label = 'SignedLMS Natural Gradient' , color = 'red' ) plt . xlabel ( 'h0' ) plt . ylabel ( 'h1' ) plt . legend () plt . title ( 'Error and Gradient' ) plt . savefig ( 'error_and_natural_gradient.png' ) plt . show () In [ ]: In [ ]:","tags":"実験","url":"/lms-signed-lmsnoju-dong-guan-cha.html","loc":"/lms-signed-lmsnoju-dong-guan-cha.html"},{"title":"LMS Filterの挙動観察","text":"\\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\end{equation*} 今日はJupyterを使って残差・残差勾配を観察していく。もう夜遅いのでnotebook上げるの挑戦できず。 勾配の計算にミスがあり、残差分布と勾配の結果が一致していなかった…3時間ほど飛ばす。 ラプラス分布の観測分散が怪しい... Deriving Mean and Variance of Laplace Distribution に1次元の場合がある。","tags":"雑記","url":"/lms-filternoju-dong-guan-cha.html","loc":"/lms-filternoju-dong-guan-cha.html"},{"title":"古い記事の移行/Jupyterの環境整備","text":"評価の前に古い記事の移行とPythonの環境整備。 PythonはJupyterを使う。Vimキーバインドで。 Jupyterコマンドモードのショートカットキーまとめ がよくまとまっていた。これ読んで進めていく。","tags":"雑記","url":"/gu-iji-shi-noyi-xing-jupyternohuan-jing-zheng-bei.html","loc":"/gu-iji-shi-noyi-xing-jupyternohuan-jing-zheng-bei.html"},{"title":"デジタル信号処理の礎","text":"まえがき 本稿はデジタル信号処理の礎となる理論を固めるべく書かれた。 \\begin{equation*} \\def\\vector#1{\\mbox{\\boldmath $#1$}} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand{\\rev}[1]{\\frac{1}{#1}} \\newcommand{\\pdiff}[2]{\\frac{\\partial #1}{\\partial #2}} \\newcommand{\\ddiff}[2]{\\frac{d#1}{d#2}} \\newcommand{\\vvec}[1]{\\left[\\begin{array}{c}#1\\end{array}\\right]} \\newcommand{\\dmatrix}[2]{\\left|\\begin{array}{#1}#2\\end{array}\\right|} \\newcommand{\\inversion}[1]{#1&#94;{\\!\\mbox{\\sf\\tiny T}}} \\newcommand{\\ifdiv}[2]{\\left\\{\\begin{array}{#1}#2\\end{array}\\right.} \\end{equation*} フーリエ変換について フーリエ変換が天下りに与えられて次の言明に対して違和感を抱いたことは無いだろうか？ 任意の周期関数は三角関数の和で表現できる といった手合いである。この言明に対しては、次の疑問が浮かぶかもしれない: 任意の周期関数に対して成り立つのか？ 何故三角関数を用いる必要があるのか？三角関数である必然性は？ 本稿では、この疑問に対して数学的に一応の解答を与えたい。細かい解説は後にして、解答としては次の様になる。 任意の区分的になめらかな周期関数は三角関数の和で表現できる 三角関数は連続関数を表現できる能力を持っている 以下、これらの項目の証明を試みる。 関数はベクトル 形式的に見れば、 関数はベクトル である。関数は入力と出力を決める規則であることから、 式1 の様に、その出力を並べることで、関数をベクトルとして見ることが出来る。 \\begin{align*} f(x) = \\vvec{ f(-\\infty) \\\\ \\vdots \\\\ f(0) \\\\ \\vdots \\\\ f(\\infty) } \\tag{1} \\end{align*} 関数をベクトルとみなすと、そこに線型代数の知見を持ち込むことができる。まず、関数による基底（関数基底）によって空間を張ることができる。関数によって張られた空間は特に 関数空間 と呼ばれる。 また、2つの関数 \\(f,g\\) の 内積 \\(\\innerp{f}{g}\\) を式 式2 の様に積分を用いて表すことが出来る。 \\begin{align*} \\innerp{f}{g} &= \\left[ f(-L) \\dots f(0) \\dots f(L) \\right] \\vvec{ g(-L) \\\\ \\vdots \\\\ g(0) \\\\ \\vdots \\\\ g(L) } \\\\ &= f(-L)g(-L) + \\dots + f(0)g(0) + \\dots + f(L)g(L) \\\\ &= \\int_{-L}&#94;{L} f(x)g(x) dx \\tag{2} \\end{align*} ここで \\(L\\) は積分範囲を決める定数である [1] 。また、関数自分自身の内積 \\(\\innerp{f}{f}\\) を ノルム という [2] 。 [1] 形式的に見た際には積分範囲は無限 \\([-\\infty,\\infty]\\) になることが多いが、定数関数同士の内積を考えれば分かるように、内積値が発散してしまう場合がある。その場合は、積分範囲を限定して議論を行う。 [2] \\(L\\) に基づいてノルム値を \\(1\\) にする操作を行うことがある。この操作を 正規化 という。 三角関数の直交性 関数をベクトルとして考えた時、異なる周波数を持つ三角関数は互いに直交（ \\(\\iff\\) 内積値が \\(0\\) になる）する。この事を計算により確かめていく。 尚、内積計算時の積分範囲は全て \\([-\\pi, \\pi]\\) とする。何故なら、周期関数が直交しているかどうかを判定するには1周期分の内積を取り、その結果が \\(0\\) になるかどうかを見れば良いからである。またその周期は、周波数を決める定数は全て整数であることにより決まり、最長の周波数は \\(\\sin(x), \\cos(x)\\) が持つ \\(2\\pi\\) である。積分範囲を \\([-\\pi, \\pi]\\) とすれば、一番長い周期を加味して内積を計算できる。 正弦波（sin）の直交性 素直に内積を計算する。三角関数の和の公式 \\begin{align*} \\cos\\{(n+m)x\\} &= \\cos(nx)\\cos(mx) - \\sin(nx)\\sin(mx) \\\\ \\cos\\{(n-m)x\\} &= \\cos(nx)\\cos(mx) + \\sin(nx)\\sin(mx) \\\\ \\implies \\sin(nx)\\sin(mx) &= \\frac{\\cos\\{(n-m)x\\} - \\cos\\{(n+m)x\\}}{2} \\end{align*} を用いて \\(\\sin\\) の積を \\(\\cos\\) の和に分割して積分を行うのがポイントである。 \\begin{align*} \\innerp{\\sin(nx)}{\\sin(mx)} &= \\int_{-\\pi}&#94;{\\pi} \\sin(nx) \\sin(mx) dx \\\\ &= \\int_{-\\pi}&#94;{\\pi} \\frac{\\cos\\{(n-m)x\\} - \\cos\\{(n+m)x\\}}{2} dx \\\\ &= \\frac{1}{2(n-m)} \\left[ \\sin\\{(n-m)x\\} \\right]_{-\\pi}&#94;{\\pi} - \\frac{1}{2(n+m)} \\left[ \\sin\\{(n+m)x\\} \\right]_{-\\pi}&#94;{\\pi} \\\\ &= \\frac{1}{2(n-m)} \\left[ \\sin\\{(n-m)\\pi\\} - \\sin\\{-(n-m)\\pi\\} \\right] - \\frac{1}{2(n+m)} \\left[ \\sin\\{(n+m)\\pi\\} - \\sin\\{-(n+m)\\pi\\} \\right] \\\\ &= \\frac{\\sin\\{(n-m)\\pi\\}}{n-m} - \\frac{\\sin\\{(n+m)\\pi\\}}{n+m} \\end{align*} ここで、最後の結果の右辺第二項は、 \\(n+m\\) が整数になることから \\(0\\) になる。一方の右辺第一項は \\(n \\neq m\\) の時は右辺第二項と同様に \\(0\\) となる。 \\(n = m\\) の時は、 \\(n-m \\to 0\\) なる極限を考えることで計算結果が確かめられる: \\begin{align*} \\lim_{(n-m) \\to 0} \\frac{\\sin\\{(n-m)\\pi\\}}{n-m} &= \\lim_{\\alpha \\to 0} \\frac{\\sin\\alpha\\pi}{\\alpha} \\\\ &= \\lim_{\\alpha \\to 0} \\frac{\\ddiff{\\sin\\alpha\\pi}{\\alpha}}{\\ddiff{\\alpha}{\\alpha}} = \\lim_{\\alpha \\to 0} \\pi \\cos\\alpha\\pi \\\\ &= \\pi \\tag{3} \\end{align*} 以上の結果をまとめると、 \\begin{align*} \\innerp{\\sin(nx)}{\\sin(mx)} = \\ifdiv{cc}{ 0 & (n \\neq m) \\\\ \\pi & (n = m) } \\tag{4} \\end{align*} この結果は、2つの意味で重要である。 （今確かめている様に、）異なる周波数を持つ正弦波は互いに直交する。 \\(n=m\\) の時の結果は、 \\(\\sin\\) のノルム値は \\(\\pi\\) であることを示している。 余弦波（cos）の直交性 計算方針は \\(\\sin\\) の時と同様である。三角関数の和の公式より、 \\begin{equation*} \\cos(mx)\\cos(nx) = \\frac{\\cos\\{(n-m)x\\} + \\cos\\{(n+m)x\\}}{2} \\end{equation*} が成立するため、 \\begin{align*} \\innerp{\\cos(nx)}{\\cos(mx)} &= \\int_{-\\pi}&#94;{\\pi} \\cos(nx) \\cos(mx) dx \\\\ &= \\int_{-\\pi}&#94;{\\pi} \\frac{\\cos\\{(n-m)x\\} + \\cos\\{(n+m)x\\}}{2} dx \\\\ &= \\frac{1}{2(n-m)} \\left[ \\sin\\{(n-m)\\pi\\} - \\sin\\{-(n-m)\\pi\\} \\right] + \\frac{1}{2(n+m)} \\left[ \\sin\\{(n+m)\\pi\\} - \\sin\\{-(n+m)\\pi\\} \\right] \\\\ &= \\frac{\\sin\\{(n-m)\\pi\\}}{n-m} + \\frac{\\sin\\{(n+m)\\pi\\}}{n+m} \\end{align*} と、 \\(\\sin\\) の内積計算時とほぼ同様の結果が得られる。最終結果の第一項に関しては式 式3 と同様に考えることで、次の結果が得られる。 \\begin{align*} \\innerp{\\cos(nx)}{\\cos(mx)} = \\ifdiv{cc}{ 0 & (n \\neq m) \\\\ \\pi & (n = m) } \\tag{5} \\end{align*} \\(\\cos\\) のノルムも \\(\\sin\\) と同様 \\(\\pi\\) であることが示されている。 正弦波と余弦波の直交性 最後に \\(\\sin\\) と \\(\\cos\\) の直交性を確かめる。 三角関数の和の公式により、 \\begin{align*} \\sin\\{(n+m)x\\} &= \\sin(nx)\\cos(mx) + \\cos(nx)\\sin(mx) \\\\ \\sin\\{(n-m)x\\} &= \\sin(nx)\\cos(mx) - \\cos(nx)\\sin(mx) \\\\ \\implies \\sin(nx)\\cos(mx) &= \\frac{\\sin\\{(n+m)x\\} + \\sin\\{(n-m)x\\}}{2} \\end{align*} が成立するため、 \\begin{align*} \\innerp{\\sin(mx)}{\\cos(mx)} &= \\int_{-\\pi}&#94;{\\pi} \\sin(nx) \\cos(mx) dx \\\\ &= \\int_{-\\pi}&#94;{\\pi} \\frac{\\sin\\{(n+m)x\\} + \\sin\\{(n-m)x\\}}{2} dx \\\\ &= \\frac{1}{2(n+m)} \\left[ \\cos\\{(n+m)\\pi\\} - \\cos\\{-(n+m)\\pi\\} \\right] + \\frac{1}{2(n-m)} \\left[ \\cos\\{(n-m)\\pi\\} - \\cos\\{-(n-m)\\pi\\} \\right] \\\\ &= 0 \\end{align*} 従って、如何なる周波数に対しても正弦波と余弦波は直交していること \\begin{equation*} \\innerp{\\sin(nx)}{\\cos(mx)} = 0 \\tag{6} \\end{equation*} が確かめられた。 フーリエ係数 次の様に信号 \\(f(x)\\) がフーリエ級数展開されていたとする。 \\begin{equation*} f(x) = \\frac{1}{2} a_{0} + \\sum_{k=1}&#94;{\\infty} a_{k} \\cos(kx) + \\sum_{k=1}&#94;{\\infty} b_{k} \\sin(kx) \\end{equation*} 上式における係数 \\(a_{0}, a_{1}, ..., b_{1}, b_{2}, ...\\) はフーリエ級数と呼ばれる。 フーリエ係数は、周波数成分への重み付けと説明される事が多い。一方、上記のように関数をベクトルとみなすと、信号を三角関数基底で表した際の一次結合係数とも捉え直す事ができる。 係数を取り出すには、上記の直交性（ 式4 , 式5 , 式6 ）を使用すれば良い。 \\(\\innerp{f(x)}{\\sin(nx)} \\ n \\in \\mathbb{N}\\) を計算すると、 \\begin{align*} \\innerp{f(x)}{\\sin(nx)} &= \\innerp{\\frac{1}{2} a_{0} + \\sum_{k=1}&#94;{\\infty} a_{k} \\cos(kx) + \\sum_{k=1}&#94;{\\infty} b_{k}\\sin(kx)}{\\sin(nx)} \\\\ &= \\innerp{\\frac{1}{2} a_{0}}{\\sin(nx)} + \\innerp{\\sum_{k=1}&#94;{\\infty} a_{k} \\cos(kx)}{\\sin(nx)} + \\innerp{\\sum_{k=1}&#94;{\\infty} b_{k}\\sin(kx)}{\\sin(nx)} \\quad (\\because 内積の線形性) \\\\ &= \\frac{1}{2} a_{0} \\innerp{1}{\\sin(nx)} + \\sum_{k=1}&#94;{\\infty} \\innerp{a_{k}\\cos(kx)}{\\sin(nx)} + \\sum_{k=1}&#94;{\\infty} \\innerp{b_{k}\\sin(kx)}{\\sin(nx)} \\quad (\\because 内積の線形性) \\\\ &= \\frac{1}{2} a_{0} \\innerp{\\cos(0)}{\\sin(nx)} + \\sum_{k=1}&#94;{\\infty} a_{k} \\innerp{\\cos(kx)}{\\sin(nx)} + \\sum_{k=1}&#94;{\\infty} b_{k} \\innerp{\\sin(kx)}{\\sin(nx)} \\\\ &= \\pi b_{n} \\quad (\\because 三角関数の直交性) \\end{align*} よって、 \\begin{equation*} b_{n} = \\frac{1}{\\pi} \\innerp{f(x)}{\\sin(nx)} \\tag{7} \\end{equation*} 全く同様にして \\(\\innerp{f(x)}{\\cos(nx)} \\ n \\in \\mathbb{N}\\) を計算することで、次の結果が得られる [3] 。 \\begin{equation*} a_{n} = \\frac{1}{\\pi} \\innerp{f(x)}{\\cos(nx)} \\tag{8} \\end{equation*} 式7 , 式8 の結果を見ると、 係数を取り出すには、関数基底と内積を取って、基底のノルムで割れば良い 事が分かる。 [3] \\(a_{0}\\) を求める際には、 \\(\\cos(0)=1\\) と \\(f(x)\\) の内積を取れば良い。 \\(\\int_{-\\pi}&#94;{\\pi} {1} dx = 2\\pi\\) により、 \\(a_{0}\\) に乗じられている \\(\\frac{1}{2}\\) が実は無意味では無いことが分かるだろう。 収束定理 いよいよ問題の核心について考えることが出来る。上記までの議論で、三角関数は基底をなすことが示された [4] 。それでは、三角関数によって構築された基底（三角関数基底）は、如何なる関数でも表現できるのだろうか？というのが次の疑問となる。 この疑問に対する答えがフーリエ級数の 収束定理 （以下、単純に収束定理）である。収束定理とは、次の有限項のフーリエ級数展開 \\begin{equation*} S_{N}(x) = \\frac{1}{2} a_{0} + \\sum_{n=1}&#94;{N} \\left\\{ a_{n} \\cos(nx) + b_{n} \\sin(nx) \\right\\} \\tag{9} \\end{equation*} を用いて信号 \\(f(x)\\) を近似（ \\(S_{N}(x) \\approx f(x)\\) ）することを考え、 \\(N\\) の極限 \\(N \\to \\infty\\) を取った時に、 \\(S_{N}(x)\\) と \\(f(x)\\) が一致する、というものである。 \\begin{equation*} \\lim_{N \\to \\infty} \\left\\{ S_{N}(x) - f(x) \\right\\} = 0 \\tag{10} \\end{equation*} 式10 が証明されれば、理論的観点から、安心してフーリエ級数を使用できると言って良い。ここで、予め注意してほしいのが、 式10 の \\(f(x)\\) は任意の関数では成立せず、定理が成り立つための制約条件が存在することである。 以下、収束定理の証明及び、 \\(f(x)\\) に課すべき制約条件を見ていく。 [4] この事実は自明ではない。全く適当に選んだ関数の集合（関数族）が基底になることはまず無い。 ディリクレ核 収束定理 式10 が成立することを示すため、まず有限項のフーリエ級数展開の 式9 に注目する。 式9 の各フーリエ係数 \\(a_{0}, a_{1}, ..., b_{1}, b_{2}, ...\\) は、 式7 , 式8 により、近似対象の関数 \\(f(x)\\) によって表すことが出来る。 \\begin{align*} S_{N}(x) &= \\frac{1}{2} a_{0} + \\sum_{n=1}&#94;{N} \\left\\{ a_{n} \\cos(nx) + b_{n} \\sin(nx) \\right\\} \\\\ &= \\frac{1}{2} \\frac{1}{\\pi} \\innerp{1}{f(x)} + \\sum_{n=1}&#94;{N} \\left\\{ \\frac{1}{\\pi} \\innerp{\\cos(ny)}{f(y)} \\cos(nx) + \\frac{1}{\\pi} \\innerp{\\sin(ny)}{f(y)} \\sin(nx) \\right\\} \\\\ &= \\frac{1}{2\\pi} \\int_{-\\pi}&#94;{\\pi} f(y) dy + \\sum_{n=1}&#94;{N} \\left\\{ \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} \\cos(ny)f(y) dy \\cos(nx) + \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} \\sin(ny)f(y) dy \\sin(nx) \\right\\} \\\\ &= \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} f(y) \\left[ \\frac{1}{2} + \\sum_{n=1}&#94;{N} \\left\\{ \\cos(ny)\\cos(nx) + \\sin(ny)\\sin(nx) \\right\\} \\right] dy \\\\ &= \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} f(y) \\left[ \\frac{1}{2} + \\sum_{n=1}&#94;{N} \\cos\\left\\{n(y-x)\\right\\} \\right] dy \\quad (\\because \\cos の加法定理を使用) \\end{align*} ここで、 \\(z=y-x\\) と積分の変数変換を行う。積分範囲は \\([-\\pi,\\pi]\\) から \\([-\\pi-x,\\pi-x]\\) に変化するが、周期関数を1周期分積分している状態で、積分範囲を左右にずらしても積分の結果は変わらないため、次の結果が得られる。 \\begin{align*} S_{N}(x) &= \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} f(z+x) \\left[ \\frac{1}{2} + \\sum_{n=1}&#94;{N} \\cos(nz) \\right] dz \\\\ &= \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} f(z+x) D_{N}(z) dz \\tag{11} \\end{align*} 式11 で導入した \\begin{equation*} D_{N}(x) = \\frac{1}{2} + \\sum_{n=1}&#94;{N} \\cos(nx) \\tag{12} \\end{equation*} を ディリクレ核(Dirichlet kernel) という。以下に述べるように、ディリクレ核にはいくつか重要な性質がある。 ディリクレ核の一周期分の積分 定義 式12 より明らかにディリクレ核は周期関数である。周期 \\(2\\pi\\) の積分を実行すると、 \\begin{align*} \\int_{-\\pi}&#94;{\\pi} D_{N}(x) dx &= \\int_{-\\pi}&#94;{\\pi} \\left\\{ \\frac{1}{2} + \\sum_{n=1}&#94;{N} \\cos(nx) \\right\\} dx \\\\ &= \\int_{-\\pi}&#94;{\\pi} \\frac{1}{2} dx + \\int_{-\\pi}&#94;{\\pi} \\sum_{n=1}&#94;{N} \\cos(nx) dx = \\int_{-\\pi}&#94;{\\pi} \\frac{1}{2} dx + \\sum_{n=1}&#94;{N} \\int_{-\\pi}&#94;{\\pi} \\cos(nx) dx \\\\ &= \\int_{-\\pi}&#94;{\\pi} \\frac{1}{2} dx \\quad (\\because 三角関数の一周期分の積分値は0) \\\\ &= \\frac{2\\pi}{2} = \\pi \\tag{13} \\end{align*} ディリクレ核のsin関数による表現 ディリクレ核は、若干技巧的ではあるが、和を持たない形式に変形することができる。 \\(D_{N}(x)\\) の左から \\(2\\sin\\left(\\frac{1}{2}x\\right)\\) を乗じると、 \\begin{align*} 2\\sin\\left(\\frac{1}{2}x\\right) D_{N}(x) &= 2\\sin\\left(\\frac{1}{2}x\\right) \\left[ \\frac{1}{2} + \\sum_{n=1}&#94;{N} \\cos(nx) \\right] \\\\ &= \\sin\\left(\\frac{1}{2}x\\right) + 2\\sin\\left(\\frac{1}{2}x\\right) \\cos(x) + 2\\sin\\left(\\frac{1}{2}x\\right) \\cos(2x) + ... + 2\\sin\\left(\\frac{1}{2}x\\right) \\cos(Nx) \\end{align*} ここで、三角関数の和の公式 \\(\\sin(nx)\\cos(mx) = \\frac{\\sin\\{(n+m)x\\} + \\sin\\{(n-m)x\\}}{2}\\) を用いれば、 \\begin{align*} 2\\sin\\left(\\frac{1}{2}x\\right) D_{N}(x) &= \\sin\\left(\\frac{1}{2}x\\right) + \\left[ \\sin\\left\\{\\left(\\frac{1}{2} - 1\\right)x\\right\\} + \\sin\\left\\{\\left(\\frac{1}{2} + 1\\right)x\\right\\} \\right] \\\\ &\\quad + \\left[ \\sin\\left\\{\\left(\\frac{1}{2} - 2\\right)x\\right\\} + \\sin\\left\\{\\left(\\frac{1}{2} + 2\\right)x\\right\\} \\right] + ... + \\left[ \\sin\\left\\{\\left(\\frac{1}{2} - N\\right)x\\right\\} + \\sin\\left\\{\\left(\\frac{1}{2} + N\\right)x\\right\\} \\right] \\\\ &= \\sin\\left(\\frac{1}{2}x\\right) + \\sin\\left(-\\frac{1}{2}x\\right) + \\sin\\left(\\frac{3}{2}x\\right) \\\\ &\\quad + \\sin\\left(-\\frac{3}{2}x\\right) + \\sin\\left(\\frac{5}{2}x\\right) + ... + \\sin\\left\\{\\left(\\frac{1}{2} - N\\right)x\\right\\} + \\sin\\left\\{\\left(\\frac{1}{2} + N\\right)x\\right\\} \\\\ &= \\sin\\left\\{\\left(\\frac{1}{2} + N\\right)x\\right\\} \\end{align*} 従って、ディリクレ核を \\(\\sin\\) のみで表現することが出来る: \\begin{equation*} D_{N}(x) = \\frac{\\sin\\left\\{\\left(\\frac{1}{2} + N\\right)x\\right\\}}{2\\sin\\left(\\frac{1}{2}x\\right)} \\tag{14} \\end{equation*} ディリクレ核の畳み込み 式11 を改めて眺めると、この式は積分範囲 \\([-\\pi,\\pi]\\) において 関数にディリクレ核を畳み込んでいる 式に捉え直せる。 \\begin{equation*} S_{N}(x) = \\frac{1}{\\pi} \\ f(x) \\ast D_{N}(x) \\end{equation*} 先取りして収束定理が成り立つと仮定すると、 \\(N\\) の極限 \\(N \\to \\infty\\) に於いて次が成り立つ: \\begin{align*} \\lim_{N \\to \\infty} S_{N}(x) &= \\lim_{N \\to \\infty} \\frac{1}{\\pi} \\ f(x) \\ast D_{N}(x) = f(x) \\\\ \\therefore \\lim_{N \\to \\infty} f(x) \\ast D_{N}(x) &= \\pi f(x) \\end{align*} 畳み込みの結果、畳込み対象の関数 \\(f(x)\\) が表れている。即ちこの結果は、 \\(N\\) の極限においてディリクレ関数はインパルス関数に近い振る舞いをすることを示している。 リーマン・ルベーグの補題 収束定理の証明のためには、もう一つ リーマン・ルベーグの補題 なる命題が必要である。この節では、リーマン・ルベーグの補題の証明を行う。 リーマン・ルベーグの補題 区分的に連続な関数 \\(f(x)\\) と \\(\\sin(Nx)\\) の積を積分区間 \\([a,b]\\) で積分したものは、 \\(N \\to \\infty\\) とすると \\(0\\) に収束する。 \\begin{equation*} \\lim_{N \\to \\infty} \\int_{a}&#94;{b} f(x) \\sin(Nx) dx = 0 \\tag{15} \\end{equation*} （証明）部分積分を用いることにより、 \\begin{align*} \\int_{a}&#94;{b} f(x) \\sin(Nx) dx &= \\int_{a}&#94;{b} f(x) \\left\\{ -\\frac{1}{N} \\cos(Nx) \\right\\}&#94;{\\prime} dx \\\\ &= \\left[ -\\frac{1}{N} f(x) \\cos(Nx) \\right]_{a}&#94;{b} - \\int_{a}&#94;{b} -\\frac{1}{N} f&#94;{\\prime}(x) \\cos(Nx) dx \\quad (\\because 部分積分) \\\\ &= -\\frac{1}{N} \\left[ f(x) \\cos(Nx) \\right]_{a}&#94;{b} + \\frac{1}{N} \\int_{a}&#94;{b} f&#94;{\\prime}(x) \\cos(Nx) dx \\end{align*} と変形できる。このまま \\(N \\to \\infty\\) なる極限をとれば、いずれの項も \\(0\\) に収束するように見える。しかしそれは 関数 \\(f(x)\\) の微分 \\(f&#94;{\\prime}(x)\\) が区間 \\([a,b]\\) で発散しない（区分的なめらかな）ときのみ 真である。この条件を関数 \\(f(x)\\) に付加した時、命題は成立する。 では一般に、 \\(f(x)\\) が区分的に連続であること のみ を仮定して証明を行う。この時は区分的なめらかな関数 \\(g(x)\\) を用いて命題が成立することを用いて、 \\(f(x)\\) を \\(g(x)\\) に近づけることで命題の成立を示す。積分区間 \\([a,b]\\) を \\(M\\) 分割し、区間の小さい方から順に \\(x_{1}, x_{2}, ..., x_{M}\\) となるようにする（当然 \\(x_{1} = a, x_{M} = b\\) が成立する）。この上で \\(f(x)\\) を次のように構成する: \\begin{equation*} f(x) = g(x_{k+1}) \\quad (k = 1,...,M-1, \\ x_{k} \\leq x \\leq x_{k+1}) \\end{equation*} 構成法から見えるように、分割数 \\(M\\) を増やしていけば、 \\(f(x)\\) と \\(g(x)\\) の差は小さくなっていくのが分かる（TODO:図を書こう）。即ち、任意の \\(\\varepsilon > 0\\) に対して、 \\(|f(x) - g(x)| < \\varepsilon\\) を成立させる \\(M\\) が存在する。 そしてこの \\(f(x)\\) を用いたとき、 \\begin{align*} \\left| \\int_{a}&#94;{b} f(x) \\sin(Nx) dx \\right| &= \\left| \\int_{a}&#94;{b} \\left\\{ f(x) - g(x) + g(x) \\right\\} \\sin(Nx) dx \\right| \\\\ &\\leq \\left| \\int_{a}&#94;{b} \\left\\{ f(x) - g(x) \\right\\} \\sin(Nx) dx \\right| + \\left| \\int_{a}&#94;{b} g(x) \\sin(Nx) dx \\right| \\\\ &\\leq \\int_{a}&#94;{b} \\left| f(x) - g(x) \\right| \\left| \\sin(Nx) \\right| dx + \\left| \\int_{a}&#94;{b} g(x) \\sin(Nx) dx \\right| \\\\ &\\leq \\int_{a}&#94;{b} \\left| f(x) - g(x) \\right| dx + \\left| \\int_{a}&#94;{b} g(x) \\sin(Nx) dx \\right| \\\\ &< \\int_{a}&#94;{b} \\varepsilon dx + \\left| \\int_{a}&#94;{b} g(x) \\sin(Nx) dx \\right| = \\varepsilon(b - a) + \\left| \\int_{a}&#94;{b} g(x) \\sin(Nx) dx \\right| \\end{align*} ここで、 \\(\\displaystyle\\left| \\int_{a}&#94;{b} g(x) \\sin(Nx) dx \\right| < \\varepsilon\\) となる様に \\(N\\) を十分大きく取る（ \\(g(x)\\) は区分的なめらかなので成立する）と、 \\begin{equation*} \\left| \\int_{a}&#94;{b} f(x) \\sin(Nx) dx \\right| < \\varepsilon(b-a) + \\varepsilon = \\varepsilon(b - a + 1) \\end{equation*} 即ち、任意の \\(\\varepsilon\\) に対して上式を成り立たせる \\(N\\) が存在するので、 式16 が成り立つ。 \\begin{equation*} \\lim_{N \\to \\infty} \\left| \\int_{a}&#94;{b} f(x) \\sin(Nx) dx \\right| = 0 \\tag{16} \\end{equation*} 式16 は、リーマン・ルベーグの補題（ 式15 ）が成立していることをそのまま示している。何故なら、ある関数の絶対値が \\(0\\) に収束することと、関数が \\(0\\) に収束することは同値だからである。 収束定理の証明 ここまでの結果を利用して、収束定理を示そう。まず 式11 より、ディリクレ核を使用して \\(S_{N}(x)\\) を書き直すと、 \\begin{equation*} S_{N}(x) - f(x) = \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} f(x+z) D_{N}(x) dx - f(x) \\end{equation*} ここで、ディリクレ核の性質（ 式13 , 式14 ）を用いると、 \\begin{align*} S_{N}(x) - f(x) &= \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} f(x+z) D_{N}(z) dz - 1 \\times f(x) \\\\ &= \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} f(x+z) D_{N}(z) dz - \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} D_{N}(z) dz f(x) \\\\ &= \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} \\left\\{ f(x+z) - f(x) \\right\\} D_{N}(z) dz \\\\ &= \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} \\left\\{ f(x+z) - f(x) \\right\\} \\frac{\\sin\\left\\{\\left( \\frac{1}{2} + N \\right)z\\right\\}}{2\\sin\\left(\\frac{1}{2}z\\right)} dz \\\\ &= \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} \\frac{ f(x+z) - f(x) }{2\\sin\\left(\\frac{1}{2}z\\right)} \\sin\\left\\{\\left( \\frac{1}{2} + N \\right)z\\right\\} dz \\end{align*} ここでリーマン・ルベーグの補題を用いる。ただし、そのためには、 \\(\\displaystyle\\frac{ f(x+z) - f(x) }{2\\sin\\left(\\frac{1}{2}z\\right)}\\) が区分的に連続でなければならない。この分数は \\(z = 0\\) の時、分母 \\(2\\sin\\left(\\frac{1}{2}z\\right)\\) が \\(0\\) になるので、 \\(z=0\\) においても発散しないことを示す必要がある。以下の極限を考えると、 \\begin{align*} \\lim_{z \\to 0} \\frac{ f(x+z) - f(x) }{2\\sin\\left(\\frac{1}{2}z\\right)} &= \\lim_{z \\to 0} \\frac{ f(x+z) - f(x) }{z} \\frac{z}{2\\sin\\left(\\frac{1}{2}z\\right)} \\\\ &= \\lim_{z \\to 0} \\frac{ f(x+z) - f(x) }{z} \\lim_{z \\to 0} \\frac{\\ddiff{z}{z}}{\\ddiff{2\\sin\\left(\\frac{1}{2}z\\right)}{z}} \\quad (\\because ロピタルの定理) \\\\ &= \\lim_{z \\to 0} \\frac{ f(x+z) - f(x) }{z} \\frac{1}{2\\frac{1}{2}} \\\\ &= f&#94;{\\prime}(x) \\end{align*} より、 \\(f&#94;{\\prime}(x)\\) が発散しない、即ち 関数 \\(f(x)\\) が区分的になめらか であれば、リーマン・ルベーグの補題を使用することで、収束定理 \\begin{equation*} \\lim_{N \\to \\infty} \\left\\{ S_{N}(x) - f(x) \\right\\} = 0 \\end{equation*} が成立する。 三角関数の完全性 フーリエ級数の収束定理を用いることで、三角関数基底によって基底は全て揃うのか？という問に答えを与える事ができる。この性質を、 三角関数の完全性 という。 三角関数の完全性 定数、 \\(\\sin\\) 、 \\(\\cos\\) によって全ての関数基底が揃っている。 証明は背理法による。 （証明）基底が揃っていない場合には次の仮定が成り立つ。 仮定 定数、 \\(\\sin\\) 、 \\(\\cos\\) の全てに直交している連続関数基底が存在する。 この命題の矛盾を導くことで、三角関数基底の完全性を示す。 まず、「定数、sin、cosの全てに直交している連続関数」を \\(h(x)\\) とおく。その定義から、以下が成り立つ： \\begin{align*} \\ifdiv{ll}{ \\innerp{h(x)}{1} = \\displaystyle\\int_{-\\pi}&#94;{\\pi} h(x) dx = 0 & \\\\ \\innerp{h(x)}{\\cos(nx)} = \\displaystyle\\int_{-\\pi}&#94;{\\pi} h(x) \\cos(nx) dx = 0 & (n \\in \\mathbb{N}) \\\\ \\innerp{h(x)}{\\sin(nx)} = \\displaystyle\\int_{-\\pi}&#94;{\\pi} h(x) \\sin(nx) dx = 0 & (n \\in \\mathbb{N}) } \\end{align*} これらの条件を満たす自明な関数に \\(h(x) = 0\\) があるが、 \\(h(x) = 0\\) は関数空間の零ベクトルに対応し空間を生成しない（この関数をスカラー倍しても同じ関数しか出てこない）ため、基底とはならない。従って、 \\(h(x) = 0\\) 以外の関数で考える。 この前提の上で、 \\(h(x)\\) をフーリエ係数展開 \\(S_{N}(x)\\) によって表現すると、 \\begin{align*} S_{N}(x) &= \\frac{1}{2} a_{0} + \\sum_{n=1}&#94;{N} \\left\\{ a_{n} \\cos(nx) + b_{n} \\sin(nx) \\right\\} \\\\ &= \\frac{1}{2} \\frac{1}{\\pi} \\innerp{1}{h(x)} + \\sum_{n=1}&#94;{N} \\left\\{ \\frac{1}{\\pi} \\innerp{\\cos(ny)}{h(y)} \\cos(nx) + \\frac{1}{\\pi} \\innerp{\\sin(ny)}{h(y)} \\sin(nx) \\right\\} \\\\ &= \\frac{1}{2\\pi} \\int_{-\\pi}&#94;{\\pi} h(y) dy + \\sum_{n=1}&#94;{N} \\left\\{ \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} \\cos(ny)h(y) dy \\cos(nx) + \\frac{1}{\\pi} \\int_{-\\pi}&#94;{\\pi} \\sin(ny)h(y) dy \\sin(nx) \\right\\} \\\\ &= 0 \\end{align*} フーリエ級数の収束定理を用いると、 \\(\\displaystyle\\lim_{N \\to \\infty} S_{N} = h(x) = 0\\) 。この結果は、 \\(h(x) = 0\\) 以外の関数で考えていることに矛盾する。従って、冒頭で述べた三角関数の完全性が成り立つ。 フーリエ変換 周期 \\(T\\) の実関数 \\(f : \\mathbb{R} \\to \\mathbb{R}\\) に対して、 （複素）フーリエ級数展開は、 \\begin{equation*} \\left\\{ \\begin{array}{l} f(t) = \\displaystyle\\sum_{n = -\\infty}&#94;{\\infty} c_{n} \\exp(j n\\omega_{0}t) \\\\ c_{n} = \\displaystyle\\frac{1}{T} \\int&#94;{T/2}_{-T/2} f(t) \\exp(-j n\\omega_{0} t) dt \\end{array} \\right. \\end{equation*} となる。 ここで \\(j\\) は虚数単位（ \\(j = \\sqrt{-1}\\) ）、 \\(\\omega_{0} = 2\\pi/T\\) である。 フーリエ級数展開により、 様々な周期関数 \\(f\\) は周波数領域（異なる周波数を持つ三角関数の和）で表現できることは周知である。 今、 \\(c_{n}\\) を消去すると、 \\begin{equation*} f(t) = \\sum_{n=-\\infty}&#94;{\\infty} \\frac{1}{T} \\left\\{ \\int&#94;{T/2}_{-T/2} f(t) \\exp(-jn\\omega_{0}t)dt \\right\\} \\exp(jn\\omega_{0}t) \\end{equation*} 更に、 \\(F(n\\omega_{0}) = \\displaystyle\\int&#94;{T/2}_{-T/2} f(t) \\exp(-jn\\omega_{0}t) dt\\) とおくと、 \\begin{equation*} f(t) = \\sum_{n=-\\infty}&#94;{\\infty} \\frac{1}{T} F(n\\omega_{0}) \\exp(jn\\omega_{0}t) = \\frac{1}{2\\pi} \\sum_{n=-\\infty}&#94;{\\infty} \\omega_{0} F(n\\omega_{0}) \\exp(j n \\omega_{0}t) \\end{equation*} となる。 今、 \\(T \\to \\infty\\) ならしめ周期を無限大にすると \\(\\omega_{0}\\) は \\(0\\) に収束するので、 \\(\\omega_{0}\\) を区間幅とした区分求積法により、 次の積分と等しくなる: \\begin{equation*} \\left\\{ \\begin{array}{l} f(t) = \\displaystyle\\frac{1}{2\\pi}\\int_{-\\infty}&#94;{\\infty} F(\\omega) \\exp(j \\omega t) d\\omega \\\\ F(\\omega) = \\displaystyle \\int&#94;{\\infty}_{-\\infty} f(t) \\exp(-j\\omega t) dt \\end{array} \\right. \\end{equation*} ここで \\(F(\\omega)\\) は \\(f(t)\\) のフーリエ変換、 \\(f(t)\\) は \\(F(\\omega)\\) のフーリエ逆変換（逆フーリエ変換）と呼ばれる。 非周期的な関数は周期無限の関数とも考えられるので、 フーリエ変換によって、 様々な関数の周波数領域表現を得る事ができる。 但し、 \\(F(\\omega)\\) の収束を保証するため、 \\(f(t)\\) は絶対可積分: \\begin{equation*} \\int_{-\\infty}&#94;{\\infty} |f(t)| dt < \\infty \\quad （(-\\infty、 \\infty)における積分値が有界） \\end{equation*} でなくてはならない。 もし、 上の積分が有界な値を取るならば、 \\begin{align*} F(\\omega) &= \\int&#94;{\\infty}_{-\\infty} f(t) \\exp(-j\\omega t) dt \\\\ &< \\int&#94;{\\infty}_{-\\infty} |f(t) \\exp(-j\\omega t)| dt < \\int&#94;{\\infty}_{-\\infty} |f(t)||\\exp(-j\\omega t)| dt \\\\ &= \\int&#94;{\\infty}_{-\\infty} |f(t)| dt \\quad （\\because オイラーの公式より |\\exp(-j\\omega t)| = \\sqrt{\\cos&#94;{2} \\omega t + \\sin&#94;{2} \\omega t} = 1） \\end{align*} となって \\(F(\\omega)\\) もまた有界である事が分かる。 ラプラス変換 実関数 \\(f(t)\\) に収束因子 \\(\\exp(-\\sigma t)\\) （ \\(\\sigma\\) は非負実数）を乗じた関数 \\(f(t)\\exp(-\\sigma t)\\) のフーリエ変換 \\begin{equation*} \\int&#94;{\\infty}_{-\\infty} f(t)\\exp(-\\sigma t) \\exp(-j\\omega t) dt = \\displaystyle \\int&#94;{\\infty}_{-\\infty} f(t)\\exp(-st) dt = F(s) \\quad （s = \\sigma + j\\omega） \\end{equation*} を （両側）ラプラス変換 と呼ぶ。 ラプラス変換は、 \\(s\\) が複素数であることにより、 周波数領域だけ（ \\(\\sigma = 0\\) とした時。 フーリエ変換と等価となる）でなく、 複素数領域で過渡的な（振動の減衰/増大）現象をも解析の対象とすることができる。 また、 \\(F(s)\\) から \\(f(t)\\) に変換するラプラス逆変換（逆ラプラス変換）は、 次の式で定義される: \\begin{equation*} f(t) = \\frac{1}{2\\pi j} \\lim_{\\omega \\to \\infty} \\int&#94;{c + j\\omega}_{c - j\\omega} F(s) \\exp(st) ds \\end{equation*} 以後、 実関数 \\(f(t)\\) のラプラス変換を \\(\\mathcal{L}[f(t)]( = F(s))\\) 、 \\(F(s)\\) のラプラス逆変換を \\(\\mathcal{L}&#94;{-1}[F(s)]( = f(t))\\) と表す。 工学的な応用の場面では、 ラプラス変換の積分範囲は \\([0, \\infty)\\) とする事が多い: \\begin{equation*} F(s) = \\int&#94;{\\infty}_{0} f(t)\\exp(-st) dt \\end{equation*} これを特に片側ラプラス変換と呼ぶ。 ラプラス変換は演算子法の一種であり、 様々な関数の変換結果（ラプラス変換対）をまとめたラプラス変換表を参照しながら、 微分方程式を代数的、 かつ簡易に解くことができる。 伝達関数 1つの入力かつ1つの出力があるシステム（一入力一出力システム）を考える。 入力の振る舞いを表す実関数を \\(x(t)\\) 、 それに対する出力も実関数 \\(y(t)\\) と表せるとする。 ここで``振る舞いを表す実関数''とは、 線形微分方程式で記述されているラプラス変換可能な関数を意味する。 従って \\(x(t), y(t)\\) のラプラス変換 \\(X(s)、 Y(s)\\) は、 微分演算子の存在によりそれぞれ \\(s\\) の多項式で表現できる事が分かる。 そして、 出力と入力のラプラス変換の比を 伝達関数(Transfer function) と呼ぶ。 伝達関数を \\(G(s)\\) とすると、 \\begin{equation*} G(s) = \\frac{Y(s)}{X(s)} \\end{equation*} と表すことができる。 伝達関数 \\(G(s)\\) は入力と出力の関係をひとまとめにし、 システムの特性（性質）を代表している事が分かる。 出力 \\(y(t)\\) の振る舞いは \\(Y(s) = G(s)X(s)\\) から両辺ラプラス逆変換を施すことにより求めることができる。 また、 \\(G(s)\\) 自体の様子（分母分子の多項式の係数）から、 システムの安定性を判定することもできる。 この様に、 伝達関数はシステムの特性を観察する際に大いに役立ち、 古典制御理論の中心をなす概念となっている。 安定性解析の概要 伝達関数からシステムの安定性を解析する事を考える。 まず、 システムが 安定(stable) であるとは、 任意の時間で有界な任意の入力 \\(x(t)\\) （ \\({}&#94;{\\forall} t. |x(t)| < \\infty\\) ）に対して、 その出力 \\(y(t)\\) もまた任意の時間で有界である時を言う [5] 。 [5] 厳密には、 リペアノフの意味で安定と言う。 逆に安定で無い、 即ち出力が有界でない時間がある（ \\({}&#94;{\\exists} t. |y(t)| = \\infty\\) ）システムを不安定(unstable)と言う。 任意の入力 \\(x(t)\\) に対してその出力 \\(y(t)\\) の挙動を調べる事は不可能だが、 実際には、 入力 \\(x(t)\\) を単位ステップ関数 \\begin{equation*} x(t) = \\left\\{ \\begin{array}{ll} 0 & t < 0 \\\\ 1 & t \\geq 0 \\end{array} \\right. \\end{equation*} とした時の出力 \\(y(t)\\) が有界な値に収束すれば安定となる事が示されている。 それでは伝達関数 \\(G(s)\\) からシステムの安定性を判定する事を考える。 入力 \\(x(t)\\) 、 出力 \\(y(t)\\) それぞれのラプラス変換の結果を \\(\\mathcal{L}[x(t)] = X(s)\\) 、 \\({\\cal L}[y(t)] = Y(s)\\) とした時、 伝達関数は \\(s\\) の多項式の比なので、一般に次の形で表せる: \\begin{align*} G(s) &= \\frac{Y(s)}{X(s)} = \\frac{b_{m}s&#94;{m} + b_{m-1}s&#94;{m-1} + \\dots + b_{1}s + b_{0}}{s&#94;{n} + a_{n-1}s&#94;{n-1} + \\dots + a_{1}s + a_{0}} \\\\ &= \\frac{b_{m}(s-z_{1})(s-z_{2})\\dots(s-z_{m})}{(s-p_{1})(s-p_{2})\\dots(s-p_{n})} \\end{align*} （現実には \\(n \\geq m\\) であることが多く、 その場合 プロパー であると呼ばれる）。 ここで、 \\(Y(s) = 0\\) の根 \\(z_{1}, \\dots, z_{m}\\) をこのシステムの零点(zero)、 \\(X(s)=0\\) の根 \\(p_{1}、\\dots、p_{n}\\) をこのシステムの極(pole)と呼ぶ [6] 。 [6] \\(X(s)\\) 自身をそのシステムの特性多項式(characteristic polynominal)、 また \\(X(s)=0\\) を特性方程式(characteristic equation)と呼ぶ 安定性の判定の為入力を単位ステップ関数とすると、 出力のラプラス変換 \\(Y(s)\\) は \\begin{equation*} Y(s) = G(s)X(s) = G(s)\\frac{1}{s} = \\frac{b_{m}(s-z_{1})(s-z_{2})\\dots(s-z_{m})}{s(s-p_{1})(s-p_{2})\\dots(s-p_{n})} \\end{equation*} となり、 この式を部分分数分解すると、 一般に \\begin{equation*} Y(s) = \\frac{A}{s} + \\sum_{k=1}&#94;{n} \\frac{B_{k}}{s-p_{k}} \\end{equation*} と表わすことができ（ \\(A、 B_{k}\\) :係数）、 これを両辺ラプラス逆変換することで、 出力の一般解 \\begin{equation*} y(t) = A + \\sum_{k=1}&#94;{n} B_{k} \\exp(p_{k}t) \\end{equation*} を得る。 更に \\(p_{k}\\) は一般に複素数なので、 実数係数 \\(\\sigma_{k}, \\omega_{k}\\) を用いて \\(p_{k} = \\sigma_{k} + j \\omega_{k}\\) と表し \\(y(t)\\) を変形すると、 \\begin{align*} y(t) &= A + \\sum_{k=1}&#94;{n} B_{k} \\exp[(\\sigma_{k} + j \\omega_{k})t] \\\\ &= A + \\sum_{k=1}&#94;{n} B_{k} \\exp(\\sigma_{k}t) (\\cos\\omega_{k}t + j\\sin\\omega_{k}t) \\quad （\\because オイラーの公式） \\end{align*} となる。 今、 ある \\(\\sigma_{i}\\ (i=1, \\dots, n)\\) が一つでも正ならば、 時間の極限 \\(t\\to \\infty\\) をとると \\(y(t)\\) は発散してしまい、 システムが不安定となることが分かる。 従って システムが安定となる為には全ての極の実数部が負 （ \\({}&#94;{\\forall} k. \\sigma_{k} < 0\\) ） となる事が必要十分 であることが分かる。この時は特に \\(y(t)\\) は \\(A\\) に収束する（ \\(\\displaystyle\\lim_{t \\to \\infty} y(t) = A\\) ）ので、 システムは 漸近安定 であると言う。 伝達関数に基づくシステムの安定性解析は、 本質的には以上の様に極の実部を調べることにより行われる。 しかし実際複雑な（ \\(n, m\\) が大きい）システムでは方程式を解き極を計算するのが困難となるので、 方程式を解かずともシステムの安定/不安定を判別する手法が存在する [7] 。 [7] 伝達関数の係数から判定する手法として、 ラウスの安定判別法や、 フルビッツの安定判別法がある ギブス現象 ギブス現象(Gibbs phenomenon) とは、 不連続な点を含む周期関数のフーリエ級数近似において、 不連続点付近では級数和の絶対値が原関数のとる値の絶対値よりも大きくなってしまう現象のことである。 その原因は、 不連続な関数を連続な関数基底で近似してしまう事による。 ギブス現象の例を数式で観察してみる。 今、不連続点を含む、区分的に連続微分可能な周期 \\(T\\) の実関数 \\(f(x)\\) を考える。 その \\(N\\) 次までの複素フーリエ級数近似 \\(S_{N}(x)\\) は: \\begin{align*} S_{N}(x) &= \\sum&#94;{N}_{n = -N} c_{n} \\exp(jn\\omega_{0}x)\\quad (\\omega_{0} = \\frac{2\\pi}{T}) \\\\ c_{n} &= \\frac{1}{T} \\int&#94;{T/2}_{-T/2} f(t)\\exp(-jn\\omega_{0}t) {\\rm dt} \\end{align*} となる。 ところで、 ギブス現象は不連続点付近で \\(S_{N}(x)\\) が飛び出る事によって認知される。 \\(S_{N}(x)\\) が三角関数の和で表現されている事に注目すると、 その飛び出た点は、 \\(S_{N}(x)\\) の極値であると捉える事ができる。 従って、 \\(S_{N}(x)\\) を \\(x\\) によって微分すると: \\begin{align*} \\ddiff{}{x}S_{N}(x) &= \\sum_{n = -N}&#94;{N} c_{n} \\ddiff{}{x}\\exp(jn\\omega_{0}x) \\quad (\\because 項別微分) \\\\ &= j \\omega_{0} \\sum&#94;{N}_{n = -N} n c_{n} \\exp(jn\\omega_{0}x) \\\\ &= j \\omega_{0} \\sum&#94;{N}_{n = -N} n c_{n} \\left\\{ \\cos(n\\omega_{0}x) + j \\sin(n\\omega_{0}x) \\right\\} \\quad (\\because オイラーの公式) \\\\ &= j \\omega_{0} \\sum&#94;{N}_{n = -N} n c_{n} \\cos(n\\omega_{0}x) - \\omega_{0} \\sum&#94;{N}_{n = -N} n c_{n} \\sin(n\\omega_{0}x) \\end{align*} \\(c_{n}\\) の実部を \\({\\rm Re}[c_{n}]\\) 、 虚部を \\({\\rm Im}[c_{n}]\\) と表すと、 \\begin{align*} \\ddiff{}{x}S_{N}(x) &= - \\omega_{0} \\left[ \\sum&#94;{N}_{n = -N} n \\left\\{ {\\rm Im}[c_{n}]\\cos(n\\omega_{0}x) + {\\rm Re}[c_{n}]\\sin(n\\omega_{0}x) \\right\\} \\right. \\\\ \\ & \\quad - \\left. j \\sum&#94;{N}_{n = -N} n \\left\\{ {\\rm Re}[c_{n}]\\cos(n\\omega_{0}x) + {\\rm Im}[c_{n}]\\sin(n\\omega_{0}x) \\right\\} \\right] \\end{align*} ここで、 \\(c_{-n} = c_{n}&#94;{\\ast}\\) ( \\(c_{n}\\) の複素共役)を用いると、 \\({\\rm Im}[c_{-n}] = -{\\rm Im}[c_{n}]\\) 、 \\({\\rm Re}[c_{-n}] = {\\rm Re}[c_{n}]\\) であることより、 以下の様に、 虚部を含まない形に整理できる。 \\begin{align*} \\ddiff{}{x}S_{N}(x) &= - \\omega_{0} \\left[ \\sum&#94;{N}_{n = 1} n \\left\\{ {\\rm Im}[c_{n}]\\cos(n\\omega_{0}x) + {\\rm Re}[c_{n}]\\sin(n\\omega_{0}x) \\right\\} \\right. \\\\ \\ & \\quad + \\sum&#94;{N}_{k = 1} (-k) \\left\\{ {\\rm Im}[c_{-k}]\\cos(k\\omega_{0}x) - {\\rm Re}[c_{-k}]\\sin(k\\omega_{0}x) \\right\\} \\\\ \\ & \\quad - j \\sum&#94;{N}_{n = 1} n \\left\\{ {\\rm Re}[c_{n}]\\cos(n\\omega_{0}x) - {\\rm Im}[c_{n}]\\sin(n\\omega_{0}x) \\right\\} \\\\ \\ & \\quad - j \\left. \\sum&#94;{N}_{k = 1} (-k) \\left\\{ {\\rm Re}[c_{-k}]\\cos(k\\omega_{0}x) + {\\rm Im}[c_{-k}]\\sin(k\\omega_{0}x) \\right\\} \\right] \\\\ &= -2\\omega_{0} \\sum&#94;{N}_{n=1} n \\left\\{ {\\rm Im}[c_{n}]\\cos(n\\omega_{0}x) + {\\rm Re}[c_{n}]\\sin(n\\omega_{0}x) \\right\\} \\end{align*} \\(\\displaystyle\\ddiff{}{x}S_{N}(x)\\) を \\(0\\) とおくと、 \\(n > 0\\) より、 極値条件の一つとして \\begin{equation*} {\\rm Im}[c_{n}]\\cos(n\\omega_{0}x) + {\\rm Re}[c_{n}]\\sin(n\\omega_{0}x) = 0 \\quad (n = 1, \\cdots, N) \\end{equation*} があり、 これを \\(x\\) について解くと、 \\begin{equation*} x = -\\frac{1}{n\\omega_{0}} \\tan&#94;{-1}\\left( \\frac{ {\\rm Im}[c_{n}] }{ {\\rm Re}[c_{n}] } \\right) \\quad (n = 1, \\cdots, N) \\end{equation*} が得られる。 ギブス現象の例として、 今、 \\(f(t)\\) として周期 \\(2\\pi\\) の矩形波を仮定する: \\begin{equation*} f(t) = \\left\\{ \\begin{array}{ll} 1 & (0 \\leq x < \\pi) \\\\ -1 & (\\pi \\leq x < 2\\pi) \\end{array} \\right. \\end{equation*} 定義のとおり、 \\(f(t)\\) は奇関数であるため \\({\\rm Re}[c_{n}] = 0\\) であり、 また \\({\\rm Im}[c_{n}]\\) は: \\begin{align*} {\\rm Im}[c_{n}] &= - \\frac{1}{2\\pi} \\int&#94;{\\pi}_{-\\pi} f(t) \\sin(nt) {\\rm dt} \\quad (\\omega_{0} = \\frac{2\\pi}{2\\pi} = 1) \\\\ &= \\frac{1}{n\\pi} \\left[ \\cos(nx) \\right]&#94;{\\pi}_{0} = - \\frac{1}{n\\pi} \\left\\{ 1 - (-1)&#94;{n} \\right\\} \\end{align*} この結果より \\(\\tan&#94;{-1}({\\rm Im}[c_{n}]/{\\rm Re}[c_{n}])\\) を考えると、 \\({\\rm Im}[c_{n}]/{\\rm Re}[c_{n}] \\to -\\infty\\) より、 極値条件は、 \\begin{equation*} x = - \\frac{1}{n} \\left( - \\frac{\\pi}{2} \\right) = \\frac{\\pi}{2n} \\quad (n = 1、\\cdots、N) \\end{equation*} となる。 この結果を用いて、 不連続点 \\(x = 0\\) における近似 \\(S_{N}(x)\\) の値を計算する事を考える。 \\(x = 0\\) に最も近い極値を与える \\(x\\) の値は、 \\(n = N\\) の時、 即ち \\(x = \\displaystyle\\frac{\\pi}{2N}\\) となるので、 \\begin{align*} S_{N}\\left(\\frac{\\pi}{2N}\\right) &= \\sum_{n = -N}&#94;{N} c_{n} \\exp\\left(j\\frac{n\\pi}{2N}\\right) \\\\ &= \\frac{2}{\\pi} \\sum_{n = 1}&#94;{N} \\frac{1}{n} \\{ 1 - (-1)&#94;{n} \\} \\sin\\left(\\frac{n\\pi}{2N}\\right) \\\\ &= \\frac{4}{\\pi} \\sum_{k = 1}&#94;{N} \\frac{1}{2k-1} \\sin\\left(\\frac{2k-1}{2N}\\pi \\right) \\quad(n = 2k - 1) \\\\ &= \\frac{2}{\\pi} \\frac{\\pi}{N} \\sum_{k = 1}&#94;{N} \\frac{1}{\\frac{2k-1}{2N}\\pi} \\sin\\left(\\frac{2k-1}{2N}\\pi \\right) \\end{align*} ここで区分求積法を用いる。 分割幅 \\(|\\Delta|\\) を \\(\\displaystyle\\frac{\\pi}{N}\\) とすると、 \\begin{align*} S_{N}\\left(\\frac{\\pi}{2N}\\right) &= \\frac{2}{\\pi} |\\Delta| \\sum_{k=1}&#94;{N}\\frac{1}{\\frac{2k-1}{2}|\\Delta|}\\sin\\left(\\frac{2k-1}{2}|\\Delta|\\right) \\\\ \\therefore \\lim_{N\\to \\infty} S_{N}\\left( \\frac{\\pi}{2N} \\right) &= \\frac{2}{\\pi} \\int&#94;{\\pi}_{0} \\frac{\\sin(y)}{y} {\\rm dy} \\approx 1.17834\\cdots \\end{align*} 従って、 \\(N\\) の極限をとっても目標値 \\(1\\) に収束できない事が確認できた。 ここで、 \\begin{equation*} \\int&#94;{\\pi}_{0} \\frac{\\sin(y)}{y} {\\rm dy} = 1.851937052\\cdots \\end{equation*} の結果はギブス定数を用いている。 エイリアシング（折り返し歪み） エイリアシングは、 連続値（アナログ）信号をPCで扱うために離散（デジタル）化するA/D変換を行った際や、 デジタル化した画像に縮小処理などのフィルターに掛けた際に発生しうる現象であり、 本来音声や画像には見られなかった干渉縞（偽解像、 モアレ）が発生してしまう。 この現象は、 A/D変換においては標本化（サンプリング）の周波数設定、 フィルター処理においてはフィルターそのものが原因である。 A/D変換におけるエイリアシングの発生の概要を見ていく。 そもそも標本化とは、 連続値信号 \\(f(t)\\) をある間隔（サンプリング周期） \\(T\\) での（ディラック）インパルス関数で表現する事を指す（ 図1 ）。 周期インパルス関数による標本化 インパルス関数 \\(\\delta(t)\\) は \\begin{equation*} \\int&#94;{\\infty}_{-\\infty} f(t)\\delta(t) {\\rm dt} = f(0) \\end{equation*} を満たす超関数であり、 標本化信号 \\(g(t)\\) は、 \\(f(t)\\) とインパルス関数を周期 \\(T\\) で並べた周期的デルタ関数 \\(\\delta_{T}(t)\\) : \\begin{equation*} \\delta_{T}(t) = \\sum&#94;{\\infty}_{n = -\\infty} \\delta(t - nT) \\end{equation*} との積で表現できる: \\begin{equation*} g(t) = f(t)\\delta_{T}(t) = \\sum&#94;{\\infty}_{n=-\\infty}f(t)\\delta(t-nT) \\end{equation*} 数値計算上、 和の無限は扱うことができないので、 ここで信号 \\(f(t)\\) は、 標本化する区間で周期性を持つと仮定する。 ここでは、 \\(f(t)\\) はサンプリング間隔の \\(N\\) 倍の周期 \\(NT\\) を持つとする: \\begin{equation*} g(t) = \\sum&#94;{N-1}_{n=0}f(t)\\delta(t-nT) \\end{equation*} その仮定の基で、 標本化信号 \\(g(t)\\) のフーリエ変換 \\(\\mathcal{F}[g(t)]\\) を求めると: \\begin{align*} \\mathcal{F}[g(t)] &= \\int&#94;{\\infty}_{-\\infty} f(t) \\delta_{T}(t) \\exp(-j\\omega t) {\\rm dt} \\\\ &= \\sum&#94;{N-1}_{n = 0} \\int&#94;{\\infty}_{-\\infty} f(t)\\delta(t - nT) \\exp(-j\\omega t) {\\rm dt} \\\\ &= \\sum&#94;{N-1}_{n = 0} f(nT) \\exp(-jn\\omega T) \\end{align*} ここで$j$は虚数単位、 \\(\\omega\\) は角周波数であり、 この式は離散フーリエ変換(DFT)の式に他ならない。 また、 \\(g(t)\\) の周波数特性を見やすくするために、 \\(\\delta_{T}(t)\\) をフーリエ級数展開する。 \\(\\delta_{T}(t)\\) の複素フーリエ級数展開の式は: \\begin{align*} \\delta_{T}(t) &= \\sum&#94;{\\infty}_{n = -\\infty} c_{n} \\exp(jn\\omega_{0}t) \\quad (\\omega_{0} = \\frac{2\\pi}{T}) \\\\ c_{n} &= \\frac{1}{T} \\int&#94;{T/2}_{-T/2} \\delta_{T}(t)\\exp(-jn\\omega_{0}t) {\\rm dt} \\end{align*} \\(c_{n}\\) を計算するとき、 積分範囲には唯一つのインパルスが存在する事に留意すると、 次のようになる: \\begin{align*} c_{n} &= \\frac{1}{T} \\int&#94;{T/2}_{-T/2} \\delta(t)\\exp(-jn\\omega_{0}t) {\\rm dt} \\\\ &= \\frac{1}{T} \\exp(0) = \\frac{1}{T} \\\\ \\therefore \\delta_{T}(t) &= \\frac{1}{T} \\sum&#94;{\\infty}_{n = -\\infty} \\exp(jn\\omega_{0} t) \\end{align*} この結果から \\(g(t)\\) の周波数特性を計算する。 \\(\\mathcal{F}[f(t)] = F(\\omega)\\) と書くと、 \\begin{align*} \\mathcal{F}[g(t)] &= \\mathcal{F}[f(t) \\frac{1}{T} \\sum&#94;{\\infty}_{n = -\\infty} \\exp(jn\\omega_{0} t)] \\\\ &= \\frac{1}{T} \\sum&#94;{\\infty}_{n = -\\infty} \\mathcal{F}[f(t)\\exp(jn\\omega_{0}t)] \\quad (\\because フーリエ変換の線形性) \\\\ &= \\frac{1}{T} \\sum&#94;{\\infty}_{n = -\\infty} \\int&#94;{\\infty}_{-\\infty} f(t) \\exp\\left[ -j(\\omega - n\\omega_{0})t \\right] {\\rm dt} \\\\ &= \\frac{1}{T} \\sum&#94;{\\infty}_{n = -\\infty} F(\\omega - n\\omega_{0}) \\end{align*} 従って、 \\(f(t)\\) の周波数特性 \\(F(\\omega)\\) を \\(\\omega_{0}\\) ずつずらして和をとったものとなる。 典型的な信号の周波数は高周波成分になるに従って振幅（パワー、 ゲイン）が減衰する事が知られているので、 原信号と離散化信号の周波数スペクトル \\(|F(\\omega)|\\) の概要図は 図2 のようになる。 典型的な信号のスペクトルの例 \\(|F(\\omega)|\\) は明らかに偶関数であり、 この時、 \\(|{\\cal F}[g(t)]|\\) のある山 \\(|F(\\omega - i\\omega_{0})|(i \\in \\mathbb{Z})\\) において、 隣の山 \\(|F(\\omega - (i \\pm 1) \\omega_{0})|\\) と交差する周波数は \\(\\displaystyle \\frac{\\omega_{0}}{2}k (k:奇数)\\) となる。 すると、 \\(|{\\cal F}[g(t)]|\\) はそれらの山の和を取るので、 結果 \\(\\displaystyle \\frac{\\omega_{0}}{2}k \\pm \\beta\\) の周波数成分のパワーが隣の山のスペクトルと区別できなくなってしまう（ 図3 ）。 特に、原信号 \\(f(t)\\) では弱かった高周波成分のスペクトルが強調されてしまい、 離散化後の信号においてそれが干渉縞等によって現れてしまう。 この現象をエイリアシングと呼ぶ。 エイリアシングが発生してしまうサンプリングの例 エイリアシングを防ぐには、原理的には、原信号 \\(f(t)\\) の周波数 \\(\\omega_{f} = \\displaystyle\\frac{2\\pi}{NT}\\) の2倍以上の周波数成分をローパスフィルターなどでカットし、かつ、サンプリング周波数を \\(2\\omega_{f}\\) （ナイキストレート）より大きくとれば良い（ 図4 ） エイリアシングを回避したサンプリングの例 信号の復元 フーリエ変換対の結果から、標本化した波形をアナログ信号に一意に復元する結果が得られる。 改めてフーリエ逆変換の結果 \\begin{equation*} f(t) = \\frac{1}{2\\pi} \\int&#94;{\\infty}_{-\\infty} F(\\omega) \\exp(j\\omega t) d\\omega \\end{equation*} を眺め、その意味をもう一度立ち戻って考えてみると、これは無限の周波数帯域を使用して信号を復元している式にも見える。 この式をサンプリング周波数で帯域制限して信号を復元する事を考えることで、標本化した信号をアナログ信号に復元する式が得られる。 まず フーリエ変換の結果 \\(F(\\omega)\\) を標本化信号によって表すことを考える。区分求積法の援用により、 \\begin{align*} F(\\omega) &= \\int&#94;{\\infty}_{-\\infty} f(t) \\exp(-j\\omega t) dt \\\\ &= \\lim_{f_{s} \\to \\infty} \\sum_{n=-\\infty}&#94;{\\infty} \\frac{1}{f_{s}} f\\left(\\frac{n}{f_{s}}\\right) \\exp\\left(-j\\omega\\frac{n}{f_{s}}\\right) \\end{align*} と形式的に表すことが出来る。ここで、 \\(f_{s}\\) はサンプリング周波数（サンプリングレート）である。この結果をフーリエ逆変換の式に代入すると、 \\begin{align*} f(t) &= \\frac{1}{2\\pi} \\int&#94;{\\infty}_{-\\infty} F(\\omega) \\exp(j\\omega t) d\\omega \\\\ &= \\frac{1}{2\\pi} \\int&#94;{\\infty}_{-\\infty} \\left\\{ \\lim_{f_{s} \\to \\infty} \\sum_{n=-\\infty}&#94;{\\infty} \\frac{1}{f_{s}} f\\left(\\frac{n}{f_{s}}\\right) \\exp\\left(-j\\omega\\frac{n}{f_{s}}\\right) \\right\\} \\exp(j\\omega t) d\\omega \\\\ &= \\frac{1}{2\\pi} \\lim_{f_{s} \\to \\infty} \\sum_{n=-\\infty}&#94;{\\infty} \\frac{1}{f_{s}} f\\left(\\frac{n}{f_{s}}\\right) \\int&#94;{\\infty}_{-\\infty} \\exp\\left[j\\omega \\left( t - \\frac{n}{f_{s}} \\right) \\right] d\\omega \\end{align*} ここで、最後の式変形の所で積分演算の線形性を用いて、和の順序を交換している。得られた最後の結果の積分 \\begin{equation*} \\int&#94;{\\infty}_{-\\infty} \\exp\\left[j\\omega \\left( t - \\frac{n}{f_{s}} \\right) \\right] d\\omega \\end{equation*} に注目する。積分範囲 \\([-\\infty, \\infty]\\) は無限になっているが、実際に得られるスペクトルは、標本化の結果 \\([-\\omega_{0}/2, \\omega_{0}/2]\\) の範囲に制限されていなければならない。従って、帯域制限を加味して積分を計算すると、 \\begin{align*} \\int&#94;{\\omega_{0}/2}_{-\\omega_{0}/2} \\exp\\left[j\\omega \\left( t - \\frac{n}{f_{s}} \\right) \\right] d\\omega &= \\frac{1}{j\\left( t - \\frac{n}{f_{s}} \\right)} \\left[ \\exp \\left\\{ j\\omega\\left( t - \\frac{n}{f_{s}} \\right) \\right\\} \\right]&#94;{\\omega_{0}/2}_{-\\omega_{0}/2} \\\\ &= \\frac{1}{j\\left( t - \\frac{n}{f_{s}} \\right)} \\left[ \\exp \\left\\{ j\\frac{\\omega_{0}}{2} \\left( t - \\frac{n}{f_{s}} \\right) \\right\\} - \\exp \\left\\{ -j\\frac{\\omega_{0}}{2} \\left( t - \\frac{n}{f_{s}} \\right) \\right\\} \\right] \\\\ &= \\frac{1}{j\\left( t - \\frac{n}{f_{s}} \\right)} j2 \\sin \\left[ \\frac{\\omega_{0}}{2} \\left( t - \\frac{n}{f_{s}} \\right) \\right] = \\frac{2 \\sin \\left[ \\pi f_{s} \\left( t - \\frac{n}{f_{s}} \\right) \\right]}{t - \\frac{n}{f_{s}}} \\end{align*} ここで、最後の式変形の所でオイラーの公式 \\begin{equation*} \\exp(jx) - \\exp(-jx) = \\cos(x) + j\\sin(x) - \\left\\{ \\cos(x) - j\\sin(x) \\right\\} = j2\\sin(x) \\end{equation*} を用いている。続けて、帯域制限を加味した積分結果を代入する。 極限 \\(\\displaystyle\\lim_{f_{s} \\to \\infty}\\) は帯域制限の結果考慮する必要が無くなる事に留意すると、 \\begin{align*} f(t) &= \\frac{1}{2\\pi} \\sum_{n=-\\infty}&#94;{\\infty} \\frac{1}{f_{s}} f\\left(\\frac{n}{f_{s}}\\right) \\frac{2 \\sin \\left[ \\pi f_{s} \\left( t - \\frac{n}{f_{s}} \\right) \\right]}{t - \\frac{n}{f_{s}}} \\\\ &= \\sum_{n=-\\infty}&#94;{\\infty} f\\left(\\frac{n}{f_{s}}\\right) \\frac{\\sin \\left[ \\pi f_{s} \\left( t - \\frac{n}{f_{s}} \\right) \\right]}{ \\pi f_{s} \\left( t - \\frac{n}{f_{s}} \\right)} \\\\ &= \\sum_{n=-\\infty}&#94;{\\infty} f\\left(\\frac{n}{f_{s}}\\right) \\mathrm{sinc} \\left[ f_{s} \\left( t - \\frac{n}{f_{s}} \\right) \\right] \\tag{17} \\end{align*} ここで、 \\begin{equation*} \\mathrm{sinc}(x) = \\frac{\\sin(\\pi x)}{\\pi x} \\end{equation*} は シンク関数(Sinc function) と呼ばれる。シンク関数の概形は次のようになっており、 \\(x=0\\) で最大値 \\(1\\) をとる（ \\(\\because\\) ロピタルの定理より、 \\(\\displaystyle \\lim_{x \\to 0} \\frac{\\sin(\\pi x)}{\\pi x} = \\lim_{x \\to 0} \\frac{\\frac{d \\sin(\\pi x)}{dx}}{\\frac{d \\pi x}{dx}} = \\lim_{x \\to 0} \\frac{\\pi \\cos(\\pi x)}{\\pi} = 1\\) ）。 式17 の結果から、 元のアナログ信号 \\(f(t)\\) はシンク関数の畳み込み演算によって完全に復元される事 [8] が示された。 [8] と言っても、無限和 \\(\\sum_{n=-\\infty}&#94;{\\infty}\\) は計算機で計算できないため、現実的には完全な復元は不可能である。 参考文献 『フーリエ変換・FFT入門』 http://www.maroon.dti.ne.jp/koten-kairo/works/fft/fft_start.html この記事は、上記記事の補足に過ぎないと思われる。","tags":"記事","url":"/dezitaruxin-hao-chu-li-nochu.html","loc":"/dezitaruxin-hao-chu-li-nochu.html"},{"title":"パーセプトロン昔話","text":"ニューラルネットワーク（Neural Network, 以下NN） は機械学習の歴史と共に歩んできたと言っても過言ではない. 戦後間もないウィーナーの時代 [1] からモデルが構築され始め, 幾つかの冬の時代（挫折）を超えて, そして現在流行りのディープラーニング（深層学習）は多層構造のNNによって構成されている. ここでは, NNの歴史に少しずつ触れながら, 多層パーセプトロンの学習則（逆誤差伝搬）までを解説していく. 本稿は主に [2] , [3] を参照している. \\begin{align*} \\newcommand{\\bvec}[1]{\\boldsymbol{#1}} \\newcommand{\\tvec}[1]{\\bvec{#1}&#94;{\\mathsf{T}}} \\newcommand{\\ve}[1]{\\bvec{#1}} \\newcommand{\\inpro}[2]{{\\left\\langle #1 , #2 \\right\\rangle}} \\newcommand{\\norm}[1]{{\\left\\| #1 \\right\\|}} \\newcommand{\\dint}[2]{\\int\\!\\!\\!\\int_{#1} #2 } \\newcommand{\\tint}[2]{\\int\\!\\!\\!\\int\\!\\!\\!\\int_{#1} #2 } \\newcommand{\\dif}[3]{\\frac{d&#94;{#1}#2}{d #3&#94;{#1}}} \\newcommand{\\pard}[3]{\\frac{\\partial&#94;{#1}#2}{\\partial #3&#94;{#1}}} \\newcommand{\\difrac}[2]{{\\frac{d #1}{d #2}}} \\newcommand{\\parfrac}[2]{{\\frac{\\partial #1}{\\partial #2}}} \\newcommand{\\tparfrac}[2]{{\\tfrac{\\partial #1}{\\partial #2}}} \\newcommand{\\Div}{{\\rm div}} \\newcommand{\\Rot}{{\\rm rot}} \\newcommand{\\Curl}{{\\rm curl}} \\newcommand{\\innprod}[2]{\\langle #1, #2 \\rangle} \\newcommand{\\n}{\\ \\\\} \\newcommand{\\cm}{{\\ , \\ }} \\def\\diag{\\mathop{\\rm diag}\\nolimits} \\def\\sign{\\mathop{\\rm sign}\\nolimits} \\end{align*} 脳機能のモデル化 活性化関数の例 形式ニューロン 単純パーセプトロンと単層パーセプトロン（パーセプトロン） 単層パーセプトロンの学習則 - ヘブ則とデルタ則 ヘブ則 デルタ則 多層パーセプトロン 多層パーセプトロンの学習則 - 逆誤差伝搬法 脳機能のモデル化 NNは脳の神経回路網を数学的なモデルで表現したものである. その為, 理論の出発点は生理学となる. その知識によると, 神経回路の構成要素であるニューロン（神経細胞）はシナプスを介して他の細胞と結合しており, 電気信号によって情報を伝達しあっている. 1つのニューロンは外部からの電気的刺激を受けると膜電位（細胞内外の電位差）を上昇させていき, 刺激の総量がある一定値（閾値）を超えると瞬間的に電位パルス（インパルス, スパイク）を放出する. 放出したパルスは他のニューロンに影響を与えることができる. この相互作用を大域的に見ることで脳活動が実現されると考えられている. 上記の生理学の知見をを事実として受け入れてみると, 次の単純なモデル化が考えられる. 1つのニューロンにおいて, 他のニューロンからの刺激（入力）の総量を \\(u\\) と表し, その入力を受けて出力を決める 活性化関数（activation function） \\(f\\) をおき, 出力を \\(y = f(u)\\) と表す. また総入力 \\(u\\) は他のニューロンからの刺激の重ねあわせによって決まるので, 単純に入力に重みを掛け合わせ和をとった総量と考えられる. 即ち, \\begin{equation*} \\begin{aligned} u = \\sum_{i=1}&#94;{n} w_{i}x_{i} + b = \\ve{w}&#94;{\\mathsf{T}} \\ve{x} + b\\end{aligned} \\end{equation*} と表せるものとする. ここで, \\(\\ve{x} = [x_{1},\\dots,x_{n}]&#94;{\\mathsf{T}}\\) は入力（他のニューロンからの出力）ベクトル, \\(\\ve{w} = [w_{1},\\dots,w_{n}]&#94;{\\mathsf{T}}\\) は入力の重み（係数）ベクトルであり, 生理学的にはシナプスの結合の強さ（影響の度合い）を表している. そして \\(-b\\) はニューロン発火の条件を与える しきい値（bias, threshold） を表している. 以上によってモデル化されるニューロンの機能の単位は図にまとめられ, ユニット（unit） と呼ばれる [4] . NNを構成する単位：ユニット 活性化関数の例 実際に良く使われる活性化関数 \\(f\\) としては, 次が挙げられる: 単位ステップ関数（ハードリミタ） \\(U(u)\\) \\(0\\) か \\(1\\) かを出力し, 決定的な識別を行う: \\begin{equation*} \\begin{aligned} f(u) = \\left\\{ \\begin{array}{ll} 0 & u < 0 \\\\ 1 & u > 0 \\end{array} \\right. \\end{aligned} \\end{equation*} \\(u=0\\) で不連続となり, \\(U(u)\\) 等で参照される事がある. 符号関数 \\(\\sign(u)\\) 二値のみを出力するのは単位ステップ関数と同じだが, \\(-1\\) か \\(1\\) を出力する: \\begin{equation*} \\begin{aligned} f(u) = \\left\\{ \\begin{array}{ll} -1 & u < 0 \\\\ 1 & u > 0 \\end{array} \\right. \\end{aligned} \\end{equation*} 単位ステップ関数とは表現を変えたい文脈で用いられる. 線形関数 \\(u\\) 入力をそのまま出力する線形関数も活性化関数に用いられる事がある: \\begin{equation*} \\begin{aligned} f(u) = u \\end{aligned} \\end{equation*} 入力が有界でない場合出力が発散する場合がある. 線形関数は微分可能なので学習規則の導出の際に役立つ. シグモイド（ロジスティック）関数 \\(\\varphi(u)\\) \\begin{equation*} \\begin{aligned} f(u) = \\frac{1}{1 + \\exp(-u)} \\end{aligned} \\end{equation*} 明らかに \\((0,1)\\) で単調増加する関数である. グラフが単位ステップ関数に類似し, 関数の形が単純であり, しかも微分可能である事から非常に重要な関数である. 実際, \\(u\\) で微分してみると, \\begin{equation*} \\begin{aligned} \\difrac{ }{u} f(u) &= - \\frac{-\\exp(-u)}{\\{1+\\exp(-u)\\}&#94;{2}} = \\frac{1}{1 + \\exp(-u)}\\left( 1 - \\frac{1}{1 + \\exp(-u)} \\right) \\\\ &= f(u) (1-f(u)) \\end{aligned} \\end{equation*} となって微分も簡易に計算できることも高評価の理由である. シグモイド関数は文献によっては \\(\\varphi(u)\\) で参照される事がある. \\(\\tanh\\) （タンジェントハイパボリック）関数 \\(\\tanh(u)\\) \\begin{equation*} \\begin{aligned} f(u) = \\tanh(u) = \\frac{\\exp(u) - \\exp(-u)}{\\exp(u) + \\exp(-u)} \\end{aligned} \\end{equation*} これは \\((-1,1)\\) で単調増加する関数であり, 値域を \\((0,1)\\) とする為に \\begin{equation*} \\begin{aligned} f(u) = \\frac{\\tanh(u) + 1}{2} \\end{aligned} \\end{equation*} とする場合がある. \\(\\tanh\\) の微分値も簡潔に表現できる: \\begin{equation*} \\begin{aligned} \\difrac{ }{u} f(u) &= \\frac{\\{\\exp(u)+\\exp(-u)\\}&#94;{2} - \\{\\exp(u)-\\exp(-u)\\}&#94;{2}}{\\{\\exp(u)+\\exp(-u)\\}&#94;{2}} \\\\ &= 1 - \\tanh&#94;{2}(u) = 1 - f&#94;{2}(u) \\end{aligned} \\end{equation*} また, 上述のシグモイド関数は \\(\\tanh\\) を用いて表すこともできる: \\begin{equation*} \\begin{aligned} \\frac{1}{1 + \\exp(-u)} &= \\frac{1}{2} \\frac{2 \\exp(u/2)}{\\exp(u/2) + \\exp(-u/2)} \\\\ &= \\frac{1}{2} \\left( \\frac{\\exp(u/2) + \\exp(-u/2)}{\\exp(u/2) + \\exp(-u/2)} + \\frac{\\exp(u/2) - \\exp(-u/2)}{\\exp(u/2) + \\exp(-u/2)} \\right) \\\\ &= \\frac{1}{2} (1 + \\tanh(u/2)) \\end{aligned} \\end{equation*} 図に関数のグラフを示す. よく使われる活性化関数のグラフ 形式ニューロン 最初にニューロンをモデル化して研究を行ったのはMcCulloch-Pitts（ウォーレン・マカロック-ウォルター・ピッツ）であり, 彼らは1943年に 形式ニューロン（formal neuron） を提案した. 形式ニューロンでは活性化関数は単にステップ関数 \\(U(u)\\) となる: \\begin{equation*} \\begin{aligned} U(u) = \\left\\{ \\begin{array}{ll} 1 & u > 0 \\\\ 0 & u < 0 \\end{array} \\right.\\end{aligned} \\end{equation*} これによって入力および出力は \\(0\\) か \\(1\\) （all-or-none）となる. 形式ニューロンでは, 重みと閾値の組み合わせによって論理素子を実現できる: NOT \\(U(-x_{1} + 0.5)\\) AND \\(U(x_{1} + x_{2} - 1.5)\\) OR \\(U(x_{1} + x_{2} - 0.5)\\) NAND \\(U(-x_{1} -x_{2} + 1.5)\\) XOR \\(U(x_{1} + x_{2} - 2U(x_{1} + x_{2} - 1.5) - 0.5)\\) 実際に入力値に値を代入して真理値表U 作ると, ユニットが正しく動作する事を確かめられる. この素子の組み合わせによって任意の（フリップフロップを含めた）論理回路が実現できるのはもちろんのこと, 形式ニューロンはチューリングマシンと同等の計算能力（チューリング完全）を持つ事が示されている. 形式ニューロンはニューロンの最初のモデルとしてNNの大本の基礎となったが, 現在のNNにあるような学習能力を持ちあわせてはいない. しかし, 重みや閾値を変更することでユニットの動作が変わるという観察から, それらを能動的に変更することで学習が実現されうるという示唆は既に生まれていたものと考えられる. 単純パーセプトロンと単層パーセプトロン（パーセプトロン） 1957年にRosenblatt（ローゼンブラッド）は形式ニューロンを入力層（Sensory Layer, S層）, 中間層（Associative Layer, A層）, 出力層（Response Layer, R層）の3つに分けて階層的に結合し, 図 1 の構造を持つ 単純パーセプトロン（simple perceptron） を提案した. ここで, S層とA層の間の重みはランダムに固定し, A層とR層の間の重みは 学習 によって決めるようになっている. 単純パーセプトロン 単純パーセプトロンの学習は, 微積分といった解析的な知見ではなく ヘブ則（Hebbian rule） と呼ばれる生理学の法則を用いている. 即ちそれは 「同時に発火したニューロン間のシナプス結合は強められる」 という法則であり, 多くの神経学者及び心理学者が受け入れている事実である. 後に述べるが, ヘブ則による学習は解が存在すれば有限回数の学習で正しい解に収束することが示されており, 次節に述べるデルタ則（これは数値解析的に学習する）と併せて有用な学習法と言える. 単純パーセプトロンはNNの学習可能性を初めて示し, 史上初のNN研究ブームを引き起こすきっかけとなった. ところで, 単純パーセプトロンは3層の階層構造をなしているが, 重みの学習の際に本質的に関与するのは中間層と出力層の間だけである. この学習する部分のみを抜き出すと, 図 2 の様に, 学習するニューロンの単純な入出力関係が得られる. これを 単層パーセプトロン（single-layer perceptron） あるいは単に パーセプトロン（perceptron） と呼ぶ. そして単純パーセプトロンの学習の際には, S層とA層間の重みをランダムに決定した後は単層パーセプトロンの学習だけを考えば良い事になる. 単層パーセプトロン（パーセプトロン） 単層パーセプトロンの学習則 - ヘブ則とデルタ則 単層パーセプトロンの学習にはサンプルが必要となるため, まずはサンプルの表記から行う. 学習の中でも特に教師あり学習（supervised learning）はサンプルのデータにラベルが付いている. ラベルは一般的にはなんでも良いが, 基本的にはデータがある性質を満たす場合（正例）はラベルを \\(1\\) に, 満たさない場合（負例）はラベルを \\(-1\\) とする [5] . そして \\(N\\) 個のデータからなるサンプルの集合 \\(Z\\) は, データ \\(\\ve{x}\\) とその（教師）ラベル \\(t\\) の組の集合で表される: \\begin{equation*} \\begin{aligned} Z = \\{ (\\ve{x}_{1}, t_{1}), (\\ve{x}_{2}, t_{2}), \\dots, (\\ve{x}_{N}, t_{N}) \\}\\end{aligned} \\end{equation*} 以下, 出力層が1つのユニットだけからなる単層パーセプトロン（図式的には図と等価）の学習を考える. ユニットが複数存在する場合でも出力層の内部でユニットは互いに独立に動作する（ \\(\\because\\) 結合が無いため）ので拡張は容易である. また, 表記を簡単にするため, ユニットへの入力 \\(u\\) はしきい値 \\(b\\) を省き, 重みと入力の内積 \\(\\ve{w}&#94;{\\mathsf{T}}\\ve{x}\\) のみで表現する: \\begin{equation*} \\begin{aligned} u &= \\sum_{i=1}&#94;{n} w_{i} x_{i} + b = \\sum_{i=1}&#94;{n+1} w_{i} x_{i} \\quad (w_{n+1} = b,\\ x_{n+1} = 1) \\\\ &\\equiv \\ve{w}&#94;{\\mathsf{T}}\\ve{x}\\end{aligned} \\end{equation*} これは常に \\(1\\) を入力するユニットを仮定し, その結合重みを \\(b\\) とすることで説明できる. ヘブ則 前節で述べたとおり, ヘブ則は「同時に発火したニューロン間のシナプス結合は強められる」というものであった. これはラベルを \\(t_{l} \\in \\{ 1, 0 \\}\\ (l=1,\\dots,N)\\) （正例を1, 負例を0）, サンプルデータ \\(\\ve{x}_{l}\\) を入力した時の出力を \\(y_{l} = U(u_{l}) = U\\left( \\ve{w}&#94;{\\mathsf{T}} \\ve{x}_{l}\\right)\\) とすれば, 重み（シナプス結合）の更新量 \\(\\Delta w_{i}\\) は次の様に表せる: \\begin{equation*} \\begin{aligned} \\Delta w_{i} &= \\left\\{ \\begin{array}{ll} \\eta (\\ve{x}_{l})_{i} & \\text{if}\\ t_{l} = y_{l} = 1 \\\\ 0 & \\text{otherwise} \\end{array} \\right. \\\\ &= \\eta t_{l}y_{l}(\\ve{x}_{l})_{i}\\end{aligned} \\end{equation*} ここで, \\((\\ve{x}_{l})_{i}\\) はベクトル \\(\\ve{x}_{l}\\) の第 \\(i\\) 要素, \\(\\eta > 0\\) は学習の早さを決める係数であり, 学習率（learning rate） と呼ばれる. 学習の際には \\(\\ve{w} = \\ve{0}\\) で初期化してサンプルを順次入力し, 上の更新量に沿って重みを更新していけば良い. 第 \\(s\\) ステップの時の重みベクトルを \\(\\ve{w}&#94;{(s)}\\) と表すと, 更新規則は, \\begin{equation*} \\begin{aligned} \\ve{w}&#94;{(s+1)} = \\ve{w}&#94;{(s)} + \\Delta \\ve{w} = \\ve{w}&#94;{(s)} + \\eta t_{l} y_{l} \\ve{x}_{l}\\end{aligned} \\end{equation*} と表せる. ここで, \\(\\Delta \\ve{w}\\) 更新量を並べたベクトル \\(\\Delta \\ve{w} = [\\Delta w_{1},\\dots,\\Delta w_{n}]&#94;{\\mathsf{T}}\\) である. 素朴なヘブ則の実装では, 上の \\(\\Delta w_{i}\\) を観察すれば即座に分かるように, 重みが際限なく大きくなって発散してしまって学習が停止しない場合がある. 従って, 重みの発散を防ぐために重みは抑制する方向に更新するようにとる. 即ち, ラベルを \\(\\{ 1, -1 \\}\\) , 活性化関数を符号関数 \\(\\sign\\) とし, 出力 \\(y_{l} = \\sign(u_{l})\\) とラベル \\(t_{l}\\) が異なる（サンプルを誤識別した）場合にのみ重みを更新する: \\begin{equation*} \\begin{aligned} \\Delta w_{i} &= \\left\\{ \\begin{array}{ll} -\\eta (\\ve{x}_{l})_{i} = \\eta t_{l}y_{l}(\\ve{x}_{l})_{i} & \\text{if}\\ t_{l} \\neq y_{l} \\\\ 0 & \\text{otherwise} \\end{array} \\right.\\end{aligned} \\end{equation*} この更新規則もヘブ則と呼ばれる事がある. ヘブ則の重要な性質に, 最適な重みが存在するならば有限ステップで学習が停止（サンプルの誤識別がなくなる）する事が示されている. ここでは, [6] に従ってその証明を行う. まず, 存在が仮定された最適な重みを \\(\\ve{w}&#94;{\\ast}\\) と表し, \\(||\\ve{w}&#94;{\\ast}||&#94;{2} = \\ve{w}&#94;{\\ast\\mathsf{T}}\\ve{w}&#94;{\\ast} = \\sum_{i=1}&#94;{n} w_{i}&#94;{\\ast 2} = 1\\) となる様に正規化しておく [7] . ここで, \\(||\\ve{v}||\\) はベクトル \\(\\ve{v}\\) の2乗ノルムである. また, \\(\\gamma = \\displaystyle \\min_{l} y_{l} u_{l} = \\min_{l} y_{l} \\ve{w}&#94;{\\ast\\mathsf{T}} \\ve{x}_{l}\\) なる定数 [8] をおき, \\(\\gamma > 0\\) とする. この時, 更新式により, \\begin{equation*} \\begin{aligned} ||\\ve{w}&#94;{(s+1)}||&#94;{2} &= \\ve{w}&#94;{(s+1)\\mathsf{T}} \\ve{w}&#94;{(s+1)} \\\\ &= (\\ve{w}&#94;{(s)} + \\Delta \\ve{w})&#94;{\\mathsf{T}}(\\ve{w}&#94;{(s)} + \\Delta \\ve{w}) \\\\ &= (\\ve{w}&#94;{(s)} + \\eta t_{l} y_{l} \\ve{x}_{l})&#94;{\\mathsf{T}}(\\ve{w}&#94;{(s)} + \\eta t_{l} y_{l} \\ve{x}_{l}) \\\\ &= \\ve{w}&#94;{(s)\\mathsf{T}} \\ve{w}&#94;{(s)} + 2\\eta t_{l} y_{l} \\ve{w}&#94;{(s)\\mathsf{T}} \\ve{x}_{l} + \\eta&#94;{2} \\ve{x}_{l}&#94;{\\mathsf{T}}\\ve{x}_{l} \\quad (\\because t_{l}&#94;{2} = y_{l}&#94;{2} = 1) \\\\ &\\leq ||\\ve{w}&#94;{(s)}||&#94;{2} + \\eta&#94;{2} ||\\ve{x}_{l}||&#94;{2} \\quad (\\because \\eta t_{l} y_{l} (\\ve{x}_{l})_{i} = \\Delta w_{i} \\leq 0)\\end{aligned} \\end{equation*} が任意の \\(l \\in \\{ 1,\\dots,N \\}\\) で成り立つ. この関係式をステップ毎に繰り返し適用すれば, \\begin{equation*} \\begin{aligned} ||\\ve{w}&#94;{(s)}||&#94;{2} &\\leq ||\\ve{w}&#94;{(s-1)}||&#94;{2} + \\eta&#94;{2}||\\ve{x}_{l&#94;{(s-1)}}||&#94;{2} \\\\ &\\leq ||\\ve{w}&#94;{(s-2)}||&#94;{2} + \\eta&#94;{2}(||\\ve{x}_{l&#94;{(s-1)}}||&#94;{2} + ||\\ve{x}_{l&#94;{(s-2)}}||&#94;{2}) \\\\ &\\dots \\\\ &\\leq ||\\ve{w}&#94;{(0)}||&#94;{2} + \\eta&#94;{2} \\sum_{k=0}&#94;{s-1} ||\\ve{x}_{l&#94;{(k)}}||&#94;{2} \\\\ &\\leq s\\eta&#94;{2} \\max_{l} ||\\ve{x}_{l}||&#94;{2} \\quad (\\because \\ve{w}&#94;{(0)} = \\ve{0})\\end{aligned} \\end{equation*} を得る. ここで, \\(l&#94;{(s)}\\) はステップ \\(s\\) の更新の時に選ばれたサンプルの番号（インデックス）を表している. また, 全ての \\(\\ve{x}_{l}\\ (l=1,\\dots,N)\\) は現実的に有界（いずれの要素も \\((-\\infty, \\infty)\\) にある）と考えられるので, 全てのデータを包む事ができる球（超球）の最小の半径を \\(R\\) とおけば, \\(\\displaystyle \\max_{l} ||\\ve{x}_{l}||&#94;{2} \\leq R&#94;{2}\\) が成り立つので, \\begin{equation*} \\begin{aligned} ||\\ve{w}&#94;{(s)}||&#94;{2} \\leq s\\eta&#94;{2} \\max_{l} ||\\ve{x}_{l}||&#94;{2} \\leq s \\eta&#94;{2} R&#94;{2}\\end{aligned} \\end{equation*} となる. 一方, \\(\\ve{w}&#94;{\\ast}\\) と \\(\\ve{w}&#94;{(s+1)}\\) の内積をとると, \\begin{equation*} \\begin{aligned} \\ve{w}&#94;{\\ast \\mathsf{T}} \\ve{w}&#94;{(s+1)} &= \\ve{w}&#94;{\\ast \\mathsf{T}} ( \\ve{w}&#94;{(s)} + \\eta t_{l} y_{l} \\ve{x}_{l}) \\\\ &= \\ve{w}&#94;{\\ast \\mathsf{T}} \\ve{w}&#94;{(s)} + \\eta t_{l} y_{l} \\ve{w}&#94;{\\ast \\mathsf{T}} \\ve{x}_{l} \\\\ &\\geq \\ve{w}&#94;{\\ast \\mathsf{T}} \\ve{w}&#94;{(s)} + \\eta \\gamma\\end{aligned} \\end{equation*} が成立し, この関係式もステップ毎に繰り返し適用すると, \\begin{equation*} \\begin{aligned} \\ve{w}&#94;{\\ast \\mathsf{T}} \\ve{w}&#94;{(s)} &\\geq \\ve{w}&#94;{\\ast \\mathsf{T}} \\ve{w}&#94;{(s-1)} + \\eta \\gamma \\\\ &\\geq \\ve{w}&#94;{\\ast \\mathsf{T}} \\ve{w}&#94;{(s-2)} + 2\\eta \\gamma \\\\ &\\dots \\\\ &\\geq \\ve{w}&#94;{\\ast \\mathsf{T}} \\ve{w}&#94;{(0)} + s\\eta \\gamma = s\\eta \\gamma\\end{aligned} \\end{equation*} を得て, この式の両辺を二乗すると次の結果を得る: \\begin{equation*} \\begin{aligned} s&#94;{2} \\eta&#94;{2} \\gamma&#94;{2} &\\leq (\\ve{w}&#94;{\\ast \\mathsf{T}}\\ve{w}&#94;{(s)})&#94;{2} \\\\ &\\leq (\\ve{w}&#94;{\\ast \\mathsf{T}} \\ve{w}&#94;{\\ast}) (\\ve{w}&#94;{(s) \\mathsf{T}} \\ve{w}&#94;{(s)}) \\quad (\\because シュワルツの不等式) \\\\ &= ||\\ve{w}&#94;{\\ast}||&#94;{2} ||\\ve{w}&#94;{(s)}||&#94;{2} = ||\\ve{w}&#94;{(s)}||&#94;{2} \\\\ &\\leq s\\eta&#94;{2}R&#94;{2}\\end{aligned} \\end{equation*} ここで, 不等式中央の内積 \\(\\ve{w}&#94;{\\ast \\mathsf{T}}\\ve{w}&#94;{(s)}\\) は最適解 \\(\\ve{w}&#94;{\\ast}\\) と現在の重み \\(\\ve{w}&#94;{(s)}\\) との類似度とも捉えられる [9] ので, この不等式によりステップ数 \\(s\\) 増加の度に類似度の下限 \\(s&#94;{2}\\eta&#94;{2}\\gamma&#94;{2}\\) が上限 \\(s\\eta&#94;{2}R&#94;{2}\\) よりも早く増加する事が観察できる. 即ち類似度は単調増加し, 重みは最適解に近づいて行くことが分かる. またステップ数 \\(s\\) について解くと \\(\\displaystyle s \\leq \\frac{R&#94;{2}}{\\gamma&#94;{2}}\\) が成立し, \\(\\gamma, R\\) は有限のために \\(s\\) もまた有限となる. これらの結果により, 有限ステップで \\(\\ve{w}&#94;{\\ast}\\) が得られ, 学習が停止することが示された. デルタ則 デルタ則（デルタルール）は現在の重み \\(\\ve{w}\\) でのサンプルによる出力とラベルの誤差（経験誤差） \\(E(\\ve{w})\\) を定義し, \\(E(\\ve{w})\\) を極小にする様に重みを更新していく学習則である. 誤差 \\(E(\\ve{w})\\) の \\(\\ve{w}\\) による偏微分 \\(\\displaystyle\\parfrac{E(\\ve{w})}{\\ve{w}}\\) は勾配, 即ち最も \\(E(\\ve{w})\\) の変化する方向（最急勾配）を表すので, 重みの更新量 \\(\\Delta \\ve{w}\\) は学習率 \\(\\eta > 0\\) を用いて \\begin{equation*} \\begin{aligned} \\Delta \\ve{w} = - \\eta \\parfrac{E(\\ve{w})}{\\ve{w}}\\end{aligned} \\end{equation*} とすれば, 更新の度に誤差を最小にする様に重み \\(\\ve{w}\\) を更新することができる. 学習の収束は, \\(\\Delta \\ve{w}\\) の大きさ（ \\(||\\Delta \\ve{w}||&#94;{2}\\) 等）が十分に小さくなった時とすれば良く, そのときは極小解 [10] が得られている. この手法は 最急勾配法（steepest gradient method） と呼ばれる基本的な数値最適化の手法の一種である. ここでは, ユニットの活性化関数を単位ステップ関数 \\(U(u)\\) , ラベルを \\(\\{ 1, 0 \\}\\) として考える. さて, 誤差は様々なものが考えられるが, 単純に二乗誤差 \\begin{equation*} \\begin{aligned} E(\\ve{w}) = \\frac{1}{2} \\sum_{l=1}&#94;{N} (t_{l} - y_{l})&#94;{2} = \\frac{1}{2} \\sum_{l=1}&#94;{N} \\left\\{ t_{l} - U(\\ve{w}&#94;{\\mathsf{T}}\\ve{x}_{l}) \\right\\}&#94;{2}\\end{aligned} \\end{equation*} とする [11] と, 後に示す様に局所最適解に嵌ってしまう可能性がある. 第一, 単位ステップ関数 \\(U(u)\\) はもとより微分可能では無く, このままでは学習則を導出できない. そこで, まず, ユニットの活性化関数を一旦微分可能なシグモイド関数 \\(\\varphi\\) とし, その出力を \\(y_{l}=1\\) となる確率 \\(p(y_{l}=1)\\) として定義する: \\begin{equation*} \\begin{aligned} p(y_{l} = 1) = \\varphi(u_{l}/T) = \\frac{1}{1+\\exp(-u_{l}/T)}\\end{aligned} \\end{equation*} ここで, \\(T \\geq 0\\) は温度パラメタと呼ばれ, 図のグラフで見れるように \\(T \\to 0\\) とすると単位ステップ関数に漸近することが分かる. 様々な温度パラメタ \\(T\\) におけるシグモイド関数 \\(\\varphi(u/T)\\) のグラフ 同時にラベル \\(t_{l}\\) もある確率分布 \\(q\\) に従って生成される確率変数と考える事ができ, \\(t_{l}\\) が \\(1\\) を取る確率は \\(q(t_{l}=1) = t_{l}\\) で定義することができる. この様に定義した出力とラベルの確率分布 \\(q,p\\) 間の\"違い\"を誤差 \\(E(\\ve{w})\\) とする. 特に機械学習では, 確率分布間の違いを測る尺度として非常に重要な KLダイバージェンス（Kullback-Leibler divergence） \\(KL(q||p)\\) がある: \\begin{equation*} \\begin{aligned} KL(q||p) = \\sum_{l=1}&#94;{N} q(t_{l}) \\log\\left[ \\frac{q(t_{l})}{p(t_{l})} \\right]\\end{aligned} \\end{equation*} すぐに分かるように \\(KL(q||p) = 0\\) となるのは \\(q\\) と \\(p\\) が完全に一致する時（ \\(q(t_{l}) = p(t_{l})\\ (l=1,\\dots,N)\\) ）のみである. それでは誤差 \\(E(\\ve{w})\\) をKLダイバージェンスとして, その \\(\\ve{w}\\) による偏微分を計算する事を考える. まず, \\(KL(q||p)\\) は定義式から次の様に展開できる: \\begin{equation*} \\begin{aligned} E(\\ve{w}) &= KL(q||p) = \\sum_{l=1}&#94;{N} q(t_{l}) \\log\\left[ \\frac{q(t_{l})}{p(t_{l})} \\right] \\\\ &= \\sum_{l=1}&#94;{N} \\left\\{ q(t_{l}=0) \\log\\left[ \\frac{q(t_{l}=0)}{p(t_{l}=0)} \\right] + q(t_{l}=1) \\log\\left[ \\frac{q(t_{l}=1)}{p(t_{l}=1)} \\right] \\right\\} \\\\ &= \\sum_{l=1}&#94;{N} \\left\\{ (1-t_{l}) \\log\\left( \\frac{1-t_{l}}{1-\\varphi(u_{l}/T)} \\right) + t_{l} \\log \\left( \\frac{t_{l}}{\\varphi(u_{l}/T)} \\right) \\right\\}\\end{aligned} \\end{equation*} 見通しを良くする為に和の内部を \\(e_{l}(\\ve{w})\\) とおき, \\(e_{l}(\\ve{w})\\) を \\(w_{i}\\) で偏微分すると, \\begin{equation*} \\begin{aligned} \\parfrac{}{w_{i}} e_{l}(\\ve{w}) &= \\parfrac{e_{l}(\\ve{w})}{\\varphi(u_{l}/T)} \\parfrac{\\varphi(u_{l}/T)}{w_{i}} \\quad (\\because 合成関数の微分) \\\\ &= \\left\\{ (1-t_{l})\\frac{1}{1-\\varphi(u_{l}/T)} - \\frac{t_{l}}{\\varphi(u_{l}/T)} \\right\\} \\parfrac{\\varphi(u_{l}/T)}{u_{l}} \\parfrac{u_{l}}{w_{i}} \\quad (\\because 合成関数の微分) \\\\ &= \\frac{\\varphi(u_{l}/T)(1 - t_{l}) - t_{l} \\left\\{ 1 - \\varphi(u_{l}/T) \\right\\}}{\\varphi(u_{l}/T) \\left\\{ 1 - \\varphi(u_{l}/T) \\right\\}} \\frac{1}{T} \\varphi(u_{l}/T) \\left\\{ 1 - \\varphi(u_{l}/T) \\right\\} (\\ve{x}_{l})_{i} \\\\ &= \\frac{1}{T} \\left\\{ \\varphi(u_{l}/T) - t_{l} \\right\\} (\\ve{x}_{l})_{i}\\end{aligned} \\end{equation*} が得られ, 更新量 \\(\\Delta \\ve{w}\\) は \\begin{equation*} \\begin{aligned} \\Delta \\ve{w} &= - \\eta \\parfrac{E(\\ve{w})}{\\ve{w}} = - \\eta \\frac{1}{T} \\sum_{l=1}&#94;{N} \\parfrac{}{\\ve{w}} e_{l}(\\ve{w}) \\\\ &= - \\frac{\\eta}{T} \\sum_{l=1}&#94;{N}(\\varphi(u_{l}/T) - t_{l}) \\ve{x}_{l} = - \\frac{\\eta}{T} \\sum_{l=1}&#94;{N} \\delta_{l} \\ve{x}_{l}\\end{aligned} \\end{equation*} とまとめられる. ここで, \\(\\delta_{l} = \\varphi(u_{l}/T) - t_{l}\\) は誤差信号と呼ばれる. シグモイド関数から単位ステップ関数に戻すために \\(T \\to 0\\) とするが, 同時に \\(\\eta \\to 0\\) として \\((\\eta / T) \\to \\epsilon\\) となる様な \\(\\epsilon > 0\\) をとって \\(\\Delta \\ve{w}\\) が発散しないようにすれば, デルタ則による重みの更新量 \\(\\Delta \\ve{w}\\) は, \\begin{equation*} \\begin{aligned} \\Delta \\ve{w} = -\\epsilon \\sum_{l=1}&#94;{N} \\delta_{l} \\ve{x}_{l} = \\epsilon \\sum_{l=1}&#94;{N} \\left\\{ t_{l} - U(u_{l}) \\right\\} \\ve{x}_{l}\\end{aligned} \\end{equation*} となる. この \\(\\epsilon\\) も学習率と呼ばれ, 実践においては \\(0.1\\) から \\(0.5\\) あたりに設定される. この学習則は \\(\\sum_{l=1}&#94;{N}\\) の存在により, 全てのサンプルを提示して更新するのでこれを特に一括（斉時）学習（batch learning）と呼ぶが, 1つのサンプル毎に重みを更新するやり方もある: \\begin{equation*} \\begin{aligned} \\Delta \\ve{w} = \\epsilon \\left\\{ t_{l} - U(u_{l}) \\right\\} \\ve{x}_{l}\\end{aligned} \\end{equation*} これは逐次学習（on-line learning）と呼ばれる. 一般に逐次学習の方が収束が早い事が知られている [12] . この更新則による学習が局所最適に陥らないことを示す. \\(\\displaystyle\\parfrac{e_{l}(\\ve{w})}{w_{i}}\\) を更に \\(w_{j}\\) で偏微分し2階の偏導関数を求めると, \\begin{equation*} \\begin{aligned} \\parfrac{ }{w_{j}}\\parfrac{e_{l}(\\ve{w})}{w_{i}} &= \\parfrac{{}&#94;{2} e_{l}(\\ve{w})}{w_{i} \\partial w_{j}} \\\\ &= \\frac{1}{T} \\parfrac{\\varphi(u_{l}/T)}{w_{j}} x_{i} = \\frac{1}{T&#94;{2}} \\varphi(u_{l}/T) \\left\\{ 1 - \\varphi(u_{l}/T) \\right\\} (\\ve{x}_{l})_{i}(\\ve{x}_{l})_{j}\\end{aligned} \\end{equation*} となり, \\((H)_{ij} = \\displaystyle \\parfrac{{}&#94;{2} e_{l}(\\ve{w})}{w_{i} \\partial w_{j}}\\) なる \\(e_{l}(\\ve{w})\\) のヘッセ行列（Hessian matrix） \\(H\\) は \\begin{equation*} \\begin{aligned} H = \\frac{1}{T&#94;{2}} \\varphi(u_{l}/T) \\left\\{ 1 - \\varphi(u_{l}/T) \\right\\} \\ve{x}_{l} \\ve{x}_{l}&#94;{\\mathsf{T}}\\end{aligned} \\end{equation*} で計算できる. 明らかに \\(\\displaystyle\\frac{1}{T&#94;{2}}\\varphi(u_{l}/T) \\left\\{ 1 - \\varphi(u_{l}/T) \\right\\} > 0\\) であり, 行列 \\(\\ve{x}_{l}\\ve{x}_{l}&#94;{\\mathsf{T}}\\) は任意のベクトル \\(\\ve{v}\\) に対して二次形式 \\(\\ve{v}&#94;{\\mathsf{T}} (\\ve{x}_{l}\\ve{x}_{l}&#94;{\\mathsf{T}}) \\ve{v}\\) が, \\begin{equation*} \\begin{aligned} \\ve{v}&#94;{\\mathsf{T}} (\\ve{x}_{l}\\ve{x}_{l}&#94;{\\mathsf{T}} ) \\ve{v} &= (\\ve{x}_{l}&#94;{\\mathsf{T}} \\ve{v})&#94;{\\mathsf{T}} (\\ve{x}_{l}&#94;{\\mathsf{T}} \\ve{v}) = (\\ve{x}_{l}&#94;{\\mathsf{T}} \\ve{v})&#94;{2} \\geq 0\\end{aligned} \\end{equation*} となるので半正定値行列である. 従って, ヘッセ行列 \\(H\\) も半正定値となり, \\(e_{l}(\\ve{w})\\) は凸関数であることが分かり, 極小値が大域的な最小値に一致する（局所最小値が存在しない）ことが確かめられた. 最後に誤差 \\(E(\\ve{w})\\) として二乗誤差を用いた場合の更新量 \\(\\Delta \\ve{w}\\) を求めておく. 今度は \\(e_{l}(\\ve{w}) = \\displaystyle \\frac{1}{2} (t_{l} - y_{l})&#94;{2}\\) とおき, ユニットの活性化関数を一般に微分可能な関数 \\(f\\) とすると, \\begin{equation*} \\begin{aligned} \\parfrac{ }{w_{i}} e_{l}(\\ve{w}) &= \\parfrac{e_{l}(\\ve{w})}{y_{l}} \\parfrac{y_{l}}{u_{l}}\\parfrac{u_{l}}{w_{i}} \\quad (\\because 合成関数の微分) \\\\ &= -(t_{l} - y_{l}) f&#94;{\\prime} (u_{l}) x_{i} \\quad (f&#94;{\\prime} (u_{l}) \\equiv \\parfrac{y_{l}}{u_{l}} = \\parfrac{ }{u_{l}} f(u_{l})) \\\\ &= \\delta_{l} f&#94;{\\prime}(u_{l}) x_{i}\\end{aligned} \\end{equation*} となる. 従って更新量 \\(\\Delta \\ve{w}\\) は \\begin{equation*} \\begin{aligned} \\Delta \\ve{w} = - \\eta \\sum_{l=1}&#94;{N} \\delta_{l} f&#94;{\\prime}(u_{l}) \\ve{x}_{l}\\end{aligned} \\end{equation*} となる. さて, この学習則は局所最小値におちいる場合がある事に上で言及したが, これは \\(e_{l}(\\ve{w})\\) の2階の偏導関数が \\begin{equation*} \\begin{aligned} \\parfrac{{}&#94;{2} e_{l}(\\ve{w})}{w_{i} \\partial w_{j}} &= \\parfrac{ }{w_{j}} y_{l} f&#94;{\\prime}(u_{l}) x_{i} - (t_{l} - y_{l}) \\parfrac{ }{w_{j}} f&#94;{\\prime}(u_{l}) x_{i} \\\\ &= \\left\\{ (f&#94;{\\prime}(u_{l}))&#94;{2} - (t_{l} - y_{l}) f&#94;{\\prime\\prime} (u_{l}) \\right\\} x_{i} x_{j}\\end{aligned} \\end{equation*} となるが, \\((f&#94;{\\prime}(u_{l}))&#94;{2} - (t_{l} - y_{l}) f&#94;{\\prime\\prime} (u_{l})\\) が常に非負になるとは限らないからである. 実際, \\(f\\) をシグモイド関数とすると2階微分は \\begin{equation*} \\begin{aligned} f&#94;{\\prime\\prime}(u_{l}) &= f&#94;{\\prime}(u_{l}) (1-f(u_{l})) - f(u_{l}) f&#94;{\\prime}(u_{l}) = f&#94;{\\prime}(u_{l}) (1 - 2 f(u_{l})) \\\\ &= f(u_{l}) (1 - f(u_{l}))(1-2f(u_{l}))\\end{aligned} \\end{equation*} であり, \\(t_{l} = 1\\) とすると, \\begin{equation*} \\begin{aligned} (f&#94;{\\prime}(u_{l}))&#94;{2} - (1 - y_{l}) f&#94;{\\prime\\prime} (u_{l}) &= (f&#94;{\\prime}(u_{l}))&#94;{2} + f&#94;{\\prime}(u_{l})(1-2f(u_{l})) - 1 \\\\ &= f&#94;{\\prime}(u_{l}) (f&#94;{\\prime}(u_{l}) + 1 - 2f(u_{l}) ) - 1 \\\\ &= f(u_{l}) (1 - f(u_{l})) (-(f(u_{l}))&#94;{2} + 1 - f(u_{l})) - 1 < 0\\end{aligned} \\end{equation*} となってしまう. 従って二乗誤差を用いる場合はヘッセ行列が半正定値行列とならず, 誤差が局所最小値におちいる場合がある. 多層パーセプトロン 単層パーセプトロンはサンプルが直線（平面）で分離できる（線形分離可能な）問題にしか適用できない事 [13] が1969年にMinskey-Papertに指摘された. 線形分離不可能な例としてよく例に引き出されるのが図 3 の XOR問題 である. XOR問題 この問題は1本の直線では分離できず, 従って単層パーセプトロンでは正しく学習することができない. この線形分離不可能な問題のために, NN研究の第一次ブームは終焉を迎え最初の冬の時代が訪れた. この問題は1986年, Rumelhart-McClelland（デビット・ラメルハート-ジェームス・マクレランド）によって提案された 多層パーセプトロン（multi-layer perceptron, MLP） によって解決を見た. 多層パーセプトロンは図 4 に表される様に, 入力層（input layer）, 任意個数の中間（隠れ）層（middle(hidden) layer）, 出力層（output layer）からなる多層構造を持ち, 全てのユニット出力の活性化関数は非線形関数（大体はシグモイド関数）となっている. 多層パーセプトロン 多層パーセプトロンが線形分離不可能な問題にも適用できるのは, 主に次の2つの理由による: 階層構造を用いている事: これは形式ニューロンのXOR素子で既に示唆されていたが, ニューロンを階層的に繋いで全ての重みを可変にすれば, 1つのユニットが1つの分離結果を持つため複数の分離結果を合成することができる. ユニットの出力が非線形であること: ユニットの出力を非線形にすることで, 線形分離不可能な入力をニューロン内部で非線形変換し, 線形分離可能な問題に還元できる場合がある. 多層パーセプトロンは様々な現実的な問題に適用できる為に, NNの第二次研究ブームを引き起こした. 現在においても, 一口にNNと言うと3層（1つの中間層）からなる多層パーセプトロン（3層NN）の事を指すことが多い. 多層パーセプトロンの学習則 - 逆誤差伝搬法 全ての重みが可変となった多層パーセプトロンでは, 単層パーセプトロンにおける学習則の様に出力層の重みを更新するだけではなく, 全ての重みを逐次更新していく必要がある. 多層パーセプトロンの学習として標準的に用いられる 逆誤差伝搬法（(error) back-propagation method） は, 出力層での誤差を順次後ろ向きに（出力 \\(\\to\\) 中間 \\(\\to\\) 入力層の順に）伝播させて重みを更新していく手法である. それでは学習則を導出していくが, 多層構造を表現する為に次の定義を導入する. まず, 入力層を第 \\(1\\) 層, 入力層と繋がった中間層を第 \\(2\\) 層, 第 \\(2\\) 層と繋がった層を第 \\(3\\) 層, \\(\\dots\\) と呼び, 出力層は第 \\(n\\) 層とする. 即ち \\(n\\) 層構造の多層パーセプトロンを考える. また, 各層のユニット個数は一般に異なっても良いことにし, 第 \\(k\\) 層におけるユニットの数を \\(L_{k}\\) と表す. 第 \\(k-1\\) 層における第 \\(i\\) ユニットと第 \\(k\\) 層における第 \\(j\\) ユニットを繋ぐ重みを \\(w_{ij}&#94;{k-1,k}\\) と表し, 第 \\(k\\) 層の第 \\(i\\) ユニットへの入力総量を \\(u_{i}&#94;{k}\\) と, またその出力を \\(y_{i}&#94;{k} = f(u_{i}&#94;{k})\\) と表す. \\(f\\) は微分可能な活性化関数ならば何でも良いが, ここではシグモイド関数とする. また, 出力層に複数ユニットが存在するのでサンプルラベルも各出力ユニットに対応して用意し, \\(i\\) 番目の出力ユニットに与えるラベルを \\(t&#94;{l}_{i}\\ (i=1,\\dots,N)\\) と表す. デルタ則の導出と同様に誤差の勾配を取ることを考える. 無論, 局所最小を回避する為に誤差関数 \\(E\\) としてKLダイバージェンスを導入する. \\(E\\) を \\(w_{ij}&#94;{k-1,k}\\) によって偏微分すると, \\begin{equation*} \\begin{aligned} \\parfrac{E}{w_{ij}&#94;{k-1, k}} &= \\parfrac{E}{u_{j}&#94;{k}} \\parfrac{u_{j}&#94;{k}}{w_{ij}&#94;{k-1,k}} \\quad (\\because 偏微分の連鎖律。 u_{j}&#94;{k} を挟み込んでいるのが逆誤差伝播のキモ。) \\\\ &= \\parfrac{E}{u_{j}&#94;{k}} \\parfrac{ }{w_{ij}&#94;{k-1,k}} \\left( \\sum_{s=1}&#94;{L_{k-1}} w_{sj}&#94;{k-1,k} y_{s}&#94;{k-1} \\right) = \\parfrac{E}{u_{j}&#94;{k}} y_{i}&#94;{k-1} \\\\ &= \\parfrac{E}{y_{j}&#94;{k}} \\parfrac{y_{j}&#94;{k}}{u_{j}&#94;{k}} y_{i}&#94;{k-1} \\quad (\\because 偏微分の連鎖律) \\\\ &= \\parfrac{E}{y_{j}&#94;{k}} f&#94;{\\prime}(u_{j}&#94;{k}) y_{i}&#94;{k-1} \\end{aligned} \\end{equation*} ここで \\(\\displaystyle\\parfrac{E}{y_{j}&#94;{k}}\\) は出力層の場合（ \\(k=n\\) ）と中間層の場合（ \\(k<n\\) ）で結果が異なる. 出力層の場合は, デルタ則の結果から, \\begin{equation*} \\begin{aligned} \\parfrac{E}{y_{j}&#94;{n}} &= \\frac{1-t_{j}&#94;{l}}{1-y_{j}&#94;{n}} - \\frac{t_{j}&#94;{l}}{y_{j}&#94;{n}} = \\frac{y_{j}&#94;{n}(1-t_{j}&#94;{l}) - t_{j}&#94;{l}(1 - y_{j}&#94;{n})}{y_{j}&#94;{n}(1-y_{j}&#94;{n})} = \\frac{y_{j}&#94;{n} - t_{j}&#94;{l}}{f&#94;{\\prime}(u_{j}&#94;{n})} \\end{aligned} \\end{equation*} となり, 一方中間層の場合は, 偏微分の連鎖律（chain rule）によって, \\begin{equation*} \\begin{aligned} \\parfrac{E}{y_{j}&#94;{k}} &= \\sum_{s=1}&#94;{L_{k+1}} \\parfrac{E}{u_{s}&#94;{k+1}} \\parfrac{u_{s}&#94;{k+1}}{y_{j}&#94;{k}} \\\\ &= \\sum_{s=1}&#94;{L_{k+1}} \\parfrac{E}{u_{s}&#94;{k+1}} \\parfrac{}{y_{j}&#94;{k}} \\left( \\sum_{t=1}&#94;{L_{k}} w_{ts}&#94;{k, k+1} y_{t}&#94;{k} \\right) = \\sum_{s=1}&#94;{L_{k+1}} \\parfrac{E}{u_{s}&#94;{k+1}} w_{js}&#94;{k,k+1} \\end{aligned} \\end{equation*} と展開できる. これらの結果をまとめると, \\begin{equation*} \\begin{aligned} \\parfrac{E}{w_{ij}&#94;{k-1, k}} = \\left\\{ \\begin{array}{ll} \\displaystyle \\frac{y_{j}&#94;{n} - t_{j}&#94;{l}}{f&#94;{\\prime}(u_{j}&#94;{n})} f&#94;{\\prime}(u_{j}&#94;{n}) y_{j}&#94;{n-1} = (y_{j}&#94;{n} - t_{l}) y_{i}&#94;{n-1} & (k = n) \\\\ \\displaystyle \\sum_{s=1}&#94;{L_{k+1}} \\parfrac{E}{u_{s}&#94;{k+1}} w_{js}&#94;{k,k+1} f&#94;{\\prime}(u_{j}&#94;{k}) y_{i}&#94;{k-1} & (k < n) \\end{array} \\right.\\end{aligned} \\end{equation*} となるが, 次の第 \\(k\\) 層の \\(i\\) 番目のユニットの 誤差信号 \\(\\delta_{i}&#94;{k}\\) \\begin{align*} \\begin{aligned} \\delta_{i}&#94;{k} &= \\parfrac{E}{u_{i}&#94;{k}} = \\parfrac{E}{y_{i}&#94;{k}} \\parfrac{y_{i}&#94;{k}}{u_{i}&#94;{k}} \\\\ &= \\left\\{ \\begin{array}{ll} y_{i}&#94;{n} - t_{i}&#94;{l} & (k = n) \\\\ \\displaystyle \\sum_{s=1}&#94;{L_{k+1}} \\parfrac{E}{u_{s}&#94;{k+1}}w_{js}&#94;{k,k+1} f&#94;{\\prime}(u_{i}&#94;{k}) = \\sum_{s=1}&#94;{L_{k+1}} \\delta_{s}&#94;{k+1} w_{js}&#94;{k,k+1} f&#94;{\\prime}(u_{i}&#94;{k}) & (k < n) \\end{array} \\right.\\end{aligned} \\end{align*} を用いれば, より簡潔に勾配を表現できる: \\begin{equation*} \\begin{aligned} \\parfrac{E}{w_{ij}&#94;{k-1, k}} = y_{i}&#94;{k-1} \\delta_{j}&#94;{k}\\end{aligned} \\end{equation*} 以上により, 逆誤差伝搬法は次の手順に従って重みを更新すれば良い事が分かる: \\(k \\leftarrow n\\) とする. 誤差信号 \\(\\delta_{i}&#94;{k}\\ (i = 1,\\dots,L_{k})\\) の計算を行う: \\begin{equation*} \\begin{aligned} \\delta_{i}&#94;{k} = \\left\\{ \\begin{array}{ll} y_{i}&#94;{n} - t_{i}&#94;{l} & (k = n) \\\\ \\displaystyle \\sum_{s=1}&#94;{L_{k+1}} \\delta_{s}&#94;{k+1} w_{js}&#94;{k,k+1} f&#94;{\\prime}(u_{i}&#94;{k}) & (k < n) \\end{array} \\right. \\end{aligned} \\end{equation*} \\(k \\leftarrow k-1\\) とする. \\(k = 1\\) ならば次へ, そうでなければ2. に戻る. 重みを更新する: \\begin{equation*} \\begin{aligned} w_{ij}&#94;{k-1,k} \\leftarrow w_{ij}&#94;{k-1,k} - \\eta y_{i}&#94;{k-1} \\delta_{j}&#94;{k} \\quad (k=2,\\dots,n,\\ i = 1,\\dots, L_{k-1},\\ j = 1,\\dots,L_{k}) \\end{aligned} \\end{equation*} これは基本となる逐次学習法であるが, 一括学習の時は \\(\\delta_{i}&#94;{n}\\) の所でサンプルについての和を取って次のようにすれば良い: \\begin{equation*} \\begin{aligned} \\delta_{i}&#94;{n} = \\sum_{l=1}&#94;{N} (y_{i}&#94;{n} - t_{i}&#94;{l})\\end{aligned} \\end{equation*} [1] ノーバート・ウィーナー, 池原止戈夫, 彌永昌吉, 室賀三郎, 戸田巌, \"ウィーナー サイバネティックス ―動物と機械における制御と通信\" 岩波書店, 2011 [2] 庄野逸, Deep Learning 勉強会(1) [3] 高橋治久, 堀田一弘, \"学習理論\" コロナ社, 2009 [4] これは非常に単純なモデルであり, 理解や応用が簡単な為に様々な場面で用いられる. 特に機械学習では無批判にこのユニットを用いる向きがある. しかし, このモデルは厳密にニューロンの動作を表現できてはいないことに注意が必要である. 例えば, このモデルでは入力 \\(u\\) が強ければ常に高電位を放出する事になるが, 実際にはニューロンはパルスを放出した後は一時的に放出電位が下がる事が実験により知られている. よりニューロンの動作を精密に表したモデルにホジキン-ハックスレー型のニューロンモデルがある[&#94;13]. [5] 正例のラベルを \\(1\\) , 負例のラベルを \\(0\\) としたり問題に応じて都合良く決められるが, 識別できる二値なら何でもよく, 本質的な違いは存在しない. [6] 高橋治久, 堀田一弘, \"学習理論\" コロナ社, 2009 [7] この正規化によっても一般性は全く失われない. \\(\\ve{w}\\) は入力の重みの比率を定めているに過ぎず, 実際 \\(u = \\ve{w}&#94;{\\mathsf{T}}\\ve{x} + b\\) から見れるように, \\(\\ve{w}\\) は面（識別面という）の法ベクトルとなっている. [8] 最も面 \\(\\ve{w}&#94;{\\ast}\\) に近いベクトルの距離を表しており, マージン と呼ばれる. かの有名なSVMのマージンそのものである [9] 2つのベクトル \\(\\ve{v}_{1}, \\ve{v}_{2}\\) がなす角度 \\(\\theta\\) は \\(\\cos\\theta = \\ve{v}_{1}&#94;{\\mathsf{T}}\\ve{v}_{2}/(||\\ve{v}_{1}||||\\ve{v}_{2}||)\\) により求められるので, \\(\\theta=0\\) ならば2つのベクトルは一致している（類似度が最大）と見ることができる. 角度 \\(\\theta\\) が \\(0\\) に近い（類似度が高い）時は内積 \\(\\ve{v}_{1}&#94;{\\mathsf{T}}\\ve{v}_{2}\\) が高い値を取ることが分かる [10] 大域的な最小解とは限らない事に注意 [11] 係数の \\(1/2\\) に本質的な意味は無いが, 微分の際に計算を簡単にする狙いがある. [12] しかし, 局所最適に嵌ってしまうリスクが潜んでいる [13] \\(\\ve{w}\\) は識別面の法ベクトルを表すが, 出力を単位ステップ（もしくは符号）関数とすると入力ベクトルが面の上半領域にある場合は \\(1\\) を, 下半領域にある場合は \\(0(-1)\\) を出力する.","tags":"記事","url":"/paseputoronxi-hua.html","loc":"/paseputoronxi-hua.html"},{"title":"最大エントロピーモデル","text":"最大エントロピーモデルの導出過程、学習の更新則、素性選択についての理論的側面を述べる。記述の大部分は [1] を参照し、一部 [2] , [3] も参照している。 最大エントロピーモデルは、データの特徴を 素性関数(feature function) によって記述し、素性関数がある 制約(constraint) を満たし、かつ、モデルを表現する確率分布のエントロピーが最大となる（最大エントロピー原理を満たす）モデルである。 エントロピーを最大にする事により、制約を満たしながら最大エントロピーモデルの確率分布が最も一様に分布する様になり、未知データに対する確率を無下に \\(0\\) にすることが無くなるため、高い汎用性（汎化性能）が期待できる。 モデルを表現する確率分布の導出 最大のエントロピー原理の性質と最尤推定 最大エントロピーモデルの唯一存在性 最大尤度を持つ最大エントロピーモデル 最大のエントロピーモデルの学習 - 反復スケーリング法 条件付き最大エントロピーモデル 素性の自動選択 脚注・参考文献 モデルを表現する確率分布の導出 まず、サンプル（事例）データのドメイン（定義域）を \\(X\\) 、データに付与されたラベルのドメインを \\(Y\\) と書く。例えば、次に来る単語を予測させたい場合には、サンプル \\(X\\) は1つ前までの単語の並び、ラベル \\(Y\\) は今の単語となる。 データとラベルを組にすることで1つの学習サンプルが構成され、また、モデルに与える \\(m\\) 個の学習サンプルの集合 \\(Z_{m} \\subset 2&#94;{X\\times Y}\\) を次で表す: \\begin{equation*} Z_{m} = \\{ (x_{1}, y_{1}), (x_{2}, y_{2}), \\dots, (x_{m}, y_{m}) \\} \\end{equation*} このようなサンプルに対し、 素性関数（素性） の集合 \\({\\cal F}\\) は次で定義される: \\begin{equation*} {\\cal F} = \\{ f_{i} : X \\times Y \\to \\{0,1\\}, i \\in \\{1,2,\\dots,n\\} \\} \\end{equation*} 即ち \\({\\cal F}\\) は、データとラベルの組 \\((x,y) \\in X \\times Y\\) を受け取って \\(\\{0,1\\}\\) いずれかを返す関数の集合である。ここでは \\(f\\) の値域は議論の簡略化のため \\(\\{0,1\\}\\) としたが、値域は \\(\\{0,\\alpha\\} (\\alpha > 0)\\) 、即ち \\(0\\) と \\(0\\) 以外の正数実数を取るようにもできる。また、素性が条件を満たし正の値を取る時は、素性が活性化しているという。 素性の例を挙げると、 \\(n\\) 個の単語列 \\(w_{1},\\dots,w_{n}\\) から、直前の \\(N-1\\) 個の単語列 \\(w_{n-N+1},\\dots,w_{n-1}\\) のみを用いて今の単語 \\(w_{n}\\) を予測する（ \\(N\\) -グラムの）場合は、素性は次の様に表現出来る。 \\begin{equation*} f_{x_{1}x_{2}\\dots x_{N}}(w_{1},\\dots,w_{n-1},w_{n}) = \\left\\{ \\begin{array}{ll} 1 & w_{n-N+1} = x_{1}, w_{n-N+2} = x_{2}, \\dots, w_{n-1} = x_{N-1}, w_{n} = x_{N} \\\\ 0 & {\\rm otherwise} \\end{array} \\right. \\end{equation*} ここで \\(f\\) のインデックス \\(x_{1}\\dots x_{N}\\) は整数との対応を適当に取ることで、容易に実現できる。 最大エントロピーモデルの制約として与えられる条件は、素性の平均（期待値）が、モデルと経験確率で一致することである。この条件を数式で表現する事を考える。 定義域 \\(X\\times Y\\) 上に定義されるモデルの確率分布を \\(P(x,y)\\) と書き、経験確率分布を \\(\\tilde{P}(x,y)\\) と書く。ここで経験確率分布 \\(\\tilde{P}\\) は、頻度確率で与える。即ち、学習サンプルに現れた \\((x,y)\\) の組の回数を \\(C(x,y)\\) と書くと、 \\begin{equation*} \\tilde{P}(x,y) = \\frac{C(x,y)}{m} \\end{equation*} と表せる。モデルの確率分布は後で導出する。 ある素性 \\(f_{i}\\) の分布 \\(p\\) による平均を \\(E_{p}[f_{i}]\\) と書くと、経験分布とモデルの確率分布のそれぞれの平均は \\begin{align*} E_{\\tilde{P}}[f_{i}] &= \\sum_{x,y} \\tilde{P}(x,y) f_{i}(x,y) \\\\ E_{P}[f_{i}] &= \\sum_{x,y} P(x,y) f_{i}(x,y) \\end{align*} と表せられ、従って制約を数式で表現すると, \\begin{align*} E_{\\tilde{P}}[f_{i}] &= E_{P}[f_{i}] \\ \\ (i=1,\\dots,n) \\\\ \\iff \\sum_{x,y} \\tilde{P}(x,y) f_{i}(x,y) &= \\sum_{x,y} P(x,y) f_{i}(x,y) \\ \\ (i=1,\\dots,n) \\end{align*} となる。最大エントロピーモデルの候補となる集合 \\({\\cal P}\\) は、全ての素性に関する制約を満たすモデルの集合となる: \\begin{equation*} {\\cal P} = \\{ P | E_{P}[f_{i}] = E_{\\tilde{P}}[f_{i}], i = \\{1,\\dots,n\\} \\} \\end{equation*} 明らかに、2つのモデル \\(P,P&#94;{\\prime} \\in {\\cal P}\\) に対して、 \\(E_{P}[f_{i}] = E_{\\tilde{P}}[f_{i}] = E_{P&#94;{\\prime}}[f_{i}]\\ \\ (i=1,\\dots,n)\\) （候補となるモデルの素性の平均は同一）となる。 更に考慮すべき点は、最大エントロピーモデルの名の通り、モデル（確率分布 \\(P\\) ）のエントロピーを最大にする必要がある。モデルのエントロピーを \\(H(P)\\) と書くと、確率分布のエントロピーの式から, \\begin{equation*} H(P) = -\\sum_{x,y}P(x,y) \\log P(x,y) \\end{equation*} と表現できる。集合 \\({\\cal P}\\) の中で最もエントロピーが高いものが得るべきモデル \\(P&#94;{\\ast}\\) である: \\begin{equation*} P&#94;{\\ast} = \\underset{P \\in {\\cal P}}{\\rm argmax}\\ H(P) \\end{equation*} この式を 最大エントロピー原理(maximum entropy principle) と呼ぶ。集合 \\({\\cal P}\\) は無限集合だが最大エントロピー原理を満たすモデルは解析的に求められ、かつ一意に存在する（後術）。 最大エントロピー原理を満たすモデルの確率分布 \\(P\\) を求める事を考える。これは制約付き非線形最適化問題であることから、ラグランジェの未定定数法が適用できる。 \\(P\\) が満たすべき制約を列挙すると \\begin{align*} 1:& \\quad E_{P}[f_{i}] = E_{\\tilde{P}}[f_{i}] \\ \\ (i=1,\\dots,n) \\\\ 2:& \\quad P(x,y) \\geq 0 \\\\ 3:& \\quad \\sum_{x,y}P(x,y) = 1 \\end{align*} であり（2,3は \\(P\\) が確率分布となる為の条件）、 \\(n\\) 個の制約に対応する未定定数を \\(\\Lambda = \\{\\lambda_{1},\\dots,\\lambda_{n}\\}\\) と書くと、ラグランジアン（ラグランジュ関数） \\({\\cal L}(P,\\Lambda)\\) は \\begin{align*} {\\cal L}(P, \\Lambda) &= H(P) + \\sum_{i=1}&#94;{n} \\lambda_{i} (E_{P}[f_{i}] - E_{\\tilde{P}}[f_{i}]) \\\\ &= -\\sum_{x,y}P(x,y)\\log P(x,y) + \\sum_{i=1}&#94;{n} \\lambda_{i} \\left\\{ \\sum_{x,y} P(x,y) f_{i}(x,y) - \\sum_{x,y} \\tilde{P}(x,y) f_{i}(x,y) \\right\\} \\end{align*} と書ける。最大値を得るため、 \\(P(x,y)\\) によって偏微分すると, \\begin{equation*} \\frac{\\partial {\\cal L}(P,\\Lambda)}{\\partial P(x,y)} = -\\log P(x,y) - 1 + \\sum_{i=1}&#94;{n} \\lambda_{i} f_{i}(x,y) \\end{equation*} この式を \\(0\\) とおいて \\(P(x,y)\\) について解くと \\begin{equation*} P(x,y) = \\exp \\left[ -1 + \\sum_{i=1}&#94;{n} \\lambda_{i} f_{i}(x,y) \\right] \\end{equation*} を得る。確率分布が指数関数で表現される為条件2の非負条件は満たされるが、条件3の全確率が1になることが保証されていない。そこで \\(\\sum_{x,y}P(x,y) = Z_{\\Lambda}\\) なる正規化項(normalization factor)を導入し \\(P(x,y)\\) の \\(x,y\\) についての総和が1になるようにする。従ってモデルの確率分布は次で表される: \\begin{align*} P(x,y) &= \\frac{ \\exp \\left[ -1 + \\sum_{i=1}&#94;{n} \\lambda_{i} f_{i}(x,y) \\right] }{ \\sum_{x,y} \\exp \\left[ -1 + \\sum_{i=1}&#94;{n} \\lambda_{i} f_{i}(x,y) \\right] } \\\\ &= \\frac{1}{Z_{\\Lambda}} \\exp \\left[ \\sum_{i} \\lambda_{i} f_{i}(x,y) \\right] \\\\ Z_{\\Lambda} &= \\sum_{x,y} \\exp \\left[ \\sum_{i} \\lambda_{i} f_{i}(x,y) \\right] \\end{align*} （以下、 \\(\\sum_{i=1}&#94;{n} \\equiv \\sum_{i}\\) とする）得られた確率分布はMRF(Markov Random Fields、マルコフ確率場)のクリークサイズを1とした時、即ち節点ポテンシャル（連想ポテンシャル）のみを考えた結合確率に一致する。従って最大エントロピーモデルはMRFのサブクラスとして捉えられる。 最大のエントロピー原理の性質と最尤推定 最大エントロピー原理を満たすモデルは上述の議論で求められたが、このモデルが唯一に定まる事を示す。まず、上述の議論で得られた確率分布を持つモデルの集合を \\({\\cal Q}\\) と書く: \\begin{equation*} {\\cal Q} = \\left\\{ P \\left| P(x,y) = \\frac{1}{Z_{\\Lambda}} \\exp\\left[ \\sum_{i} \\lambda_{i}f_{i}(x,y) \\right] \\right. \\right\\} \\end{equation*} 集合 \\({\\cal Q}\\) の要素に制約は陽に表れていない。そして、 \\({\\cal P,Q}\\) と最大エントロピー原理について次の定理が成り立つ: 最大エントロピーモデルの唯一存在性 \\(P&#94;{\\ast} \\in {\\cal P} \\cap {\\cal Q}\\) ならば, \\begin{equation*} P&#94;{\\ast} = \\underset{P \\in {\\cal P}}{\\rm argmax} \\ H(P) \\end{equation*} が成り立ち、かつ \\(P&#94;{\\ast}\\) は唯一に定まる。 （証明）まず補助定理として、 \\(R, S \\in {\\cal P}, T \\in {\\cal Q}\\) ならば, \\begin{equation*} \\sum_{x,y} R(x,y) \\log T(x,y) = \\sum_{x,y} S(x,y) \\log T(x,y) \\end{equation*} を示す。 \\(T \\in {\\cal Q}\\) より \\(T(x,y) = \\displaystyle\\frac{1}{Z_{\\Lambda}} \\exp\\left[ \\sum_{i} \\lambda_{i} f_{i}(x,y) \\right]\\) と表せるので、 \\begin{align*} （左辺） &= \\sum_{x,y} R(x,y) \\left[ \\sum_{i} \\lambda_{i} f_{i}(x,y) - \\log Z_{\\Lambda} \\right] = \\sum_{i} \\lambda_{i} \\sum_{x,y} R(x,y) f_{i}(x,y) - \\log Z_{\\Lambda} \\sum_{x,y}R(x,y) \\\\ &= \\sum_{i} \\lambda_{i} E_{R}[f_{i}] - \\log Z_{\\Lambda} \\\\ &= \\sum_{i} \\lambda_{i} E_{S}[f_{i}] - \\log Z_{\\Lambda} \\ \\ (\\because E_{R}[f_{i}] = E_{\\tilde{P}}[f_{i}] = E_{S}[f_{i}]） \\\\ &= \\sum_{x,y} S(x,y) \\left[\\sum_{i} \\lambda_{i} f_{i}(x,y) \\right] - \\sum_{x,y} S(x,y) \\log Z_{\\Lambda} \\\\ &= \\sum_{x,y} S(x,y) \\log T(x,y) = （右辺） \\end{align*} 補助定理を用いて、定理の証明を行う。 \\(P \\in {\\cal P}, P&#94;{\\ast} \\in {\\cal P} \\cap {\\cal Q}\\) とすると, \\begin{align*} H(P&#94;{\\ast}) - H(P) &= -\\sum_{x,y} P&#94;{\\ast}(x,y) \\log P&#94;{\\ast}(x,y) + \\sum_{x,y} P(x,y) \\log P(x,y) \\\\ &= -\\sum_{x,y} P(x,y) \\log P&#94;{\\ast}(x,y) + \\sum_{x,y} P(x,y) \\log P(x,y) \\ \\ （\\because 補助定理） \\\\ &= \\sum_{x,y} P(x,y) \\log \\left[ \\frac{P(x,y)}{P&#94;{\\ast}(x,y)} \\right] \\\\ &= {\\rm KL}(P || P&#94;{\\ast}) \\geq 0\\ \\ （{\\rm KL}:KLダイバージェンス） \\end{align*} よって \\(H(P&#94;{\\ast}) \\geq H(P)\\) が成立する。また \\(H(P&#94;{\\ast}) = H(P)\\) ならばKLダイバージェンスの性質により \\(P&#94;{\\ast} = P\\) となる。以上により、定理の成立が示された。 生成モデルの学習に関連して、最大エントロピー原理を満たすモデル \\(P&#94;{\\ast}\\) は、経験確率分布 \\(\\tilde{P}\\) が与えられた時に最大尤度を持つ事も示されている。モデルの尤度の式を導く事を考えると、まず経験確率分布 \\(\\tilde{P}\\) に対するモデル \\(P\\) の経験誤差はKLダイバージェンス \\({\\rm KL}(\\tilde{P} || P)\\) で与えられる [4] ので, \\begin{align*} {\\rm KL}(\\tilde{P} || P) &= \\sum_{x,y} \\tilde{P}(x,y) \\log \\left[ \\frac{\\tilde{P}(x,y)}{P(x,y)} \\right] \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\log \\tilde{P}(x,y) - \\sum_{x,y} \\tilde{P}(x,y) \\log P(x,y) \\end{align*} なる。大数の弱法則より、サンプル数の極限 \\(m\\to \\infty\\) を取ることにより経験確率分布は標的概念の確率分布に一致し、また経験誤差は汎化誤差に一致する。今 \\({\\rm KL}(\\tilde{P} || P) \\geq 0\\) であり、かつ、 \\(\\tilde{P}\\) は観測により固定されるので、経験誤差を最小にするには下段の式の第2項を最大化すれば良いことになる。そして、下段式の第2項は対数尤度（経験対数尤度）と呼ばれる。モデル \\(P\\) の対数尤度を \\(L(P)\\) と書くと、 \\begin{equation*} L(P) = \\sum_{x,y} \\tilde{P}(x,y) \\log P(x,y) \\end{equation*} と表すことができる。尤度との関連として、最大エントロピー原理を満たすモデル \\(P&#94;{\\ast}\\) は次を満たす: 最大尤度を持つ最大エントロピーモデル \\(P&#94;{\\ast} \\in {\\cal P} \\cap {\\cal Q}\\) ならば、 \\begin{equation*} P&#94;{\\ast} = \\underset{Q \\in {\\cal Q}}{\\rm argmax} \\ L(Q) \\end{equation*} が成り立ち、かつ \\(P&#94;{\\ast}\\) は唯一に定まる。 （証明）前の定理と同様の方針と、補助定理により, \\begin{align*} L(P&#94;{\\ast}) - L(P) &= \\sum_{x,y} \\tilde{P}(x,y) \\log P&#94;{\\ast}(x,y) - \\sum_{x,y} \\tilde{P}(x,y) \\log P(x,y) \\\\ &= \\sum_{x,y} P&#94;{\\ast}(x,y) \\log P&#94;{\\ast}(x,y) - \\sum_{x,y} P&#94;{\\ast}(x,y) \\log P(x,y) \\ \\ (\\because 反射性 E_{\\tilde{P}}[f_{i}] = E_{\\tilde{P}}[f_{i}]により、\\tilde{P} \\in {\\cal P}) \\\\ &= \\sum_{x,y} P&#94;{\\ast}(x,y) \\log \\left[ \\frac{P&#94;{\\ast}(x,y)}{P(x,y)} \\right] \\\\ &= {\\rm KL}(P&#94;{\\ast} || P) \\geq 0 \\end{align*} よって \\(L(P&#94;{\\ast}) \\geq L(P)\\) であり、再びKLダイバージェンスの性質により、 \\(L(P&#94;{\\ast}) = L(P)\\) ならば \\(P&#94;{\\ast} = P\\) が成り立つので唯一性も示される。従って定理の成立が示された。 定理1と2により、次の性質が成り立つ: \\begin{equation*} P&#94;{\\ast} = \\underset{P \\in {\\cal P}}{\\rm argmax} \\ H(P) = \\underset{Q \\in {\\cal Q}}{\\rm argmax} \\ L(Q) \\end{equation*} 即ち、モデルの最大エントロピー原理は最尤推定の枠組みで捉える事もでき、尤度を最大化したモデルが最大のエントロピーを持つ。よって、モデルの学習には通常の生成モデルの学習と同じ様に、 \\({\\cal Q}\\) の要素で表現されるモデルの尤度最大化を考えれば良いことになる。 最大のエントロピーモデルの学習 - 反復スケーリング法 最尤推定法に基づく最大エントロピーモデルの学習は、モデルの尤度が最大になるようにモデル \\(P\\) のパラメタ \\(\\Lambda\\) を調節してやれば良い。単純なアプローチとしては、対数尤度 \\(L(P)\\) をパラメタ \\(\\Lambda=\\{\\lambda_{1},\\cdots,\\lambda_{n}\\}\\) で偏微分し、最急上昇法によって最大値を得る方法がある。実際に計算してみると, \\begin{align*} \\frac{\\partial L(P)}{\\partial \\lambda_{i}} &= \\sum_{x,y} \\tilde{P}(x,y) \\frac{\\partial}{\\partial \\lambda_{i}} \\log P(x,y) \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\frac{\\partial}{\\partial \\lambda_{i}} \\left[ \\sum_{j} \\lambda_{j} f_{j}(x,y) - \\log Z_{\\Lambda} \\right] \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\left[ f_{i}(x,y) - \\frac{1}{Z_{\\Lambda}} \\sum_{x&#94;{\\prime},y&#94;{\\prime}} f_{i}(x&#94;{\\prime},y&#94;{\\prime}) \\exp \\left( \\sum_{j} \\lambda_{j} f_{j}(x&#94;{\\prime},y&#94;{\\prime}) \\right) \\right] \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\left( f_{i}(x,y) - E_{P}[f_{i}] \\right) \\\\ &= E_{\\tilde{P}}[f_{i}] - E_{P}[f_{i}] \\end{align*} であり（最適時には制約が満たされることが分かる）、ステップ \\(t\\) におけるパラメタ \\(\\lambda_{i}&#94;{t}\\) の更新規則は次の様に得られる: \\begin{align*} \\lambda_{i}&#94;{t+1} &= \\lambda_{i}&#94;{t} + \\eta \\frac{\\partial L(P)}{\\partial \\lambda_{i}&#94;{t}} \\\\ &= \\lambda_{i}&#94;{t} + \\eta ( E_{\\tilde{P}}[f_{i}] - E_{P}[f_{i}] ) \\end{align*} ここで \\(\\eta\\) は収束の早さを決める学習率(learning rate)であり、ヒューリスティックに決める必要がある。 この様に再急上昇法による学習は単純だが、学習（収束）が遅く、 \\(\\eta\\) を決めなければならないという問題がある。 \\(\\eta\\) を大きく設定し過ぎると勾配の谷を越えてしまい発散を招き、逆に小さく設定すると学習がいつまでたっても終わらない。現状、最大エントロピーモデルの学習では、反復スケーリング法(iterative scaling)という学習手法が伝統的に用いられている。 反復スケーリング法の基本的な考え方は、まずパラメタ \\(\\Lambda\\) を \\(\\Lambda+\\Delta\\) に変化させた時の対数尤度の変化量の下限 \\(A(\\Lambda,\\Delta)\\) を計算し、次にこの \\(A(\\Lambda,\\Delta)\\) を最大にする \\(\\Delta\\) を求める事で、結果増加量を最大にするようにしている。この考え方には学習率の様なヒューリスティックは介在せず、かつ毎ステップの対数尤度の増加量を最大にするようにパラメタを更新できる。 それでは反復スケーリング法の更新式を導くことを考える。各パラメタの更新量を \\(\\Delta=\\{\\delta_{1},\\cdots,\\delta_{n}\\}\\) と表すものとし、まず、パラメタ更新時の対数尤度の変化量 \\(L(P_{\\Lambda+\\Delta})-L(P_{\\Lambda})\\) は, \\begin{align*} L(P_{\\Lambda+\\Delta})-L(P_{\\Lambda}) &= \\sum_{x,y} \\tilde{P}(x,y) \\log P_{\\Lambda+\\Delta}(x,y) - \\sum_{x,y} \\tilde{P}(x,y) \\log P_{\\Lambda}(x,y) \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\log \\left[ \\frac{P_{\\Lambda+\\Delta}(x,y)}{P_{\\Delta}(x,y)} \\right] \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\log \\left[ \\frac{Z_{\\Lambda}}{Z_{\\Lambda+\\Delta}} \\frac{\\exp\\left[ \\sum_{i}(\\lambda_{i} + \\delta_{i}) f_{i}(x,y) \\right]}{\\exp\\left[ \\sum_{i}\\lambda_{i}f_{i}(x,y) \\right] } \\right] \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\left[ \\sum_{i} \\delta_{i} f_{i}(x,y) - \\log\\left(\\frac{Z_{\\Lambda+\\Delta}}{Z_{\\Lambda}} \\right) \\right] \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\sum_{i} \\delta_{i} f_{i}(x,y) - \\log \\left(\\frac{Z_{\\Lambda+\\Delta}}{Z_{\\Lambda}} \\right) \\\\ &\\geq \\sum_{x,y} \\tilde{P}(x,y) \\sum_{i} \\delta_{i} f_{i}(x,y) + 1 - \\frac{Z_{\\Lambda+\\Delta}}{Z_{\\Lambda}} \\ \\ (\\because -\\log x \\geq 1-x) \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\sum_{i} \\delta_{i} f_{i}(x,y) + 1 - \\frac{\\sum_{x,y}\\exp\\left[ \\sum_{i}(\\lambda_{i} + \\delta_{i})f_{i}(x,y) \\right]}{\\sum_{x,y}\\exp\\left[ \\sum_{i}\\lambda_{i}f_{i}(x,y) \\right]} \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\sum_{i} \\delta_{i} f_{i}(x,y) + 1 - \\frac{Z_{\\Lambda}\\sum_{x,y}P_{\\Lambda}(x,y)\\exp\\left[ \\sum_{i}\\delta_{i}f_{i}(x,y) \\right]}{Z_{\\Lambda} \\sum_{x,y}P_{\\Lambda}(x,y)} \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\sum_{i} \\delta_{i} f_{i}(x,y) + 1 - \\sum_{x,y}P_{\\Lambda}(x,y)\\exp\\left[ \\sum_{i}\\delta_{i}f_{i}(x,y) \\right] \\end{align*} 素性 \\(f_{i}(x,y)\\) の \\(i\\) についての和 \\(f&#94;{\\#}(x,y) = \\sum_{i=1}&#94;{n}f_{i}(x,y)\\) を用いると、 \\begin{equation*} L(P_{\\Lambda+\\Delta})-L(P_{\\Lambda}) = \\sum_{x,y} \\tilde{P}(x,y) \\sum_{i} \\delta_{i} f_{i}(x,y) + 1 - \\sum_{x,y}P_{\\Lambda}(x,y)\\exp\\left[ \\sum_{i}\\frac{f_{i}(x,y)}{f&#94;{\\#}(x,y)}\\delta_{i}f&#94;{\\#}(x,y) \\right] \\end{equation*} と書ける。今 \\(f_{i}(x,y)/f&#94;{\\#}(x,y)\\) は確率分布となることから、 \\(\\sum_{i}\\frac{f_{i}(x,y)}{f&#94;{\\#}(x,y)}\\delta_{i}f&#94;{\\#}(x,y)\\) は \\(\\delta_{i}f&#94;{\\#}(x,y)\\) についての平均と読み取れる。更に \\(\\exp\\) は明らかに凸関数であることから、イェンセンの不等式 \\(\\exp(E[X]) \\leq E[\\exp(X)]\\) を用いて最終的な下限の式を得る。 \\begin{align*} L(P_{\\Lambda+\\Delta})-L(P_{\\Lambda}) &\\geq \\sum_{x,y} \\tilde{P}(x,y) \\sum_{i} \\delta_{i} f_{i}(x,y) + 1 - \\sum_{x,y}P_{\\Lambda}(x,y)\\sum_{i}\\frac{f_{i}(x,y)}{f&#94;{\\#}(x,y)}\\exp\\left[ \\delta_{i}f&#94;{\\#}(x,y) \\right] \\\\ &= A(\\Lambda, \\Delta) \\end{align*} 次に \\(A(\\Lambda, \\Delta)\\) を \\(\\delta_{i}\\) で偏微分することで下限の最大化を考える。 \\begin{align*} \\frac{\\partial A(\\Lambda, \\Delta)}{\\partial \\delta_{i}} &= \\sum_{x,y} \\tilde{P}(x,y) f_{i}(x,y) - \\sum_{x,y} P_{\\Lambda}(x,y) f_{i}(x,y) \\exp \\left[ \\delta_{i}f&#94;{\\#}(x,y) \\right] \\\\ &= E_{\\tilde{P}}[f_{i}] - \\sum_{x,y} P_{\\Lambda}(x,y) f_{i}(x,y) \\exp \\left[ \\delta_{i}f&#94;{\\#}(x,y) \\right] \\end{align*} この式を \\(0\\) とおき \\(\\delta_{i}\\) について解くことで変化量を求める事ができる。この式は \\(\\delta_{i}\\) について閉じた形をしていないので、基本的には数値解析によって極値を求める。しかし、もしも任意の \\((x,y)\\) に対し \\(f&#94;{\\#}(x,y) = C\\) （定数）となるならば、 \\(\\delta_{i}\\) について解く事ができ、次の結果を得る。 \\begin{align*} & E_{\\tilde{P}}[f_{i}] - \\sum_{x,y} P_{\\Lambda}(x,y) f_{i}(x,y) \\exp \\left[ \\delta_{i}f&#94;{\\#}(x,y) \\right] = 0 \\\\ &\\implies \\exp \\left[C \\delta_{i} \\right] \\sum_{x,y} P_{\\Lambda}(x,y) f_{i}(x,y) = E_{\\tilde{P}}[f_{i}] \\iff \\exp \\left[C \\delta_{i} \\right] = \\frac{E_{\\tilde{P}}[f_{i}]}{E_{P}[f_{i}]} \\\\ &\\iff \\delta_{i} = \\frac{1}{C} \\log \\left( \\frac{E_{\\tilde{P}}[f_{i}]}{E_{P}[f_{i}]} \\right) \\end{align*} 任意の \\((x,y)\\) で \\(f&#94;{\\#}(x,y)\\) が定数にならない場合でも、実は \\(C = \\displaystyle\\max_{x,y} f&#94;{\\#}(x,y)\\) とし、新しい素性 \\(f_{n+1}(x,y)\\) を \\(f_{n+1}(x,y) = C - f&#94;{\\#}(x,y)\\) とおけば、変更後の和 \\(f&#94;{\\#\\prime}(x,y)\\) は \\(f&#94;{\\#\\prime}(x,y)=C\\) となる事が知られている。 \\(f&#94;{\\#\\prime}(x,y)\\) について検算を行ってみると, \\begin{align*} f&#94;{\\#\\prime}(x,y) &= \\sum_{i=1}&#94;{n+1} f_{i}(x,y) = \\sum_{i=1}&#94;{n} f_{i}(x,y) + f_{n+1}(x,y) \\\\ &= f&#94;{\\#}(x,y) + C - f&#94;{\\#}(x,y) = C \\end{align*} となって、定数 \\(C\\) を取ることが確かめられた。 条件付き最大エントロピーモデル 前節までのモデルはあるパターン \\((x,y)\\) を生成する結合確率を表現しているが、応用上は何らかの入力 \\(x\\) に対して出力 \\(y\\) の結果を得たいというケースが多い。例えば、再び単語予測の例を挙げると、一つ前までの単語を \\(x\\) として入力として、今の単語 \\(y\\) を予測するというタスクである。そのような場合はモデルの条件付き確率 \\(P(y|x)\\) が用いられる。このモデルは \\(y\\) の識別を行うので生成識別モデルと呼ばれ、条件付き最大エントロピーモデルはCRF(Conditional Random Fields、条件付き確率場)のサブクラスとして捉えられる。 条件付き最大エントロピーモデルの確率分布 \\(P_{\\Lambda}(y|x)\\) は、 \\(P_{\\Lambda}(x,y)\\) とベイズの定理から得られる。 \\begin{align*} P_{\\Lambda}(y|x) &= \\frac{P_{\\Lambda}(x,y)}{P_{\\Lambda}(x)} \\\\ &= \\frac{\\exp\\left[ \\sum_{i}\\lambda_{i}f_{i}(x,y) \\right]}{Z_{\\Lambda}} \\left( \\sum_{y} \\frac{\\exp\\left[ \\sum_{i}\\lambda_{i}f_{i}(x,y) \\right]}{Z_{\\Lambda}} \\right)&#94;{-1} \\\\ &= \\frac{1}{Z_{\\Lambda}(x)} \\exp\\left[ \\sum_{i}\\lambda_{i}f_{i}(x,y) \\right] \\\\ Z_{\\Lambda}(x) &= \\sum_{y}\\exp\\left[\\sum_{i}\\lambda_{i}f_{i}(x,y)\\right] \\end{align*} このモデルを用いた素性の平均 \\(E_{P}[f_{i}]\\) は次の様に計算できる。 \\begin{align*} E_{P}[f_{i}] &= \\sum_{x,y} P(x,y) f_{i}(x,y) = \\sum_{x,y} P(y|x)P(x)f_{i}(x,y) \\\\ &= \\sum_{x} P(x) \\sum_{y} P(y|x) f_{i}(x,y) \\end{align*} 外側の \\(P(x)\\) の和は、考えうる全ての入力 \\(x \\in X\\) についての和を取らねばならず、その計算は現実的に不可能である。従って経験確率による近似 \\(P(x) \\approx \\tilde{P}(x)\\) を用いて、平均は \\begin{equation*} E_{P}[f_{i}] \\approx \\sum_{x}\\tilde{P}(x) \\sum_{y} P(y|x) f_{i}(x,y) \\end{equation*} とする。この近似を用いることで、 \\(x\\) については学習データに現れるものだけの和を取ればよく、また \\(y\\) についても素性関数が非零の時のみ和を取れば良ため、計算の効率化が望める。 平均だけでなく、正規化項 \\(Z_{\\Lambda}(x)\\) の計算もボトルネックな部分であり、効率化が望まれる。そこで、文献 [5] [6] による効率的な正規化項の計算手法を見ていく。まず、素性関数の集合 \\({\\cal F}\\) を次の2つに分割する: \\begin{align*} {\\cal F}_{m} &= \\{ f_{i} | \\forall{w,x,y} \\ f_{i}(x,y) = f_{i}(w,y) \\} \\ \\ \\text{（周辺素性(marginalized feature)の集合）} \\\\ {\\cal F}_{c} = {\\cal F}_{m}&#94;{c} &= \\{ f_{i} | \\exists{w,x,y} \\ f_{i}(x,y) \\neq f_{i}(w,y) \\} \\ \\ \\text{（条件付き素性(conditional feature)の集合）} \\end{align*} 周辺素性は \\(y\\) の値のみによって決まる素性であり、 \\(y\\) の関数として捉えられる。集合演算の性質により、 \\({\\cal F}\\_{m} \\cap {\\cal F}_{c} = \\emptyset\\) は自明に成り立つ。次に、 \\(y\\) の値域 \\(Y\\) についても次の分割を行う: \\begin{align*} Y_{m} &= \\{ y | \\exists f_{i} \\in {\\cal F}_{m} \\ f_{i}(y) \\neq 0 \\} \\ \\ \\text{（周辺素性が活性化される$Y$の要素）} \\\\ Y(x) &= \\{ y | \\exists f_{i} \\in {\\cal F}_{c} \\ f_{i}(x,y) \\neq 0 \\} \\ \\ \\text{（$x$を固定した時に,条件付き素性が活性化される$Y$の要素）} \\end{align*} 定義より \\begin{equation*} Y_{m}&#94;{c} = \\{ y | \\forall{f_{i}} \\in {\\cal F}_{m} \\ f_{i}(y) = 0 \\} \\end{equation*} （どの周辺素性に対しても活性化されない \\(Y\\) の要素）は自明に成り立つ。また、一般には \\(Y_{m} \\cap Y(x) \\neq \\emptyset\\) である。即ち周辺素性と条件付き素性を同時に活性化させる \\(Y\\) の要素は存在する。 以上の集合分割を考慮しつつ、正規化項 \\(Z_{\\Lambda}(x) = \\sum_{y}\\exp\\left[\\sum_{i}\\lambda_{i}f_{i}(x,y)\\right]\\) の計算を考えていくが、表記の簡略化の為、文献と同じように次の表記を用いる: \\begin{equation*} z(y|x) = \\exp\\left[ \\sum_{i}\\lambda_{i} f_{i}(x,y) \\right] \\ ,\\ z(y) = \\exp\\left[ \\sum_{f_{i} \\in {\\cal F}_{m}} \\lambda_{i} f_{i}(y) \\right] \\end{equation*} 正規化項 \\(Z_{\\Lambda}(x)\\) の計算式は次のように展開される。 \\begin{align*} Z_{\\Lambda}(x) &= \\sum_{y \\in Y}z(y|x) \\\\ &= \\sum_{y \\in Y_{m}&#94;{c} \\cap Y(x)&#94;{c}} z(y|x) + \\sum_{y \\in Y_{m} \\cap Y(x)&#94;{c}} z(y|x) + \\sum_{y \\in Y(x)} z(y|x) \\\\ \\end{align*} ここで、 \\begin{align*} y \\in Y(x)&#94;{c} &\\implies z(y|x) = z(y) \\\\ &\\because z(y|x) = \\exp\\left[ \\sum_{f_{i} \\in {\\cal F}_{m}} \\lambda_{i} f_{i}(y) + \\sum_{f_{i} \\in {\\cal F}_{c}} \\lambda_{i} 0 \\right] = \\exp \\left[ \\sum_{f_{i} \\in {\\cal F}_{m}} \\lambda_{i} f_{i}(y) \\right] = z(y) \\end{align*} が成立するので、 \\begin{equation*} Z_{\\Lambda}(x) = \\sum_{y \\in Y_{m}&#94;{c} \\cap Y(x)&#94;{c}} z(y) + \\sum_{y \\in Y_{m} \\cap Y(x)&#94;{c}} z(y) +\\sum_{y \\in Y(x)} z(y|x) \\end{equation*} となり、さらに集合の包含関係に注目すれば、 \\begin{align*} \\sum_{y \\in Y} z(y) &= \\sum_{y \\in Y_{m} \\cap Y(x)&#94;{c}} z(y) + \\sum_{y \\in Y_{m}&#94;{c} \\cap Y(x)&#94;{c}} z(y) + \\sum_{y \\in Y(x)} z(y) \\\\ &= \\sum_{y \\in Y_{m}} z(y) + \\sum_{y \\in Y_{m}&#94;{c}} z(y) \\\\ \\therefore \\sum_{y \\in Y_{m} \\cap Y(x)&#94;{c}} z(y) + \\sum_{y \\in Y_{m}&#94;{c} \\cap Y(x)&#94;{c}} z(y) &= \\sum_{y \\in Y_{m}} z(y) + \\sum_{y \\in Y_{m}&#94;{c}} z(y) - \\sum_{y \\in Y(x)} z(y) \\end{align*} が成立するので、 \\begin{equation*} Z_{\\Lambda}(x) = \\sum_{y \\in Y_{m}&#94;{c}} z(y) + \\sum_{y \\in Y_{m}} z(y) + \\sum_{y \\in Y(x)} \\left\\{ z(y|x) -z(y) \\right\\} \\end{equation*} となり、更に \\(Y_{m}&#94;{c}\\) の要素の性質 \\begin{align*} y \\in Y_{m}&#94;{c} &\\implies z(y) = 1 \\\\ &\\because z(y) = \\exp\\left[ \\sum_{f_{i} \\in {\\cal F}_{m}} \\lambda 0 \\right] = 1 \\end{align*} を用いて、次の最終結果を得る。 \\begin{align*} Z_{\\Lambda}(x) &= \\sum_{y \\in Y_{m}&#94;{c}} 1 + \\sum_{y \\in Y_{m}} z(y) + \\sum_{y \\in Y(x)} \\left\\{ z(y|x) -z(y) \\right\\} \\\\ &= |Y-Y_{m}| + \\sum_{y \\in Y_{m}}z(y) + \\sum_{y \\in Y(x)} \\left\\{ z(y|x) -z(y) \\right\\} \\end{align*} ここで \\(Y-Y_{m}=Y \\cap Y_{m}&#94;{c}\\) は集合演算の意味での差である。この計算式は、第1項と第2項は予め計算しておくことができ、しかも第3項については \\(Y\\) の部分集合 \\(Y(x)\\) の和を考えれば良い。結果、ナイーブな計算（計算量 \\(O(|X||Y|)\\) ）を行うよりも効率的（計算量 \\(O(|X||Y(x)|+|X|)\\) ）に計算を行うことができる。 素性の自動選択 前節までは、最大エントロピーモデルの学習について考えてきたが、モデルの構成要素となる素性については触れてなかった。観測された経験確率分布 \\(\\tilde{P}(x,y)\\) に対し、素性の組み合わせによって実現可能な最大尤度が異なり、従って尤度が最大になる素性集合 \\({\\cal F}\\) を選び出さなければならない。 しかし素性の候補となる集合 \\({\\cal F}_{0}\\) は非常に大きくなる為に、網羅的に全ての素性の組み合わせを試していくのは現実的に不可能である。また、サンプルで出現頻度が高い素性を選択する手法も存在するが、これでは尤度を厳密に最大化できない。そこで、逐次的にモデルの尤度が増加する様に素性を追加する手法が基本的に用いられており、その手順の概要は以下の様になる。 モデルの素性集合 \\({\\cal F}\\) を空集合とする: \\({\\cal F} \\leftarrow \\emptyset\\) （反復スケーリング法等の学習手法によって）素性集合 \\({\\cal F}\\) における最大尤度モデル \\(P_{\\cal F}\\) を得る。 素性集合の候補 \\({\\cal F}\\_{0}\\) の各要素 \\(f_{0} \\in {\\cal F}_{0}\\) について、以下を行う。 1. 素性を加えたモデルを学習し \\(P_{{\\cal F} \\cup f_{0}}\\) を得る。 2. 対数尤度の増分 \\(\\Delta L({\\cal F}, f_{0})\\) を計算する: \\(\\Delta L({\\cal F}, f_{0}) \\leftarrow L(P_{{\\cal F} \\cup f_{0}}) - L(P_{\\cal F})\\) 最大の増分 \\(\\Delta L({\\cal F}, \\hat{f})\\) を与える \\(\\hat{f} = \\underset{f \\in {\\cal F}_{0}}{\\rm argmax}\\ \\Delta L({\\cal F}, f)\\) を選び出し、素性集合に加える: \\({\\cal F} \\leftarrow {\\cal F} \\cup \\hat{f}\\) 最大増分がある閾値以下になったら終了し、それ以外は2.に戻る。 逐次的に計算が行える為に手続き的に実行しやすいものの、結局手順3,4において \\({\\cal F}_{0}\\) を走査しているので依然として膨大な計算量が必要になる。文献 [7] [8] では対数尤度の増分を近似的に求める手法を述べているが、それでも本質的に計算量を削減できたとは言えず、効率的な素性選択の手法については研究の対象となっていた [9] [10] 。 ここでは元の文献 [11] [12] に述べられていた、増分の近似による手法を見ていく。近似の仮定としては、元のモデル \\(P_{\\cal F}\\) とそのパラメタ集合 \\(\\Lambda\\) に \\(f \\in {\\cal F}\\) とそれに付随するパラメタ \\(\\alpha\\) を加えたモデル \\(P_{{\\cal F} \\cup f}\\) においても、最大尤度を与える元のパラメタ \\(\\Lambda\\) は変化しないというものである。実際には素性を加える事で最大尤度を与えるパラメタ \\(\\Lambda\\) は変化するが、この変化を無視することでモデル \\(P_{{\\cal F} \\cup f}\\) の最大尤度 \\(L(P_{{\\cal F} \\cup f})\\) の計算を回避する。素性を追加することにより尤度は増えこそすれ減ることはないので（ \\(\\because\\) 経験分布に適合しない素性に対しては学習の結果 \\(\\alpha = 0\\) となり、元のモデルと一致するので尤度増分は0） 、近似的増分を最大にする \\(\\alpha\\) を探索する問題に帰着される。 仮定の下で、素性集合 \\({\\cal F} \\cup f\\) に対するモデル \\(P_{{\\cal F} \\cup f}&#94;{\\alpha}\\) の確率分布は次の様に書ける。 \\begin{align*} P_{ {\\cal F} \\cup f}&#94;{\\alpha}(y|x) &= \\frac{1}{Z_{\\alpha}(x)} P_{\\cal F} (y|x) \\exp \\left[ \\alpha f(x,y) \\right] \\\\ Z_{\\alpha}(x) &= \\sum_{y} P_{\\cal F}(y|x) \\exp \\left[ \\alpha f(x,y) \\right] \\end{align*} 対数尤度の近似的増分 \\(G_{{\\cal F} \\cup f}(\\alpha)\\) は, \\begin{align*} G_{{\\cal F} \\cup f}(\\alpha) &= L(P_{{\\cal F}\\cup f}&#94;{\\alpha}) - L(P_{\\cal F}) \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\log P_{{\\cal F} \\cup f}&#94;{\\alpha}(x,y) - \\sum_{x,y} \\tilde{P}(x,y) \\log P_{\\cal F}(x,y) \\\\ &= \\sum_{x,y} \\tilde{P}(x,y) \\left\\{ \\log P_{\\cal F}(x,y) + \\alpha f(x,y) - \\log Z_{\\alpha}(x) - \\log P_{\\cal F}(x,y) \\right\\} \\\\ &= \\alpha \\sum_{x,y} \\tilde{P}(x,y) f(x,y) - \\sum_{x} \\log Z_{\\alpha}(x) \\sum_{y} \\tilde{P}(x,y) \\\\ &= \\alpha E_{\\tilde{P}}[f] - \\sum_{x} \\tilde{P}(x) \\log Z_{\\alpha}(x) \\end{align*} となる、 \\(G_{{\\cal F} \\cup f}(0) = 0\\) は \\(Z_{0}(x) = 1\\) より容易に確かめられる。増分最大化の為、偏微分 \\(\\frac{\\partial G_{{\\cal F} \\cup f}}{\\partial \\alpha} = G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha)\\) を計算すると, \\begin{align*} G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha) &= E_{\\tilde{P}}[f] - \\sum_{x} P(x) \\frac{\\partial \\log Z_{\\alpha}(x)}{\\partial \\alpha} \\\\ &= E_{\\tilde{P}}[f] - \\sum_{x} \\tilde{P}(x) \\frac{1}{Z_{\\alpha}(x)} \\sum_{y} P_{\\cal F}(y|x) \\exp\\left[ \\alpha f(x,y) \\right] f(x,y) \\\\ &= E_{\\tilde{P}}[f] - \\sum_{x} \\tilde{P}(x) \\sum_{y} P_{ {\\cal F} \\cup f}&#94;{\\alpha}(y|x) f(x,y)\\ \\ (= E_{\\tilde{P}}[f] - E_{P_{ {\\cal F} \\cup f}}[f]) \\\\ &= E_{\\tilde{P}}[f] - \\sum_{x} \\tilde{P}(x) Q_{ {\\cal F} \\cup f}&#94;{\\alpha} (f|x) \\end{align*} ここで、文献にもあるように \\(Q_{ {\\cal F} \\cup f}&#94;{\\alpha} (h|x) = \\sum_{y} P_{ {\\cal F} \\cup f}&#94;{\\alpha}(y|x) h(x,y)\\) （分布 \\(P_{ {\\cal F} \\cup f}\\) による、 \\(h\\) の \\(y\\) における平均）とおいている。 \\(G_{{\\cal F} \\cup f}&#94;{\\prime}(0)\\) の値は \\(P_{ {\\cal F} \\cup f}&#94;{0}(y|x) = P_{\\cal F}(y|x)\\) により \\(G_{{\\cal F}\\cup f}&#94;{\\prime}(0) = E_{\\tilde{P}}[f] - E_{P_{\\cal F}}[f]\\) となる。更に2階微分 \\(G_{{\\cal F} \\cup f}&#94;{\\prime \\prime}(\\alpha)\\) を計算すると, \\begin{align*} G_{{\\cal F} \\cup f}&#94;{\\prime \\prime}(\\alpha) &= - \\sum_{x} P(x) \\frac{1}{Z_{\\alpha}&#94;{2}(x)} \\left[ \\left\\{ \\sum_{y} P_{\\cal F}(y|x) \\exp\\left[ \\alpha f(x,y) \\right] f&#94;{2}(x,y) \\right\\} Z_{\\alpha}(x) \\right. \\\\ & \\left. - \\left\\{ \\sum_{y} P_{\\cal F}(y|x)\\exp\\left[ \\alpha f(x,y) \\right] f(x,y) \\right\\}&#94;{2} \\right] \\\\ &= - \\sum_{x} \\tilde{P}(x) \\left[ Q_{ {\\cal F} \\cup f}&#94;{\\alpha} (f&#94;{2}|x) - \\left\\{Q_{ {\\cal F} \\cup f}&#94;{\\alpha}(f|x) \\right\\}&#94;{2} \\right] \\\\ &= - \\sum_{x} \\tilde{P}(x) Q_{ {\\cal F} \\cup f}&#94;{\\alpha} \\left( (f - Q_{ {\\cal F} \\cup f}&#94;{\\alpha}(f|x))&#94;{2} | x \\right) \\end{align*} ここで最下段の式変形には、分散と平均の関係 \\(E[(X-E[X])&#94;{2}] = E[X&#94;{2}] - \\{E[X]\\}&#94;{2}\\) を用いている。 \\((f - Q_{ {\\cal F} \\cup f}&#94;{\\alpha}(f|x))&#94;{2} \\geq 0\\) より、 \\(G_{{\\cal F} \\cup f}&#94;{\\prime \\prime}(\\alpha) \\leq 0\\) が成立し、 \\(G_{{\\cal F} \\cup f}(\\alpha)\\) は上に凸な関数であり、極大値がそのまま大域的な最大値となる事が分かる。 上述の議論により、 \\(G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha&#94;{\\ast}) = 0\\) を満たす \\(\\alpha&#94;{\\ast}\\) を得れば良いことになるが、解くべき式が \\(\\alpha\\) について閉じた形をしていない為、数値解析的な手法を用いることになる。文献 [13] [14] [15] によると、 \\(G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha)\\) は \\(\\alpha\\) に対して凸関数ではないが、 \\(\\exp(\\alpha)\\) に関しては下に凸の減少関数、かつ \\(\\exp(-\\alpha)\\) に関しては上に凸の増加関数となる事が示されているので、 \\(\\exp(\\alpha)、\\exp(-\\alpha)\\) の数列に対してニュートン法を適用する事を考える。偏微分の連鎖律を用いることで, \\begin{align*} \\frac{\\partial G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha)}{\\partial \\exp(\\alpha)} &= \\frac{\\partial G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha)}{\\partial \\alpha} \\frac{\\partial \\alpha}{\\partial \\exp(\\alpha)} \\\\ &= \\frac{\\log t}{t} G_{{\\cal F} \\cup f}&#94;{\\prime \\prime}(\\alpha) \\ \\ (t = \\exp(\\alpha)) \\\\ &= \\frac{1}{t} G_{{\\cal F} \\cup f}&#94;{\\prime \\prime}(\\alpha) = \\exp(-\\alpha) G_{{\\cal F} \\cup f}&#94;{\\prime \\prime}(\\alpha) \\end{align*} が成り立つので、ニュートン法の更新則は、 \\begin{align*} \\exp(\\alpha_{n+1}) &= \\exp(\\alpha_{n}) - \\frac{G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{\\frac{\\partial G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{\\partial \\exp(\\alpha_{n})}} = \\exp(\\alpha_{n}) \\left[ 1 - \\frac{G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{G_{{\\cal F} \\cup f}&#94;{\\prime\\prime}(\\alpha_{n})} \\right] \\\\ \\iff \\alpha_{n+1} &= \\alpha_{n} + \\log \\left[ 1 - \\frac{G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{G_{{\\cal F} \\cup f}&#94;{\\prime\\prime}(\\alpha_{n})} \\right] \\\\ \\exp(-\\alpha_{n+1}) &= \\exp(-\\alpha_{n}) - \\frac{G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{\\frac{\\partial G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{\\partial \\exp(-\\alpha_{n})}} = \\exp(-\\alpha_{n}) \\left[ 1 + \\frac{G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{G_{{\\cal F} \\cup f}&#94;{\\prime\\prime}(\\alpha_{n})} \\right] \\\\ \\iff \\alpha_{n+1} &= \\alpha_{n} - \\log \\left[ 1 + \\frac{G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha_{n})}{G_{{\\cal F} \\cup f}&#94;{\\prime\\prime}(\\alpha_{n})} \\right] \\end{align*} となる。最適値 \\(\\alpha&#94;{\\ast}\\) が \\(\\alpha&#94;{\\ast} > 0\\) の場合（ \\(E_{\\tilde{P}}[f] > E_{P_{\\cal F}}[f]\\) [16] ）には上の更新式を用いれば良く、 \\(\\alpha&#94;{\\ast} < 0\\) の場合（ \\(E_{\\tilde{P}}[f] < E_{P_{\\cal F}}[f]\\) ）には下の更新式を用いれば良い。 脚注・参考文献 [1] 北研二、辻井潤一、\"確率的言語モデル\"、東京大学出版会、1999 [2] 高村大也、奥村学、\"言語処理のための機械学習入門\"、コロナ社、2010 [3] 高橋治久、堀田一弘、\"学習理論\" コロナ社、2009 [4] 高橋治久、堀田一弘、\"学習理論\" コロナ社、2009 [5] 北研二、辻井潤一、\"確率的言語モデル\"、東京大学出版会、1999 [6] Wu, Jun, and Sanjeev Khudanpur, \"Efficient training methods for maximum entropy language modeling.\" INTERSPEECH. 2000. [7] 北研二、辻井潤一、\"確率的言語モデル\"、東京大学出版会、1999 [8] Berger, Adam L., Vincent J, Della Pietra, and Stephen A. Della Pietra. \"A maximum entropy approach to natural language processing.\" Computational linguistics 22.1 (1996): 39-71. [9] Zhou, Yaqian, et al. \"A fast algorithm for feature selection in conditional maximum entropy modeling.\" Proceedings of the 2003 conference on Empirical methods in natural language processing. Association for Computational Linguistics, 2003. [10] 谷垣宏一, 渡邉圭輔, and 石川泰, ``最大エントロピー法による発話理解のための効率的モデル構築 (< 特集> 音声言語情報処理とその応用).'' 情報処理学会論文誌 43.7 (2002): 2138-2146. [11] 北研二、辻井潤一、\"確率的言語モデル\"、東京大学出版会、1999 [12] Berger, Adam L., Vincent J, Della Pietra, and Stephen A. Della Pietra. \"A maximum entropy approach to natural language processing.\" Computational linguistics 22.1 (1996): 39-71. [13] 北研二、辻井潤一、\"確率的言語モデル\"、東京大学出版会、1999 [14] Berger, Adam L., Vincent J, Della Pietra, and Stephen A. Della Pietra. \"A maximum entropy approach to natural language processing.\" Computational linguistics 22.1 (1996): 39-71. [15] Pietra, Stephen Della, Vincent Della Pietra, and John Lafferty. \"Inducing features of random fields.\" Pattern Analysis and Machine Intelligence、IEEE Transactions on 19.4 (1997): 380-393. [16] \\(G_{{\\cal F} \\cup f}&#94;{\\prime}(\\alpha)\\) は \\(\\alpha\\) に関して単調減少するので、 \\(G_{{\\cal F} \\cup f}&#94;{\\prime}(0) = E_{\\tilde{P}}[f] - E_{P_{\\cal F}}[f]>0\\) ならば、かつその時に限り最適値 \\(\\alpha&#94;{\\ast}\\) は正の値をとる。","tags":"記事","url":"/zui-da-entoropimoderu.html","loc":"/zui-da-entoropimoderu.html"},{"title":"SVM（サポートベクトルマシン）","text":"SVM(Support Vector Machine, サポートベクトルマシン) は、深層学習の影に隠れがちではあるものの、現在使われている識別学習モデルの中でも比較的認識性能が優れ、実用に供される事はもちろん、様々な研究でも比較対象となる手法の一つである。 SVMの大雑把な理論的概要を述べると、SVMは与えられた学習サンプルを最も適切に分離（識別）する境界面（ 識別面 ）を発見する手法である。その識別面は凸計画問題に帰着して求める事ができるので、どの様なサンプルにおいても（存在するならば）最適な識別面を構成できる。 本稿では、最初に基本となる線形SVMの定式化を行い、次に汎用性をより高めた非線形SVMとソフトマージンSVMを説明し、最後にSVMを回帰問題に適用したSVR(Support Vector Regression, サポートベクトル回帰)を説明する。最後にC言語による実装例を挙げる。 SVMも知り尽くされており、文献・資料は大量に存在する。ここでは、参考書籍 [1] , [2] を挙げる。 線形SVM マージンの定式化 マージン最大化 KKT条件 非線形SVM ソフトマージンSVM SVR（Support Vector Regression, サポートベクトル回帰） 1ノルムSVR・双対問題の導出 2ノルムSVR・双対問題の導出 実装の例 学習 学習則の導出 実装 制約条件の考慮 正例と負例の双対係数の和を等しくする 双対係数は非負 識別 脚注 線形SVM マージンの定式化 識別の例として、まずは図にあるような、2次元空間 \\(X\\times Z\\) に存在する2クラスのサンプルデータ（以下サンプル）を仮定する。各クラスは二値のラベル付け \\(y=\\{-1, 1\\}\\) がなされており、識別面（2次元空間では直線） \\(ax+bz+c=0\\) の上半領域（ \\(ax+bz+c>0\\) ）にラベル \\(y=1\\) のサンプルが、下半領域（ \\(ax+bz+c<0\\) ）にラベル \\(y=-1\\) のサンプルが分布するようにする。 2クラス分離の例 更に、 \\(n\\) 次元空間の元（ベクトル） \\(\\boldsymbol{x} \\in \\mathbb{R}&#94;{n}\\) で表されるサンプルに対しても一般化でき、 \\(n\\) 次元の係数ベクトル \\(\\boldsymbol{w} \\in \\mathbb{R}&#94;{n}\\) を用いることで、 識別面は \\begin{equation*} \\begin{aligned} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x} + b = 0 \\end{aligned} \\end{equation*} と表現できる。ここで \\(b \\in \\mathbb{R}\\) は切片（しきい値、 バイアス）である。 概要でも述べたとおり、識別面は異なるラベルが付いたサンプルを互いに分離さえできていれば良いので、識別面の候補は無限に存在してしまう（上の2次元の例でも明らかである）。しかし、 その全てが適切な識別面とは限らない。 SVMでは、次の2点を最適な識別面の条件とする。 各クラスの、最も識別面に近いサンプル（ サポートベクトル ）までの距離を最大にする。 また、 その距離を各クラスで同一にする。 この2点を満たす識別面ならば、 丁度クラス間の中心を区切ることが出来、適切な識別面といえる。 また、図に示す様に、サポートベクトル間の距離を マージン （余白）という。 SVMは、このマージンを最大化することが目的となる。 マージン それでは、 マージンの定式化を考える。 \\(n\\) 次元空間上に \\(N\\) 個存在するサンプルを \\(\\boldsymbol{x}\\_{i} \\in \\mathbb{R}&#94;{n} \\ (i=1, \\dots, N)\\) と書き、またそのデータに対応する二値ラベルを \\(y_{i} \\in \\{-1, 1\\}\\ (i=1, \\dots, N)\\) とかく。全てのサンプルが正しく識別されている時には、 \\begin{equation*} \\begin{aligned} y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) \\geq 0 \\quad (i = 1, \\dots, N) \\end{aligned} \\end{equation*} が明らかに成立する。 そして、異なる2クラスのサポートベクトル \\(\\boldsymbol{x}\\_{s}, \\boldsymbol{x}\\_{t}\\) が \\begin{equation*} \\begin{aligned} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{s} + b = l , \\quad \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{t} + b = -l\\end{aligned} \\end{equation*} が成立すると仮定する [3] と（ \\(l>0\\) ）、 \\(\\boldsymbol{x}\\_{s}\\) と \\(\\boldsymbol{x}\\_{t}\\) の、識別面に対して平行な距離がマージンとして計算できる。マージンを \\(\\gamma\\) と書くと、 平面の単位法ベクトルは \\(\\boldsymbol{w}/||\\boldsymbol{w}||\\) （ \\(||\\boldsymbol{w}|| = \\sqrt{\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w}}\\) ）で与えられるので、マージンは \\begin{equation*} \\begin{aligned} & \\boldsymbol{w}&#94;{\\mathsf{T}}(\\boldsymbol{x}_{t} + \\gamma \\frac{\\boldsymbol{w}}{||\\boldsymbol{w}||}) + b = \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{s} + b \\nonumber \\\\ &\\iff \\gamma \\frac{\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w}}{||\\boldsymbol{w}||} = \\gamma ||\\boldsymbol{w}|| = (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{s}+b) - (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{t}+b) = 2l \\nonumber \\\\ &\\therefore \\gamma = \\frac{2l}{||\\boldsymbol{w}||}\\end{aligned} \\end{equation*} で求められる。 マージン最大化 前節でも既に述べたが、 SVMの目的はマージン \\(\\gamma\\) を最大化することである。単純には \\(\\max \\gamma\\) と書けるが、 最適化を行いやすくするため、 \\(1/\\gamma\\) の最小化に置き換え、 \\(l\\) は最適化に関与しないので \\(l=1\\) とし、更に \\(||\\boldsymbol{w}||\\) が最小化された時は \\(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w}\\) も最小化されるので、考えるべき最適化問題は次のように書ける: \\begin{equation*} \\begin{aligned} & \\max_{\\scriptsize \\boldsymbol{w}} \\gamma = \\frac{2l}{||\\boldsymbol{w}||} \\quad \\text{subject to : } y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) \\geq l \\nonumber \\\\ &\\implies \\min_{\\scriptsize \\boldsymbol{w}} \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} \\quad \\text{subject to : } y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) \\geq 1 \\quad (i=1, \\dots, N)\\end{aligned} \\end{equation*} この最適化問題は、 凸計画問題 [4] であり、不等式制約付き非線形計画問題なので、 KKT条件(Karush-Kuhn-Tucker condition)を用いる。KKT条件はラグランジェの未定乗数法（等式制約）の一般化であり、次の定理で表される: KKT条件 \\(\\boldsymbol{v}&#94;{\\star}\\) を \\(f(\\boldsymbol{v})\\) に関しての最適化問題の最適解とするならば、次の条件を満たす最適重みベクトル \\(\\boldsymbol{\\alpha}&#94;{\\star}=[\\alpha_{1}&#94;{\\star}, \\cdots, \\alpha_{N}&#94;{\\star}]&#94;{\\mathsf{T}}\\ (\\alpha_{i} \\geq 0)\\) が存在する。 \\begin{equation*} \\begin{aligned} \\left\\{ \\begin{array}{ll} \\displaystyle\\frac{\\partial{\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star})}{\\partial \\boldsymbol{v}} &= 0 \\\\ \\boldsymbol{\\alpha}&#94;{\\star\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}&#94;{\\star}) &= 0 \\end{array} \\right. \\end{aligned} \\end{equation*} ここで \\(\\boldsymbol{g}(\\boldsymbol{v})\\) は制約条件式 \\(\\boldsymbol{g}(\\boldsymbol{v}) = [g_{1}(\\boldsymbol{v}), \\cdots, g_{N}(\\boldsymbol{v})]&#94;{\\mathsf{T}}\\) , \\({\\cal L}\\) はラグランジアン（ラグランジェ関数）であり以下の様に表される。 \\begin{equation*} \\begin{aligned} g_{i}(\\boldsymbol{v}) &\\geq 0\\ \\ (i = 1, \\dots, N) \\\\ {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}) &= f(\\boldsymbol{v}) + \\boldsymbol{\\alpha}&#94;{\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}) \\end{aligned} \\end{equation*} \\({\\cal L}\\) が凸関数ならば、最適点 \\((\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star})\\) は鞍点にあり、 \\(\\displaystyle\\max_{\\scriptsize \\boldsymbol{v}} {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}&#94;{\\star})\\) を主問題とする時、 \\(\\displaystyle\\min_{\\scriptsize \\boldsymbol{\\alpha}}{\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha})\\) を主問題に対する双対問題という。 [5] それでは実際にKKT条件を適用し、最適化問題を主問題(式)から双対問題へ変換する事を考える。 まず制約条件から \\begin{equation*} \\begin{aligned} g_{i}(\\boldsymbol{w}) = 1 - y_{i} (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) \\leq 0\\end{aligned} \\end{equation*} （最小化を考えているので、 符号が逆転している事に注意）より、ラグランジアンは、 \\begin{equation*} \\begin{aligned} {\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\alpha}) &= \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} + \\boldsymbol{\\alpha}&#94;{\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{w}) \\\\ &= \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} + \\sum_{i=1}&#94;{N}\\alpha_{i} \\{ 1 - y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) \\}\\end{aligned} \\end{equation*} と表現でき、 \\({\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\alpha})\\) の \\(\\boldsymbol{w}, b\\) による偏微分は、 \\begin{equation*} \\begin{aligned} \\frac{\\partial {\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\alpha})}{\\partial \\boldsymbol{w}} = \\boldsymbol{w} - \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i}\\boldsymbol{x}_{i}, \\quad \\frac{\\partial {\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\alpha})}{\\partial b} = \\sum_{i=1}&#94;{N}\\alpha_{i}y_{i}\\end{aligned} \\end{equation*} となる。 \\(\\displaystyle\\frac{\\partial {\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\alpha})}{\\partial \\boldsymbol{w}} = \\boldsymbol{0}\\) とおくことで最適時の係数 \\(\\boldsymbol{w}&#94;{\\star}\\) が求まる: \\begin{equation*} \\begin{aligned} \\boldsymbol{w}&#94;{\\star} = \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i}\\boldsymbol{x}_{i}\\end{aligned} \\end{equation*} また、 \\(\\displaystyle\\frac{\\partial {\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\alpha})}{\\partial b} = 0\\) により双対変数 \\(\\boldsymbol{\\alpha}\\) の制約条件が得られる: \\begin{equation*} \\begin{aligned} \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0\\end{aligned} \\end{equation*} これらの関係式をラグランジアンに代入することで、 双対問題式を得る: \\begin{equation*} \\begin{aligned} {\\cal L}(\\boldsymbol{w}&#94;{\\star}、 \\boldsymbol{\\alpha}) &= \\frac{1}{2} \\boldsymbol{w}&#94;{\\star\\mathsf{T}}\\boldsymbol{w}&#94;{\\star} + \\boldsymbol{\\alpha}&#94;{\\mathsf{T}} \\boldsymbol{g}(\\boldsymbol{w}&#94;{\\star}) \\\\ &= \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\boldsymbol{x}_{j}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + \\sum_{i=1}&#94;{N} \\alpha_{i} \\left\\{ 1 - y_{i} \\left( \\sum_{j=1}&#94;{N}\\alpha_{j}y_{j}\\boldsymbol{x}_{j}&#94;{\\mathsf{T}} \\boldsymbol{x}_{i} + b \\right) \\right\\} \\\\ &= \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\boldsymbol{x}_{i}&#94;{\\mathsf{T}}\\boldsymbol{x}_{j} + \\sum_{i=1}&#94;{N} \\alpha_{i} - b\\sum_{i=1}&#94;{N} \\alpha_{i} y_{i} - \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\boldsymbol{x}_{i}&#94;{\\mathsf{T}} \\boldsymbol{x}_{j} \\\\ &= \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\boldsymbol{x}_{i}&#94;{\\mathsf{T}}\\boldsymbol{x}_{j}\\end{aligned} \\end{equation*} （途中の式変形において、内積の対称性（ \\(\\boldsymbol{x}&#94;{\\mathsf{T}}\\_{j}\\boldsymbol{x}\\_{i} = \\boldsymbol{x}&#94;{\\mathsf{T}}\\_{i}\\boldsymbol{x}\\_{j}\\) ）を用いている。）よって、 双対問題は \\begin{equation*} \\begin{aligned} & \\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\boldsymbol{x}_{i}&#94;{\\mathsf{T}}\\boldsymbol{x}_{j} \\right] \\\\ & \\text{subject to : } \\alpha_{i} \\geq 0, \\ \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0 \\quad (i = 1, \\dots, N) \\nonumber\\end{aligned} \\end{equation*} と表現できる。双対問題は非負制約 \\(\\alpha_{i} \\geq 0\\) の中で \\(\\boldsymbol{\\alpha}\\) を動かし、その最大値を得れば良いので、 主問題を直接解くよりも容易に、数値最適化によって解を求める（学習する）ことができる。実際の実装については後に述べる。 非線形SVM 前節までの議論は、入力データと同じ空間（次元）で適切な識別面を発見するSVMであり、これを特に 線形SVM という。 線形SVMの場合、識別面は入力データ空間の次元 \\(n\\) に対し \\(n-1\\) 次元の平面（ 超平面 ）であり（例:2次元空間では直線、3次元空間では平面）、図の様に、異なるクラスのサンプルが入り組んだ状態では識別面を構成できない（ 線形分離不可能 ）。 線形分離不可能な例 この場合、入力データの空間 \\(\\mathbb{R}&#94;{n}\\) から高次元空間 \\(\\mathbb{R}&#94;{h}\\) ( \\(h \\gg n\\) )への高次元な非線形写像（ 特徴写像 ） \\(\\boldsymbol{\\phi} : \\mathbb{R}&#94;{n} \\to \\mathbb{R}&#94;{h}\\) を用いて高次元空間（特徴空間）へ写像すれば、線形分離不可能だったサンプルを一般位置 [6] に写し、識別面を構成できる（線形分離可能）ようになる（図参照）。 特徴空間で線形分離可能になる例 図では、入力空間は1次元（数直線）、 特徴空間は2次元（平面）である。入力空間で線形分離不可能なサンプルが、 特徴写像によって一般位置に写され、線形分離可能になっている。 この様に、 入力データ次元で線形分離不可能なサンプルを、特徴写像によって写して識別面を構成し、元の次元に戻すSVMを 非線形SVM という。 この場合、識別面は曲がった形状を持つ（超曲面）。 それでは非線形SVMの定式化を見ていく。特徴写像を用いてサンプルを写像することで、高次元空間内のサンプル（特徴サンプル） \\(\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})\\ (i =1, \\dots, N)\\) が得られる。後は線形SVMの時と全く同様の議論を適用し、 双対問題は次の様に表現される: \\begin{equation*} \\begin{aligned} &\\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{j}) \\right] \\\\ &\\text{subject to : } \\alpha_{i} \\geq 0,\\ \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0 \\quad (i = 1, \\dots, N) \\nonumber\\end{aligned} \\end{equation*} さて、 この様にして非線形SVMが実現できるが、 一般に、入力次元 \\(n\\) はもとより特徴空間の次元 \\(h\\) は非常に大きくなる（ \\(\\infty\\) 次元にすらなりうる）。特徴写像 \\(\\boldsymbol{\\phi}\\) を構成する \\(h\\) 個の非線形な基底を用意するのは、非常に困難であり、 実用上大変な不便が生じる。 そこで、特徴写像同士の内積 \\(\\boldsymbol{\\phi}(\\boldsymbol{x}\\_{i})&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}\\_{j})\\) の計算結果はノルムなので、その内積を計算するのではなく、 天下り的に、最初から内積値を与えてしまうやり方がある。 即ち、 特徴写像同士の内積値を、 カーネル関数 \\(K : \\mathbb{R}&#94;{n} \\times \\mathbb{R}&#94;{n} \\to \\mathbb{R}\\) で定める: \\begin{equation*} \\begin{aligned} K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) = \\langle \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\boldsymbol{\\phi}(\\boldsymbol{x}_{j}) \\rangle = \\boldsymbol{\\phi}(\\boldsymbol{x}_{i})&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{j})\\end{aligned} \\end{equation*} ここで \\(K\\) は入力データのみで記述されるので、特徴写像はカーネル関数の中に閉じ込められてしまい、 陽に現れない。 即ち、特徴写像を構成する必要がないというのが大きなメリットである。任意の関数がカーネルになるとは限らず、 マーサーの定理 [7] という条件をカーネル関数は満たす必要がある。代表的なカーネル関数を以下に挙げる: 線形カーネル: \\begin{equation*} \\begin{aligned} K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) = \\langle \\boldsymbol{x}_{i}, \\boldsymbol{x}_{j} \\rangle \\end{aligned} \\end{equation*} 入力次元における標準内積もカーネルとなり、 線形カーネルと呼ばれる。 ガウシアン（Radial Basis Function、 RBF:放射基底関数）カーネル: \\begin{equation*} \\begin{aligned} K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) = \\exp\\left(-\\frac{||\\boldsymbol{x}_{i}-\\boldsymbol{x}_{j}||&#94;{2}}{2\\sigma&#94;{2}}\\right) \\end{aligned} \\end{equation*} 分散パラメタ \\(\\sigma\\) を伴ってガウス関数に従った分布を示す。実用上よく用いられる。 多項式カーネル: \\begin{equation*} \\begin{aligned} K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) = (\\langle \\boldsymbol{x}_{i}, \\boldsymbol{x}_{j} \\rangle + c)&#94;{k} \\end{aligned} \\end{equation*} 正定数 \\(c\\) と多項式の次数 \\(k\\) によって構成されるカーネルである。ガウシアンカーネルよりも性能がパラメタに依存しない特徴を持つ。 カーネル関数 \\(K\\) を用いる事で、 非線形SVMの双対問題は次で表される: \\begin{equation*} \\begin{aligned} &\\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}K(\\boldsymbol{x}_{i}、 \\boldsymbol{x}_{j}) \\right] \\\\ &\\text{subject to : } \\alpha_{i} \\geq 0、\\ \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0 \\quad (i = 1, \\dots, N) \\nonumber\\end{aligned} \\end{equation*} ソフトマージンSVM 前節までのSVMは、 マージンの内部にサンプルが入る事を一切許さないので、これを特に ハードマージンSVM ということがある。カーネルを用いた非線形ハードマージンSVMは、線形分離不可能なサンプルにでも強引に曲がりくねった識別面を構成する。これは実用に供する場合に問題になることがある。 例えば、データに雑音が乗っていたり、 一部のラベルを付け間違えたりする場合であり、これらは実データを扱う場合、 往々にして起こりうる事である。この様な雑音を拾いすぎてしまうとSVMの汎化性能 [8] が悪化してしまうので、マージンの制約を緩め、一部のサンプルはマージンの内部に入っても良いようにSVMを改善する事を考える。マージンの内部にサンプルが入ることを許すSVMを ソフトマージンSVM と呼ぶことがある。 ハードマージンSVMの制約を緩める事を考える。サンプル \\(\\boldsymbol{x}\\_{i}\\) に対応するスラック（緩衝）変数 \\(\\eta_{i} \\geq 0\\ (i=1, \\dots, N)\\) を用意して、 SVMの制約を \\begin{equation*} \\begin{aligned} y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}\\_{i}) + b) \\geq 1 - \\eta_{i} \\quad (i = 1, \\dots, N)\\end{aligned} \\end{equation*} とする（最初から、サンプルは特徴写像 \\(\\boldsymbol{\\phi}\\) によって写像されている場合を考える）。スラック変数はサンプルがマージンに食い込んでいる距離を表しており、もちろん、 \\(\\eta_{i}\\) は小さい方が良く、 \\(\\eta_{i} = 0\\) の時はハードマージンに一致する。 そして、 \\(\\eta_{i}\\) も同時に最適化に組み込んでしまう事で、ソフトマージンSVMが実現できる。 多くの文献では、スラック変数のノルムの取り方で異なる2種類のソフトマージンSVMの式を提示している: 1ノルムソフトマージンSVM・主問題 \\begin{equation*} \\begin{aligned} & \\min_{\\scriptsize \\boldsymbol{w}} \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} + C_{1}\\sum_{i=1}&#94;{N} \\eta_{i} \\\\ & \\text{subject to : } y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) \\geq 1 - \\eta_{i}, \\ \\eta_{i} \\geq 0 \\quad (i=1, \\dots, N) \\end{aligned} \\end{equation*} 2ノルムソフトマージンSVM・主問題 \\begin{equation*} \\begin{aligned} &\\min_{\\scriptsize \\boldsymbol{w}} \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} + \\frac{C_{2}}{2}\\sum_{i=1}&#94;{N} \\eta_{i}&#94;{2} \\quad \\\\ &\\text{subject to : } y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) \\geq 1 - \\eta_{i} \\quad (i=1, \\dots, N) \\end{aligned} \\end{equation*} ここで、 \\(C_{1}, C_{2}\\) はハードマージンとソフトマージンのトレードオフを与える定数 [9] で、最適な値は実験等によって求める必要がある。 双対問題の導出は、前節までの議論と同様に、 KKT条件に当てはめる事により得られる: 1ノルムソフトマージンSVM・双対問題の導出 ラグランジアンは、 \\(\\beta_{i} \\geq 0\\) なる双対変数を導入して、 \\(-\\beta_{i}\\eta_{i} \\leq 0\\) より、 \\begin{equation*} \\begin{aligned} {\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}, \\boldsymbol{\\alpha}, \\boldsymbol{\\beta}) = \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{w} + C_{1} \\sum_{i=1}&#94;{N}\\eta_{i} + \\sum_{i=1}&#94;{N} \\alpha_{i} \\left\\{ 1 - \\eta_{i} - y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) \\right\\} + \\sum_{i=1}&#94;{N}(-\\beta_{i}\\eta_{i}) \\end{aligned} \\end{equation*} より、 \\({\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}, \\boldsymbol{\\alpha}, \\boldsymbol{\\beta})\\) の \\(\\boldsymbol{w}, b, \\eta_{i},\\) による偏微分 \\(\\displaystyle\\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}}, \\frac{\\partial \\cal L}{\\partial b}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}}\\) は、 \\begin{equation*} \\begin{aligned} \\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}} = \\boldsymbol{w} - \\sum_{i=1}&#94;{N} y_{i} \\alpha_{i} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad \\frac{\\partial \\cal L}{\\partial b} = \\sum_{i=1}&#94;{N}\\alpha_{i}y_{i}, \\quad \\frac{\\partial \\cal L}{\\partial \\eta_{i}} = C_{1} - \\alpha_{i} - \\beta_{i} \\end{aligned} \\end{equation*} \\(\\displaystyle\\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}} = \\boldsymbol{0}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}} = 0\\) とおくことで、最適時パラメタは、 \\begin{equation*} \\begin{aligned} \\boldsymbol{w}&#94;{\\star} = \\sum_{i=1}&#94;{N} y_{i} \\alpha_{i} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad C_{1} = \\alpha_{i} + \\beta_{i} \\end{aligned} \\end{equation*} \\(\\boldsymbol{w}&#94;{\\star}\\) をラグランジアンに代入すると、 \\begin{equation*} \\begin{aligned} {\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\eta}&#94;{\\star}、 \\boldsymbol{\\alpha}、 \\boldsymbol{\\beta}) &= \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) + \\sum_{i=1}&#94;{N} (C_{1} - \\alpha_{i} - \\beta_{i}) \\eta_{i} \\\\ &= \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\end{aligned} \\end{equation*} 制約条件 \\(\\alpha_{i}, \\beta_{i} \\geq 0\\) を含めて考えると、 \\(\\beta_{i} = C_{1} - \\alpha_{i} \\geq 0\\) より、 \\(\\alpha_{i}\\) についての制約 \\(0 \\leq \\alpha_{i} \\leq C_{1}\\) が得られ、結局、普通のSVMの双対問題に \\(\\alpha_{i}\\) についての制約を加えるだけで、1ノルムソフトマージンSVMが実現できる。 1ノルムソフトマージンSVM・双対問題 \\begin{equation*} \\begin{aligned} &\\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\right] \\\\ &\\text{subject to : } 0 \\leq \\alpha_{i} \\leq C_{1}, \\ \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0 \\quad (i = 1, \\dots, N) \\nonumber\\end{aligned} \\end{equation*} 2ノルムソフトマージンSVM・双対問題の導出 ラグランジアンは、 \\begin{equation*} \\begin{aligned} {\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}, \\boldsymbol{\\alpha}) = \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{w} + \\frac{C_{2}}{2} \\sum_{i=1}&#94;{N}\\eta_{i}&#94;{2} + \\sum_{i=1}&#94;{N} \\alpha_{i} \\left\\{ 1 - \\eta_{i} - y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) \\right\\} \\end{aligned} \\end{equation*} より、 \\({\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}, \\boldsymbol{\\alpha})\\) の \\(\\boldsymbol{w}, b, \\eta_{i}\\) による偏微分 \\(\\displaystyle\\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}}, \\frac{\\partial \\cal L}{\\partial b}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}}\\) は、 \\begin{equation*} \\begin{aligned} \\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}} = \\boldsymbol{w} - \\sum_{i=1}&#94;{N} y_{i} \\alpha_{i} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad \\frac{\\partial \\cal L}{\\partial b} = \\sum_{i=1}&#94;{N}\\alpha_{i}y_{i}, \\quad \\frac{\\partial \\cal L}{\\partial \\eta_{i}} = C_{2}\\eta_{i} - \\alpha_{i} \\end{aligned} \\end{equation*} \\(\\displaystyle\\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}} = \\boldsymbol{0}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}} = 0\\) とおくことで、最適時パラメタは、 \\begin{equation*} \\begin{aligned} \\boldsymbol{w}&#94;{\\star} = \\sum_{i=1}&#94;{N} y_{i} \\alpha_{i} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad \\eta_{i}&#94;{\\star} = \\frac{\\alpha_{i}}{C_{2}} \\end{aligned} \\end{equation*} これをラグランジアンに代入すると、 \\begin{equation*} \\begin{aligned} {\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\eta}&#94;{\\star}, \\boldsymbol{\\alpha}) &= \\sum_{i=1}&#94;{N} \\alpha_{i} + \\frac{1}{2C_{2}} \\sum_{i=1}&#94;{N} \\alpha_{i}&#94;{2} + \\sum_{i=1}&#94;{N} \\alpha_{i} \\left[ - \\frac{\\alpha_{i}}{C_{2}} - y_{i} \\sum_{j=1}&#94;{N} y_{j}\\alpha_{j} K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\right] + \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\\\ &= \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2C_{2}} \\sum_{i=1}&#94;{N} \\alpha_{i}&#94;{2} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\end{aligned} \\end{equation*} ここで \\(y_{i}y_{j} \\in \\{-1, 1\\}\\) に注目すれば、 \\begin{equation*} \\begin{aligned} {\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\eta}&#94;{\\star}, \\boldsymbol{\\alpha}) = \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\left( K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) + \\frac{1}{C_{2}}\\delta_{ij} \\right) \\end{aligned} \\end{equation*} と整理できる。ここで \\(\\delta_{ij}\\) はディラックのデルタであり、 \\begin{equation*} \\begin{aligned} \\delta_{ij} = \\left\\{ \\begin{array}{ll} 1 & i = j \\\\ 0 & otherwise \\end{array} \\right. \\end{aligned} \\end{equation*} を満たす。 2ノルムソフトマージンSVMも、 結局、カーネル関数を簡単に書き換える事で実現できる。 2ノルムソフトマージンSVM・双対問題 \\begin{equation*} \\begin{aligned} &\\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\left(K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) + \\frac{1}{C_{2}}\\delta_{ij} \\right) \\right] \\\\ &\\text{subject to : } \\alpha_{i} \\geq 0, \\ \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0 \\quad (i = 1,\\dots,N) \\nonumber \\end{aligned} \\end{equation*} SVR（Support Vector Regression, サポートベクトル回帰） 一般にSVMは識別器として用いられる事がほとんどだが、ラベルを実数とした回帰問題 [10] にも適用することができる。SVMによる回帰モデルのことを、 SVR （Support Vector Regression, サポートベクトル回帰）という。 基本的な考え方としては、図の様に、識別面（回帰面）を中心に幅 \\(2\\varepsilon\\) の\"帯\"に多くのサンプルが入るようにすれば良い。 SVR 帯を考慮して制約を表現すると、 \\begin{equation*} \\begin{aligned} | y_{i} - (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})+b) | \\leq \\varepsilon \\quad (i = 1, \\dots, N) \\end{aligned} \\end{equation*} となる。 これはハードマージン的な制約であり、幅 \\(2\\varepsilon\\) の帯に全てのサンプルが入る事を要求している。もちろん \\(\\varepsilon\\) を十分に大きくとれば全てのサンプルは帯に入るが、帯が広すぎるために自由度が大きく、 結果汎化性能の悪化に繋がってしまう。ラベルが実数となり、 雑音の影響をより受けやすくなることから、SVRにおいては、 最初からスラック変数を用いて、ソフトマージン的に定式化することが多い。 スラック変数を用いて、帯から飛び出た距離 \\(\\eta_{i}&#94;{+}, \\eta_{i}&#94;{-} \\geq 0\\) を次で定義する（図参照）: \\begin{align*} \\begin{aligned} \\eta_{i}&#94;{+} = \\left\\{ \\begin{array}{ll} y_{i} - \\varepsilon - (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})+b) & y_{i} \\geq (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})+b) + \\varepsilon \\\\ 0 & otherwise \\end{array} \\right. \\\\ \\eta_{i}&#94;{-} = \\left\\{ \\begin{array}{ll} (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})+b) - y_{i} - \\varepsilon & y_{i} \\leq (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})+b) - \\varepsilon \\\\ 0 & otherwise \\end{array} \\right. \\end{aligned} \\end{align*} なお、サンプルは帯からどちらか一方にしか飛び出ないので、 \\(\\eta_{i}&#94;{+}, \\eta_{i}&#94;{-}\\) のいずれか一方は必ず \\(0\\) となり、サンプルが帯に収まっている時は両方共 \\(0\\) となる。スラック変数を用いる事で、 制約は次のように表現できる: \\begin{equation*} \\begin{aligned} \\left\\{ \\begin{array}{l} (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})+b) - y_{i} \\leq \\varepsilon + \\eta_{i}&#94;{-} \\\\ y_{i} - (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})+b) \\leq \\varepsilon + \\eta_{i}&#94;{+} \\end{array} \\right. \\end{aligned} \\end{equation*} ソフトマージンの時と同様に考える事で、 最適化問題が定式化できる: 1ノルムSVR・主問題 \\begin{equation*} \\begin{aligned} &\\min_{\\scriptsize \\boldsymbol{w}} \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} + C_{1}\\sum_{i=1}&#94;{N} (\\eta_{i}&#94;{+} + \\eta_{i}&#94;{-}) \\\\ &\\text{subject to : } (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) - y_{i} \\leq \\varepsilon + \\eta_{i}&#94;{-}, \\ y_{i} - (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) \\leq \\varepsilon + \\eta_{i}&#94;{+} \\quad (i=1,\\dots,N) \\end{aligned} \\end{equation*} 2ノルムSVR・主問題 \\begin{equation*} \\begin{aligned} &\\min_{\\scriptsize \\boldsymbol{w}} \\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} + \\frac{C_{2}}{2}\\sum_{i=1}&#94;{N} \\left\\{ (\\eta_{i}&#94;{+})&#94;{2} + (\\eta_{i}&#94;{-})&#94;{2} \\right\\} \\\\ &\\text{subject to : } (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) - y_{i} \\leq \\varepsilon + \\eta_{i}&#94;{-}, \\ y_{i} - (\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}_{i} + b) \\leq \\varepsilon + \\eta_{i}&#94;{+} \\quad (i=1, \\dots, N) \\end{aligned} \\end{equation*} 後はKKT条件にぶち込むだけの流れ作業である。よし、じゃあぶち込んでやるぜ！ 1ノルムSVR・双対問題の導出 \\begin{equation*} \\begin{aligned} \\begin{split} &{\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}&#94;{+}, \\boldsymbol{\\eta}&#94;{-}, \\boldsymbol{\\alpha}&#94;{+}, \\boldsymbol{\\alpha}&#94;{-}, \\boldsymbol{\\beta}&#94;{+}, \\boldsymbol{\\beta}&#94;{-}) = \\\\ &\\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{w} + C_{1} \\sum_{i=1}&#94;{N}(\\eta_{i}&#94;{+}+\\eta_{i}&#94;{-}) + \\sum_{i=1}&#94;{N}(-\\beta_{i}&#94;{+}\\eta_{i}&#94;{+} -\\beta_{i}&#94;{-}\\eta_{i}&#94;{-} ) \\\\ &+ \\sum_{i=1}&#94;{N} \\left[ \\alpha_{i}&#94;{-} \\left\\{ (\\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) - y_{i} - \\varepsilon - \\eta_{i}&#94;{-} \\right\\} + \\alpha_{i}&#94;{+} \\left\\{ y_{i} - (\\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) - \\varepsilon - \\eta_{i}&#94;{+} \\right\\} \\right] \\end{split} \\end{aligned} \\end{equation*} より、 \\({\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}&#94;{+}, \\boldsymbol{\\eta}&#94;{-}, \\boldsymbol{\\alpha}&#94;{+}, \\boldsymbol{\\alpha}&#94;{-}, \\boldsymbol{\\beta}&#94;{+}, \\boldsymbol{\\beta}&#94;{-})\\) の \\(\\boldsymbol{w}, b, \\eta_{i}&#94;{+}, \\eta_{i}&#94;{-}\\) による偏微分 \\(\\displaystyle\\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}}, \\frac{\\partial \\cal L}{\\partial b}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{+}}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{-}}\\) は、 \\begin{equation*} \\begin{aligned} \\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}} = \\boldsymbol{w} + \\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-} - \\alpha_{i}&#94;{+}) \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad \\frac{\\partial \\cal L}{\\partial b} = \\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-} - \\alpha_{i}&#94;{+}) \\\\ \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{+}} = C_{1} - \\alpha_{i}&#94;{+} - \\beta_{i}&#94;{+}, \\quad \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{-}} = C_{1} - \\alpha_{i}&#94;{-} - \\beta_{i}&#94;{-} \\end{aligned} \\end{equation*} それぞれ \\(0\\) とおくと、 \\begin{equation*} \\begin{aligned} \\boldsymbol{w}&#94;{\\star} = \\sum_{i=1}&#94;{N} (\\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-}) \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad \\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-} - \\alpha_{i}&#94;{+}) = 0, \\quad C_{1} = \\alpha_{i}&#94;{+} + \\beta_{i}&#94;{+} = \\alpha_{i}&#94;{-} + \\beta_{i}&#94;{-} \\end{aligned} \\end{equation*} これをラグランジアンに代入すると、 \\begin{equation*} \\begin{aligned} \\begin{split} &{\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\eta}&#94;{+\\star}, \\boldsymbol{\\eta}&#94;{-\\star}, \\boldsymbol{\\alpha}&#94;{+}, \\boldsymbol{\\alpha}&#94;{-}, \\boldsymbol{\\beta}&#94;{+}, \\boldsymbol{\\beta}&#94;{-}) = \\\\ &\\frac{1}{2} \\sum_{i、j=1}&#94;{N} (\\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-})(\\alpha_{j}&#94;{+} - \\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) + C_{1} \\sum_{i=1}&#94;{N}(\\eta_{i}&#94;{+}+\\eta_{i}&#94;{-}) - \\sum_{i=1}&#94;{N}(\\beta_{i}&#94;{+}\\eta_{i}&#94;{+} + \\beta_{i}&#94;{-}\\eta_{i}&#94;{-}) \\\\ &+\\sum_{i=1}&#94;{N} \\left[ \\alpha_{i}&#94;{-}\\sum_{j=1}&#94;{N}(\\alpha_{j}&#94;{+}-\\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) - \\alpha_{i}&#94;{+}\\sum_{j=1}&#94;{N}(\\alpha_{j}&#94;{+}-\\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\right] \\\\ &+\\sum_{i=1}&#94;{N}\\left[ \\alpha_{i}&#94;{-} (-\\varepsilon-\\eta_{i}&#94;{-}-y_{i}) + \\alpha_{i}&#94;{+} (-\\varepsilon-\\eta_{i}&#94;{+}+y_{i}) \\right] \\end{split} \\end{aligned} \\end{equation*} \\(C_{1} = \\alpha_{i}&#94;{+} + \\beta_{i}&#94;{+} = \\alpha_{i}&#94;{-} + \\beta_{i}&#94;{-}\\) を用いて整理すると、 \\begin{equation*} \\begin{aligned} \\begin{split} &{\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\eta}&#94;{+\\star}, \\boldsymbol{\\eta}&#94;{-\\star}, \\boldsymbol{\\alpha}&#94;{+}, \\boldsymbol{\\alpha}&#94;{-}, \\boldsymbol{\\beta}&#94;{+}, \\boldsymbol{\\beta}&#94;{-}) = \\\\ &\\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{+}-\\alpha_{i}&#94;{-}) - \\varepsilon\\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-}+\\alpha_{i}&#94;{+}) - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} (\\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-})(\\alpha_{j}&#94;{+} - \\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\end{split} \\end{aligned} \\end{equation*} ところで、上でも既に述べたが \\(\\eta_{i}&#94;{+}, \\eta_{i}&#94;{-}\\) のどちらか一方は必ず \\(0\\) となるので、その場合は対応する \\(\\alpha_{i}&#94;{+}, \\alpha_{i}&#94;{-}\\) の制約条件はなくなり、従って、 \\(\\alpha_{i}&#94;{+}, \\alpha_{i}&#94;{-}\\) のどちらか一方も \\(0\\) となる。この事から \\(\\alpha_{i} = \\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-}\\) とおけば、 \\(\\alpha_{i}&#94;{-} + \\alpha_{i}&#94;{+} = |\\alpha_{i}|\\) と表現できるので、双対問題は以下の様に表現できる。 1ノルムSVR・双対問題 \\begin{equation*} \\begin{aligned} &\\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N}y_{i}\\alpha_{i} - \\varepsilon\\sum_{i=1}&#94;{N}|\\alpha_{i}| - \\frac{1}{2} \\sum_{i、j=1}&#94;{N}\\alpha_{i}\\alpha_{j}K(\\boldsymbol{x}_{i}、 \\boldsymbol{x}_{j}) \\right] \\\\ &\\text{subject to : } \\sum_{i=1}&#94;{N}\\alpha_{i} = 0, \\ -C_{1} \\leq \\alpha_{i} \\leq C_{1} \\quad (i = 1、\\dots、N) \\nonumber \\end{aligned} \\end{equation*} 2ノルムSVR・双対問題の導出 \\begin{equation*} \\begin{aligned} &{\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}&#94;{+}, \\boldsymbol{\\eta}&#94;{-}, \\boldsymbol{\\alpha}&#94;{+}, \\boldsymbol{\\alpha}&#94;{-}) = \\\\ &\\frac{1}{2} \\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{w} + \\frac{C_{2}}{2} \\sum_{i=1}&#94;{N} \\{ (\\eta_{i}&#94;{+})&#94;{2} + (\\eta_{i}&#94;{-})&#94;{2} \\} \\\\ &+\\sum_{i=1}&#94;{N} \\left[ \\alpha_{i}&#94;{-} \\left\\{ (\\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) - y_{i} - \\varepsilon - \\eta_{i}&#94;{-} \\right\\} + \\alpha_{i}&#94;{+} \\left\\{ y_{i} - (\\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}) + b) - \\varepsilon - \\eta_{i}&#94;{+} \\right\\} \\right] \\end{aligned} \\end{equation*} より、 \\({\\cal L}(\\boldsymbol{w}, \\boldsymbol{\\eta}&#94;{+}, \\boldsymbol{\\eta}&#94;{-}, \\boldsymbol{\\alpha}&#94;{+}, \\boldsymbol{\\alpha}&#94;{-})\\) の \\(\\boldsymbol{w}, b, \\eta_{i}&#94;{+}, \\eta_{i}&#94;{-}\\) による偏微分 \\(\\displaystyle\\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}}, \\frac{\\partial \\cal L}{\\partial b}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{+}}, \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{-}}\\) は、 \\begin{equation*} \\begin{aligned} \\frac{\\partial \\cal L}{\\partial \\boldsymbol{w}} = \\boldsymbol{w} + \\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-} - \\alpha_{i}&#94;{+}) \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad \\frac{\\partial \\cal L}{\\partial b} = \\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-} - \\alpha_{i}&#94;{+}) \\\\ \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{+}} = C_{2}\\eta_{i}&#94;{+} - \\alpha_{i}&#94;{+}, \\quad \\frac{\\partial \\cal L}{\\partial \\eta_{i}&#94;{-}} = C_{2}\\eta_{i}&#94;{-} - \\alpha_{i}&#94;{-} \\end{aligned} \\end{equation*} それぞれ \\(0\\) とおくと、 \\begin{equation*} \\begin{aligned} \\boldsymbol{w}&#94;{\\star} = \\sum_{i=1}&#94;{N} (\\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-}) \\boldsymbol{\\phi}(\\boldsymbol{x}_{i}), \\quad \\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-} - \\alpha_{i}&#94;{+}) = 0, \\quad \\eta_{i}&#94;{+\\star} = \\frac{\\alpha_{i}&#94;{+}}{C_{2}}, \\quad \\eta_{i}&#94;{-\\star} = \\frac{\\alpha_{i}&#94;{-}}{C_{2}} \\end{aligned} \\end{equation*} \\(\\boldsymbol{w}&#94;{\\star}\\) をラグランジアンに代入すると、 \\begin{equation*} \\begin{aligned} \\begin{split} &{\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\eta}&#94;{+\\star}, \\boldsymbol{\\eta}&#94;{-\\star}, \\boldsymbol{\\alpha}&#94;{+},\\boldsymbol{\\alpha}&#94;{-}) = \\\\ &\\frac{1}{2} \\sum_{i、j=1}&#94;{N} (\\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-})(\\alpha_{j}&#94;{+} - \\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) + \\frac{1}{C_{2}} \\sum_{i=1}&#94;{N}\\left\\{ (\\alpha_{i}&#94;{+})&#94;{2}+(\\alpha_{i}&#94;{-})&#94;{2} \\right\\} \\\\ &+\\sum_{i=1}&#94;{N} \\left[ \\alpha_{i}&#94;{-}\\sum_{j=1}&#94;{N}(\\alpha_{j}&#94;{+}-\\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) - \\alpha_{i}&#94;{+}\\sum_{j=1}&#94;{N}(\\alpha_{j}&#94;{+}-\\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\right] \\\\ &+\\sum_{i=1}&#94;{N}\\left[ \\alpha_{i}&#94;{-} (-\\varepsilon - \\frac{\\alpha_{i}&#94;{-}}{C_{2}} - y_{i}) + \\alpha_{i}&#94;{+} (- \\varepsilon - \\frac{\\alpha_{i}&#94;{+}}{C_{2}} +y_{i}) \\right] \\\\ &=\\sum_{i=1}&#94;{N} (\\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-})y_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N}(\\alpha_{i}&#94;{+}-\\alpha_{i}&#94;{-})(\\alpha_{j}&#94;{+}-\\alpha_{j}&#94;{-})K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) \\\\ &-\\varepsilon\\sum_{i=1}&#94;{N}(\\alpha_{i}&#94;{-} + \\alpha_{i}&#94;{+}) - \\frac{1}{2C_{2}}\\sum_{i=1}&#94;{N}\\left\\{ (\\alpha_{i}&#94;{-})&#94;{2} + (\\alpha_{i}&#94;{+})&#94;{2} \\right\\} \\end{split} \\end{aligned} \\end{equation*} 1ノルムSVRの時と同様に、 \\(\\alpha_{i} = \\alpha_{i}&#94;{+} - \\alpha_{i}&#94;{-}\\) とおくと、 \\((\\alpha_{i}&#94;{+})&#94;{2} + (\\alpha_{i}&#94;{-})&#94;{2} = \\alpha_{i}&#94;{2}\\) が成り立つので、双対問題は以下の様に表現できる。 2ノルムSVR・双対問題 \\begin{equation*} \\begin{aligned} & \\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N}y_{i}\\alpha_{i} - \\varepsilon\\sum_{i=1}&#94;{N}|\\alpha_{i}| - \\frac{1}{2} \\sum_{i, j=1}&#94;{N}\\alpha_{i}\\alpha_{j}\\left( K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) + \\frac{1}{C_{2}} \\right) \\right] \\\\ & \\text{subject to : } \\sum_{i=1}&#94;{N}\\alpha_{i} = 0 \\quad (i = 1, \\dots, N) \\nonumber \\end{aligned} \\end{equation*} 実装の例 実装例は ここ にある。本稿では要点を絞って見ていく。 学習 学習則の導出 SVMの学習は、双対問題 \\begin{equation*} \\begin{aligned} &\\max_{\\scriptsize \\boldsymbol{\\alpha}} \\left[ \\sum_{i=1}&#94;{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i、j=1}&#94;{N} \\alpha_{i}\\alpha_{j}y_{i}y_{j}\\boldsymbol{\\phi}(\\boldsymbol{x}_{i})&#94;{\\mathsf{T}}\\boldsymbol{\\phi}(\\boldsymbol{x}_{j}) \\right] = \\max_{\\scriptsize \\boldsymbol{\\alpha}} {\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\alpha}) \\\\ &\\text{subject to : } \\alpha_{i} \\geq 0,\\ \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0 \\quad (i = 1, \\dots, N) \\end{aligned} \\end{equation*} を解けば良いことになる。 脚注 [11] で既に触れたが、SVMのマージン最大化は凸計画問題である。従って局所最適解が存在せず、極大値が大域的な最大値に一致する。 ソフトマージンに対応する時は、1ノルムソフトマージンの際には係数に値域 \\(0 \\geq \\alpha_{i} \\geq C_{1}\\ (i=1,...,N)\\) を設け、2ノルムの際にはカーネル関数 \\(K\\) を次のように書き換えれば良い： \\begin{equation*} K'(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) = K(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}) + \\frac{\\delta_{ij}}{C_{2}} \\end{equation*} ここでは簡単な 最急勾配法 によって解を求めることを考える。 最急勾配法の原理は単純である。 \\(F(\\boldsymbol{\\alpha}) = {\\cal L}(\\boldsymbol{w}&#94;{\\star}, \\boldsymbol{\\alpha})\\) とおくと、その \\(\\boldsymbol{\\alpha}\\) による偏微分 \\(\\frac{\\partial F(\\boldsymbol{\\alpha})}{\\partial \\boldsymbol{\\alpha}}\\) は 勾配 、即ち \\(F(\\boldsymbol{\\alpha})\\) の最も上昇する方向を指すベクトルとなるので、係数の更新量 \\(\\Delta\\boldsymbol{\\alpha}\\) は学習率 \\(\\eta > 0\\) を用いて \\begin{equation*} \\Delta \\boldsymbol{\\alpha} = \\eta \\frac{\\partial F(\\boldsymbol{\\alpha})}{\\partial \\boldsymbol{\\alpha}} \\end{equation*} とすれば良い [12] 。学習の収束判定は、例えば \\(||\\Delta \\boldsymbol{\\alpha}||\\) が十分小さくなった時とすれば良く、その時は極大値が得られている。 実際に \\(\\frac{\\partial F(\\boldsymbol{\\alpha})}{\\partial \\boldsymbol{\\alpha}}\\) を計算することを考える。 \\(\\frac{\\partial F(\\boldsymbol{\\alpha})}{\\partial \\alpha_{i}}\\ (i=1,...,N)\\) は、 \\begin{equation*} \\begin{aligned} \\frac{\\partial F(\\boldsymbol{\\alpha})}{\\partial \\alpha_{i}} &= 1 - \\frac{1}{2} \\frac{\\partial}{\\partial \\alpha_{i}} \\left( \\alpha_{1} \\alpha_{1} y_{1} y_{1} \\boldsymbol{x}_{1}&#94;{\\mathsf{T}} \\boldsymbol{x}_{1} + ... + \\alpha_{i} \\alpha_{1} y_{i} y_{1} \\boldsymbol{x}_{i}&#94;{\\mathsf{T}} \\boldsymbol{x}_{1} + ... + \\alpha_{i} \\alpha_{N} y_{i} y_{N} \\boldsymbol{x}_{i}&#94;{\\mathsf{T}} \\boldsymbol{x}_{N} + ... + \\alpha_{1} \\alpha_{i} y_{1} y_{i} \\boldsymbol{x}_{1}&#94;{\\mathsf{T}} \\boldsymbol{x}_{i} + ... + \\alpha_{N} \\alpha_{i} y_{N} y_{i} \\boldsymbol{x}_{N}&#94;{\\mathsf{T}} \\boldsymbol{x}_{i} + ... + \\alpha_{N} \\alpha_{N} y_{N} y_{N} \\boldsymbol{x}_{N}&#94;{\\mathsf{T}} \\boldsymbol{x}_{N} \\right) \\\\ &= 1 - \\sum_{j=1}&#94;{N} \\alpha_{j} y_{i} y_{j} \\boldsymbol{x}_{i}&#94;{\\mathsf{T}} \\boldsymbol{x}_{j} \\end{aligned} \\end{equation*} よって、ステップ \\(t\\) 時の係数 \\(\\alpha_{i}(t)\\ (i=1,...,N)\\) について以下の更新規則に従って学習を行えば良い： \\begin{equation*} \\alpha_{i}(t+1) = \\alpha_{i}(t) + \\eta \\left( 1 - \\sum_{j=1}&#94;{N} \\alpha_{j} y_{i} y_{j} \\boldsymbol{x}_{i}&#94;{\\mathsf{T}} \\boldsymbol{x}_{j} \\right) \\end{equation*} 実装 学習を行っている箇所を抜粋すると次の様になる： /* 勾配値の計算 */ diff_dist = 0.0f ; for ( i_x = 0 ; i_x < handle -> sample_num ; ++ i_x ) { diff_sum = 0.0f ; for ( i_y = 0 ; i_y < handle -> sample_num ; ++ i_y ) { /* C2を踏まえたカーネル関数値を計算 */ kernel_val = GRAM_MATRIX_AT ( handle -> gram_matrix , handle -> sample_num , i_x , i_y ); if ( i_x == i_y ) { kernel_val += ( 1.0f / soft_margin_C2 ); } diff_sum += handle -> dual_coef [ i_y ] * handle -> sample_label [ i_y ] * kernel_val ; } diff_sum *= handle -> sample_label [ i_x ]; diff_dual_coef [ i_x ] = 1.0f - diff_sum ; diff_dist += ( 1.0f - diff_sum ) * ( 1.0f - diff_sum ); } /* 双対係数の更新 */ for ( i_sample = 0 ; i_sample < handle -> sample_num ; ++ i_sample ) { if ( handle -> sample_label [ i_sample ] == 0 ) { continue ; } /* printf(\"dual_coef[%d]:%f -> \", i_sample, handle->dual_coef[i_sample]); */ handle -> dual_coef [ i_sample ] += handle -> learning_rate * ( diff_dual_coef [ i_sample ] + SMPSVM_MOMENT_RATE * pre_diff_dual_coef [ i_sample ]); /* printf(\"%f \\n\", handle->dual_coef[i_sample]); */ /* 非数,無限チェック */ if ( isnan ( handle -> dual_coef [ i_sample ]) || isinf ( handle -> dual_coef [ i_sample ]) ) { fprintf ( stderr , \"Detected NaN or Inf Dual-Coffience. \\n \" ); return - 3 ; } } 既にコメントが付いているが、特筆すべき点について補足する。 /* C2を踏まえたカーネル関数値を計算 */ kernel_val = GRAM_MATRIX_AT ( handle -> gram_matrix , handle -> sample_num , i_x , i_y ); 予め計算しておいたカーネル関数値をグラム行列から取り出している。学習中は何度もカーネル関数値を計算するため、グラム行列を用意しておくことで若干高速化できる。 if ( i_x == i_y ) { kernel_val += ( 1.0f / soft_margin_C2 ); } 2ノルムソフトマージンのカーネル関数値を加味している。2ノルムソフトマージンを使用しない場合は soft_margin_C2 == FLT_MAX となっているため、無視できる。 handle -> dual_coef [ i_sample ] += handle -> learning_rate * ( diff_dual_coef [ i_sample ] + SMPSVM_MOMENT_RATE * pre_diff_dual_coef [ i_sample ]); 係数更新を行っている。ここでは、単純な最急勾配分のみだけではなく、前回の勾配値に定数を乗じて加えた モーメント法 を使用している。一般にモーメント法を使用したほうが学習が早くなることが知られている。 制約条件の考慮 学習則は単純に見えても実装時に落とし穴になるのが制約条件である。 正例と負例の双対係数の和を等しくする KKT条件から導かれる \\(\\boldsymbol{\\alpha}\\) についての制約 \\begin{equation*} \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i} = 0 \\end{equation*} を実現するのが案外難しい。上の制約から、 \\begin{equation*} \\begin{aligned} &\\sum_{y_{i}=1} \\alpha_{i} - \\sum_{y_{i}=-1} \\alpha_{i} = 0 \\\\ &\\iff \\sum_{y_{i}=1} \\alpha_{i} = \\sum_{y_{i}=-1} \\alpha_{i} \\end{aligned} \\end{equation*} が導かれるため、正例と負例の双対係数の和は等しくなる事が分かる。 本実装では、 \\(\\alpha_{i}y_{i}\\) の平均を取り、全係数 \\(\\alpha_{i}\\ (i=1,...,N)\\) をその平均に寄せることで上記の制約を満たすように係数を修正している。 /* 制約1: 正例と負例の双対係数和を等しくする. */ dual_coef_average = 0.0f ; for ( i_sample = 0 ; i_sample < handle -> sample_num ; ++ i_sample ) { dual_coef_average += ( handle -> sample_label [ i_sample ] * handle -> dual_coef [ i_sample ]); } dual_coef_average /= handle -> sample_num ; for ( i_sample = 0 ; i_sample < handle -> sample_num ; ++ i_sample ) { if ( handle -> sample_label [ i_sample ] == 0 ) { continue ; } handle -> dual_coef [ i_sample ] -= ( dual_coef_average / handle -> sample_label [ i_sample ]); } この制約を満たすための実装はこの限りではない。 双対係数は非負 双対係数は非負でなければならないため、負になった係数は全て0に修正してしまう。 学習が進むに連れて0の係数が増えていくが、それはSVMの持つスパース学習の効果が現れている状態である。学習が収束した時、0に潰れず非負値となった係数に対応するサンプルが サポートベクトル である。 /* 制約2: 双対係数は非負 */ coef_dist = 0.0f ; for ( i_sample = 0 ; i_sample < handle -> sample_num ; ++ i_sample ) { if ( handle -> dual_coef [ i_sample ] < 0.0f ) { handle -> dual_coef [ i_sample ] = 0.0f ; } else if ( handle -> dual_coef [ i_sample ] > soft_margin_C1 ) { /* C1ノルムの制約を適用 */ handle -> dual_coef [ i_sample ] = soft_margin_C1 ; } /* ここで最終結果が出る. 前回との変化を計算 */ coef_diff = pre_dual_coef [ i_sample ] - handle -> dual_coef [ i_sample ]; coef_dist += ( coef_diff * coef_diff ); } 本実装では、非負条件に咥えて1ノルムソフトマージンの制約も追加で判定している。1ノルムソフトマージンを使用しない時は soft_margin_C1 == FLT_MAX となっているため、無視できる。 識別 マージンの定式化 で述べたが、SVMのクラス識別は出力値 \\(y\\) の正負によって判断する [13] 。SVMの出力式 \\begin{equation*} g(\\boldsymbol{x}, \\boldsymbol{w}) = \\boldsymbol{w}&#94;{\\mathsf{T}} \\boldsymbol{x} + b \\end{equation*} に、KKT条件における最適条件 \\(\\boldsymbol{w}&#94;{\\star} = \\sum_{i=1}&#94;{N} \\alpha_{i}y_{i}\\boldsymbol{x}_{i}\\) を代入すれば、次の 双対表現 が得られる： \\begin{equation*} g(\\boldsymbol{x}, \\boldsymbol{w}&#94;{\\star}) = \\sum_{i=1}&#94;{N} \\alpha_{i} y_{i} K(\\boldsymbol{x}_{i}, \\boldsymbol{x}) + b \\end{equation*} 識別の際には、学習済みの係数 \\(\\boldsymbol{\\alpha}\\) を使用して上式を計算し、その正負を判定すれば良い。実装としては次の様になる： /* ネットワーク出力計算 */ network_output = 0.0f ; for ( i_sample = 0 ; i_sample < handle -> sample_num ; ++ i_sample ) { /* 係数が正に相当するサンプル（サポートベクトル） * のみを計算する */ if ( handle -> dual_coef [ i_sample ] > 0.0f ) { network_output += handle -> sample_label [ i_sample ] * handle -> dual_coef [ i_sample ] * handle -> kernel_function ( handle -> sample_data [ i_sample ], normalized_data , data_dim , handle -> kernel_parameter ); } } /* 識別 */ * result = ( network_output >= 0.0f ) ? 1 : - 1 ; 脚注 [1] 高村大也、 奥村学、 \"言語処理のための機械学習入門\"、 コロナ社、 2010 [2] 高橋治久、 堀田一弘、 \"学習理論\" コロナ社、 2009 [3] くどいかもしれないが、 サポートベクトルは最も識別面に近いサンプルなので、この仮定により \\(y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}+b) \\geq l \\quad (i=1, \\dots, N)\\) が成り立つ。 [4] （証明） - 最適化対象について、 \\(\\displaystyle \\frac{1}{2}\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} = \\frac{1}{2} \\sum_{i=1}&#94;{n} w_{i}&#94;{2}\\) より（ \\(\\boldsymbol{w}=[w_{1}\\dots w_{n}]&#94;\\mathsf{T}\\) ）、 明らかに下に凸である。 - 制約条件について、 \\(W_{i} = \\{ \\boldsymbol{w} | y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}\\_{i}+b) \\geq 1 \\}\\) とおくと、 \\(\\forall \\boldsymbol{w}&#94;{\\prime}, \\boldsymbol{w}&#94;{\\prime\\prime} \\in W_{i}, \\forall t \\in [0, 1]\\) に対して、 \\begin{equation*} \\begin{aligned} y_{i} \\left[ \\left( t\\boldsymbol{w}&#94;{\\prime\\mathsf{T}} + (1-t) \\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}} \\right) \\boldsymbol{x}\\_{i} + b \\right] = y_{i} \\left[ t(\\boldsymbol{w}&#94;{\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} - \\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i}) + \\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b \\right] \\\\ = y_{i} \\left[ t\\left( (\\boldsymbol{w}&#94;{\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b) - (\\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b) \\right) + \\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b \\right] \\\\ = t y_{i} (\\boldsymbol{w}&#94;{\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b) + (1-t) y_{i}(\\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b) \\\\ \\geq t + (1-t) = 1\\end{aligned} \\end{equation*} よって、 \\(t\\boldsymbol{w}&#94;{\\prime} + (1-t) \\boldsymbol{w}&#94;{\\prime\\prime} \\in W_{i}\\) より \\(W_{i}\\) は凸集合。 最適化問題においては、 \\(W_{i}\\) の共通部分 \\(\\bigcap_{i=1}&#94;{N} W_{i}\\) を考えれば良く、 凸集合の積集合もまた凸集合 なので、 制約条件も凸集合となる。以上の2点より、 マージン最大化は凸計画問題。 （凸集合の積集合もまた凸集合であることの証明）2つの凸集合を \\(A_{1},A_{2}\\) とする。 両者の集合の積 \\(A_{1}\\cap A_{2}\\) が空集合ならば、 空集合は凸集合と定義されるので命題は成立する。 一般に \\(A_{1}\\cap A_{2}\\) から2点 \\(x,y\\) をとると, \\(x, y\\) を結ぶ線分は、 \\(A_{1}, A_{2}\\) は共に凸集合なので、 \\(A_{1}\\) にも \\(A_{2}\\) にも属していて飛び出ることはない。 これは集合の積 \\(A_{1}\\cap A_{2}\\) が凸集合であることを示している。 [5] （鞍点 \\((\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star})\\) が最適点となる事の証明） \\((\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star})\\) は鞍点なので、 \\begin{equation*} \\begin{aligned} {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}&#94;{\\star}) \\leq {\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star}) \\leq {\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}) \\end{aligned} \\end{equation*} を満たす。 従って右側の不等式から \\(\\boldsymbol{\\alpha}&#94;{\\star\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}&#94;{\\star}) \\leq \\boldsymbol{\\alpha}&#94;{\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}&#94;{\\star})\\) が任意の \\(\\boldsymbol{\\alpha}\\) で成立する。 即ち \\(\\boldsymbol{\\alpha} = \\boldsymbol{0}\\) の時、 \\(g_{i}(\\boldsymbol{v}&#94;{\\star}) \\geq 0\\) と併せて \\(\\boldsymbol{\\alpha}&#94;{\\star\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}&#94;{\\star}) = 0\\) が成立する。 更に、 ここで関係式 \\begin{equation*} \\begin{aligned} {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}&#94;{\\star}) - {\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star}) \\leq \\left( \\frac{\\partial {\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha})}{\\partial \\boldsymbol{v}} \\right)&#94;{\\mathsf{T}} (\\boldsymbol{v} - \\boldsymbol{v}&#94;{\\star}) \\end{aligned} \\end{equation*} を用いる（証明は後術）と、 鞍点であることから \\(\\displaystyle\\frac{\\partial {\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha})}{\\partial \\boldsymbol{v}} = \\boldsymbol{0}\\) であり、 また、 \\(\\boldsymbol{\\alpha}&#94;{\\star\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}&#94;{\\star}) = 0\\) より、 \\begin{equation*} \\begin{aligned} {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}&#94;{\\star}) - {\\cal L}(\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star}) &= {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}&#94;{\\star}) - f(\\boldsymbol{v}&#94;{\\star}) \\leq 0 \\iff f(\\boldsymbol{v}&#94;{\\star}) \\geq {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}&#94;{\\star}) \\end{aligned} \\end{equation*} が成り立つ。 更に、 もとより \\(\\boldsymbol{\\alpha}&#94;{\\star\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}) \\geq 0\\) なので、 \\begin{equation*} \\begin{aligned} f(\\boldsymbol{v}) \\leq f(\\boldsymbol{v}) + \\boldsymbol{\\alpha}&#94;{\\star\\mathsf{T}}\\boldsymbol{g}(\\boldsymbol{v}) = {\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha}&#94;{\\star}) \\end{aligned} \\end{equation*} 従って \\(f(\\boldsymbol{v}&#94;{\\star}) \\geq f(\\boldsymbol{v})\\) が任意の \\(\\boldsymbol{v}\\) で成立し、 \\((\\boldsymbol{v}&#94;{\\star}, \\boldsymbol{\\alpha}&#94;{\\star})\\) が最適点となる事が示された。 次いで(＊)を証明する。 \\({\\cal L}(\\boldsymbol{v}, \\boldsymbol{\\alpha})\\) が凸関数ならば、 \\({\\cal L}(t\\boldsymbol{v}&#94;{\\prime}+(1-t)\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) \\geq t {\\cal L}(\\boldsymbol{v}&#94;{\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) + (1-t) {\\cal L}(\\boldsymbol{v}&#94;{\\prime}, \\boldsymbol{\\alpha}&#94;{\\star})\\) が \\(t \\in [0,1]\\) で成立する。 よって、 \\begin{equation*} t{\\cal L}(\\boldsymbol{v}&#94;{\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) \\leq t{\\cal L}(\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) - {\\cal L}(\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) + {\\cal L}(t\\boldsymbol{v}&#94;{\\prime}+(1-t)\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) \\iff {\\cal L}(\\boldsymbol{v}&#94;{\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) \\leq {\\cal L}(\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) + \\frac{{\\cal L}(\\boldsymbol{v}&#94;{\\prime\\prime} + t(\\boldsymbol{v}&#94;{\\prime}-\\boldsymbol{v}&#94;{\\prime\\prime}), \\boldsymbol{\\alpha}&#94;{\\star}) - {\\cal L}(\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star})}{t} \\end{equation*} ここで \\(t \\to 0\\) ならしめれば、 方向微分と勾配の関係式より、 \\begin{equation*} {\\cal L}(\\boldsymbol{v}&#94;{\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) - {\\cal L}(\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star}) \\leq \\left( \\frac{\\partial {\\cal L}(\\boldsymbol{v}&#94;{\\prime\\prime}, \\boldsymbol{\\alpha}&#94;{\\star})}{\\partial \\boldsymbol{v}} \\right)&#94;{\\mathsf{T}} (\\boldsymbol{v}&#94;{\\prime} - \\boldsymbol{v}&#94;{\\prime\\prime}) \\end{equation*} を得る。 [6] 互いに同一平面上 以外 の位置にある事。 例えば、2次元空間では同一直線上以外の位置であり、3次元空間では同一平面上以外の位置である。異なるクラスのサンプルが一般位置にあれば、もとより線形分離可能である。 [7] 有限個数 \\(N<\\infty\\) のサンプルに対し、 \\((\\boldsymbol{G})\\_{ij} = K(\\boldsymbol{x}\\_{i}, \\boldsymbol{x}\\_{j})\\) 、即ち \\((i,j)\\) 成分の値が \\(K(\\boldsymbol{x}\\_{i}, \\boldsymbol{x}\\_{j})\\) となっている行列 \\(\\boldsymbol{G}\\) をグラム（カーネル）行列という。特徴写像が有限次元ならば、グラム行列が（有限）正定値行列ならば \\(K\\) はカーネル関数となる。特徴写像が無限次元の場合のカーネル関数の条件がマーサーの定理である。 その内容は、入力空間 \\(X\\subset \\mathbb{R}&#94;{n}\\) が有界閉集合（ \\(\\iff\\) コンパクト）であるとし、対象な連続関数 \\(K\\) が正定値、即ち任意の二乗可積分（二乗積分可能）な関数 \\(f\\) に対し \\begin{equation*} \\begin{aligned} \\int_{X\\times X}K(x, z)f(x)f(z)dxdz \\geq 0\\end{aligned} \\end{equation*} ならば、ヒルベルト空間の正規直交基底 \\(\\phi_{j}\\ (j=1, 2, \\dots)\\) で次式が一様収束するものが存在する場合、 \\(K\\) はカーネル関数である。 \\begin{equation*} \\begin{aligned} K(x, z) = \\sum_{j=1}&#94;{\\infty} \\phi_{j}(x)\\phi_{j}(z) \\end{aligned} \\end{equation*} [8] サンプルに現れない未知のデータでももれなく識別できる能力 [9] 双対問題において、 \\(C_{1}, C_{2} \\to \\infty\\) とすると、ハードマージンSVMに一致することが分かる [10] サンプルに最も当てはまる曲線（面）を探す問題。もう少し形式的に言うと、各サンプル \\(\\boldsymbol{x}\\_{i}\\) でのラベル \\(y_{i}\\) の平均値を表す関数 \\(f\\) を学習する問題。 [11] （証明） - 最適化対象について、 \\(\\displaystyle \\frac{1}{2}\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{w} = \\frac{1}{2} \\sum_{i=1}&#94;{n} w_{i}&#94;{2}\\) より（ \\(\\boldsymbol{w}=[w_{1}\\dots w_{n}]&#94;\\mathsf{T}\\) ）、 明らかに下に凸である。 - 制約条件について、 \\(W_{i} = \\{ \\boldsymbol{w} | y_{i}(\\boldsymbol{w}&#94;{\\mathsf{T}}\\boldsymbol{x}\\_{i}+b) \\geq 1 \\}\\) とおくと、 \\(\\forall \\boldsymbol{w}&#94;{\\prime}, \\boldsymbol{w}&#94;{\\prime\\prime} \\in W_{i}, \\forall t \\in [0, 1]\\) に対して、 \\begin{equation*} \\begin{aligned} y_{i} \\left[ \\left( t\\boldsymbol{w}&#94;{\\prime\\mathsf{T}} + (1-t) \\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}} \\right) \\boldsymbol{x}\\_{i} + b \\right] = y_{i} \\left[ t(\\boldsymbol{w}&#94;{\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} - \\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i}) + \\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b \\right] \\\\ = y_{i} \\left[ t\\left( (\\boldsymbol{w}&#94;{\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b) - (\\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b) \\right) + \\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b \\right] \\\\ = t y_{i} (\\boldsymbol{w}&#94;{\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b) + (1-t) y_{i}(\\boldsymbol{w}&#94;{\\prime\\prime\\mathsf{T}}\\boldsymbol{x}\\_{i} + b) \\\\ \\geq t + (1-t) = 1\\end{aligned} \\end{equation*} よって、 \\(t\\boldsymbol{w}&#94;{\\prime} + (1-t) \\boldsymbol{w}&#94;{\\prime\\prime} \\in W_{i}\\) より \\(W_{i}\\) は凸集合。 最適化問題においては、 \\(W_{i}\\) の共通部分 \\(\\bigcap_{i=1}&#94;{N} W_{i}\\) を考えれば良く、 凸集合の積集合もまた凸集合 なので、 制約条件も凸集合となる。以上の2点より、 マージン最大化は凸計画問題。 （凸集合の積集合もまた凸集合であることの証明）2つの凸集合を \\(A_{1},A_{2}\\) とする。 両者の集合の積 \\(A_{1}\\cap A_{2}\\) が空集合ならば、 空集合は凸集合と定義されるので命題は成立する。 一般に \\(A_{1}\\cap A_{2}\\) から2点 \\(x,y\\) をとると, \\(x, y\\) を結ぶ線分は、 \\(A_{1}, A_{2}\\) は共に凸集合なので、 \\(A_{1}\\) にも \\(A_{2}\\) にも属していて飛び出ることはない。 これは集合の積 \\(A_{1}\\cap A_{2}\\) が凸集合であることを示している。 [12] ただし学習率 \\(\\eta\\) の決め方は問題依存である。一般に、 \\(\\eta\\) が小さすぎると学習が進行せず、大きすぎると極値を飛び越えてしまい学習が収束しない。 [13] \\(y = 0\\) の場合の判断を明確にしている書類がない。ここでは正と判定する。","tags":"記事","url":"/svmsapotobekutorumashin.html","loc":"/svmsapotobekutorumashin.html"},{"title":"MCMC（マルコフ連鎖モンテカルロ）法","text":"本稿ではMCMC法の解説のため、MC法による積分の計算方法（モンテカルロ積分）から、MCMCによる手法の概要を見ていく。MCMC法は有名かつ知り尽くされた手法で、多くの良質な説明資料 [1] , [2] , [3] , [4] , [5] が存在している。従ってここの説明は読まずに、資料を見てもらった方が理解が早いかもしれない。 一般に MC（Monte-Calro, モンテカルロ）法 は、サンプリング（サンプルを乱数から生成すること）によってシミュレーションや数値計算を行う手法である。特に確率分布が関わる積分値 [6] を近似的に求めるMC法はモンテカルロ積分と呼ばれる。モンテカルロ積分は確率的な推論の一種であり、大数の法則 [7] によって、十分なサンプル数をとれば近似精度をいくらでも良くする事ができる。サンプリングの手間がある為、近似分布をあらかじめ仮定する様な決定論的な推論よりも遥かに推論が遅い。しかし、MCは近似分布が求められないような場合にも適用可能であり、汎用性が高いと言える。 MC法によって原理的には任意の解を求められるが、十分なサンプル数の要求というのが大きな問題を孕んでいる。サンプリングの自由度（範囲及び次元）が大きくなると、解の計算にあまり寄与しない（無駄な）サンプルが増えてしまう。計算を現実的かつ効率的に行うためには、サンプルの選択が重要になる。 そして MCMC（Markov Chain Monte-Calro, マルコフ連鎖モンテカルロ）法 は、新しいサンプルを以前に生成したサンプルに確率的に依存して（サンプルの列がマルコフ連鎖となる様に）生成するMC法である。MCMCでは、新しく生成したサンプルを採択（採用）するか棄却（捨てる）するかも確率的に判断する。この手続きによって、無駄なサンプルを極力減らすようにサンプリングを実行することができる。 MC法による積分 - モンテカルロ積分 重点サンプリング MCMC 遷移確率の条件 - 詳細釣り合い条件 メトロポリス-ヘイスティングス法 ギブスサンプリング MCMCによる最適化 焼きなまし法 補足 エルゴード的なマルコフ連鎖の定常分布 詳細釣り合い条件の証明 脚注 MC法による積分 - モンテカルロ積分 確率変数を \\(d\\) 次元の実数値ベクトル [8] \\(\\boldsymbol{x} = [x_{1},\\dots,x_{d}]&#94;{\\mathsf{T}} \\in X \\subset \\mathbb{R}&#94;{d}\\) とする。ここで \\(X\\) は全事象 [9] の集合である。 \\(\\boldsymbol{x}\\) の確率分布を \\(r(\\boldsymbol{x})\\) とし、関数 \\(h\\) の確率分布 \\(r\\) による平均（期待値） \\begin{equation*} I = \\int_{X} h(\\boldsymbol{x})r(\\boldsymbol{x}) d\\boldsymbol{x} = \\mathrm{E}_{r}[h(\\boldsymbol{x})] \\tag{1} \\end{equation*} を求めることを考える。ここで、 \\(\\mathrm{E}_{p}[\\cdot]\\) は確率分布 \\(p\\) による平均を表す。 \\(I\\) において、関数 \\(h\\) の形に制約を与えておらず積分として様々な値が計算できる。例を挙げると: \\(h(\\boldsymbol{x}) = \\boldsymbol{x}\\) : この場合は \\(\\mathrm{E}_{r}[\\boldsymbol{x}]\\) 、即ち \\(\\boldsymbol{x}\\) の平均を求める \\(h(\\boldsymbol{x}) = (\\boldsymbol{x} - \\mathrm{E_{r}}[\\boldsymbol{x}])(\\boldsymbol{x} - \\mathrm{E_{r}}[\\boldsymbol{x}])&#94;{\\mathsf{T}}\\) : \\(\\boldsymbol{x}\\) の分散を求める … その他 [10] もし \\(r(\\boldsymbol{x})\\) が既知で、分布 \\(r\\) から簡単に独立にサンプリングできる [11] ならば、 \\(r(\\boldsymbol{x})\\) からの独立な（他のサンプルに依存して生成しない） \\(n\\) 個のサンプルを \\(\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, \\dots, \\boldsymbol{x}_{n}\\) と書くと、 \\(I\\) の標本平均による近似値 \\(\\hat{I}\\) は \\begin{equation*} \\hat{I} = \\frac{1}{n} \\sum_{i=1}&#94;{n} h(\\boldsymbol{x}_{i}) \\tag{2} \\end{equation*} で計算できる。大数の法則により、サンプル数の極限を取れば標本平均は真の平均に一致する: \\begin{equation*} \\lim_{n \\to \\infty} \\hat{I} = I \\end{equation*} この様にして平均を求める方法を モンテカルロ積分(Monte-Carlo Integration) という。一般にモンテカルロ法(Monte-Carlo Method)はサンプリングによってシミュレーションや数値計算を行う事を指す。 重点サンプリング モンテカルロ積分によって、原理的には \\(\\hat{I}\\) を多くのサンプルで計算する事で \\(I\\) を精度良く計算できる。しかし実際確率分布 \\(r(\\boldsymbol{x})\\) は複雑であることが多く、その場合 \\(r(\\boldsymbol{x})\\) から直接サンプリングするのは困難となる。そこで、より簡単でサンプリング可能な確率分布（ 提案分布 という） \\(q(\\boldsymbol{x})\\) を用意して、そこからサンプリングする事を考える。 \\(q(\\boldsymbol{x})\\) を使えば、 \\(I\\) は次の様に変形できる: \\begin{equation*} I = \\int_{X} h(\\boldsymbol{x})\\frac{r(\\boldsymbol{x})}{q(\\boldsymbol{x})} q(\\boldsymbol{x}) d\\boldsymbol{x} = \\mathrm{E}_{q}\\left[ h(\\boldsymbol{x})\\frac{r(\\boldsymbol{x})}{q(\\boldsymbol{x})} \\right] \\end{equation*} モンテカルロ積分の時と同じ様にに考え、次は \\(\\boldsymbol{x}_{1},\\dots,\\boldsymbol{x}_{n}\\) を \\(q(\\boldsymbol{x})\\) からの独立な \\(n\\) 個のサンプルにすれば、 \\(I\\) の近似値 \\(\\hat{I}_{IS}\\) として \\begin{equation*} \\hat{I}_{IS} = \\frac{1}{n} \\sum_{i=1}&#94;{n} h(\\boldsymbol{x}_{i}) \\frac{r(\\boldsymbol{x}_{i})}{q(\\boldsymbol{x}_{i})} = \\frac{1}{n} \\sum_{i=1}&#94;{n} h(\\boldsymbol{x}_{i}) w(\\boldsymbol{x}_{i}) \\tag{3} \\end{equation*} が得られる。ここで \\(w(\\boldsymbol{x}_{i}) = r(\\boldsymbol{x}_{i})/q(\\boldsymbol{x}_{i})\\) はサンプル \\(\\boldsymbol{x}_{i}\\) に対する重みと見ることができる。この様に、重みが付いたサンプルで平均を求める手法を 重点サンプリング(Importance Sampling) という。重点サンプリングにおいても、 \\(q(\\boldsymbol{x})\\) がある条件を満たしていれば、大数の法則によって \\(\\displaystyle\\lim_{n \\to \\infty} \\hat{I}_{IS} = I\\) となることが保証されている。 MCMC 重点サンプリングの考え方によって、確率分布 \\(r\\) が複雑でも替わりに提案分布 \\(q\\) を用いてサンプリングを行えばモンテカルロ積分が計算できる事が確かめられた。しかし、\" \\(r\\) より簡単でサンプリング可能な \\(q\\) \" を構成する事自体が一般に困難である。特に次元 \\(d\\) が増加すれば \\(r\\) が複雑になるのはもちろん、全事象 \\(X\\) の自由度が増加し次元の呪い [12] を引き起こす。即ち、 \\(r\\) を \\(q\\) で良く近似出来てない時に毎回独立にサンプリングを行っていると、空間 \\(X\\) から当てずっぽうなサンプルを取得しているのと同様な状態になる。 そこで、簡単な提案分布 \\(q\\) を用いて、かつ逐次的に以前のサンプルを使用して新しくサンプルを生成する手法が90年代以降使われる様になってきた。この場合、サンプル列はマルコフ連鎖(Markov Chain)をなす。そして、マルコフ連鎖で生成したサンプルによるMC法をMCMC（Markov Chain Monte-Calro）法という。サンプル間の独立性は担保されなくなる為にMC法の基本原理が成立しなくなるが、提案分布（マルコフ連鎖の遷移確率）がある性質を満たせば、十分なサンプル数で確率分布 \\(r\\) からのサンプリングが実現できる。 遷移確率の条件 - 詳細釣り合い条件 概要でも既に述べたが、MCMCは生成したサンプル列がマルコフ連鎖をなすように生成する。今、サンプル列 \\(\\boldsymbol{x}_{0}, \\boldsymbol{x}_{1}, \\dots\\) はマルコフ連鎖をなすので、生成した時刻（ステップ）で実際に観測した状態を \\(\\boldsymbol{e}_{0}, \\boldsymbol{e}_{1}, \\dots \\ (\\boldsymbol{e}_{i} \\in X \\ i=0,1,\\dots)\\) と書くと、任意の時刻 \\(n \\geq 0\\) で、 \\begin{equation*} P(\\boldsymbol{x}_{n+1} = \\boldsymbol{e}_{n+1}|\\boldsymbol{x}_{0} = \\boldsymbol{e}_{0}, \\boldsymbol{x}_{1} = \\boldsymbol{e}_{1}, \\dots, \\boldsymbol{x}_{n} = \\boldsymbol{e}_{n}) = P(\\boldsymbol{x}_{n+1} = \\boldsymbol{e}_{n+1}|\\boldsymbol{x}_{n} = \\boldsymbol{e}_{n}) \\end{equation*} が成り立つ（この性質をマルコフ性 [13] という）。即ち、サンプルは直前のサンプルのみに依存して生成する。この様にサンプルを生成する場合、実はマルコフ連鎖が エルゴード的(ergodic) という性質を満たせば、大量のサンプルを用いた時にある分布（ 定常分布 ） \\(\\pi\\) からサンプリングしているのと同様になる。 マルコフ連鎖がエルゴード的であるとは、規約性（どの状態からでも任意の状態へ遷移できる）と正再帰性（任意の状態へ何回でも遷移できる）非周期性（任意の状態は一回の遷移で元に戻れる）を全て同時に満たすことを言う [14] 。 エルゴード的なマルコフ連鎖と定常分布 \\(\\pi\\) の関係は、次の定理で表せる: マルコフ連鎖の収束 マルコフ連鎖 \\(\\boldsymbol{x}_{0}, \\boldsymbol{x}_{1}, \\dots\\) がエルゴード的であり、その遷移確率行列を \\(\\boldsymbol{P}\\) とおく。 \\(\\pi\\) を \\(\\boldsymbol{P}\\) の定常（不変）分布とした時、任意の初期状態から始まるマルコフ連鎖はサンプル数の極限において定常分布 \\(\\pi\\) に収束する。 ここで遷移確率行列 \\(\\boldsymbol{P}\\) とは、その \\((i,j)\\) 要素 \\((\\boldsymbol{P})\\_{ij} = p_{ij}\\ (i,j \\in X)\\) が任意の時刻 \\(t \\geq 0\\) で \\begin{equation*} (\\boldsymbol{P})_{ij} = p_{ij} = P(\\boldsymbol{x}_{t+1}=j|\\boldsymbol{x}_{t}=i) \\end{equation*} を満たすような行列である [15] 。 また、定常分布とは時刻が経過しようとも不変なマルコフ連鎖（一般に確率過程）の各状態の確率分布である [16] 。即ち、十分に長いマルコフ連鎖を観測すれば、どの状態にいる傾向があるのかを定常分布によって知ることができる。 上記の議論により、マルコフ連鎖がエルゴード的であればサンプリングが定常分布に従う事は分かったが、次は遷移確率の設計が問題となる。遷移確率を規約性と正再帰性と非周期性とを満たすように設定するのは案外容易 [17] であるが、それだけでは定常分布の存在のみを保証するので、その定常分布が希望する分布に一致するとは限らない。次に問題となるのは、希望の確率分布 \\(r\\) を定常分布とするように遷移確率を設計することである。その問題は次の 詳細釣り合い条件(detailed balance condition) という条件によって解決できる。 詳細釣り合い条件 希望する確率分布 \\(r\\) と遷移確率 \\(p\\) が次の条件を満たす時、そのマルコフ連鎖の定常分布 \\(\\pi\\) は \\(r\\) に一致する: \\begin{equation*} r_{i} p_{ij} = r_{j} p_{ji} \\end{equation*} ここで \\(r_{i} = r(\\boldsymbol{x} = i)\\) である（証明は 補足 に示した）。 詳細釣り合い条件を満たす遷移確率を用いさえすれば、十分大きな \\(m>0\\) を取った時に、マルコフ連鎖 \\(\\boldsymbol{x}_{m}, \\boldsymbol{x_{m+1}},\\dots\\) は \\(r\\) からのサンプルとなる。 次の節で紹介するアルゴリズムの遷移確率は、いずれも詳細釣り合い条件を満たすように設計されている。 メトロポリス-ヘイスティングス法 メトロポリス-ヘイスティングス法は、サンプルは重点サンプリングの時と同じように提案分布によって生成し、そして新しく生成したサンプルを 採択 （採用）するか、もしくは 棄却 （捨てる）のかを 採択確率(acceptance rate) と呼ばれる確率によって決め、採択された場合は新しい状態に遷移し、棄却された場合には遷移は行わずに（状態を変えずに）もう一度サンプリングし直す、という手続きを繰り返す手法である。 メトロポリス-ヘイスティングス法の更新規則を導出してみる。 まず、状態 \\(i \\in X\\) から状態 \\(j \\in X\\) に遷移する時の提案分布を条件付き確率 \\(q(\\boldsymbol{x}_{n+1}=j|\\boldsymbol{x}_{n}=i) = q_{ij}\\) と書き、また状態 \\(i\\) にいる時に状態 \\(j\\) を採択する確率（採択確率）を \\(\\alpha(i \\to j)\\) と表す。すると、 \\(i\\) から \\(j\\) への遷移確率 \\(p_{ij}\\) は \\(q_{ij}\\) と \\(\\alpha(i \\to j)\\) の積で表せる: \\begin{equation*} p_{ij} = q_{ij} \\alpha(i \\to j) \\tag{4} \\end{equation*} そして、詳細釣り合い条件から、 \\begin{align*} \\frac{p_{ij}}{p_{ji}} = \\frac{r_{j}}{r_{i}} &\\iff \\frac{q_{ij}\\alpha(i \\to j)}{q_{ji}\\alpha(j \\to i)} = \\frac{r_{j}}{r_{i}} \\\\ &\\iff \\frac{\\alpha(i \\to j)}{\\alpha(j \\to i)} = \\frac{r_{j}q_{ji}}{r_{i}q_{ij}} \\end{align*} となる。採択確率はこの条件を満たす様に設計する。メトロポリス-ヘイスティングス法では特に、 \\begin{equation*} \\alpha(i \\to j) = \\min \\left( 1, \\frac{r_{j}q_{ji}}{r_{i}q_{ij}} \\right) \\tag{5} \\end{equation*} とする [18] 。アルゴリズムの実行中には、この式によって採択確率を計算し、 \\([0,1]\\) の範囲の一様乱数を発生させて採択/棄却を判断する。 これでメトロポリス-ヘイスティングス法が実行できるが、その利点を2つ挙げる: \\(r\\) が厳密計算出来なくても良い \\(r\\) は一般に複雑なので直接的な計算は難しいが、上の採択確率の式は確率の比率のみに注目している。従って分布が厳密に計算できなくてもアルゴリズムを実行できる。比率さえ一致すれば良いので、分布 \\(r\\) の近似分布 \\(\\hat{r}\\) として \\begin{equation*} \\hat{r} = \\frac{1}{Z_{r}} r \\end{equation*} としても良い事になる( \\(Z_{r}\\) :正規化定数)。特に、近似分布をボルツマン-ギブス分布 \\begin{equation*} \\hat{r}(\\boldsymbol{x}) = \\frac{1}{Z_{r}} \\exp(-r(\\boldsymbol{x})/T) \\end{equation*} とする場合が多い。ここで、 \\(T>0\\) は温度パラメタ [19] である。 \\(q_{ij} = q_{ji}\\) が成り立つ場合には、より簡単にサンプリングできる \\(q_{ij} = q_{ji}\\) が成立する提案分布で有名なものに 酔歩連鎖(random walk chain) がある: \\begin{equation*} q_{ij} = {\\cal N}(i, \\sigma&#94;{2}\\boldsymbol{I}) \\end{equation*} 即ち平均（中心）を現在状態 \\(i\\) 、分散を \\(\\sigma\\) [20] とした正規分布からの乱択でサンプリングを行う [21] 。 正規分布以外でも、 \\(i\\) を平均とした一様分布、多変量 \\(t\\) 分布でも実行できる。 ギブスサンプリング ギブスサンプリング(Gibbs Sampling, 熱浴法とも)は提案分布の変数を1個ずつ更新していく手法である。 主に多次元確率分布 [22] の推定に用いられる事が多い。説明のため、現在の状態を組 \\(\\boldsymbol{x} = (x_{1}, x_{2}, \\dots, x_{d})\\) と書く。状態の更新の際には、変数を1つ選び出し [23] て \\(x_{i} \\to x_{i}&#94;{\\prime}\\) と遷移させる( \\(i=1,\\dots,d\\) )。更新後の状態を \\(\\boldsymbol{x}&#94;{\\prime} = (x_{1}, \\dots, x_{i-1}, x_{i}&#94;{\\prime}, x_{i+1}, \\dots, x_{d})\\) と書く。ここで、遷移確率 \\(q(\\boldsymbol{x}&#94;{\\prime}|\\boldsymbol{x})\\) は次で定義される: \\begin{align*} q(\\boldsymbol{x}&#94;{\\prime}|\\boldsymbol{x}) &= \\frac{r(\\boldsymbol{x}&#94;{\\prime})}{\\sum_{x_{i}} r(\\boldsymbol{x})} \\\\ &= r(x&#94;{\\prime}_{i}|x_{1},\\dots,x_{i-1},x_{i+1},\\dots,x_{d}) \\quad (\\because ベイズの定理) \\end{align*} 即ち、選択した変数 \\(x_{i}\\) 以外を全て``固定''した確率分布 \\(r\\) から \\(x_{i}&#94;{\\prime}\\) を新しくサンプリングする。上記右辺が計算できる場合にのみ、ギブスサンプリングは適用可能となる。 この更新規則が詳細釣り合い条件を満たすことは、再びベイズの定理を用いて、 \\begin{align*} r(\\boldsymbol{x})q(\\boldsymbol{x}&#94;{\\prime}|\\boldsymbol{x}) &= r(\\boldsymbol{x}) r(x&#94;{\\prime}_{i}|x_{1},\\dots,x_{i-1},x_{i+1},\\dots,x_{d}) \\\\ &= r(\\boldsymbol{x})\\frac{r(\\boldsymbol{x}&#94;{\\prime})}{\\sum_{{x}_{i}}r(\\boldsymbol{x})} = r(\\boldsymbol{x}&#94;{\\prime}) \\frac{r(\\boldsymbol{x})}{\\sum_{x_{i}&#94;{\\prime}}r(\\boldsymbol{x}&#94;{\\prime})} \\\\ &= r(\\boldsymbol{x}&#94;{\\prime}) q(\\boldsymbol{x}|\\boldsymbol{x}&#94;{\\prime}) \\end{align*} により確認できる。また、メトロポリス-ヘイスティングス法の採択確率の式から、 \\begin{align*} \\alpha(\\boldsymbol{x} \\to \\boldsymbol{x}&#94;{\\prime}) &= \\min \\left(1, \\frac{r(\\boldsymbol{x}&#94;{\\prime})q(\\boldsymbol{x}|\\boldsymbol{x}&#94;{\\prime})}{r(\\boldsymbol{x})q(\\boldsymbol{x}&#94;{\\prime}|\\boldsymbol{x})} \\right) \\\\ &= \\min (1, 1) = 1 \\end{align*} となり、ギブスサンプリングはメトロポリス-ヘイスティングス法で採択確率を \\(1\\) （必ず採択）するようにした特別の場合である事が分かる。採択/棄却の手順を踏まくくても良く、しかも遷移確率 \\(q\\) は予め計算できるので、高速な推定ができるようになっている。 MCMCによる最適化 MCMCは関数最適化に用いることもできる。今、サンプリングを行う確率分布をボルツマン-ギブス分布 \\begin{equation*} r(\\boldsymbol{x}) = \\frac{1}{Z_{r}} \\exp(-f(\\boldsymbol{x})/T) \\end{equation*} とした時、定義式により、 \\(f(\\boldsymbol{x})\\) が小さな値を与える点ではその確率 \\(r(\\boldsymbol{x})\\) は同時に大きくことが即座に観察できる。従って、MCMCによって \\(r(\\boldsymbol{x})\\) からのサンプリングを行えば、 \\(f(\\boldsymbol{x})\\) が小さな値をとる点を集中してサンプリングできる事から、 \\(f(\\boldsymbol{x})\\) の最小化（最大化の場合は \\(-f(\\boldsymbol{x})\\) の最小化に置き換えれば良い）を考える事ができる。実際、関数 \\(f\\) の最小値を与える点を \\(\\boldsymbol{x}&#94;{\\ast}\\) と表せば、サンプル数 \\(N\\) の極限において最小値 \\(f(\\boldsymbol{x}&#94;{\\ast})\\) が確率1で得られる事: \\begin{equation*} \\lim_{N \\to \\infty} P(\\min(f(\\boldsymbol{x}_{1}), f(\\boldsymbol{x}_{2}), \\dots, f(\\boldsymbol{x}_{N})) = f(\\boldsymbol{x}&#94;{\\ast})) = 1 \\end{equation*} が示せる。以下、その証明を示す。 （証明） MCMCにおいて、定常分布を \\(r\\) とする様に（詳細釣り合い条件を満たす様に）サンプリングを行う。この時マルコフ連鎖 \\(\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, \\dots, \\boldsymbol{x}_{n},\\dots\\) は、十分大きな \\(n > 1\\) においては \\(r(\\boldsymbol{x})\\) からのサンプルとみなせる。関数 \\(f\\) に最小値 \\(f(\\boldsymbol{x}&#94;{\\ast})\\) が存在すれば、 \\(\\boldsymbol{x}&#94;{\\ast}\\) をサンプリングする確率 \\(r(\\boldsymbol{x}&#94;{\\ast})\\) も存在が保証され、分布の中で最大の確率を与えている。従って、 \\(n\\) 回目以降のマルコフ連鎖 \\(\\boldsymbol{x}_{n}, \\boldsymbol{x}_{n+1},\\dots\\) において、 \\(m \\geq n\\) 回目に初めて \\(\\boldsymbol{x}&#94;{\\ast}\\) がサンプリングできる確率 \\(P(\\boldsymbol{x}_{m} = \\boldsymbol{x}&#94;{\\ast})\\) は、幾何分布と同じ様に、 \\begin{equation*} P(\\boldsymbol{x}_{m} = \\boldsymbol{x}&#94;{\\ast}) = r(\\boldsymbol{x})\\left\\{ 1-r(\\boldsymbol{x}&#94;{\\ast}) \\right\\}&#94;{m-n} \\end{equation*} によって計算できる。また、初めて \\(\\boldsymbol{x&#94;{\\ast}}\\) がサンプリングできるまでの回数が \\(N \\geq n\\) 回以内となる確率は、 \\begin{align*} P(\\boldsymbol{x}_{n} = \\boldsymbol{x}&#94;{\\ast}) + P(\\boldsymbol{x}_{n+1} = \\boldsymbol{x}&#94;{\\ast}) + \\dots + P(\\boldsymbol{x}_{N} = \\boldsymbol{x}&#94;{\\ast}) &= \\sum_{m=n}&#94;{N} P(\\boldsymbol{x}_{N} = \\boldsymbol{x}&#94;{\\ast}) \\\\ &= \\sum_{k=0}&#94;{N-n} r(\\boldsymbol{x}&#94;{\\ast})\\left\\{ 1-r(\\boldsymbol{x}&#94;{\\ast}) \\right\\}&#94;{k} \\end{align*} となる。 ここでサンプル数の極限 \\(N \\to \\infty\\) をとると、初項 \\(r(\\boldsymbol{x}&#94;{\\ast})\\) 、項比 \\(1-r(\\boldsymbol{x}&#94;{\\ast})\\) とした等比級数の和の公式より、 \\begin{equation*} \\lim_{N \\to \\infty} \\sum_{k=0}&#94;{N-n} r(\\boldsymbol{x}&#94;{\\ast})\\left\\{ 1-r(\\boldsymbol{x}&#94;{\\ast}) \\right\\}&#94;{k} = \\frac{r(\\boldsymbol{x}&#94;{\\ast})}{1-\\left\\{1-r(\\boldsymbol{x}&#94;{\\ast})\\right\\}} = 1 \\end{equation*} が得られる。即ち、サンプリングを無限に繰り返せば \\(\\boldsymbol{x}&#94;{\\ast}\\) が確率1で得られることが示された。この結果は、サンプルの関数列 \\(f(\\boldsymbol{x}_{1}), f(\\boldsymbol{x}_{2}), \\dots\\) の中に少なくとも1つ \\(f(\\boldsymbol{x}&#94;{\\ast})\\) が存在する事と同値である。 焼きなまし法 以上でMCMCによる最適化が理論的に可能なことが示されたが、最適化の際に特に問題となるのは分布 \\(r\\) の温度パラメタ \\(T\\) である。 \\(T\\) が大きければ、 \\(\\exp\\) 内部の \\(f(\\boldsymbol{x})\\) の値に影響されず \\(r(\\boldsymbol{x})\\) は一様分布に近くなり、一様乱数からのサンプリングと殆ど変わらなくなる。逆に \\(T\\) が \\(0\\) に近いと \\(r(\\boldsymbol{x})\\) は \\(f(\\boldsymbol{x})\\) の値に大きく影響されるが、サンプリングが特定の場所だけに集中してしまって局所最適値しか得られない場合がある。この様に \\(T\\) は適切に決定する必要があるが、 \\(T\\) の適切な決定法は存在せず、問題依存となる場合が多い。 そこで、最初は \\(T\\) （温度）を高い状態から初めてサンプリングの度に少しずつ \\(T\\) を下げていくやり方があり、これを焼きなまし法（Simulated Annealing, SA）と呼ぶ。この様に \\(T\\) を変化させると最初は空間全体の中から大雑把な \\(f\\) の値を取得し、後に最適値の近傍を集中してサンプリングすることができるために効率的な探索が期待できる。証明は省くが、温度パラメタの系列 \\(T_{1}, T_{2}, \\dots\\) が次の条件を満たせばサンプリングによって \\(\\boldsymbol{x}&#94;{\\ast}\\) が得られる事（収束定理）が示されている: \\begin{equation*} \\sum_{n=1}&#94;{\\infty} \\exp(-D/T_{n}) = \\infty \\end{equation*} ここで、 \\(D\\) は問題によって決まる定数である。 補足 エルゴード的なマルコフ連鎖の定常分布 上記の議論で、「マルコフ連鎖がエルゴード的ならば、一意な定常分布が存在する」という事に触れた。この定理についての証明を述べていくが、準備として確率過程についての用語や記法の定義、基本的な定理の証明を行う。大方の証明は ここ を参照した。なお、状態空間（全事象） \\(X\\) は有限集合であるとする。 離散時間マルコフ連鎖 確率過程（サンプル列） \\(\\boldsymbol{x}_{0}, \\boldsymbol{x}_{1}, \\dots\\) が次を満たす時、離散時間マルコフ連鎖という。 \\begin{equation*} \\forall n \\geq 0, \\forall i_{0}, \\dots, i_{n+1} \\in X.\\ P(\\boldsymbol{x}_{n+1} = i_{n+1} |\\boldsymbol{x}_{0} = i_{0}, \\boldsymbol{x}_{1} = i_{1}, \\dots, \\boldsymbol{x}_{n} = i_{n}) = P(\\boldsymbol{x}_{n+1}=i_{n+1}|\\boldsymbol{x}_{n}=i_{n}) \\end{equation*} またこの性質をマルコフ性という。 遷移確率の斉時性、nステップ遷移確率 任意の状態 \\(i,j \\in X\\) と非負整数 \\(n \\geq 0\\) に対して \\begin{equation*} p_{ij}(n) = P(\\boldsymbol{x}_{n+1}=j|\\boldsymbol{x}_{n}=i) \\end{equation*} を、状態 \\(i\\) から状態 \\(j\\) への遷移確率という。 \\(p_{ij}(n)\\) が \\(n\\) と独立で常に \\(p_{ij}(n) = p_{ij}(0) = p_{ij}\\) となる時、離散時間マルコフ連鎖は斉時であるという。今後、遷移確率は \\(p_{ij}\\) を用いて表す。また、 \\begin{equation*} p_{ij}&#94;{(n)} = P(\\boldsymbol{x}_{n}=j|\\boldsymbol{x}_{0}=i) \\end{equation*} は状態 \\(i\\) から始まって \\(n\\) ステップ後に状態が \\(j\\) になる確率を表しており、 \\(n\\) ステップ遷移確率と呼ぶ。 チャップマン−コルモゴロフ方程式 任意の状態 \\(i,j \\in X\\) に対し、 \\(n\\) ステップ遷移確率 \\(p_{ij}&#94;{(n)}\\) は次を満たす: \\begin{equation*} p_{ij}&#94;{(n)} = \\sum_{r \\in X} p_{ir}&#94;{(k)}p_{rj}&#94;{(n-k)} \\quad 0 \\leq k \\leq n \\end{equation*} （証明） \\begin{align*} p_{ij}&#94;{(n)} &= P(\\boldsymbol{x}_{n}=j|\\boldsymbol{x}_{0}=i) = \\sum_{r \\in X} P(\\boldsymbol{x}_{n}=j, \\boldsymbol{x}_{k}=r|\\boldsymbol{x}_{0}=i) \\quad (\\because 確率分布の周辺化) \\\\ &= \\sum_{r\\in S} P(\\boldsymbol{x}_{n}=j|\\boldsymbol{x}_{k}=r, \\boldsymbol{x}_{0}=i) P(\\boldsymbol{x}_{k}=r|\\boldsymbol{x}_{0}=i) \\quad (\\because ベイズの定理) \\\\ &= \\sum_{r\\in S} P(\\boldsymbol{x}_{n}=j|\\boldsymbol{x}_{k}=r) P(\\boldsymbol{x}_{k}=r|\\boldsymbol{x}_{0}=i) \\quad (\\because マルコフ性) \\\\ &= \\sum_{r\\in S} P(\\boldsymbol{x}_{n-k}=j|\\boldsymbol{x}_{0}=r) P(\\boldsymbol{x}_{k}=r|\\boldsymbol{x}_{0}=i) \\quad (\\because 斉時性) \\\\ &= \\sum_{r\\in S} p_{rj}&#94;{(n-k)}p_{ir}&#94;{(k)} \\end{align*} 到達可能、連結 ある状態 \\(i,j \\in X\\) に対して \\(p_{ij}&#94;{(n)} > 0\\) なる非負整数 \\(n \\geq 0\\) が存在する時、状態 \\(j\\) は状態 \\(i\\) から到達可能であると言い、 \\(i\\to j\\) と表す。 また \\(i \\to j \\land j \\to i\\) ならば、 \\(i\\) と \\(j\\) は連結しているといい、 \\(i \\leftrightarrow j\\) と表す。 連結関係は、反射性( \\(i \\leftrightarrow i\\) )、対称性( \\(i \\leftrightarrow j \\Leftrightarrow j \\leftrightarrow i\\) )、推移性( \\(i \\leftrightarrow j \\land j \\leftrightarrow k \\Rightarrow i \\leftrightarrow k\\) )が成り立つ。 連結クラス（連結成分） \\(X\\) の部分集合 \\(C \\subseteq X\\) において、 \\(i \\in C \\land j \\in C \\implies i \\leftrightarrow j\\) \\(i \\in C \\land i \\leftrightarrow j \\implies j \\in C\\) が常に成立する時、 \\(C\\) を \\(X\\) の連結クラス（連結成分）という。定義より、 \\(C\\) の要素は互いに連結している。また、連結クラス \\(C\\) の任意の状態 \\(i \\in C\\) から \\(j \\notin C\\) に到達できない時、 \\(C\\) は閉じていると言う。 規約性 \\(X\\) 内の全ての状態が単一の閉じた連結クラスに属する、即ち \\(X\\) の全ての要素が互いに連結している時、そのマルコフ連鎖は規約であるという。 周期性 状態 \\(i \\in X\\) に対して \\(p_{ii}&#94;{(n)} > 0\\) となる（ \\(n\\) ステップ後に元の状態に戻る） \\(n\\) の最大公約数 \\(d\\) を、状態 \\(i\\) の周期と呼ぶ。 \\(d = 1\\) の時は状態 \\(i\\) は非周期的と呼ばれ、 \\(d \\geq 2\\) の時は周期的であると呼ばれる。 再帰的、過渡的 確率変数 \\(T_{j}\\) を次で定義する: \\begin{equation*} T_{j} = \\min_{n} \\{ n > 0 | \\boldsymbol{x}_{n} = j \\} \\end{equation*} 即ち、離散時間マルコフ連鎖が初めて状態 \\(j\\) を訪れる時刻を表す。また、 \\(T_{i}\\) を用いて次の値を定義する: \\begin{align*} f_{i} &= P(T_{i} < \\infty | \\boldsymbol{x}_{0} = i) = \\sum_{n=1}&#94;{\\infty}P(T_{i} = n|\\boldsymbol{x}_{0}=i) \\\\ m_{i} &= \\mathrm{E}[T_{i}|\\boldsymbol{x}_{0}=i] = \\sum_{k=0}&#94;{\\infty} k P(T_{i}=k|\\boldsymbol{x}_{0}=i) \\end{align*} \\(f_{i}\\) は将来状態 \\(i\\) に戻ってくる確率を表しており、 \\(f_{i}=1\\) ならば確率 \\(1\\) で状態 \\(i\\) を訪れる（無限にしばしば訪れる）ので状態 \\(i\\) は再帰的であるという。 \\(f_{i} < 1\\) ならば状態 \\(i\\) は過渡的であるという。また、 \\(m_{i}\\) は初期状態が \\(i\\) の時に、再び状態 \\(i\\) に戻るまでの時間の期待値を表しており、 \\(m_{i} < \\infty\\) ならば状態 \\(i\\) は正再帰的（有限時間で \\(i\\) に戻る）であるといい、 \\(m_{i} = \\infty\\) ならば状態 \\(i\\) は零再帰的であるという。 エルゴード的な離散時間マルコフ連鎖 離散時間マルコフ連鎖 \\(\\boldsymbol{x}_{0}, \\boldsymbol{x}_{1},\\dots\\) が規約かつ正再帰かつ非周期的であるならば、この離散時間マルコフ連鎖はエルゴード的とも呼ばれる ここまでで用語の定義は揃ったので、それではエルゴード的なマルコフ連鎖の定常分布の存在についての定理を証明する。 エルゴード的な離散時間マルコフ連鎖の定常分布 離散時間マルコフ連鎖 \\(\\boldsymbol{x}_{0}, \\boldsymbol{x}_{1}, \\dots\\) がエルゴード的ならば、任意の状態 \\(i, j \\in X\\) について次が成り立つ: \\(\\displaystyle\\lim_{n \\to \\infty} p_{ij}&#94;{(n)} = \\lim_{n \\to \\infty} p_{jj}&#94;{(n)} = \\frac{1}{m_{j}} = \\pi_{j}\\) \\(\\pi_{j}\\) は \\(\\displaystyle \\pi_{j} = \\sum_{i \\in X} \\pi_{i} p_{ij}\\) と \\(\\displaystyle\\sum_{j \\in X}\\pi_{j} = 1\\) を満たす解であり、唯一に定まる。 2.を満たす \\(\\pi_{j}\\) を極限分布（定常状態分布）と言う。 一方、初期分布として \\(P(\\boldsymbol{x}_{0} = j) = \\pi_{j}\\) を持つ離散時間マルコフ連鎖では、任意の \\(n \\geq 1\\) に対して \\(P(\\boldsymbol{x}_{n}=j) = \\pi_{j}\\) が成り立ち、 \\(\\boldsymbol{x}_{n}\\) は \\(n\\) と独立した分布を持つ。この様に、時間に関して不変な分布 \\(\\pi_{j} = P(\\boldsymbol{x}_{n} = j)\\ n = 0,1,\\dots\\) を 定常分布 と呼ぶ。 （証明）まず1.から考える。最初に \\(i\\neq j\\) なる状態に対して \\begin{equation*} u_{k} = P(T_{j} = k|\\boldsymbol{x}_{0} = i) \\end{equation*} を（初期状態が \\(i\\) で、初めて \\(j\\) に訪れる時刻が \\(k\\) となる確率）おく。この時、 \\begin{align*} p_{ij}&#94;{(1)} &= u_{1} \\\\ p_{ij}&#94;{(2)} &= u_{2} + u_{1} p_{jj}&#94;{(1)} \\\\ p_{ij}&#94;{(3)} &= u_{3} + u_{2}p_{jj}&#94;{(1)} + u_{1}p_{jj}&#94;{(2)} \\\\ &\\vdots \\end{align*} の観察により、 \\(n \\geq 1\\) なる \\(n\\) に対して帰納的に \\begin{equation*} p_{ij}&#94;{(n)} = \\sum_{k=1}&#94;{n} u_{k} p_{jj}&#94;{(n-k)} \\end{equation*} が成立する（最初の \\(k\\) ステップで状態 \\(j\\) に行き、その後 \\(n-k\\) ステップ後に再び \\(j\\) に行く）ことが分かる。また、任意の \\(i\\) と \\(j\\) は連結している（ \\(i \\leftrightarrow j\\) ）ので、 \\begin{equation*} \\sum_{k=1}&#94;{\\infty} u_{k} = P(\\exists n \\geq 0.\\ \\boldsymbol{x}_{n} = j | \\boldsymbol{x}_{0} =i) = 1 \\end{equation*} （状態 \\(i\\) から始まり、 \\(j\\) へいつかは訪れる確率は \\(1\\) ）が成り立つ。一方 \\(p_{jj}&#94;{(n)}\\) は、 \\begin{align*} p_{jj}&#94;{(n)} &= P(\\boldsymbol{x}_{n} = j|\\boldsymbol{x}_{0}=j) \\\\ &= \\sum_{k=1}&#94;{n}P(\\boldsymbol{x}_{n}=j, T_{j} = k|\\boldsymbol{x}_{0}=j) \\quad (\\because 確率分布の周辺化) \\\\ &= \\sum_{k=1}&#94;{n}P(\\boldsymbol{x}_{n}=j|T_{j}=k, \\boldsymbol{x}_{0}=j)P(T_{j}=k|\\boldsymbol{x}_{0}=j) \\quad (\\because ベイズの定理) \\\\ &= \\sum_{k=1}&#94;{n}P(\\boldsymbol{x}_{n}=j|\\boldsymbol{x}_{k}=j, \\boldsymbol{x}_{0}=j)P(T_{j}=k|\\boldsymbol{x}_{0}=j) \\quad (\\because T_{j} = k \\implies \\boldsymbol{x}_{k} = j) \\\\ &= \\sum_{k=1}&#94;{n}P(\\boldsymbol{x}_{n}=j|\\boldsymbol{x}_{k}=j)P(T_{j}=k|\\boldsymbol{x}_{0}=j) \\quad (\\because マルコフ性) \\\\ &= \\sum_{k=1}&#94;{n}p_{jj}&#94;{(n-k)} u_{k} \\end{align*} と展開できる。数列 \\(p_{jj}&#94;{(n)}\\) の極限 \\(\\displaystyle\\lim_{n \\to \\infty} p_{jj}&#94;{(n)}\\) を求める為、ここでは数列の 母関数 を定義し、（片側）Z変換の最終値定理 [24] を用いる。その為、今、 \\(\\displaystyle G(z) = \\sum_{n=0}&#94;{\\infty}p_{jj}&#94;{(n)}z&#94;{n},\\ U(z) = \\sum_{n=1}&#94;{\\infty}u_{n}z&#94;{n}\\) なる母関数を定義し、上式の両辺に \\(z&#94;{n}\\) を掛けて \\(n=1,2,\\dots\\) についての和を取ると、 \\begin{align*} （左辺）\\sum_{n=1}&#94;{\\infty} p_{jj}&#94;{(n)}z&#94;{n} &= \\sum_{n=1}&#94;{\\infty} p_{jj}&#94;{(n)}z&#94;{n} = \\sum_{n=0}&#94;{\\infty}p_{jj}&#94;{(n)}z&#94;{n} - p_{jj}&#94;{(0)} \\\\ &= G(z) - 1 \\\\ （右辺）\\sum_{n=1}&#94;{\\infty} \\sum_{k=1}&#94;{n} p_{jj}&#94;{(n-k)}u_{k}z&#94;{n} &= \\sum_{n=1}&#94;{\\infty} \\sum_{k=1}&#94;{n} p_{jj}&#94;{(n-k)}z&#94;{n-k}u_{k}z&#94;{k} \\\\ &= G(z)U(z) \\\\ \\therefore G(z) &= \\frac{1}{1-U(z)} \\end{align*} ここで、右辺式の最後の式変形には冪級数の積の公式 [25] を用いている。最終値定理を適用する事を考えると、この場合は、 \\begin{equation*} \\lim_{n \\to \\infty} p_{jj}&#94;{(n)} = \\lim_{z \\to 1}(1-z)G(z) \\end{equation*} が成立する [26] ので、 \\(\\displaystyle\\lim_{n \\to \\infty} p_{jj}&#94;{(n)}\\) の結果として、 \\begin{align*} \\lim_{n \\to \\infty} p_{jj}&#94;{(n)} &= \\lim_{z \\to 1}(1-z)G(z) = \\lim_{z \\to 1}\\frac{1-z}{1-U(z)} \\\\ &= \\lim_{z \\to 1}\\frac{\\frac{d(1-z)}{dz}}{\\frac{d(1-U(z))}{dz}} \\quad (\\because ロピタルの定理) \\\\ &= \\lim_{z \\to 1}\\frac{1}{\\frac{dU(z)}{dz}} = \\frac{1}{m_{j}} = \\pi_{j} \\\\ \\because \\lim_{z \\to 1} \\frac{dU(z)}{dz} &= \\lim_{z \\to 1}\\sum_{n=1}&#94;{\\infty}n u_{n} z&#94;{n-1} = \\lim_{z \\to 1}\\sum_{n=0}&#94;{\\infty} n u_{n} z&#94;{n} = \\sum_{n=0}&#94;{\\infty}n u_{n} = m_{j} \\end{align*} が得られる。さて、この結果より、任意の正数 \\(\\epsilon > 0\\) に対して \\(n \\geq N\\) なる全ての \\(n\\) が \\begin{equation*} |p_{jj}&#94;{(n)} - \\pi_{j}| \\leq \\frac{\\epsilon}{2} \\quad かつ \\quad \\sum_{k = N+1}&#94;{\\infty} u_{k} \\leq \\frac{\\epsilon}{2} \\end{equation*} を同時に満たすような \\(N\\) を取ることができる。今、 \\(n \\geq 2N\\) に対し、 \\begin{align*} |p_{ij}&#94;{(n)} - \\pi_{j}| &= | \\sum_{k=1}&#94;{n} u_{k} p_{jj}&#94;{(n-k)} - \\pi_{j}| = | \\sum_{k=1}&#94;{n} u_{k} p_{jj}&#94;{(n-k)} - \\sum_{k=1}&#94;{\\infty}u_{k}\\pi_{j}| \\\\ &= |\\sum_{k=1}&#94;{n-N}u_{k}(p_{jj}&#94;{(n-k)}-\\pi_{j}) + \\sum_{k=n-N+1}&#94;{n} u_{k}(p_{jj}&#94;{(n-k)} - \\pi_{j}) -\\sum_{k=n+1}&#94;{\\infty}u_{k}\\pi_{j}| \\\\ &\\leq \\sum_{k=1}&#94;{n-N}u_{k}|p_{jj}&#94;{(n-k)}-\\pi_{j}| + \\sum_{k=n-N+1}&#94;{n} u_{k}|p_{jj}&#94;{(n-k)} - \\pi_{j}| + \\sum_{k=n+1}&#94;{\\infty}|u_{k}\\pi_{j}| \\\\ &\\leq \\sum_{k=1}&#94;{n-N}u_{k}\\frac{\\epsilon}{2} + \\sum_{k=n-N+1}&#94;{n} u_{k} + \\sum_{k=n+1}&#94;{\\infty}u_{k} = \\frac{\\epsilon}{2}\\sum_{k=1}&#94;{n-N}u_{k} + \\sum_{k=n-N+1}&#94;{\\infty} u_{k} \\\\ &\\leq \\frac{\\epsilon}{2} + \\frac{\\epsilon}{2} = \\epsilon \\end{align*} よって、 \\(\\displaystyle \\lim_{n \\to \\infty} p_{ij}&#94;{(n)} = \\pi_{j} = \\lim_{n \\to \\infty} p_{jj}&#94;{(n)}\\) 。 次に2. の \\(\\pi_{j}\\) の一意性を示す。まず、 \\(\\displaystyle \\sum_{j \\in X}p_{ij}&#94;{(n)} = 1\\) （どこかの状態には確率1で遷移している）より、この式で \\(n \\to \\infty\\) ならしめれば、1. により \\begin{equation*} \\sum_{j \\in X} \\pi_{j} = 1 \\end{equation*} を得る。また、 \\(a_{j}(n) = P(\\boldsymbol{x}_{n} = j)\\) （時刻 \\(n\\) で状態 \\(j\\) を訪れる確率）とおくと、 \\begin{align*} a_{j}(n) &= \\sum_{i \\in X}P(\\boldsymbol{x}_{0}=i)P(\\boldsymbol{x}_{n}=j|\\boldsymbol{x}_{0}=i) = \\sum_{i \\in X}P(\\boldsymbol{x}_{0}=i)p_{ij}&#94;{(n)} \\\\ \\therefore \\lim_{n \\to \\infty} a_{j}(n) &= \\sum_{i \\in X}P(\\boldsymbol{x}_{0}=i) \\lim_{n \\to \\infty}p_{ij}&#94;{(n)} = \\pi_{j} \\sum_{i \\in X} P(\\boldsymbol{x}_{0} = i) = \\pi_{j} \\end{align*} が成立し、チャップマン−コルモゴロフ方程式により、 \\(n, m \\geq0\\) なる整数に対し、 \\begin{align*} a_{j}(m+n) &= \\sum_{r \\in X}P(\\boldsymbol{x}_{0}=r)P(\\boldsymbol{x_{m+n}}=j|\\boldsymbol{x}_{0}=r) = \\sum_{r \\in X} P(\\boldsymbol{x}_{0} = r) p_{rj}&#94;{(m+n)} \\\\ &= \\sum_{r \\in X} P(\\boldsymbol{x}_{0}=r) \\sum_{i \\in X} p_{ri}&#94;{(m)}p_{ij}&#94;{(n)} \\quad (\\because チャップマン-コルモゴロフ方程式を使用) \\\\ &= \\sum_{i \\in X}\\sum_{r \\in X}P(\\boldsymbol{x}_{0}=r)p_{ri}&#94;{(m)} p_{ij}&#94;{(n)} = \\sum_{i \\in X} a_{i}(m) p_{ij}&#94;{(n)} \\end{align*} この式の両辺を \\(m \\to \\infty\\) ならしめれば、極限と和の交換法則より、 \\begin{equation*} \\pi_{j} = \\sum_{i \\in X}\\pi_{i} p_{ij}&#94;{(n)} \\end{equation*} を得る。特に \\(n=1\\) とすれば、 \\(\\displaystyle \\pi_{j} = \\sum_{i \\in X} \\pi_{j} p_{ij}\\) が得られる。 次に一意性を示す。今、 \\(\\pi_{i}&#94;{\\prime}\\ (i \\in X)\\) が、 \\begin{equation*} \\pi_{j}&#94;{\\prime} = \\sum_{i \\in X}\\pi_{i}&#94;{\\prime} p_{ij} \\quad かつ \\quad \\sum_{i \\in X} \\pi_{i}&#94;{\\prime} = 1 \\end{equation*} を満たすとする。上述の議論により、全ての正整数 \\(n \\geq 0\\) に対し、 \\begin{equation*} \\pi_{j}&#94;{\\prime} = \\sum_{i \\in X}\\pi_{i}&#94;{\\prime} p_{ij}&#94;{(n)} \\end{equation*} を得る。 \\(n \\to \\infty\\) とすると、 \\begin{equation*} \\pi_{j}&#94;{\\prime} = \\left(\\sum_{i \\in X}\\pi_{i}&#94;{\\prime}\\right) \\pi_{j} = \\pi_{j} \\end{equation*} となって、一意性が示される。 詳細釣り合い条件の証明 最後に詳細釣り合い条件を示す。今、確率分布 \\(r\\) と遷移確率が \\begin{equation*} r_{i} p_{ij} = r_{j} p_{ji} \\end{equation*} を満たしているとする。この時両辺ともに状態 \\(i\\) について和をとると、 \\begin{equation*} \\sum_{i \\in X} r_{i} p_{ij} = r_{j} \\sum_{i \\in X} p_{ji} = r_{j} \\end{equation*} 2.により、 \\(r\\) は定常分布の解となっている事が分かる。 脚注 [1] 古澄英雄, 「21世紀の統計科学」第Ⅲ巻 第10章 マルコフ連鎖モンテカルロ法入門 [2] 笠原正治, 確率過程論基礎 [3] 中川裕志, マルコフ連鎖モンテカルロ法 [4] 福島孝治, マルコフ連鎖モンテカルロ法の実践 [5] tera monagi, マルコフ連鎖モンテカルロ法入門-1 [6] 主に、確率分布の平均（期待値）、分散が対象となる [7] 十分な回数の独立な試行を行った経験分布は理論的（真の）分布に一致する、という法則。例えばコイン投げをひたすら繰り返せば、表及び裏が出る 頻度の比率 はそれぞれ \\(1/2\\) に近づいていく。厳密には大数の法則は2種類（強、弱法則）あり、確率の応用において非常に非常に重要な法則であるが、ここでは説明をしない。 [8] 確率変数のとる値が実数値でなくとも、事象が有限個存在（ \\(\\iff\\) 全事象が有限集合）する場合（例。サイコロとかコインを投げる試行）は議論で用いている分布を離散確率分布で考えれば良い。 [9] 起こりえる全ての事象の集合。 [10] 他の個人的に興味深い例：強化学習において \\(X\\) を選択した行動列の集合、 \\(h:X \\to \\mathbb{R}\\) を報酬関数とすれば、 \\(h(\\boldsymbol{x})\\) で行動列の報酬が計算でき、 \\(I\\) の計算結果は報酬の期待値となる。報酬の期待値が計算できることはエージェントの行動決定において大変有用である。 [11] 一様分布や正規分布等のよく知られた分布は、サンプリングアルゴリズムも確立されている。一様分布はメルセンヌ・ツイスタ、正規分布にはボックス-ミューラー法といった具合である。 [12] 空間の次元が増加すると、その空間の自由度が直感に反して 指数的 に増加すること。例えば、ユークリッド空間で一辺の長さが \\(a\\) の \\(n\\) 次元超立方体を占める直径 \\(a\\) の超球体の割合を計算してみると \\(\\frac{\\sqrt{(\\pi(a/2)&#94;{2})&#94;{n}}}{a&#94;{n} \\Gamma(\\frac{n}{2}+1)}\\) であり、 \\(n\\) を増加させると階乗オーダー（即ち、指数オーダーよりも早く）で減少する事が分かる。従って、一様乱数を用いていると、 \\(n\\) 次元空間で超球体の内部にサンプルが入る確率が階乗オーダーで小さくなる。 [13] 厳密には、直前の1つのサンプルのみに依存するので1階マルコフ性と呼ばれる。 [14] 詳細は 補足 で述べる。一般にエルゴード的とは、長時間に渡って観測した状態の平均（長時間平均）と、状態空間の平均（位相平均）が一致するという事を表す概念である。エルゴード理論がある様に、厳密な数学理論が展開されるが、ここではマルコフ連鎖以外については詳しくは説明しない（筆者がついていけてない）。 [15] 連続な状態空間では、遷移確率行列の代わりに \\begin{equation*} P(\\boldsymbol{x}_{t+1} \\in C|\\boldsymbol{x}_{t} = \\boldsymbol{e}_{t}) = \\int_{C} T(\\boldsymbol{e}_{t}, \\boldsymbol{y}) d \\boldsymbol{y} \\quad C \\subset X, \\boldsymbol{e}_{t} \\in X \\end{equation*} となる様な条件付き確率分布 \\(T(\\boldsymbol{x}, \\boldsymbol{y})\\) （遷移核）を用いれば良い。 [16] 形式的に書くと、状態 \\(j \\in X\\) の定常分布 \\(\\pi_{j}\\) は \\(\\pi_{j} = P(\\boldsymbol{x}_{n} = j)\\ n=0,1,\\dots\\) と表される。 [17] 例えば、現在状態を中心とした正規分布からでの乱択でも3つの性質を満たし、マルコフ連鎖はエルゴード的となる。 [18] これが詳細釣り合い条件を満たすことは、場合分けにより分かる: \\(\\alpha(i \\to j) = 1\\) の時： \\(\\alpha(j \\to i) = \\frac{r_{i}q_{ij}}{r_{j}q_{ji}}\\) となるので、 \\begin{equation*} p_{ji} = q_{ji} \\alpha(j \\to i) = q_{ji} \\frac{r_{i}q_{ij}}{r_{j}q_{ji}} = \\frac{r_{i}}{r_{j}}q_{ij} = \\frac{r_{i}}{r_{j}} p_{ij} \\iff r_{i}p_{ij} = r_{j}p_{ji} \\end{equation*} \\(\\alpha(i \\to j) = \\frac{r_{j}q_{ji}}{r_{i}q_{ij}}\\) の時： \\(\\alpha(j \\to i) = 1\\) となるので、 \\begin{equation*} p_{ij} = q_{ij} \\alpha(i \\to j) = q_{ij} \\frac{r_{j}q_{ji}}{r_{i}q_{ij}} = \\frac{r_{j}}{r_{i}}q_{ji} = \\frac{r_{j}}{r_{i}} p_{ji} \\iff r_{i}p_{ij} = r_{j}p_{ji} \\end{equation*} [19] 温度パラメタの調節は非常に難しい事が知られている。実験結果を見て経験的に設定される事がほとんどである。 [20] 分散パラメタの調節も非常に難しい。分散を大きくすると遷移幅（ステップサイズという）が大きくなって定常分布に落ち着くまでに時間が掛かり、分散を小さくし過ぎると遷移の動きが小さく、探索が十分に行われない危険性がある。一般に分散パラメタと温度パラメタにはトレードオフの関係がある。 [21] \\(q_{ij} = q_{ji}\\) が成立する理由は、この場合 \\(j\\) は \\begin{equation*} j = i + \\varepsilon \\quad \\varepsilon \\sim {\\cal N}(\\boldsymbol{0}, \\sigma&#94;{2} \\boldsymbol{I}) \\end{equation*} と書けるので、平均が \\(\\boldsymbol{0}\\) かつ正規分布の対称性により、 \\begin{equation*} i = j - \\varepsilon = j + \\varepsilon \\end{equation*} よって \\(q_{ij} = {\\cal N}(i, \\sigma&#94;{2}\\boldsymbol{I}) = {\\cal N}(j, \\sigma&#94;{2}\\boldsymbol{I}) = q_{ji}\\) を満たす [22] 機械学習では、ベイジアンネットワークやボルツマンマシン（深層学習の一部）等のモデル学習に使われる [23] 毎回ランダムで選んでも、順番に全変数を1個ずつ選んでも良い [24] 数列 \\(a_{n}\\) の母関数を \\(F(z) = \\displaystyle\\sum_{n=0}&#94;{\\infty}a_{n}z&#94;{n}\\) とする。今、複素数 \\(s \\in \\mathbb{C}\\) を用いて \\(z = \\exp(-s)\\) とおき、 \\(n\\) の和を \\(t\\) の積分に置き換えると、 \\begin{equation*} F(\\exp(-s)) = \\int_{0}&#94;{\\infty} a_{t}\\exp(-st) dt \\end{equation*} これは数列 \\(a_{t}\\) のラプラス変換に他ならない。従ってラプラス変換の最終値定理を適用できる。離散の場合のラプラス変換を（片側）Z変換と呼ぶ。 [25] 2つの冪級数を \\(\\displaystyle\\sum_{n=0}&#94;{\\infty}a_{n}z&#94;{n}, \\sum_{n=0}&#94;{\\infty}b_{n}z&#94;{n}\\) とし、積の結果を \\(\\displaystyle\\sum_{n=0}&#94;{\\infty}c_{n}z&#94;{n}\\) とする。等号を立てると、 \\begin{align*} \\left(\\sum_{n=0}&#94;{\\infty}a_{n}z&#94;{n}\\right)\\left(\\sum_{n=0}&#94;{\\infty}b_{n}z&#94;{n} \\right) &= a_{0}b_{0}z&#94;{0} + (a_{0}b_{1} + a_{1}b_{0})z&#94;{1} + (a_{0}b_{2}+a_{1}b_{1}+a_{2}b_{0})z&#94;{2} + \\dots \\\\ &= \\sum_{n=0}&#94;{\\infty}c_{n}z&#94;{n} = c_{0}z&#94;{0} + c_{1}z&#94;{1} + c_{2}z&#94;{2} + \\dots \\end{align*} 係数比較により、 \\(c_{0} = a_{0}b_{0},\\ c_{1} = a_{0}b_{1} + a_{1}b_{0},\\ \\dots\\) が成立し、よって \\(c_{n} = \\displaystyle \\sum_{k=0}&#94;{n}a_{k}b_{n-k}\\) となる。ここの例では、 \\(a_{k} = u_{k}z&#94;{k},\\ b_{k} = p_{jj}&#94;{(k)}z&#94;{k}\\) とおけば良い。 [26] （証明）母関数（Z変換）を \\(F(z) = \\displaystyle \\sum_{n=0}&#94;{\\infty}a_{n}z&#94;{n}\\) とおくと、 \\begin{align*} \\lim_{z \\to 1} (1-z) F(z) &= \\lim_{z \\to 1}(1-z) \\sum_{n=0}&#94;{\\infty} a_{n}z&#94;{n} = \\lim_{z \\to 1} \\sum_{n=0}&#94;{\\infty} a_{n} (z&#94;{n} - z&#94;{n+1}) = \\lim_{z \\to 1} \\lim_{n \\to \\infty} \\sum_{k=0}&#94;{n} a_{k} (z&#94;{k} - z&#94;{k+1}) \\\\ &= \\lim_{z \\to 1} \\lim_{n \\to \\infty} \\sum_{k=0}&#94;{n} (a_{k} - a_{k-1}) z&#94;{k} \\quad (\\because a_{-1} = 0, また a_{0}(z&#94;{0}-z&#94;{1}) + a_{1}(z&#94;{1}-z&#94;{2}) +\\dots = a_{0}z&#94;{0} + (a_{0}-a_{1})z&#94;{1} + \\dots) \\\\ &= \\lim_{n \\to \\infty} \\sum_{k=0}&#94;{n} (a_{k} - a_{k-1}) = \\lim_{n \\to \\infty} a_{n} \\end{align*}","tags":"記事","url":"/mcmcmarukohulian-suo-montekarurofa.html","loc":"/mcmcmarukohulian-suo-montekarurofa.html"},{"title":"LPC（Linear Predictive Coding, 線形予測符号化）","text":"線形予測分析等とも言及される。 英語版で決定的に簡単な資料は ここ で見れます。ここの解説はその日本語訳以下の何かです。英語が読める人はそっちを見たほうが絶対早いです。 ここよりも良い資料が有ります：（ 人工知能に関する断創録 ） アルゴリズムの導出 問題設定 誤差の最小化 偏微分 Levinson-Durbin再帰（Levinson-Durbin recursion）へ Levinson-Durbin再帰 k=1の時 一般のkの時 アルゴリズム 補足 周波数特性の導出 標本自己相関の計算 参考資料リスト 実装 実験 アルゴリズムの導出 問題設定 時間について離散化した信号が \\(y_{0}, y_{1}, ..., y_{n}\\) として得られたとする。ここで、 \\(y_{n}\\) を直前の \\(y_{i}\\ (i=0,...,n-1)\\) によって予測する事を考える。 予測にあたって、線形予測では \\(k\\) 個の係数 \\(a_{1},...,a_{k}\\) を用いた単純な線形結合 \\begin{equation*} -a_{1}y_{n-1} - a_{2}y_{n-2} - ... - a_{k}y_{n-k} = - \\sum_{i=1}&#94;{k} a_{i} y_{n-i} \\end{equation*} によって \\(y_{n}\\) を近似する： \\begin{equation*} y_{n} \\approx - \\sum_{i=1}&#94;{k} a_{i} y_{n-i} \\end{equation*} （係数に負号 \\(-\\) が付いているのは、システムのフィードバック係数として捉えた時は負を付けるのが常識となっているからと考えられる。全ての係数の符号を反転させれば通常の和に戻るので、以下の導出にとって本質的な問題にならない。） 予測の 誤差 は、全ての \\(n\\) における 二乗誤差 の和 \\(E\\) によって測る： \\begin{equation*} \\begin{split} E &= \\sum_{n=-\\infty}&#94;{\\infty} \\left[ y_{n} - \\left\\{ -\\sum_{i=1}&#94;{k} a_{i} y_{n-i} \\right\\} \\right]&#94;{2} \\\\ &= \\sum_{n=-\\infty}&#94;{\\infty} \\left\\{ y_{n} + \\sum_{i=1}&#94;{k}a_{i}y_{n-i} \\right\\}&#94;{2} \\end{split} \\end{equation*} ここで \\(a_{0} = 1\\) と定義すると、 \\begin{equation*} E = \\sum_{n=-\\infty}&#94;{\\infty} \\left\\{\\sum_{i=0}&#94;{k}a_{i}y_{n-i}\\right\\}&#94;{2} \\end{equation*} とまとめられる。後は、この \\(E\\) を最小化するように係数 \\(a_{1},...,a_{k}\\) を定めれば良い。 誤差の最小化 偏微分 誤差の最小化を考える。常套手段ではあるが、 \\(E\\) を \\(a_{j} \\ (j=1,...,k)\\) によって偏微分し、その結果を \\(0\\) とおいて解くことを考える。まず、 \\(E\\) の偏微分は、 \\begin{equation*} \\begin{split} \\frac{\\partial E}{\\partial a_{j}} &= \\sum_{n=-\\infty}&#94;{\\infty} \\frac{\\partial}{\\partial a_{j}} \\left\\{\\sum_{i=0}&#94;{k}a_{i}y_{n-i} \\right\\}&#94;{2} \\\\ &= \\sum_{n=-\\infty}&#94;{\\infty} \\frac{\\partial}{\\partial a_{j}} \\left\\{ a_{0}y_{n} + ... + a_{j}y_{n-j} + ... + a_{k}y_{n-k} \\right\\}&#94;{2} \\\\ &= \\sum_{n=-\\infty}&#94;{\\infty} 2 y_{n-j} \\sum_{i=0}&#94;{k}a_{i}y_{n-i} \\\\ &= 2 \\sum_{i=0}&#94;{k}a_{i} \\sum_{n=-\\infty}&#94;{\\infty} y_{n-j} y_{n-i} \\quad (\\because \\text{和の順序交換}) \\\\ &= 2 \\sum_{i=0}&#94;{k}a_{i} \\sum_{n&#94;{\\prime}=-\\infty}&#94;{\\infty} y_{n&#94;{\\prime}} y_{n&#94;{\\prime}+j-i} \\quad (n&#94;{\\prime} = n-j \\ \\text{とおいた}) \\end{split} \\end{equation*} ここで、 \\(R_{l}\\) を次の式で定義する： \\begin{equation*} R_{l} = \\sum_{n=-\\infty}&#94;{\\infty} y_{n} y_{n+l} \\end{equation*} （ 自己相関 という。） \\(R_{l}\\) を用いることで、偏微分の結果は、 \\begin{equation*} \\frac{\\partial E}{\\partial a_{j}} = 2 \\sum_{i=0}&#94;{k} a_{i}R_{|j-i|} \\end{equation*} と表せる。 次に、 \\(\\displaystyle\\frac{\\partial E}{\\partial a_{j}} = 0\\ (j=1,...,k)\\) とおいて解く事を考える。和の前に付いている係数 \\(2\\) は両辺 \\(2\\) で割ることで消すことが出来る。その上で \\(j=1,...,k\\) での式を並べてみると、 \\begin{equation*} \\begin{split} a_{0}R_{|0-1|} + a_{1}R_{|1-1|} + ... + a_{k}R_{|k-1|} &= 0 \\\\ a_{0}R_{|0-2|} + a_{1}R_{|1-2|} + ... + a_{k}R_{|k-2|} &= 0 \\\\ \\vdots \\\\ a_{0}R_{|0-k|} + a_{1}R_{|1-k|} + ... + a_{k}R_{|k-k|} &= 0 \\\\ \\end{split} \\end{equation*} より、行列形式で \\begin{equation*} \\begin{bmatrix} R_{1} & R_{0} & R_{1} & ... & R_{k-1} \\\\ R_{2} & R_{1} & R_{0} & ... & R_{k-2} \\\\ \\vdots & & & \\ddots & \\vdots \\\\ R_{k} & R_{k-1} & R_{k-2} & ... & R_{0} \\end{bmatrix} \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\end{bmatrix} = \\vec{0} \\end{equation*} と表せられる。以下、 \\begin{equation*} M = \\begin{bmatrix} R_{1} & R_{0} & ... & R_{k-1} \\\\ R_{2} & R_{1} & ... & R_{k-2} \\\\ \\vdots & & \\ddots & \\vdots \\\\ R_{k} & R_{k-1} & ... & R_{0} \\end{bmatrix} \\ , \\ \\vec{a}_{k} = \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\end{bmatrix} \\end{equation*} として、 \\(M\\vec{a}_{k} = \\vec{0}\\) を解くことを考える。 Levinson-Durbin再帰（Levinson-Durbin recursion）へ 上までで求まった連立方程式 \\(M\\vec{a}\\_{k+1} = \\vec{0}\\) をもう少し整理していく。数値解法的には、 \\(M\\) は正方行列にしておくのが望ましい。そこで、 \\(M\\) の一番上の行に \\([R_{0} R_{1} ... R_{k}]\\) を追加すると、 \\begin{align*} \\begin{split} M\\vec{a}_{k} &= \\begin{bmatrix} R_{1} & R_{0} & ... & R_{k-1} \\\\ R_{2} & R_{1} & ... & R_{k-2} \\\\ \\vdots & & \\ddots & \\vdots \\\\ R_{k} & R_{k-1} & ... & R_{0} \\end{bmatrix} \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\end{bmatrix} \\\\&= \\begin{bmatrix} R_{0} & R_{1} & ... & R_{k} \\\\ R_{1} & R_{0} & ... & R_{k-1} \\\\ \\vdots & & \\ddots & \\vdots \\\\ R_{k} & R_{k-1} & ... & R_{0} \\end{bmatrix} \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\end{bmatrix} -\\begin{bmatrix} \\sum_{i=0}&#94;{k}a_{i}R_{i} \\\\ 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} = \\vec{0} \\end{split} \\end{align*} と変形できる。よって、次の連立方程式を解くことに帰着できる： \\begin{equation*} \\begin{bmatrix} R_{0} & R_{1} & ... & R_{k} \\\\ R_{1} & R_{0} & ... & R_{k-1} \\\\ \\vdots & & \\ddots & \\vdots \\\\ R_{k} & R_{k-1} & ... & R_{0} \\end{bmatrix} \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\end{bmatrix} =\\begin{bmatrix} \\sum_{i=0}&#94;{k}a_{i}R_{i} \\\\ 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} \\end{equation*} この連立方程式を高速に解くアルゴリズムが、Levinson-Durbin再帰法である。以下、 \\(e_{k} = \\sum_{i=0}&#94;{k} a_{i} R_{i}\\) とし、また行列 \\(N_{k}\\) を次で定義する： \\begin{equation*} N_{k} = \\begin{bmatrix} R_{0} & R_{1} & ... & R_{k} \\\\ R_{1} & R_{0} & ... & R_{k-1} \\\\ \\vdots & & \\ddots & \\vdots \\\\ R_{k} & R_{k-1} & ... & R_{0} \\end{bmatrix} \\end{equation*} Levinson-Durbin再帰 このアルゴリズムは、数学的帰納法によく似ている： \\(k=1\\) の場合で係数を求める 一般の \\(k\\) で係数が求まったとし、その結果から \\(k+1\\) で係数を求める （ 参考資料 で筆者は、「Levinson-Durbin帰納法と言ったほうがいいんじゃないか」と書いてあった。）ここでは、1.および2.の場合の解をそれぞれ見ていく。 k=1の時 \\begin{equation*} \\vec{a}_{1}= \\begin{bmatrix} 1 \\\\ a_{1} \\end{bmatrix} ,\\ N_{1}\\vec{a}_{1}= \\begin{bmatrix} e_{1} \\\\ 0 \\end{bmatrix} ,\\ N_{1}= \\begin{bmatrix} R_{0} & R_{1} \\\\ R_{1} & R_{0} \\end{bmatrix} \\end{equation*} より、実際に \\(N_{1}\\vec{a}_{1}\\) を計算してみると、 \\begin{equation*} N_{1}\\vec{a}_{1}= \\begin{bmatrix} R_{0} + R_{1}a_{1} \\\\ R_{1} + R_{0}a_{1} \\end{bmatrix}= \\begin{bmatrix} e_{1} \\\\ 0 \\end{bmatrix} \\end{equation*} より、 \\(e_{1} = R_{0} + R_{1}a_{1}\\) 、及び \\(R_{1} + R_{0}a_{1} = 0\\) から \\(a_{1} = -\\displaystyle\\frac{R_{1}}{R_{0}}\\) と求められる。（ \\(R_{0} = \\displaystyle\\sum_{n=-\\infty}&#94;{\\infty}y_{n}&#94;{2} > 0\\) より、至る所ゼロ除算の心配はない） 一般のkの時 仮定として、 \\begin{equation*} N_{k}\\vec{a}_{k}= \\begin{bmatrix} R_{0} & R_{1} & ... & R_{k} \\\\ R_{1} & R_{0} & ... & R_{k-1} \\\\ \\vdots & & \\ddots & \\vdots \\\\ R_{k} & R_{k-1} & ... & R_{0} \\end{bmatrix} \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\end{bmatrix} =\\begin{bmatrix} e_{k} \\\\ 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} \\end{equation*} が成立していたとする。 \\(k+1\\) の時、行列 \\(N_{k+1}\\) は \\begin{equation*} N_{k+1}= \\begin{bmatrix} R_{0} & R_{1} & ... & R_{k} & R_{k+1} \\\\ R_{1} & R_{0} & ... & R_{k-1} & R_{k} \\\\ \\vdots & & \\ddots & & \\vdots \\\\ R_{k} & R_{k-1} & ... & R_{0} & R_{1} \\\\ R_{k+1} & R_{k} & ... & R_{1} & R_{0} \\end{bmatrix}= \\left[ \\begin{array}{cccc|c} & & & & R_{k+1} \\\\ & N_{k} & & & R_{k} \\\\ & & & & \\vdots \\\\ & & & & R_{1} \\\\\\hline R_{k+1} & R_{k} & ... & R_{1} & R_{0} \\end{array} \\right] \\end{equation*} となり、 \\(N_{k}\\) の行・列共に1つ増えた行列となる。 一方の \\(\\vec{a}_{k+1}\\) は未知である。そこで、技巧的ではあるが次 \\(\\vec{a}\\_{k}\\) を \\(0\\) を追加する事で拡張した次のベクトル \\(\\vec{u}\\_{k+1}, \\vec{v}\\_{k+1}\\) を用いる事を考える： \\begin{equation*} \\vec{u}_{k+1}= \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\\\ 0 \\end{bmatrix}\\ ,\\ \\vec{v}_{k+1}= \\begin{bmatrix} 0 \\\\ a_{k} \\\\ \\vdots \\\\ a_{2} \\\\ a_{1} \\\\ 1 \\end{bmatrix} \\end{equation*} \\(\\vec{u}\\_{k+1}, \\vec{v}\\_{k+1}\\) は互いに要素を反転したベクトルである（互いに 一次独立 で有ることにも注目）。これら \\(\\vec{u}\\_{k+1}, \\vec{v}\\_{k+1}\\) を用いて \\(N\\_{k+1}\\vec{u}\\_{k+1}\\) と \\(N_{k+1}\\vec{v}\\_{k+1}\\) を計算すると、まず \\(N\\_{k+1}\\vec{u}\\_{k+1}\\) は \\begin{align*} \\begin{split} N_{k+1}\\vec{u}_{k+1}&= \\left[ \\begin{array}{cccc|c} & & & & R_{k+1} \\\\ & N_{k} & & & R_{k} \\\\ & & & & \\vdots \\\\ & & & & R_{1} \\\\\\hline R_{k+1} & R_{k} & ... & R_{1} & R_{0} \\end{array} \\right] \\begin{bmatrix} 1 \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{k} \\\\ 0 \\end{bmatrix}\\\\ &= \\begin{bmatrix} \\\\ \\\\ N_{k}\\vec{a}_{k} \\\\ \\\\ \\\\ \\hline [R_{k+1} R_{k} ... R_{1}] \\vec{a}_{k} \\end{bmatrix}= \\begin{bmatrix} e_{k} \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ \\displaystyle\\sum_{j=0}&#94;{k} a_{j} R_{k+1-j} \\end{bmatrix} \\end{split} \\end{align*} であり、もう一方の \\(N\\_{k+1}\\vec{v}\\_{k+1}\\) は、 \\(N\\_{k+1}\\) が 対称行列 なので \\(N\\_{k+1}\\vec{u}\\_{k+1}\\) の結果を反転したベクトルとなる： \\begin{equation*} N_{k+1}\\vec{v}_{k+1}= \\begin{bmatrix} \\displaystyle\\sum_{j=0}&#94;{k} a_{j} R_{k+1-j} \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ e_{k} \\end{bmatrix} \\end{equation*} そして、 \\(\\vec{a}\\_{k+1}\\) は \\(\\vec{u}\\_{k+1}\\) と \\(\\vec{v}\\_{k+1}\\) の線形結合で表現できる： \\begin{equation*} \\vec{a}_{k+1} = \\vec{u}_{k+1} + \\lambda \\vec{v}_{k+1} \\quad (\\lambda : 実数) \\end{equation*} これは、実際に \\(N\\_{k+1}(\\vec{u}\\_{k+1} + \\lambda \\vec{v}\\_{k+1})\\) を計算することで確かめられる： \\begin{equation*} N_{k+1}(\\vec{u}_{k+1} + \\lambda \\vec{v}_{k+1}) = N_{k+1}\\vec{u}_{k+1} + N_{k+1}\\lambda \\vec{v}_{k+1}= \\begin{bmatrix} e_{k} + \\lambda \\displaystyle\\sum_{j=0}&#94;{k} a_{j} R_{k+1-j} \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ \\displaystyle\\sum_{j=0}&#94;{k} a_{j} R_{k+1-j} + \\lambda e_{k} \\end{bmatrix} \\end{equation*} ここで \\(\\lambda = - \\displaystyle\\frac{\\sum_{j=0}&#94;{k} a_{j} R_{k+1-j}}{e_{k}}\\) とすれば、 \\begin{equation*} N_{k+1}(\\vec{u}_{k+1} + \\lambda \\vec{v}_{k+1}) = \\begin{bmatrix} e_{k} - \\lambda&#94;{2} e_{k} \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ \\displaystyle\\sum_{j=0}&#94;{k} a_{j} R_{k+1-j} - \\displaystyle\\sum_{j=0}&#94;{k} a_{j} R_{k+1-j} \\end{bmatrix}= \\begin{bmatrix} (1-\\lambda&#94;{2}) e_{k} \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} \\end{equation*} となって \\(e\\_{k+1}\\) が求まる。同時に右辺の結果を与える \\(\\lambda\\) は唯一つしか存在しないので、この時の \\(\\vec{u}\\_{k+1} + \\lambda \\vec{v}\\_{k+1}\\) は \\(\\vec{a}\\_{k+1}\\) と一致する。 アルゴリズム 以上の導出結果をまとめると、 \\(k=1\\) の時： \\begin{equation*} a_{1} = - \\frac{R_{1}}{R_{0}} \\ , \\ e_{1} = R_{0} + R_{1}a_{1} \\end{equation*} \\(k\\) が求まった時、 \\(k+1\\) は： \\begin{equation*} \\lambda = - \\displaystyle\\frac{\\sum_{j=0}&#94;{k}a_{j}R_{k+1-j}}{e_{k}} \\ , \\ e_{k+1} = (1-\\lambda&#94;{2})e_{k}\\ ,\\ \\vec{a}_{k+1} = \\vec{u}_{k+1} + \\lambda \\vec{v}_{k+1} \\end{equation*} ここで、 \\begin{equation*} R_{l} = \\sum_{n=-\\infty}&#94;{\\infty} y_{n}y_{n+l}\\ ,\\ \\vec{u}_{k+1}= \\begin{bmatrix} 1 \\\\ a_{1} \\\\ \\vdots \\\\ a_{k} \\\\ 0 \\end{bmatrix}\\ ,\\ \\vec{v}_{k+1}= \\begin{bmatrix} 0 \\\\ a_{k} \\\\ \\vdots \\\\ a_{1} \\\\ 1 \\end{bmatrix} \\end{equation*} となる。 自己相関 \\(R_{l}\\) は過去から未来までの無限の信号和になっているので現実の計算機では計算出来ない。実際には自己相関の代わりに次の 標本自己相関 \\(\\tilde{R}\\_{l}\\) を用いる： \\begin{equation*} \\tilde{R}_{l} = \\sum_{i=0}&#94;{n} y_{i}y_{i-l} \\quad (l = 0, ..., k) \\end{equation*} 補足 周波数特性の導出 近似式は誤差項 \\(e_{n}\\) を用いて次の等式で書き表せる： \\begin{equation*} \\begin{split} y_{n} = - a_{1}y_{n-1} - a_{2}y_{n-2} - \\dots -a_{k}y_{n-k} + e_{n} \\\\ y_{n} = - \\sum_{i=1}&#94;{k} a_{i}y_{n-k} + e_{n} \\end{split} \\end{equation*} この式を両辺z変換すると、次の伝達関数を得る： \\begin{equation*} \\begin{split} Y(z) = - \\sum_{i=1}&#94;{k} a_{i}z&#94;{-i}Y(z) + E(z) \\\\ \\iff \\frac{Y(z)}{E(z)} = \\frac{1}{1+ \\sum_{i=1}&#94;{k}a_{i}z&#94;{-i}} \\end{split} \\end{equation*} この結果は、予測誤差を入力することで出力音声が得られるシステムを表している。人間の声帯から発せられた音声を \\(E(z)\\) とすれば、この伝達関数は声道の共鳴する特性をモデル化していると考えることができる。共鳴が発生する周波数では伝達関数のパワー（振幅、ゲイン）が高くなり、この結果からフォルマント分析を行うことができる。 伝達関数の周波数特性を求めるには、z変換の結果に \\(z=\\exp(j\\omega), (\\omega=2\\pi f:角周波数)\\) を代入する： \\begin{equation*} \\begin{split} \\frac{Y(z)}{E(z)} = \\frac{1}{1+ \\sum_{i=1}&#94;{k} a_{i} \\exp(-j i \\omega) } \\end{split} \\end{equation*} 標本自己相関の計算 標本自己相関は自分自身との相関を計算するので \\(O(N&#94;{2})\\) の計算量があるが、ウィーナー・ヒンチンの定理（信号のパワースペクトラムは、その自己相関に等しい）を使って自己相関を計算すれば、実質FFTと同等の計算量 \\(O(N \\log N)\\) で抑えることもできる。但し、巡回畳み込みや、パワースペクトラムの平均処理を考慮する必要がある。 参考資料リスト LPCについて： 東京大学 音情報処理論 ウィーナー・ヒンチンの定理： 京都大学 工業数学 実装 実装はC言語です（リファレンスはLLで書くべきだった…） #include <stdio.h> #include <math.h> #include <stdlib.h> #include <string.h> #include <float.h> /* （標本）自己相関の計算 */ static int calc_auto_correlation ( double * auto_corr , const double * data , const size_t num_sample , const size_t max_order ); /* Levinson-Durbin再帰計算 */ static int levinson_durbin_recursion ( double * lpc_coef , const double * auto_corr , const size_t max_order ); int main ( void ) { int num_sample = 300 ; /* サンプル数 */ int max_delay = 10 ; /* LPC係数の数 */ int i_sample , i_delay ; double * data = ( double * ) malloc ( sizeof ( double ) * num_sample ); double * predict = ( double * ) malloc ( sizeof ( double ) * num_sample ); double * auto_cor = ( double * ) malloc ( sizeof ( double ) * ( max_delay + 1 )); double * coff = ( double * ) malloc ( sizeof ( double ) * ( max_delay + 1 )); double error ; /* 波形の生成 */ for ( i_sample = 0 ; i_sample < num_sample ; i_sample ++ ) { data [ i_sample ] = sin ( i_sample * 0.01 ) + 0.5 * cos ( 4.0f * sin ( i_sample * 0.05 )); } /* 自己相関・Levinson-Durbin再帰計算 */ calc_auto_correlation ( auto_cor , data , num_sample , max_delay + 1 ); levinson_durbin_recursion ( coff , auto_cor , max_delay ); /* 予測テスト */ for ( i_sample = 0 ; i_sample < num_sample ; i_sample ++ ) { if ( i_sample < max_delay ) { /* 最初のmax_delayステップ分は元信号を単純コピー */ predict [ i_sample ] = data [ i_sample ]; } else { /* 以降は予測 */ predict [ i_sample ] = 0.0f ; for ( i_delay = 1 ; i_delay <= max_delay ; i_delay ++ ) { predict [ i_sample ] -= ( coff [ i_delay ] * data [ i_sample - i_delay ]); } } } /* 誤差計算・結果表示 */ error = 0.0f ; for ( i_sample = 0 ; i_sample < num_sample ; i_sample ++ ) { error += pow ( predict [ i_sample ] - data [ i_sample ], 2 ); printf ( \"No:%d Data: %f Predict: %f \\n \" , i_sample , data [ i_sample ], predict [ i_sample ]); } printf ( \"Error : %f \\n \" , sqrt ( error / num_sample )); free ( data ); free ( predict ); free ( auto_cor ); free ( coff ); return 0 ; } static int levinson_durbin_recursion ( double * lpc_coef , const double * auto_corr , const size_t max_order ) { int delay , i_delay ; double lambda ; double * u_vec , * v_vec , * a_vec , * e_vec ; if ( lpc_coef == NULL || auto_corr == NULL ) { fprintf ( stderr , \"Data or result pointer point to NULL. \\n \" ); return - 1 ; } /* * 0次自己相関（信号の二乗和）が0に近い場合、入力信号は無音と判定 * => 予測誤差, LPC係数は全て0として無音出力システムを予測. */ if ( fabs ( auto_corr [ 0 ]) < FLT_EPSILON ) { for ( i_delay = 0 ; i_delay < max_order + 1 ; ++ i_delay ) { lpc_coef [ i_delay ] = 0.0f ; } return 0 ; } /* 初期化 */ a_vec = ( double * ) malloc ( sizeof ( double ) * ( max_order + 2 )); /* a_0, a_k+1を含めるとmax_order+2 */ e_vec = ( double * ) malloc ( sizeof ( double ) * ( max_order + 2 )); /* e_0, e_k+1を含めるとmax_order+2 */ u_vec = ( double * ) malloc ( sizeof ( double ) * ( max_order + 2 )); v_vec = ( double * ) malloc ( sizeof ( double ) * ( max_order + 2 )); for ( i_delay = 0 ; i_delay < max_order + 2 ; i_delay ++ ) { u_vec [ i_delay ] = v_vec [ i_delay ] = a_vec [ i_delay ] = 0.0f ; } /* 最初のステップの係数をセット */ a_vec [ 0 ] = 1.0f ; e_vec [ 0 ] = auto_corr [ 0 ]; a_vec [ 1 ] = - auto_corr [ 1 ] / auto_corr [ 0 ]; e_vec [ 1 ] = auto_corr [ 0 ] + auto_corr [ 1 ] * a_vec [ 1 ]; u_vec [ 0 ] = 1.0f ; u_vec [ 1 ] = 0.0f ; v_vec [ 0 ] = 0.0f ; v_vec [ 1 ] = 1.0f ; /* 再帰処理 */ for ( delay = 1 ; delay < max_order ; delay ++ ) { lambda = 0.0f ; for ( i_delay = 0 ; i_delay < delay + 1 ; i_delay ++ ) { lambda += a_vec [ i_delay ] * auto_corr [ delay + 1 - i_delay ]; } lambda /= ( - e_vec [ delay ]); e_vec [ delay + 1 ] = ( 1 - lambda * lambda ) * e_vec [ delay ]; /* u_vec, v_vecの更新 */ for ( i_delay = 0 ; i_delay < delay ; i_delay ++ ) { u_vec [ i_delay + 1 ] = v_vec [ delay - i_delay ] = a_vec [ i_delay + 1 ]; } u_vec [ 0 ] = 1.0f ; u_vec [ delay + 1 ] = 0.0f ; v_vec [ 0 ] = 0.0f ; v_vec [ delay + 1 ] = 1.0f ; /* resultの更新 */ for ( i_delay = 0 ; i_delay < delay + 2 ; i_delay ++ ) { a_vec [ i_delay ] = u_vec [ i_delay ] + lambda * v_vec [ i_delay ]; } } /* 結果の取得 */ memcpy ( lpc_coef , a_vec , sizeof ( double ) * ( max_order + 1 )); free ( u_vec ); free ( v_vec ); free ( a_vec ); free ( e_vec ); return 0 ; } static int calc_auto_correlation ( double * auto_corr , const double * data , const size_t num_sample , const size_t max_order ) { int i_sample , delay_time ; if ( max_order > num_sample ) { fprintf ( stderr , \"Max order(%zu) is larger than number of samples(%zu). \\n \" , max_order , num_sample ); return - 1 ; } if ( auto_corr == NULL || data == NULL ) { fprintf ( stderr , \"Data or result pointer point to NULL. \\n \" ); return - 2 ; } /* （標本）自己相関の計算 */ for ( delay_time = 0 ; delay_time < max_order ; delay_time ++ ) { auto_corr [ delay_time ] = 0.0f ; for ( i_sample = delay_time ; i_sample < num_sample ; i_sample ++ ) { auto_corr [ delay_time ] += data [ i_sample ] * data [ i_sample - delay_time ]; } } return 0 ; } 実験 実際に走らせた結果のグラフは以下。 原信号が簡単すぎたのか、係数は少なめでも十分に予測できている。しかし、適当な係数の数の取り方を決める手法がないと、実信号で使い物になりそうにない。とりあえず、自己相関を使いこなしたN. Wiener is GOD.（結言）","tags":"記事","url":"/lpclinear-predictive-coding-xian-xing-yu-ce-fu-hao-hua.html","loc":"/lpclinear-predictive-coding-xian-xing-yu-ce-fu-hao-hua.html"},{"title":"離散フーリエ変換（DFT）","text":"離散時間かつ離散周波数でのフーリエ変換を離散フーリエ変換という。 準備：時間領域で離散化すると、周波数領域では周期的になる 離散フーリエ変換・離散フーリエ逆変換 離散化の仮定 離散フーリエ変換の導出 準備：時間領域で離散化すると、周波数領域では周期的になる \\(f(t)\\) を離散化した信号を \\(g(t)\\) とおく。離散化には、サンプリング周期 \\(t_{s}\\) の周期的デルタ関数 \\(\\delta_{t_{s}}(t)\\) を用いて \\begin{equation*} g(t) = f(t) \\delta_{t_s}(t) = \\sum_{n=-\\infty}&#94;{\\infty} f(t) \\delta(t - nt_{s}) \\end{equation*} とする。デルタ関数 \\(\\delta(t)\\) は関数 \\(f(t)\\) に対して次が成り立つ（超）関数である： \\begin{equation*} \\int&#94;{\\infty}_{-\\infty} f(t) \\delta(t) dt = f(0) \\end{equation*} \\(t_{s}\\) の逆数はサンプリングレート（ \\(f_{s} = 1/t_{s}\\) ）そのものである。また、周期的デルタ関数の（複素）フーリエ級数は、 \\begin{equation*} \\begin{aligned} \\delta_{t_{s}}(t) &= \\sum_{n=-\\infty}&#94;{\\infty} c_{n} \\exp(j\\omega_{s}t)dt \\\\ c_{n} &= \\frac{1}{t_{s}} \\int&#94;{t_{s}/2}_{-t_{s}/2} \\delta_{t_{s}}(t) \\exp(-jn\\omega_{s}t)dt \\end{aligned} \\end{equation*} と表せる。ここで \\(\\omega_{s}=2\\pi/t_{s}\\) （サンプリング角周波数）である。 \\(c_{n}\\) の計算を考えると、積分範囲 \\([-t_{s}/2, t_{s}/2]\\) に唯一つのインパルスが存在する事に留意すれば、次の結果を得る： \\begin{equation*} c_{n} = \\frac{1}{t_{s}} \\int&#94;{t_{s}/2}_{-t_{s}/2} \\delta(t) \\exp(-jn\\omega_{s}t)dt = \\frac{1}{t_{s}}\\exp(0) = \\frac{1}{t_{s}} \\end{equation*} よって、周期的デルタ関数の複素フーリエ級数は、 \\begin{equation*} \\delta_{t_s}(t) = \\frac{1}{t_{s}} \\sum_{n=-\\infty}&#94;{\\infty} \\exp(j n \\omega_{s} t) = \\frac{1}{t_{s}} \\sum_{n=-\\infty}&#94;{\\infty} \\exp(j 2\\pi n t) \\end{equation*} であり、この結果を用いると、 \\(g(t)\\) のフーリエ変換 \\({\\cal F}[g(t)]\\) は、 \\begin{equation*} \\begin{split} {\\cal F}[g(t)] &= \\frac{1}{t_{s}} \\sum_{n=-\\infty}&#94;{\\infty} {\\cal F} \\left[ f(t) \\exp(j n \\omega_{s} t) \\right] \\\\ &= \\frac{1}{t_{s}} \\sum_{n=-\\infty}&#94;{\\infty} \\int_{-\\infty}&#94;{\\infty} f(t) \\exp[ -j (\\omega - n\\omega_{s}) t] dt \\\\ &= \\frac{1}{t_{s}} \\sum_{n=-\\infty}&#94;{\\infty} F(\\omega - n\\omega_{s}) \\end{split} \\end{equation*} ここで、 \\(F(\\omega)\\) は \\(f(t)\\) をフーリエ変換した結果を表している。この結果は、離散化した信号のフーリエ変換は周波数領域で 周期 \\(\\omega_{s}\\) で \\(F(\\omega)\\) を繰り返す 事を示している。 離散フーリエ変換・離散フーリエ逆変換 離散化の仮定 時間領域で離散化した信号 \\(f[n]\\) を次の様に定義する： \\begin{equation*} f[n] = f(nt_{s}) \\quad n = 0,...,N-1 \\end{equation*} ここで、 \\(N\\) はサンプリング個数である。重要な仮定として、 \\(f(t)\\) は \\(N\\) このサンプリング期間で周期的であるとする。即ち、 \\(f(t)\\) の周期を \\(T\\) とおくと、 \\begin{equation*} T = Nt_{s} \\end{equation*} が成立する。更に、 周波数領域についても \\(\\omega_{s}\\) を \\(N\\) 分割 し、 \\begin{equation*} \\omega_{k} = \\frac{\\omega_{s}}{N} k = \\frac{2\\pi}{Nt_{s}}k \\quad k = 0,...,N-1 \\end{equation*} として、周波数領域で離散化した信号 \\(F[k]\\) を次の様に定義する： \\begin{equation*} F[k] = F(\\omega_{k}) \\quad k = 0,...,N-1 \\end{equation*} 分割の個数 \\(N\\) が時間領域と周波数領域で異なる場合、変換対が対称にならないので高速フーリエ変換の時に不都合が生じる。 離散フーリエ変換の導出 離散化の仮定のもとで、フーリエ変換は次の様に計算できる： \\begin{equation*} F[k] = \\int_{-\\infty}&#94;{\\infty} f(t) \\exp(-j\\omega_{k}t) dt = \\int_{-\\infty}&#94;{\\infty} f(t) \\exp\\left(-j\\frac{2\\pi k}{Nt_{s}} t \\right) dt \\end{equation*} \\(f(t)\\) は周期 \\(T\\) で繰り返すので、積分範囲は1周期分とする（なぜ一周期か：フーリエ係数の仮定から。係数は1周期の積分で良い。三角関数の完全性を見よ）： \\begin{equation*} F[k] = \\int&#94;{T}_{0} f(t) \\exp \\left(-j \\frac{2\\pi k}{Nt_{s}} t \\right)dt \\end{equation*} \\(t = nt_{s}\\) と変数変換すると（ \\(n\\) を積分変数とする）、 \\begin{equation*} F[k] = t_{s}\\int&#94;{N}_{0} f(nt_{s}) \\exp \\left(-j \\frac{2\\pi k}{N} n\\right)dn \\end{equation*} この積分は、次の和で近似できる。 \\begin{equation*} F[k] \\approx t_{s}\\sum&#94;{N-1}_{n=0} f(nt_{s}) \\exp \\left(-j \\frac{2\\pi k}{N} n\\right) = t_{s} \\sum&#94;{N-1}_{n=0} f[n] \\exp \\left(-j \\frac{2\\pi nk}{N} \\right) \\end{equation*} この式が離散フーリエ変換の式となる。逆変換については、複素フーリエ級数 \\begin{equation*} \\left\\{ \\begin{array}{l} f(nt_{s}) = \\displaystyle \\sum_{k=-\\infty}&#94;{\\infty} c_{n} \\exp(j\\omega_{k}kn t) \\\\ c_{n} = \\displaystyle \\frac{1}{T} \\int&#94;{T}_{0} f(t) \\exp(-j n\\omega_{k} t) dt \\end{array} \\right. \\end{equation*} から、 \\(c_{n}\\) を消去すると、 \\begin{align*} f(nt_{s}) = \\sum_{k=-\\infty}&#94;{\\infty} \\left\\{ \\frac{1}{T} \\int&#94;{T}_{0} f(t) \\exp\\left( -j \\frac{2\\pi kt}{T} \\right) dt \\right\\} \\exp\\left( \\frac{j2\\pi k}{T} nt_{s} \\right) \\\\ f(nt_{s}) = \\frac{\\omega_{s}}{2 \\pi N} \\sum_{k=-\\infty}&#94;{\\infty} F[k] \\exp\\left(j \\frac{2\\pi nk}{N} \\right) \\end{align*} \\(F[k]\\) の周期は \\(\\omega_{s}\\) なので、1周期分は \\(k = 0,...,N-1\\) となる。再び1周期分のみを考えると、 \\begin{equation*} f[n] = \\frac{\\omega_{s}}{2 \\pi N} \\sum_{k=0}&#94;{N-1} F[k] \\exp\\left(j \\frac{2\\pi nk}{N} \\right) \\end{equation*} この式が離散フーリエ逆変換の式となる。変換の式をまとめると、 \\begin{equation*} \\left\\{ \\begin{array}{l} \\displaystyle F[k] = t_{s} \\sum&#94;{N-1}_{n=0} f[n] \\exp \\left(-j \\frac{2\\pi nk}{N} \\right) \\\\ \\displaystyle f[n] = \\frac{\\omega_{s}}{2 \\pi N} \\sum_{k=0}&#94;{N-1} F[k] \\exp\\left(j \\frac{2\\pi nk}{N} \\right) \\end{array} \\right. \\end{equation*} これがフーリエ変換対となり、一方に他方を代入するとちゃんと逆に戻る事が確認できる： \\begin{equation*} \\begin{split} f[n] &= \\frac{\\omega_{s}}{2\\pi N}\\sum_{k=0}&#94;{N-1}F[k]\\exp\\left(j\\frac{2\\pi nk}{N}\\right) \\\\ &= \\frac{2\\pi t_{s}}{2\\pi t_{s}N}\\sum_{k=0}&#94;{N-1}\\left\\{ \\sum&#94;{N-1}_{n&#94;\\prime=0} f[n&#94;\\prime] \\exp \\left(-j \\frac{2\\pi n&#94;\\prime k}{N} \\right) \\right\\} \\exp\\left(j\\frac{2\\pi nk}{N}\\right) \\\\ &= \\frac{1}{N} \\sum_{n&#94;{\\prime}=0}&#94;{N-1} f[n&#94;\\prime] \\sum_{k=0}&#94;{N-1} \\exp\\left[ -j (n-n&#94;\\prime) \\frac{2\\pi k}{N} \\right] \\end{split} \\end{equation*} \\(\\sum_{k=0}&#94;{N-1} \\exp\\left[ -j (n-n&#94;\\prime) \\frac{2\\pi k}{N} \\right]\\) の値ついては \\(k\\) の積分 \\begin{equation*} \\int&#94;{N}_{0} \\exp\\left[ -j (n-n&#94;\\prime) \\frac{2\\pi k}{N} \\right] dk \\end{equation*} と考えれば、 \\(n=n&#94;\\prime\\) の時は明らかに \\(N\\) であり、残りの \\(n \\neq n&#94;\\prime\\) の時は \\begin{equation*} \\begin{split} \\int&#94;{N}_{0} \\exp\\left[ -j (n-n&#94;\\prime) \\frac{2\\pi k}{N} \\right] dk &= - \\frac{1}{j(n-n&#94;\\prime)\\frac{2\\pi}{N}} \\left[ \\exp\\left[ -j(n-n&#94;\\prime)\\frac{2\\pi k}{N} \\right] \\right]_{0}&#94;{N} \\\\ &= - \\frac{1}{j(n-n&#94;\\prime)\\frac{2\\pi}{N}} \\left\\{ \\exp[-j2(n-n&#94;\\prime)\\pi] - \\exp(0)\\right\\} \\\\ &= 0 \\end{split} \\end{equation*} となるので、最終的に \\begin{equation*} \\frac{1}{N} \\sum_{n&#94;{\\prime}=0}&#94;{N-1} f[n&#94;\\prime] \\sum_{k=0}&#94;{N-1} \\exp\\left[ -j (n-n&#94;\\prime) \\frac{2\\pi k}{N} \\right] = \\frac{1}{N} f[n] N = f[n] \\end{equation*} を得る。 また \\(t_{s}=1\\) とおくと、 \\(\\omega_{s} = 2\\pi\\) となって、DFTのよく見る変換式が得られる： \\begin{equation*} \\left\\{ \\begin{array}{l} \\displaystyle F[k] = \\sum&#94;{N-1}_{n=0} f[n] \\exp \\left(-j \\frac{2\\pi nk}{N} \\right) \\\\ \\displaystyle f[n] = \\frac{1}{N} \\sum_{k=0}&#94;{N-1} F[k] \\exp\\left(j \\frac{2\\pi nk}{N} \\right) \\end{array} \\right. \\end{equation*} これらの式を実装するのは簡単である。じゃあ、実装しようか…（暗黒微笑） （デルタ関数から導く方法だと、どうしても正規化定数 \\(1/N\\) が出てこない。正規化定数は本質的では無いとかいうけど、計算上は無視できない。）","tags":"記事","url":"/li-san-huriebian-huan-dft.html","loc":"/li-san-huriebian-huan-dft.html"},{"title":"Signed-LMSの2階微分 その2","text":"\\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\end{equation*} 早速既存研究が無いか見ている。二乗誤差最小化のLMSでもヘッセ行列の逆行列の計算負荷が高いから使わん、という論調がほとんど。Signed-LMSについては今の所、微分してるところも見てない。 NEURAL NETWORK Widrow-Hoff Learning Adaline Hagan LMS 観測分散行列がヘッセ行列に一致することが書いてあった。 Stochastic error whitening algorithm for linear filter estimation with noisy data 評価関数として絶対値が入ったものを使っている。 The Least Mean Squares Algorithm 分かりやすめな解説。そうか、ウィーナーフィルタか。 行列 \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}}\\) が正則にならない件について、これ正則化すればいいんじゃねと思い立つ。要は \\(\\lambda\\) を正則化パラメータとして \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}} + \\lambda \\ve{I}\\) に対して逆行列を求めていく。 多分、係数側に正則項を追加することになるはず。 \\(\\min \\mathrm{E}[|\\varepsilon(n)|] + \\lambda ||\\ve{h}||_{2}\\) のような定式化か？ それでも逆行列 \\((\\ve{X}\\ve{X}&#94;{\\mathsf{T}} + \\lambda \\ve{I})&#94;{-1}\\) を求めるのは骨が折れそう。そこで、自然勾配学習で使っていた適応的自然勾配学習法（ Singularities Affect Dynamics of Learning in Neuromanifolds より）が使えそう。具体的には、次の式で自然勾配を適応的に求めていく。 \\begin{equation*} \\ve{G}_{t+1}&#94;{-1} = (1 + \\varepsilon_{t}) \\ve{G}_{t}&#94;{-1} - \\varepsilon_{t} \\ve{G}_{t}&#94;{-1} \\parfrac{J(\\ve{h})}{\\ve{h}} \\left( \\ve{G}_{t}&#94;{-1} \\parfrac{J(\\ve{h})}{\\ve{h}} \\right)&#94;{\\mathsf{T}} \\end{equation*} ここで \\(\\varepsilon_{t}\\) は小さな定数。『情報幾何の新展開』では、カルマンフィルタ由来らしい。うーん、もう試してみたいな。 （念の為） \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}} + \\lambda \\ve{I}\\) が正則行列になる理由 すぐに思い出せなくてヒヤッとしたのでここで示しておく。 \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}}\\) は対称行列だから、直交行列 \\(\\ve{P}\\) （ \\(\\ve{P}&#94;{-1} = \\ve{P}&#94;{\\mathsf{T}}\\) ）と固有値を並べた対角行列 \\(\\ve{\\Lambda}\\) を用いて、 \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}} = \\ve{P}&#94;{\\mathsf{T}} \\ve{\\Lambda} \\ve{P}\\) と対角化できる。よって、 \\(\\lambda > 0\\) なる定数を用いた時、 \\begin{align*} \\ve{X}\\ve{X}&#94;{\\mathsf{T}} + \\lambda \\ve{I} &= \\ve{P}&#94;{\\mathsf{T}} \\ve{\\Lambda} \\ve{P} + \\lambda \\ve{P}&#94;{\\mathsf{T}} \\ve{P} \\\\ &= \\ve{P}&#94;{\\mathsf{T}} \\ve{\\Lambda} \\ve{P} + \\ve{P}&#94;{\\mathsf{T}} \\lambda \\ve{I} \\ve{P} \\\\ &= \\ve{P}&#94;{\\mathsf{T}} (\\ve{\\Lambda} + \\lambda \\ve{I}) \\ve{P} \\end{align*} また、任意のベクトル \\(\\ve{v}\\) を使った時、 \\begin{align*} \\ve{v}&#94;{\\mathsf{T}} \\ve{X} \\ve{X}&#94;{\\mathsf{T}} \\ve{v} &= (\\ve{X}&#94;{\\mathsf{T}} \\ve{v})&#94;{\\mathsf{T}} \\ve{X}&#94;{\\mathsf{T}} \\ve{v} = ||\\ve{X}&#94;{\\mathsf{T}} \\ve{v} ||_{2}&#94;{2} \\\\ \\ve{v}&#94;{\\mathsf{T}} \\ve{X} \\ve{X}&#94;{\\mathsf{T}} \\ve{v} &= \\ve{v}&#94;{\\mathsf{T}} \\ve{P}&#94;{\\mathsf{T}} \\ve{\\Lambda} \\ve{P} \\ve{v} = \\sum_{i}&#94;{N} \\ve{\\Lambda}_{ii} (\\ve{Pv})_{i}&#94;{2} \\\\ \\Rightarrow ||\\ve{X}&#94;{\\mathsf{T}} \\ve{v} ||_{2}&#94;{2} &= \\sum_{i}&#94;{N} \\ve{\\Lambda}_{ii} (\\ve{Pv})_{i}&#94;{2} \\geq 0 \\end{align*} の関係式が成り立つ。最後の不等式が成り立つには、全ての \\(i\\) に対して \\(\\ve{\\Lambda}_{ii} \\geq 0\\) でなければならない。よって \\(\\ve{XX}&#94;{\\mathsf{T}}\\) の固有値は全て非負。 ここで \\(\\ve{P}&#94;{\\mathsf{T}} (\\ve{\\Lambda} + \\lambda \\ve{I}) \\ve{P}\\) に注目すると、全ての固有値に \\(\\lambda\\) が足されていることが分かる。 \\(\\lambda\\) は正だから、 \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}} + \\lambda \\ve{I}\\) の固有値は全て正になり正定値行列となる。正定値行列は正則だから、 \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}} + \\lambda \\ve{I}\\) は正則行列。 フィッシャー情報行列とヘッセ行列と分散行列の絡みについて 以下の記事が非常にわかりやすい。 Fisher Information Matrix Natural Gradient Descent 結論、ラプラス分布に従う残差を仮定した最尤推定において、観測分散行列はフィッシャー情報行列に一致し、その逆行列は自然勾配に該当するはず。つうかニュートン法の特殊ケースに見えるがどうなんでしょ。フィッシャー情報行列がヘッセ行列に見えるんだが、定義通り（対数尤度のヘッセ行列）そうだよな。指数族の最尤推定をニュートン法で解こうとしたら全部自然勾配学習法にならね？ TODO 評価のことを考えて行きたい。固定した信号（答えが分かっている信号。乱数固定。）を使ったときに、誤差平面と勾配はどうなっている？フィルタの次元は2ぐらいにして、フィルタを固定して各統計量がどうなっているかプロットする。まずは絶対値残差と勾配の観察が重要に思える（もちろん、2次の最小化ケースも重要）。 評価がまとまったら結果共有に入りたい。 OMPを使う。 メッセージパッシング使えない？ 何らかの確率モデル化をせよ、というふうに受け取った。 AMP, Survay-Propagation（三村さん、樺島さん）がありえる。 → AMP, Survay-Propagationについて調査すべし。 いろんな論文で自然勾配をどうやって定義しているか要観察。","tags":"雑記","url":"/signed-lmsno2jie-wei-fen-sono2.html","loc":"/signed-lmsno2jie-wei-fen-sono2.html"},{"title":"残差勾配 \\(\\mathrm{E}[\\varepsilon(n) x(n - m)]\\) の挙動観察/Signed-LMSの目的関数の2階微分","text":"残差勾配 \\(\\mathrm{E}[\\varepsilon(n) x(n - m)]\\) の挙動観察 \\(m\\) が大きいときは無視できるのでは？ なお、長時間平均値は0に収束していることを見た。 \\(m\\) をずらした時の平均値の様子を見る。どこかで影響が小さくなって打ち切れるはず。 ガチャガチャ弄ってるってるけど示唆があんまりない。 低次（〜10）の係数は大きく変動する傾向。しかし、次に述べるピッチなどに影響しているのか、全てに当てはまる傾向ではない。 \\(\\mathrm{E}[\\varepsilon(n) x(n - m)]\\) は \\(m\\) を大きくすれば単調減少するわけではない。音源依存で傾向が異なる。ピッチ？か何かに反応して大きくなる場合がある。 同一発音区間では、フィルタ係数の符号は同一になる傾向が見られる。単一のsin波を等価させたときはわかりやすい。 440.0Hzのsin波に対する各タップの平均勾配変化 ボイス対する各タップの平均勾配変化 ピアノ演奏に対する各タップの平均勾配変化 Signed-LMSの目的関数の2階微分 勇気を出してやってみる。 \\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\end{equation*} 符号関数を \\(\\tanh(Tx)\\) で近似して微分してみる（ \\(T\\) は温度パラメータで、 \\(\\tanh(Tx)\\) を \\(T \\to \\infty\\) ならしめれば符号関数に近づく）と、 \\begin{equation*} \\frac{d}{dx} \\tanh(Tx) = T (\\tanh(Tx))&#94;{\\prime} = T(1 - \\tanh&#94;{2}(Tx)) \\end{equation*} さて、 \\(1 - \\tanh&#94;{2}(Tx)\\) に注目すると、 \\(T\\) の極限では \\(x = 0\\) を除き0を取るが、 \\(x = 0\\) において1を取る。よってこれはインパルス関数になる（極限と微分操作を交換したけどやかましいことは暗黙で...）。 符号関数を微分するとインパルス関数が出てくることについては 超関数的微分_δ関数関連（２） を見るのが早いかも。以下では、その話に従って、 \\(\\frac{d}{dx} \\mathrm{sign}(x) = 2\\delta(x)\\) とする。 さて、今一度評価関数 \\(\\mathrm{E}[|\\varepsilon(n)|]\\) の偏微分と2階の偏導関数を考える。 \\begin{align*} \\parfrac{}{h(m)} \\mathrm{E}[|\\varepsilon(n)|] &= \\mathrm{E}\\left[ \\parfrac{}{h(m)} |\\varepsilon(n)| \\right] \\\\ &= \\mathrm{E}\\left[ \\left\\{ \\parfrac{}{h(m)} \\varepsilon(n) \\right\\} \\mathrm{sign}[\\varepsilon(n)] \\right] \\\\ &= -\\mathrm{E}\\left[ \\mathrm{sign}[\\varepsilon(n)] x(n - m) \\right] \\\\ \\frac{\\partial&#94;{2}}{\\partial h(m) \\partial h(k)} \\mathrm{E}[|\\varepsilon(n)|] &= - \\parfrac{}{h(k)} \\mathrm{E}\\left[ \\mathrm{sign}[\\varepsilon(n)] x(n - m) \\right] \\\\ &= - \\mathrm{E}\\left[ \\left\\{ \\parfrac{}{h(k)} \\varepsilon(n) \\right\\} 2\\delta(\\varepsilon(n)) x(n - m) \\right] \\\\ &= 2\\mathrm{E}\\left[ \\delta(\\varepsilon(n)) x(n - m) x(n - k) \\right] \\end{align*} ここで \\(\\mathrm{E}\\left[ \\delta(\\varepsilon(n)) x(n - m) x(n - k) \\right]\\) に注目する。これは \\(\\varepsilon(n) = 0\\) のときだけ和を取る演算だ。 \\(\\sum\\) を用いると、 \\begin{equation*} \\mathrm{E}\\left[ \\delta(\\varepsilon(n)) x(n - m) x(n - k) \\right] = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n = 1, \\varepsilon(n) = 0}&#94;{N} x(n - m) x(n - k) \\end{equation*} という計算に該当する。厳密計算は \\(\\varepsilon(n) = 0\\) なる \\(n\\) を見つけたら足していく感じでいいと思うけど、今は \\(\\varepsilon(n)\\) はラプラス分布に従うと仮定している。だからラプラス分布に従って \\(P(\\varepsilon(n) = 0) = \\frac{1}{2\\lambda}\\) （分散 \\(2\\lambda&#94;{2}\\) ）の重み付けをして計算してしまって良いように見えるのだがどうなんだろう。なんか怪しくて考え続けている。 もし適応フィルタに組み込むなら、残差が0になったら上の式に従ってヘッセ行列を更新し、ニュートン法を使い続ける。これは試してみたい。問題はヘッセ行列が逆行列を持つかというところ…4-20で半正定値であることは確認したが正定値とは限らない。共役勾配法を検討する必要があるかも。 \\(\\ve{X}\\ve{X}&#94;{\\mathsf{T}}\\) は正則になるとは思えない…。（軽く試したけどすぐにだめな例が見つかった。） 他の頂いたアイディア 周波数領域に一旦飛ばすのはあり？ ありだけど計算量が高い。圧縮率が上がるのであれば大アリ。 確率的PCAとか使えない？辞書は小さくて済む。 線形ダイナミクスにより上手く定式化できない？ 優先度低 出す学会については先生に聞くこと。 相談する機会はどこかで絶対に必要。 著作権処理済み音源データベースについて相談 → 自分で情報をまとめて、申し込んでいいかというところまで進めるべし。 RWC 研究用音楽データベース: 音楽ジャンルデータベースと楽器音データベース RWC研究用音楽データベース → 進めた。動けるようになったら書類をまとめていく。 Donohoさんなどが圧縮センシングの文脈で既にやりきってない？ ありえる。調査すべし。 → ライス大学では成果をすべて公開しているから見るだけ見たほうが良い。 → http://dsp.rice.edu/cs/ を見よ。 Compressed sensing block MAP-LMS adaptive filter for sparse channel estimation and a bayesian Cramer-Rao bound 残差はガウス分布としてるけどクラメル-ラオ下限との絡みを述べている。何か重要そう。 Bayesian Compressive Sensing Using Laplace Priors これもパラメータの事前分布にラプラス分布を導入してベイズ推定するもの。残差ではないはず。 「L1」, 「Laplace」, 「residual」, 「lossless」で検索したけどスパース解を求めるものばかり。今のところはセーフ？ → 継続して調査はする。","tags":"雑記","url":"/can-chai-gou-pei-mathrmevarepsilonn-xn-m-noju-dong-guan-cha-signed-lmsnomu-de-guan-shu-no2jie-wei-fen.html","loc":"/can-chai-gou-pei-mathrmevarepsilonn-xn-m-noju-dong-guan-cha-signed-lmsnomu-de-guan-shu-no2jie-wei-fen.html"},{"title":"IRLSの更新式について","text":"MathJaxの環境を確認しつつ使用中。プリアンブルが無いけどページ内で一回 newcommand を行えばずっと使えるみたい。便利。 \\begin{equation*} \\newcommand\\innerp[2]{\\langle #1, #2 \\rangle} \\newcommand\\ve[1]{\\boldsymbol{#1}} \\newcommand\\parfrac[2]{\\frac{\\partial #1}{\\partial #2}} \\end{equation*} 逐次的更新の件について。IRLSでは以下の評価関数 \\(J(\\ve{\\beta})\\) の最小化を考える。 \\begin{equation*} J(\\ve{\\beta}) = \\sum&#94;{M}_{i = 1} w_{i} (y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}})&#94;{2} \\end{equation*} ここで \\(M\\) は観測数。これは二次式だから評価関数は凸関数になる。早速 \\(\\ve{\\beta}\\) で偏微分してみると、 \\begin{align*} \\parfrac{}{\\ve{\\beta}} J(\\ve{\\beta}) &= \\sum&#94;{M}_{i = 1} w_{i} 2 \\left(- \\frac{\\partial}{\\partial \\ve{\\beta}} \\innerp{\\ve{\\beta}}{\\ve{x}_{i}} \\right) (y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}}) \\\\ &= -2 \\sum&#94;{M}_{i = 1} w_{i} (y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}}) \\ve{x}_{i} \\end{align*} \\(\\parfrac{}{\\ve{\\beta}} J(\\ve{\\beta}) = 0\\) とおくと、 \\begin{align*} \\sum_{i = 1}&#94;{M} w_{i} \\innerp{\\ve{\\beta}}{\\ve{x}_{i}} \\ve{x}_{i} &= \\sum_{i = 1}&#94;{M} w_{i} y_{i} \\ve{x}_{i} \\\\ \\iff \\left[ \\ve{x}_{1} ... \\ve{x}_{M} \\right] \\left[ \\begin{array}{c} w_{1} \\innerp{\\ve{\\beta}}{\\ve{x}_{1}} \\\\ \\vdots \\\\ w_{M} \\innerp{\\ve{\\beta}}{\\ve{x}_{M}} \\end{array} \\right] &= \\left[ \\ve{x}_{1} ... \\ve{x}_{M} \\right] \\left[ \\begin{array}{c} w_{1}y_{1} \\\\ \\vdots \\\\ w_{M}y_{M} \\end{array} \\right] \\\\ \\iff \\left[ \\ve{x}_{1} ... \\ve{x}_{M} \\right] \\left[ \\begin{array}{ccc} w_{1} & \\dots & 0 \\\\ \\vdots & \\ddots & \\vdots \\\\ 0 & \\dots & w_{M} \\end{array} \\right] \\left[ \\begin{array}{c} \\innerp{\\ve{\\beta}}{\\ve{x}_{1}} \\\\ \\vdots \\\\ \\innerp{\\ve{\\beta}}{\\ve{x}_{M}} \\end{array} \\right] &= \\left[ \\ve{x}_{1} ... \\ve{x}_{M} \\right] \\left[ \\begin{array}{ccc} w_{1} & \\dots & 0 \\\\ \\vdots & \\ddots & \\vdots \\\\ 0 & \\dots & w_{M} \\end{array} \\right] \\left[ \\begin{array}{c} y_{1} \\\\ \\vdots \\\\ y_{M} \\end{array} \\right] \\\\ \\iff \\left[ \\ve{x}_{1} ... \\ve{x}_{M} \\right] \\left[ \\begin{array}{ccc} w_{1} & \\dots & 0 \\\\ \\vdots & \\ddots & \\vdots \\\\ 0 & \\dots & w_{M} \\end{array} \\right] \\left[ \\begin{array}{c} \\ve{x}_{1}&#94;{\\mathsf{T}} \\\\ \\vdots \\\\ \\ve{x}_{M}&#94;{\\mathsf{T}} \\end{array} \\right] \\ve{\\beta} &= \\left[ \\ve{x}_{1} ... \\ve{x}_{M} \\right] \\left[ \\begin{array}{ccc} w_{1} & \\dots & 0 \\\\ \\vdots & \\ddots & \\vdots \\\\ 0 & \\dots & w_{M} \\end{array} \\right] \\ve{y} \\\\ \\iff \\ve{X} \\ve{W} \\ve{X}&#94;{\\mathsf{T}} \\ve{\\beta} &= \\ve{X} \\ve{W} \\ve{y} \\end{align*} \\(\\ve{X}\\ve{W}\\ve{X}&#94;{\\mathsf{T}}\\) が正則（TODO: \\(\\ve{X}\\) が行フルランク、かつ \\(\\ve{W}\\) が正則なら行けそうに見えるけど本当か？）の場合は閉形式で係数が求まる: \\begin{equation*} \\ve{\\beta} = (\\ve{X} \\ve{W} \\ve{X}&#94;{\\mathsf{T}})&#94;{-1} \\ve{X} \\ve{W} \\ve{y} \\end{equation*} ここまでは一般論。さて、更新式に注目する。 \\(\\beta_{j}\\) だけで偏微分してみると、 \\begin{align*} \\parfrac{J(\\ve{\\beta})}{\\beta_{j}} &= \\sum_{i = 1}&#94;{M} \\parfrac{}{\\beta_{j}} w_{i} (y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}})&#94;{2} \\\\ &= -2 \\sum_{i = 1}&#94;{M} w_{i} (\\ve{x}_{i})_{j} (y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}}) \\end{align*} 残差のL1ノルム最小化を考えるときは \\(w_{i} = \\frac{1}{|y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}}|}\\) とおくので代入すると、 \\begin{equation*} \\parfrac{J(\\ve{\\beta})}{\\beta_{j}} = -2 \\sum_{i = 1}&#94;{M} (\\ve{x}_{i})_{j} \\mathrm{sign}(y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}}) \\end{equation*} 瞬間値（ \\(M=1\\) とする）を考えるとSigned-LMSの更新式そのものになっている。 和を取ると平均操作に近いから、LMSアルゴリズムと考えていることは同じ。 \\(\\parfrac{J(\\ve{\\beta})}{\\beta_{j}}\\) を更に \\(\\beta_{k}\\) で偏微分してみると、 \\begin{align*} \\frac{\\partial&#94;{2} J(\\ve{\\beta})}{\\partial \\beta_{j} \\partial \\beta_{k}} &= -2 \\sum_{i = 1}&#94;{M} w_{i} (\\ve{x}_{i})_{j} \\parfrac{}{\\beta_{k}} (y_{i} - \\innerp{\\ve{\\beta}}{\\ve{x}_{i}}) \\\\ &= 2 \\sum_{i = 1}&#94;{M} w_{i} (\\ve{x}_{i})_{j} (\\ve{x}_{i})_{k} \\\\ &= 2 \\left[ (\\ve{x}_{1})_{j} \\dots (\\ve{x}_{M})_{j} \\right] \\left[ \\begin{array}{c} w_{1} (\\ve{x}_{1})_{k} \\\\ \\vdots \\\\ w_{M} (\\ve{x}_{M})_{k} \\end{array} \\right] = 2 \\left[ (\\ve{x}_{1})_{j} \\dots (\\ve{x}_{M})_{j} \\right] \\ve{W} \\left[ \\begin{array}{c} (\\ve{x}_{1})_{k} \\\\ \\vdots \\\\ (\\ve{x}_{M})_{k} \\end{array} \\right] \\end{align*} 2次式が出てくるのがわかる（ \\(\\ve{W}\\) は計量だ）。そして \\((\\ve{H})_{jk} = \\frac{\\partial&#94;{2} J(\\ve{\\beta})}{\\partial \\beta_{j} \\partial \\beta_{k}}\\) なるヘッセ行列 \\(\\ve{H}\\) は以下: \\begin{equation*} \\ve{H} = 2 \\ve{X} \\ve{W} \\ve{X}&#94;{\\mathsf{T}} \\end{equation*} ヘッセ行列の性質により関数の最小値・最大値の存在がわかる。対称行列なのは間違いない（ \\((\\ve{X})_{ij} = (\\ve{X})_{ji}\\) は自明）。（固有値分解とは見れない。 \\(\\ve{H}\\) は \\(N \\times N\\) の行列であるのに対して、 \\(\\ve{X}\\) は \\(N \\times M\\) の行列。 \\(\\ve{X} \\ve{X}&#94;{\\mathsf{T}}\\) は平均化、除算を抜いた分散共分散行列になり半正定値行列。）また、任意のベクトル \\(\\ve{v}\\) に対して、 \\begin{align*} \\ve{v}&#94;{\\mathsf{T}} \\ve{X} \\ve{W} \\ve{X}&#94;{\\mathsf{T}} \\ve{v} &= \\ve{v}&#94;{\\mathsf{T}} \\ve{X} \\ve{W}&#94;{1/2} \\ve{W}&#94;{1/2} \\ve{X}&#94;{\\mathsf{T}} \\ve{v} \\\\ &= (\\ve{W}&#94;{1/2} \\ve{X}&#94;{\\mathsf{T}} \\ve{v})&#94;{\\mathsf{T}} \\ve{W}&#94;{1/2} \\ve{X}&#94;{\\mathsf{T}} \\ve{v} \\\\ &= || \\ve{W}&#94;{1/2} \\ve{X}&#94;{\\mathsf{T}} \\ve{v} ||_{2}&#94;{2} \\geq 0 \\end{align*} だから、 \\(\\ve{W}\\) が半正定値（ \\(\\iff\\) すべての重みが非負）ならばヘッセ行列は半正定値行列で、極小値が最小値になる。また、 \\(J(\\ve{\\beta})\\) は凸関数（半正定値だから狭義の凸関数ではない）。 もう少しヘッセ行列を見る。ヘッセ行列を上手く使えたらニュートン法で解けそうな気がして。 \\begin{equation*} (\\ve{H})_{jk} = 2 \\sum_{i = 1}&#94;{M} w_{i} (\\ve{x}_{i})_{j} (\\ve{x}_{i})_{k} \\end{equation*} より、スペクトル分解的に見ると、 \\begin{align*} \\frac{1}{2} \\ve{H} &= w_{1} \\left[ \\begin{array}{ccc} (\\ve{x}_{1})_{1}&#94;{2} & \\dots & (\\ve{x}_{1})_{1} (\\ve{x}_{1})_{N} \\\\ \\vdots & \\ddots & \\vdots \\\\ (\\ve{x}_{1})_{N} (\\ve{x}_{1})_{1} & \\dots & (\\ve{x}_{1})_{N}&#94;{2} \\\\ \\end{array} \\right] + \\dots + w_{M} \\left[ \\begin{array}{ccc} (\\ve{x}_{M})_{1}&#94;{2} & \\dots & (\\ve{x}_{M})_{1} (\\ve{x}_{M})_{N} \\\\ \\vdots & \\ddots & \\vdots \\\\ (\\ve{x}_{M})_{N} (\\ve{x}_{M})_{1} & \\dots & (\\ve{x}_{M})_{N}&#94;{2} \\\\ \\end{array} \\right] \\\\ &= w_{1} \\ve{x}_{1} \\ve{x}_{1}&#94;{\\mathsf{T}} + \\dots + w_{M} \\ve{x}_{M} \\ve{x}_{M}&#94;{\\mathsf{T}} \\\\ &= \\sum_{i = 1}&#94;{M} w_{i} \\ve{x}_{i} \\ve{x}_{i}&#94;{\\mathsf{T}} \\end{align*} 信号処理的には \\(\\ve{x}_{1}, \\ve{x}_{2}, \\dots \\ve{x}_{M}\\) は系列で現れる。 LMSフィルタでは \\(i = 1\\) の時だけを考えていたと考えられれる。 \\(i = 2,\\dots,M\\) のときの影響は少ないのではないかと思う。 FIRフィルタを考えるのならば、各 \\(\\ve{x}_{1}\\) は入ってきた1次元信号データを時系列順に並べたものだから、直前のベクトル \\(\\ve{x}_{2}\\) を使えそうな構造に見える。 上の仮定を使ってヘッセ行列の逆行列 \\(\\ve{H}&#94;{-1}\\) を逐次近似計算できない？ 分散共分散行列がほぼヘッセ行列になってるけどこれは何？ 金谷さんの解説 にそれとなく解説がある。フィッシャー情報行列との関連もある。。。クラメル・ラオの下限についてわかりやすい説明あり。 最尤法 にもそれとなく解説あり。 奥村さん もあり。観測からヘッセ行列を構成できる？ そして自然勾配のアイディアが出てくる。自然勾配を使ったLMSアルゴリズムは…あった… Normalized Natural Gradient Adaptive Filtering for Sparse and Nonsparse Systems 甘利先生による解説 で、LMSアルゴリズム含めて大まかなところはだいたい言ってる。 高知工科大学の博論 ワンチャンスL1残差最小化はやってないかも。 TODO: 前のMTGで言われたことの整理 分散行列、ヘッセ行列、フィッシャー情報行列、自然勾配の整理 Fisher Information Matrix OMPが気になる。試してみたい。","tags":"雑記","url":"/irlsnogeng-xin-shi-nitsuite.html","loc":"/irlsnogeng-xin-shi-nitsuite.html"},{"title":"IRLS(Iteratively Reweighted Least Squares) その2","text":"理論ばっかり追っていて悶々してきたので、IRLSでL1残差最小化が解けないか実験してみる。 第5章 厳密解から近似解へ に『スパースモデリング』5章のPython実装あり。 スパースモデリング：第3章 追跡アルゴリズム は『スパースモデリング』3章のPython実装。 IRLSの実装は カレル大学卒論 を参考に。Pythonで簡単にできた。 import numpy # IRLS法によりPhi @ x = yのスパース解を求める def irls_update ( Phi , x , y , order ): EPSILON = 10 ** ( - 8.0 ) # 重みの計算 weight = numpy . abs ( y - Phi @ x ) . flatten () # 小さくなりすぎた重みは打ち切る weight [ weight < EPSILON ] = EPSILON # 対角行列に展開 W = numpy . diag ( weight ** ( order - 2 )) # 更新後の係数: Phi.T @ W @ Phi @ x = Phi.T @ W @ y の解 return numpy . linalg . solve ( Phi . T @ W @ Phi , Phi . T @ W @ y ) if __name__ == \"__main__\" : DIMENSION = 2 NUM_SAMPLES = 100 NUM_ITERATION = 50 # 解ベクトル X_ANSWER = numpy . array ([ 0.5 , 0.5 ]) . reshape (( DIMENSION , 1 )) x = numpy . zeros (( DIMENSION , 1 )) xhistory = numpy . zeros (( DIMENSION , NUM_ITERATION )) # 観測を生成 Phi = numpy . random . rand ( NUM_SAMPLES , DIMENSION ) y = Phi @ X_ANSWER # 加法的雑音を重畳 # yrand = y + numpy.random.normal(0, 0.3, (NUM_SAMPLES, 1)) yrand = y + numpy . random . laplace ( 0 , 0.3 , ( NUM_SAMPLES , 1 )) error = numpy . zeros ( NUM_ITERATION ) emp_error = numpy . zeros ( NUM_ITERATION ) # IRLSを繰り返し適用 for count in range ( NUM_ITERATION ): x = irls_update ( Phi , x , yrand , 1 ) xhistory [:, count ] = x . reshape ( 2 ) error [ count ] = numpy . linalg . norm ( y - Phi @ x , ord = 1 ) / NUM_SAMPLES emp_error [ count ] = numpy . linalg . norm ( yrand - Phi @ x , ord = 1 ) / NUM_SAMPLES 実装は楽だったけど、誤差解析が沼。 誤差を重畳してみると、真の誤差と経験誤差が当然一致しない。 経験誤差的には局所解に入っている印象。 サンプル数が少ないと大域最小解に入らないケースあり（経験誤差曲面の最小値が真の誤差の曲面の最小値に不一致） 経験誤差の曲面は二次曲線に見える。（2次式の最小化を考えているから当然のはず。） 最小二乗解よりも誤差が悪い時がある。最小二乗解はorder=2とすれば良くて、その時重み行列Wは単位行列になり、普通の最小二乗法と一致。 思いつき: IRLSは評価関数の最小化を考える時閉形式で求まるので何も考えない。パラメータに関してもう一度微分できるのでニュートン法使えそう。 フィルタのときのように逐次的に求められない？ パラメータ全てではなく1こずつ。サンプルについても1こずつ。更新していく。評価関数の最小化は平均値の最小化に見受けられるので、逐次的に更新しても良いように見える。 今日は遅いのでもう寝る。","tags":"雑記","url":"/irlsiteratively-reweighted-least-squares-sono2.html","loc":"/irlsiteratively-reweighted-least-squares-sono2.html"},{"title":"IRLS(Iteratively Reweighted Least Squares)","text":"LAD(Least Absolute Deviation)を近似的・逐次的に解く方法としてのIRLSについて調査。そういえば基本的な原理を抑えていなかった。 Iteratively Reweighted Least Squares についてサクッと。 文字通りサクッとしたまとめ。OMPを使って解いているというのがとても気になる Iterative Reweighted Least Squares 導入から解法まで。しかしなぜ解が求まるのかは不明。 Iterative Reweighted Least Squares バッファロー大の講義資料？これも何故解けるのかはちゃんと書いてない。 Iterative Reweighted Least Squares これが一番いいかも。なぜ解けるかもざっくり証明がある。 そこで出てきたsupergradient（優勾配？劣勾配に対応している？）がよくわからん。資料のすぐ下に解説があったけど。 Supergradients に定義はあったけど幾何学的イメージが欲しい。 Weiszfeld Algorithmsという幾何中央値を求めるアルゴリズムは Generalized Weiszfeld Algorithms for Lq Optimization に解説あり。しかしこの論文いいこと言ってる。「Generalized Weiszfeld Algorithms」は圧縮センシングとは異なりスパース表現を求めるわけではない。スパース性は担保されなくても、よりL1ノルムの意味で小さい解を求める。 なぜ、IRLSとLMSアルゴリズムを結びつける研究がないのか。IRLSの逐次適用によってもフィルタ係数を更新していけそうだけど。試してみるし、類似研究が無いか引き続き調べる。 『スパースモデリング』の5章にも記述はある。しかし残差のL1最小化ではない。","tags":"雑記","url":"/irlsiteratively-reweighted-least-squares.html","loc":"/irlsiteratively-reweighted-least-squares.html"},{"title":"LAD(Least Absolute Deviation)","text":"LAD(Least Absolute Deviation)を見ている。これは、残差をL1ノルムにした回帰問題一般のこと。 カレル大学卒論 が結構まとまっている。 最尤推定による近似的手法 は軽く読んだ。各傾きと切片を固定して逐次更新していく。更新時は中央値を拾ってくる。うーん中央値だと高速推定が厳しい。。。 ラプラス分布の最尤推定しようとしてもがく。対数尤度とって見てみても、単純な絶対値和が出て止まるし、反復スケーリング法を参考に、パラメータの増分を加えた時の対数尤度の下限を求めようとしたが上手く行かず。4時間飛ばす。 最尤推定の計算のあがき あがいて「A maximum likelihood approach to least absolute deviation regression」を引用している文献を漁ったら辞書学習をL1にしているやつが、やっぱりいた。 Online Robust Non-negative Dictionary Learning for Visual Tracking パーティクルフィルターを使っておる。 上の文献で使ってるHuber Loss結構すごくね？この誤差に基づくLMSアルゴリズムねえの？→「Robust Huber adaptive filter」だけど中身を読めず… また、 Convex Optimization and Modeling を読んでたらHuber損失はL1とL2の中間的な性質を示すようで、0に集中しなくなりそうな印象を受けた。","tags":"雑記","url":"/ladleast-absolute-deviation.html","loc":"/ladleast-absolute-deviation.html"},{"title":"LMSフィルターの挙動観察","text":"\\(\\mathrm{E}[\\mathrm{sign}[e(n)]x(n-m)]\\) の挙動を追いたい。色々な信号に対して、 \\(m\\) が十分大きいとき、0に近づくかどうか を知りたい。もし0に近づくならば有効な過程として解法に使える。 しかしその前に、LMSフィルター自体の挙動を追いたい。 残差はどの様に減る？残差の時系列は？ ステップサイズにより収束の度合い（残差の分布）が違う... 当然、フィルタ次数でも収束の度合い（残差の分布）が違う 残差分布はどうなってる？Signed-LMSでラプラス分布に近づいてる？ これは本当のようで、Signed-LMSの方が裾が細い残差分布が得られている。 単純な正弦波に対してはLMSのほうが残差が小さくなるが、ボイスやピアノ音源に対しては圧倒的にSignLMSの方が性能が良い（残差のヒストグラムを見ると、裾が狭い） \\(\\mathrm{E}[\\mathrm{sign}[e(n)]x(n-m)]\\) , \\(\\mathrm{E}[e(n)x(n-m)]\\) は両方とも0。 逐次計算していったら、音源非依存で0に近づいていく 当然だよな…そもそもの過程として入力と雑音は無相関と仮定しているのだから。 仮定しているのだからは正しくなくて、無相関にするようにフィルタ係数を更新しているが正しい。 無相関になったときに勾配が0で最急勾配法が止まる。 なんか絶対値誤差最小化ってどっかで見たよな…と思っていたら、 https://en.wikipedia.org/wiki/Least_absolute_deviations 修士のときに一回戦っていた。 カレル大学卒論 が結構まとまっている。 \\(L_{1}\\) ノルム最小化を近接オペレータの繰り返し適用で解けんじゃね？と思っている 近接勾配法とproximal operator を読んだが、パラメータ正則化だけだな パラメータ正則化はあるけど、残差をスパースにするのがない。なんで？","tags":"雑記","url":"/lmshuirutanoju-dong-guan-cha.html","loc":"/lmshuirutanoju-dong-guan-cha.html"},{"title":"続・古いロスレス音声コーデックの調査","text":"古いロスレス音声コーデックと理論の概要を取りまとめた雑誌の特集があった: Lossless Compression of Digital Audio 理論としてもその通りだし、雑誌発行時点(1998)からさしたるブレークスルーが無いように見える。 AudioPak, OggSquish, Philips, Sonarc, WAという謎のコーデック現る…。いったい何個あるんだ。","tags":"雑記","url":"/sok-gu-irosuresuyin-sheng-kodetsukunodiao-cha.html","loc":"/sok-gu-irosuresuyin-sheng-kodetsukunodiao-cha.html"},{"title":"古いロスレス音声コーデックの調査/スパース適応フィルタ","text":"ロスレス音声の歴史を探るために古いロスレス音声コーデックの情報を探っている。以下のサイトが Hydrogenaudioでの比較 よりも古い内容を扱っている。 Lossless Compression of Audio 見つけたロスレス音声コーデックを一覧する。というかほぼ Really Rare Wares 様へのリンク。 古めのロスレス音声コーデック RKAU(RK Audio) 古い比較において優秀な圧縮率を誇っていた。当時のMonkey's Audioよりも上。サイトを覗いたら exe と dll のみの配布だった。 RKAUのホームページ（魚拓） を見ても特に情報なし。 AudioZip これも圧縮率が比較的優秀。 AudioZipのホームページ（魚拓） を見てもこちらも特に情報なし。 WavArc こちらも最大圧縮率(-c5)を選択するとそれなりに優秀な結果を出していた。このページにexeとドキュメントをまとめたzipもあり。 WaveZip 圧縮率よりは速度重視のコーデックのようだ。MUSICompress というアルゴリズムの実装。 WaveZipのデータシート によると符号化にはLZ(Lampel-Ziv)を使用しているようだ。 WaveZipの概要 が比較サイトに掲載されていた。どうやら、入力波形を近似波形と誤差波形に分けて符号化するようだ。WaveZipではHu LPAC/LTAC LPACはMPEG4-ALSの前身。LPACの前身がLTAC。LPACの平均的な圧縮率は優秀なようだ。 LPAC（魚拓） に以前公開していたサイトあり。 LTAC(Lossless Transform Audio Compression)は名前の通り変換符号化に基づくロスレス音声圧縮コーデック、LPAC(Lossless Predictive Audio Compression)は予測に基づくロスレス音声圧縮コーデック。 LPACに ベルリン工科大学、Real Networks、NTT の改良が加わってMPEG4-ALSが出来上がり、それ以降LPACの開発は停止されている。この経緯については MPEG4-ALS（魚拓） に記述あり。 Shorten（魚拓） おそらくロスレス音声の最古参にして基礎。なんと執筆時点（2020-04-08）でも brew でインストールできた（ Shortenのmanページ もあるから各Linuxディストリビューションで使えるものと想像する）。エンコード速度はピカイチ。 Shortenの論文 （テクニカルレポート）もある。この論文で、今のロスレス音声につながる重要な事実に幾つか触れている。 音声信号は準定常（短い区間では定常とみなせる）だからブロックに分けてエンコード/デコードすべき。 音声のモデル化には線形予測(LPC, Linear Predictive Coding)が使える。 残差信号はガウス分布よりもラプラス分布に従っていると見える。その符号化にはライス符号を使うのが良い。 この時点で既にラプラス分布を仮定したパラメータ設定を行っているからかなりの慧眼。他のロスレス音声コーデックはShortenを発展させたものに過ぎないと見える。 所感 どうも2000年代前半までは各自でロスレス音声コーデックを作り、各自で最強を謳っていたらしい。 歴史を雑にまとめると、1994年にShortenの論文が出てから、それよりも圧縮率の良いもの、圧縮速度（展開速度）が早いものが開発されて混沌に突入し上記のコーデックが現れた。その後、Monkey's Audio, WavPack, FLAC, LPAC（MPEG4-ALS）が生き残り、2000年以降はLa（更新停止）, TAK, TTA, ALAC（更新停止）, WMAL(Windows Media Audio Lossless), 2010年以降はOptimFROGが出現しているようだ。 気になるのは比較サイトの Rice Coding, AKA Rice Packing, Elias Gamma codes and other approaches である。Rice符号よりも効率の良いとされるPod符号の紹介がある。要観察。 スパース適応フィルタ LPCの定式化をスパースにする試みは多くなされている。 Sparse Modeling for Lossless Audio Compression : Ghidoさん（OptimFROGの人）の試み 貪欲法によりスパース解を求めている。 スパース表現に基づく音声音響符号化 : NTTの試み 最小二乗解を求めるのではなくL1最小化に置き換えた定式化を行う。 でも、TTAがやっているような適応フィルタをスパース解に近づける手法はまだロスレス音声に対してやっていないように見える。 スパースな解を目指してフィルタ係数を更新する適応フィルタはスパース適応フィルタ(Sparse Adaptive Filters)というようで、2000年代以降に研究が進んでいるようだ。 最も基本的な適応フィルタであるLMS(Least Mean Square)フィルタは名前の通り二乗誤差最小化に立脚している。 スパース適応フィルタの主な用途はエコーキャンセル、ブラインド話者分離、複数話者特定ではあるが、やはり変換後の分布がスパースになるというのは大きい。 スパース適応フィルタの最近のサーベイ論文 を流し読みした。スパース適応フィルタは、変数更新のときに1部の変数だけ更新する方法と、スパース最適化に従って更新するやり方の2つがあった。PNLMS(Proportionate NLMS), IPNLMS(Improved PNLMS)が後者の定式化で興味あり。引き続き見ていく。 Regularized Least-Mean-Square Algorithms には正則化を入れたLMSアルゴリズムの解説あり。LASSOにモチベーションを受けた最適化アルゴリズムが ZA-LMS や APWL1 として提案されている。","tags":"雑記","url":"/gu-irosuresuyin-sheng-kodetsukunodiao-cha-supasushi-ying-huiruta.html","loc":"/gu-irosuresuyin-sheng-kodetsukunodiao-cha-supasushi-ying-huiruta.html"},{"title":"ブログ導入","text":"GitHub io + Pelican を使ってみた。しばらくこちらで日報を書きたい。 GitHub io + Pelicanは以下の記事を参考にしている。まだあんまり分かってない。 Python製静的HTMLジェネレータのPelicanでGitHub Pagesを公開する方法 GitHub Pagesで静的サイトを簡単に作る Python製 Pelican を使ってサクッとブログを公開する Pelicanのテーマ集 テーマ導入時にハマったので参考にしたissue comment 今日は（というか3月末）からSLAの高速化作業とまとめをしていた。 格子型フィルタ演算はどうしても1乗算型にできず。次数演算を4次数にしてSSE演算するのがやっと。 SSE化するときに、スカラー演算とベクトル演算が混じったときに処理負荷が大きく上がってハマった。 StackOverFlowの記事 では _mm_set_epi32 のコストが高い旨記述あり。 _mm_loadu_si128 の使用に置き換えた。 他の記事 で言及があってようやく分かった。全てをベクトル演算化したところ、処理負荷は4/5倍になった。あんまり早くなっていない。遺憾。 gccとVC にはgccとVisual Studioの挙動の差異について色々と書いてあった。","tags":"雑記","url":"/burogudao-ru.html","loc":"/burogudao-ru.html"}]};